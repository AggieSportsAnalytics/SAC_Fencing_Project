{"id":"node_modules/openai/resources/audio/speech.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/audio/speech.js.map","includedInParent":true,"mtime":1705364963617},{"name":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/src/resources/audio/speech.ts","includedInParent":true,"mtime":1705364966990},{"name":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1705364973798},{"name":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/package.json","includedInParent":true,"mtime":1705364962840},{"name":"openai/resource","loc":{"line":5,"column":27,"index":183},"parent":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/audio/speech.js","resolved":"/Users/vpenumarti/Desktop/CS/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resource.js"}],"generated":{"js":"\"use strict\";\n// File generated from our OpenAPI spec by Stainless.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Speech = void 0;\nconst resource_1 = require(\"openai/resource\");\nclass Speech extends resource_1.APIResource {\n    /**\n     * Generates audio from the input text.\n     */\n    create(body, options) {\n        return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\n    }\n}\nexports.Speech = Speech;\n(function (Speech) {\n})(Speech = exports.Speech || (exports.Speech = {}));\n"},"sourceMaps":{"js":{"version":3,"file":"speech.js","sourceRoot":"","sources":["../../src/resources/audio/speech.ts"],"names":[],"mappings":";AAAA,qDAAqD;;;AAGrD,8CAA8C;AAI9C,MAAa,MAAO,SAAQ,sBAAW;IACrC;;OAEG;IACH,MAAM,CAAC,IAAwB,EAAE,OAA6B;QAC5D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,eAAe,EAAE,EAAE,IAAI,EAAE,GAAG,OAAO,EAAE,gBAAgB,EAAE,IAAI,EAAE,CAAC,CAAC;IAC1F,CAAC;CACF;AAPD,wBAOC;AAkCD,WAAiB,MAAM;AAEvB,CAAC,EAFgB,MAAM,GAAN,cAAM,KAAN,cAAM,QAEtB","sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from \"../../core\";\nimport { APIResource } from \"../../resource\";\nimport { type Response } from \"../../_shims/index\";\nimport * as SpeechAPI from \"./speech\";\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   */\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\n  }\n}\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models/tts):\n   * `tts-1` or `tts-1-hd`\n   */\n  model: (string & {}) | 'tts-1' | 'tts-1-hd';\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`,\n   * `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are\n   * available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech/voice-options).\n   */\n  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, and `flac`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n}\n\nexport namespace Speech {\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\n}\n"]}},"error":null,"hash":"1945f4f8fa7970a3258dc3b6db8a0670","cacheData":{"env":{}}}