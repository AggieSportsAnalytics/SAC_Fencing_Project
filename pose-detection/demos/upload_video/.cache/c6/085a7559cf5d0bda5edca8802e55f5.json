{"id":"node_modules/openai/resources/audio/translations.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/audio/translations.js.map","includedInParent":true,"mtime":1705657321526},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/src/resources/audio/translations.ts","includedInParent":true,"mtime":1705657321526},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1705897977865},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/package.json","includedInParent":true,"mtime":1705657321526},{"name":"openai/resource","loc":{"line":5,"column":27,"index":189},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/audio/translations.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resource.js"},{"name":"openai/core","loc":{"line":6,"column":23,"index":232},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/audio/translations.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/core.js"}],"generated":{"js":"\"use strict\";\n// File generated from our OpenAPI spec by Stainless.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Translations = void 0;\nconst resource_1 = require(\"openai/resource\");\nconst core_1 = require(\"openai/core\");\nclass Translations extends resource_1.APIResource {\n    /**\n     * Translates audio into English.\n     */\n    create(body, options) {\n        return this._client.post('/audio/translations', (0, core_1.multipartFormRequestOptions)({ body, ...options }));\n    }\n}\nexports.Translations = Translations;\n(function (Translations) {\n})(Translations = exports.Translations || (exports.Translations = {}));\n"},"sourceMaps":{"js":{"version":3,"file":"translations.js","sourceRoot":"","sources":["../../src/resources/audio/translations.ts"],"names":[],"mappings":";AAAA,qDAAqD;;;AAGrD,8CAA8C;AAE9C,sCAA2E;AAE3E,MAAa,YAAa,SAAQ,sBAAW;IAC3C;;OAEG;IACH,MAAM,CAAC,IAA6B,EAAE,OAA6B;QACjE,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,qBAAqB,EAAE,IAAA,kCAA2B,EAAC,EAAE,IAAI,EAAE,GAAG,OAAO,EAAE,CAAC,CAAC,CAAC;IACrG,CAAC;CACF;AAPD,oCAOC;AA0CD,WAAiB,YAAY;AAG7B,CAAC,EAHgB,YAAY,GAAZ,oBAAY,KAAZ,oBAAY,QAG5B","sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from \"../../core\";\nimport { APIResource } from \"../../resource\";\nimport * as TranslationsAPI from \"./translations\";\nimport { type Uploadable, multipartFormRequestOptions } from \"../../core\";\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   */\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation> {\n    return this._client.post('/audio/translations', multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationCreateParams {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` is currently available.\n   */\n  model: (string & {}) | 'whisper-1';\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the transcript output, in one of these options: `json`, `text`,\n   * `srt`, `verbose_json`, or `vtt`.\n   */\n  response_format?: string;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport namespace Translations {\n  export import Translation = TranslationsAPI.Translation;\n  export import TranslationCreateParams = TranslationsAPI.TranslationCreateParams;\n}\n"]}},"error":null,"hash":"e452c83b8c72b663b6750ba61c1cfdbf","cacheData":{"env":{}}}