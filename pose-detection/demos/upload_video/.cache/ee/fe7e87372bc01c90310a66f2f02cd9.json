{"id":"node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js.map","includedInParent":true,"mtime":1701727604738},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1708744722972},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"../../constants","loc":{"line":56,"column":26,"index":3343},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/constants.js"},{"name":"../ops/get_points_confidence","loc":{"line":57,"column":38,"index":3401},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/ops/get_points_confidence.js"},{"name":"./decode_single_pose_util","loc":{"line":58,"column":40,"index":3474},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose_util.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.decodeSinglePoseGPU = exports.decodeSinglePose = void 0;\nvar constants_1 = require(\"../../constants\");\nvar get_points_confidence_1 = require(\"../ops/get_points_confidence\");\nvar decode_single_pose_util_1 = require(\"./decode_single_pose_util\");\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors. It returns a single pose detection. It works as follows:\n * argmax2d is done on the scores to get the y and x index in the heatmap\n * with the highest score for each part, which is essentially where the\n * part is most likely to exist. This produces a tensor of size 17x2, with\n * each row being the y and x index in the heatmap for each keypoint.\n * The offset vector for each part is retrieved by getting the\n * y and x from the offsets corresponding to the y and x index in the\n * heatmap for that part. This produces a tensor of size 17x2, with each\n * row being the offset vector for the corresponding keypoint.\n * To get the keypoint, each partâ€™s heatmap y and x are multiplied\n * by the output stride then added to their corresponding offset vector,\n * which is in the same scale as the original image.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @return A promise that resolves with single pose with a confidence score,\n * which contains an array of keypoints indexed by part id, each with a score\n * and position.\n */\nfunction decodeSinglePose(heatmapScores, offsets, outputStride) {\n    return __awaiter(this, void 0, void 0, function () {\n        var totalScore, heatmapValues, allTensorBuffers, scoresBuffer, offsetsBuffer, heatmapValuesBuffer, offsetPoints, offsetPointsBuffer, keypointConfidence, keypoints;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    totalScore = 0.0;\n                    heatmapValues = (0, decode_single_pose_util_1.argmax2d)(heatmapScores);\n                    return [4 /*yield*/, Promise.all([heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()])];\n                case 1:\n                    allTensorBuffers = _a.sent();\n                    scoresBuffer = allTensorBuffers[0];\n                    offsetsBuffer = allTensorBuffers[1];\n                    heatmapValuesBuffer = allTensorBuffers[2];\n                    offsetPoints = (0, decode_single_pose_util_1.getOffsetPoints)(heatmapValuesBuffer, outputStride, offsetsBuffer);\n                    return [4 /*yield*/, offsetPoints.buffer()];\n                case 2:\n                    offsetPointsBuffer = _a.sent();\n                    keypointConfidence = Array.from((0, decode_single_pose_util_1.getPointsConfidence)(scoresBuffer, heatmapValuesBuffer));\n                    keypoints = keypointConfidence.map(function (score, keypointId) {\n                        totalScore += score;\n                        return {\n                            y: offsetPointsBuffer.get(keypointId, 0),\n                            x: offsetPointsBuffer.get(keypointId, 1),\n                            score: score,\n                            name: constants_1.COCO_KEYPOINTS[keypointId]\n                        };\n                    });\n                    heatmapValues.dispose();\n                    offsetPoints.dispose();\n                    return [2 /*return*/, { keypoints: keypoints, score: totalScore / keypoints.length }];\n            }\n        });\n    });\n}\nexports.decodeSinglePose = decodeSinglePose;\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors with GPU.\n */\nfunction decodeSinglePoseGPU(heatmapScores, offsets, outputStride) {\n    return __awaiter(this, void 0, void 0, function () {\n        var heatmapValues, offsetPoints, keypointConfidence;\n        return __generator(this, function (_a) {\n            heatmapValues = (0, decode_single_pose_util_1.argmax2d)(heatmapScores);\n            offsetPoints = (0, decode_single_pose_util_1.getOffsetPointsGPU)(heatmapValues, outputStride, offsets);\n            keypointConfidence = (0, get_points_confidence_1.getPointsConfidenceGPU)(heatmapScores, heatmapValues);\n            return [2 /*return*/, [offsetPoints, keypointConfidence]];\n        });\n    });\n}\nexports.decodeSinglePoseGPU = decodeSinglePoseGPU;\n"},"sourceMaps":{"js":{"version":3,"file":"decode_single_pose.js","sourceRoot":"","sources":["../../../src/posenet/calculators/decode_single_pose.ts"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;;GAeG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAIH,6CAA+C;AAG/C,sEAAoE;AAGpE,qEAA6G;AAE7G;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA8BG;AACH,SAAsB,gBAAgB,CAClC,aAA0B,EAAE,OAAoB,EAChD,YAAiC;;;;;;oBAC/B,UAAU,GAAG,GAAG,CAAC;oBAEf,aAAa,GAAG,IAAA,kCAAQ,EAAC,aAAa,CAAC,CAAC;oBAErB,qBAAM,OAAO,CAAC,GAAG,CACtC,CAAC,aAAa,CAAC,MAAM,EAAE,EAAE,OAAO,CAAC,MAAM,EAAE,EAAE,aAAa,CAAC,MAAM,EAAE,CAAC,CAAC,EAAA;;oBADjE,gBAAgB,GAAG,SAC8C;oBAEjE,YAAY,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBACnC,aAAa,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBACpC,mBAAmB,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;oBAE1C,YAAY,GACd,IAAA,yCAAe,EAAC,mBAAmB,EAAE,YAAY,EAAE,aAAa,CAAC,CAAC;oBAC3C,qBAAM,YAAY,CAAC,MAAM,EAAE,EAAA;;oBAAhD,kBAAkB,GAAG,SAA2B;oBAEhD,kBAAkB,GACpB,KAAK,CAAC,IAAI,CAAC,IAAA,6CAAmB,EAAC,YAAY,EAAE,mBAAmB,CAAC,CAAC,CAAC;oBAEjE,SAAS,GAAG,kBAAkB,CAAC,GAAG,CAAC,UAAC,KAAK,EAAE,UAAU;wBACzD,UAAU,IAAI,KAAK,CAAC;wBACpB,OAAO;4BACL,CAAC,EAAE,kBAAkB,CAAC,GAAG,CAAC,UAAU,EAAE,CAAC,CAAC;4BACxC,CAAC,EAAE,kBAAkB,CAAC,GAAG,CAAC,UAAU,EAAE,CAAC,CAAC;4BACxC,KAAK,OAAA;4BACL,IAAI,EAAE,0BAAc,CAAC,UAAU,CAAC;yBACjC,CAAC;oBACJ,CAAC,CAAC,CAAC;oBACH,aAAa,CAAC,OAAO,EAAE,CAAC;oBACxB,YAAY,CAAC,OAAO,EAAE,CAAC;oBAEvB,sBAAO,EAAC,SAAS,WAAA,EAAE,KAAK,EAAE,UAAU,GAAG,SAAS,CAAC,MAAM,EAAC,EAAC;;;;CAC1D;AAlCD,4CAkCC;AAED;;;GAGG;AACH,SAAsB,mBAAmB,CACrC,aAA0B,EAAE,OAAoB,EAChD,YAAiC;;;;YAC7B,aAAa,GAAG,IAAA,kCAAQ,EAAC,aAAa,CAAC,CAAC;YACxC,YAAY,GAAG,IAAA,4CAAkB,EAAC,aAAa,EAAE,YAAY,EAAE,OAAO,CAAC,CAAC;YAExE,kBAAkB,GACpB,IAAA,8CAAsB,EAAC,aAAa,EAAE,aAA0B,CAAC,CAAC;YACtE,sBAAO,CAAC,YAAY,EAAE,kBAAkB,CAAC,EAAC;;;CAC3C;AATD,kDASC","sourcesContent":[null]}},"error":null,"hash":"0de7baa01b1513996d3e7a83cdbeef02","cacheData":{"env":{}}}