{"id":"node_modules/@tensorflow-models/pose-detection/movenet/detector.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js.map","includedInParent":true,"mtime":1701727604736},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1705897977865},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"@tensorflow/tfjs-converter","loc":{"line":56,"column":18,"index":3294},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow/tfjs-converter/dist/index.js"},{"name":"@tensorflow/tfjs-core","loc":{"line":57,"column":17,"index":3342},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../calculators/bounding_box_tracker","loc":{"line":58,"column":37,"index":3405},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/calculators/bounding_box_tracker.js"},{"name":"../calculators/keypoint_tracker","loc":{"line":59,"column":33,"index":3478},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/calculators/keypoint_tracker.js"},{"name":"../calculators/types","loc":{"line":60,"column":22,"index":3536},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/calculators/types.js"},{"name":"../constants","loc":{"line":61,"column":26,"index":3587},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/constants.js"},{"name":"../shared/calculators/constants","loc":{"line":62,"column":26,"index":3630},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/constants.js"},{"name":"../shared/calculators/image_utils","loc":{"line":63,"column":28,"index":3694},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/image_utils.js"},{"name":"../shared/calculators/is_video","loc":{"line":64,"column":25,"index":3757},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/is_video.js"},{"name":"../shared/filters/keypoints_one_euro_filter","loc":{"line":65,"column":42,"index":3834},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/filters/keypoints_one_euro_filter.js"},{"name":"../shared/filters/low_pass_filter","loc":{"line":66,"column":32,"index":3914},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/filters/low_pass_filter.js"},{"name":"../types","loc":{"line":67,"column":22,"index":3974},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/types.js"},{"name":"../util","loc":{"line":68,"column":21,"index":4008},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/util.js"},{"name":"./constants","loc":{"line":69,"column":26,"index":4046},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/constants.js"},{"name":"./crop_utils","loc":{"line":70,"column":27,"index":4089},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/crop_utils.js"},{"name":"./detector_utils","loc":{"line":71,"column":31,"index":4137},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/movenet/detector_utils.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.load = void 0;\nvar tfc = require(\"@tensorflow/tfjs-converter\");\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar bounding_box_tracker_1 = require(\"../calculators/bounding_box_tracker\");\nvar keypoint_tracker_1 = require(\"../calculators/keypoint_tracker\");\nvar types_1 = require(\"../calculators/types\");\nvar constants_1 = require(\"../constants\");\nvar constants_2 = require(\"../shared/calculators/constants\");\nvar image_utils_1 = require(\"../shared/calculators/image_utils\");\nvar is_video_1 = require(\"../shared/calculators/is_video\");\nvar keypoints_one_euro_filter_1 = require(\"../shared/filters/keypoints_one_euro_filter\");\nvar low_pass_filter_1 = require(\"../shared/filters/low_pass_filter\");\nvar types_2 = require(\"../types\");\nvar util_1 = require(\"../util\");\nvar constants_3 = require(\"./constants\");\nvar crop_utils_1 = require(\"./crop_utils\");\nvar detector_utils_1 = require(\"./detector_utils\");\n/**\n * MoveNet detector class.\n */\nvar MoveNetDetector = /** @class */ (function () {\n    function MoveNetDetector(moveNetModel, config) {\n        this.moveNetModel = moveNetModel;\n        this.modelInputResolution = { height: 0, width: 0 };\n        this.keypointIndexByName = (0, util_1.getKeypointIndexByName)(types_2.SupportedModels.MoveNet);\n        // Only single-pose models have a fixed input resolution.\n        if (config.modelType === constants_3.SINGLEPOSE_LIGHTNING) {\n            this.modelInputResolution.width = constants_3.MOVENET_SINGLEPOSE_LIGHTNING_RESOLUTION;\n            this.modelInputResolution.height =\n                constants_3.MOVENET_SINGLEPOSE_LIGHTNING_RESOLUTION;\n        }\n        else if (config.modelType === constants_3.SINGLEPOSE_THUNDER) {\n            this.modelInputResolution.width = constants_3.MOVENET_SINGLEPOSE_THUNDER_RESOLUTION;\n            this.modelInputResolution.height = constants_3.MOVENET_SINGLEPOSE_THUNDER_RESOLUTION;\n        }\n        this.multiPoseModel = config.modelType === constants_3.MULTIPOSE_LIGHTNING;\n        if (!this.multiPoseModel) {\n            this.keypointFilter = new keypoints_one_euro_filter_1.KeypointsOneEuroFilter(constants_3.KEYPOINT_FILTER_CONFIG);\n            this.cropRegionFilterYMin = new low_pass_filter_1.LowPassFilter(constants_3.CROP_FILTER_ALPHA);\n            this.cropRegionFilterXMin = new low_pass_filter_1.LowPassFilter(constants_3.CROP_FILTER_ALPHA);\n            this.cropRegionFilterYMax = new low_pass_filter_1.LowPassFilter(constants_3.CROP_FILTER_ALPHA);\n            this.cropRegionFilterXMax = new low_pass_filter_1.LowPassFilter(constants_3.CROP_FILTER_ALPHA);\n        }\n        this.enableSmoothing = config.enableSmoothing;\n        if (config.minPoseScore) {\n            this.minPoseScore = config.minPoseScore;\n        }\n        else {\n            this.minPoseScore = constants_3.DEFAULT_MIN_POSE_SCORE;\n        }\n        if (config.multiPoseMaxDimension) {\n            this.multiPoseMaxDimension = config.multiPoseMaxDimension;\n        }\n        else {\n            this.multiPoseMaxDimension = constants_3.MOVENET_MULTIPOSE_DEFAULT_MAX_DIMENSION;\n        }\n        this.enableTracking = config.enableTracking;\n        if (this.multiPoseModel && this.enableTracking) {\n            if (config.trackerType === types_1.TrackerType.Keypoint) {\n                this.tracker = new keypoint_tracker_1.KeypointTracker(config.trackerConfig);\n            }\n            else if (config.trackerType === types_1.TrackerType.BoundingBox) {\n                this.tracker = new bounding_box_tracker_1.BoundingBoxTracker(config.trackerConfig);\n            }\n            if (this.enableSmoothing) {\n                this.keypointFilterMap = new Map();\n            }\n        }\n    }\n    /**\n     * Runs inference on an image using a model that is assumed to be a single\n     * person keypoint model that outputs 17 keypoints.\n     *\n     * @param inputImage 4D tensor containing the input image. Should be of size\n     * [1, modelHeight, modelWidth, 3].\n     * @return A `Pose`.\n     */\n    MoveNetDetector.prototype.runSinglePersonPoseModel = function (inputImage) {\n        return __awaiter(this, void 0, void 0, function () {\n            var outputTensor, inferenceResult, pose, numValidKeypoints, i;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        outputTensor = this.moveNetModel.execute(inputImage);\n                        // We expect an output tensor of shape [1, 1, 17, 3] (batch, person,\n                        // keypoint, (y, x, score)).\n                        if (outputTensor.shape.length !== 4 || outputTensor.shape[0] !== 1 ||\n                            outputTensor.shape[1] !== 1 ||\n                            outputTensor.shape[2] !== constants_3.NUM_KEYPOINTS ||\n                            outputTensor.shape[3] !== constants_3.NUM_KEYPOINT_VALUES) {\n                            outputTensor.dispose();\n                            throw new Error(\"Unexpected output shape from model: [\".concat(outputTensor.shape, \"]\"));\n                        }\n                        if (!(tf.getBackend() !== 'webgpu')) return [3 /*break*/, 1];\n                        inferenceResult = outputTensor.dataSync();\n                        return [3 /*break*/, 3];\n                    case 1: return [4 /*yield*/, outputTensor.data()];\n                    case 2:\n                        inferenceResult = _a.sent();\n                        _a.label = 3;\n                    case 3:\n                        outputTensor.dispose();\n                        pose = { keypoints: [], score: 0.0 };\n                        numValidKeypoints = 0;\n                        for (i = 0; i < constants_3.NUM_KEYPOINTS; ++i) {\n                            pose.keypoints[i] = {\n                                y: inferenceResult[i * constants_3.NUM_KEYPOINT_VALUES],\n                                x: inferenceResult[i * constants_3.NUM_KEYPOINT_VALUES + 1],\n                                score: inferenceResult[i * constants_3.NUM_KEYPOINT_VALUES + 2]\n                            };\n                            if (pose.keypoints[i].score > constants_3.MIN_CROP_KEYPOINT_SCORE) {\n                                ++numValidKeypoints;\n                                pose.score += pose.keypoints[i].score;\n                            }\n                        }\n                        if (numValidKeypoints > 0) {\n                            pose.score /= numValidKeypoints;\n                        }\n                        return [2 /*return*/, pose];\n                }\n            });\n        });\n    };\n    /**\n     * Runs inference on an image using a model that is assumed to be a\n     * multi-person keypoint model that outputs 17 keypoints and a box for a\n     * multiple persons.\n     *\n     * @param inputImage 4D tensor containing the input image. Should be of size\n     * [1, width, height, 3], where width and height are divisible by 32.\n     * @return An array of `Pose`s.\n     */\n    MoveNetDetector.prototype.runMultiPersonPoseModel = function (inputImage) {\n        return __awaiter(this, void 0, void 0, function () {\n            var outputTensor, inferenceResult, poses, numInstances, i, boxIndex, scoreIndex, j;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        outputTensor = this.moveNetModel.execute(inputImage);\n                        // Multi-pose model output is a [1, n, 56] tensor ([batch, num_instances,\n                        // instance_keypoints_and_box]).\n                        if (outputTensor.shape.length !== 3 || outputTensor.shape[0] !== 1 ||\n                            outputTensor.shape[2] !== constants_3.MULTIPOSE_INSTANCE_SIZE) {\n                            outputTensor.dispose();\n                            throw new Error(\"Unexpected output shape from model: [\".concat(outputTensor.shape, \"]\"));\n                        }\n                        if (!(tf.getBackend() !== 'webgpu')) return [3 /*break*/, 1];\n                        inferenceResult = outputTensor.dataSync();\n                        return [3 /*break*/, 3];\n                    case 1: return [4 /*yield*/, outputTensor.data()];\n                    case 2:\n                        inferenceResult = _a.sent();\n                        _a.label = 3;\n                    case 3:\n                        outputTensor.dispose();\n                        poses = [];\n                        numInstances = inferenceResult.length / constants_3.MULTIPOSE_INSTANCE_SIZE;\n                        for (i = 0; i < numInstances; ++i) {\n                            poses[i] = { keypoints: [] };\n                            boxIndex = i * constants_3.MULTIPOSE_INSTANCE_SIZE + constants_3.MULTIPOSE_BOX_IDX;\n                            poses[i].box = {\n                                yMin: inferenceResult[boxIndex],\n                                xMin: inferenceResult[boxIndex + 1],\n                                yMax: inferenceResult[boxIndex + 2],\n                                xMax: inferenceResult[boxIndex + 3],\n                                width: inferenceResult[boxIndex + 3] - inferenceResult[boxIndex + 1],\n                                height: inferenceResult[boxIndex + 2] - inferenceResult[boxIndex]\n                            };\n                            scoreIndex = i * constants_3.MULTIPOSE_INSTANCE_SIZE + constants_3.MULTIPOSE_BOX_SCORE_IDX;\n                            poses[i].score = inferenceResult[scoreIndex];\n                            poses[i].keypoints = [];\n                            for (j = 0; j < constants_3.NUM_KEYPOINTS; ++j) {\n                                poses[i].keypoints[j] = {\n                                    y: inferenceResult[i * constants_3.MULTIPOSE_INSTANCE_SIZE + j * constants_3.NUM_KEYPOINT_VALUES],\n                                    x: inferenceResult[i * constants_3.MULTIPOSE_INSTANCE_SIZE + j * constants_3.NUM_KEYPOINT_VALUES + 1],\n                                    score: inferenceResult[i * constants_3.MULTIPOSE_INSTANCE_SIZE + j * constants_3.NUM_KEYPOINT_VALUES + 2]\n                                };\n                            }\n                        }\n                        return [2 /*return*/, poses];\n                }\n            });\n        });\n    };\n    /**\n     * Estimates poses for an image or video frame. This does standard ImageNet\n     * pre-processing before inferring through the model. The image pixels should\n     * have values [0-255]. It returns an array of poses.\n     *\n     * @param image ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement\n     * The input image to feed through the network.\n     * @param config Optional. Currently not used.\n     * @param timestamp Optional. In milliseconds. This is useful when image is\n     * a tensor, which doesn't have timestamp info. Or to override timestamp in a\n     * video.\n     * @return An array of `Pose`s.\n     */\n    MoveNetDetector.prototype.estimatePoses = function (image, estimationConfig, timestamp) {\n        if (estimationConfig === void 0) { estimationConfig = constants_3.MOVENET_ESTIMATION_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var imageTensor3D, imageSize, imageTensor4D, poses, poseIdx, keypointIdx;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        estimationConfig = (0, detector_utils_1.validateEstimationConfig)(estimationConfig);\n                        if (image == null) {\n                            this.reset();\n                            return [2 /*return*/, []];\n                        }\n                        if (timestamp == null) {\n                            if ((0, is_video_1.isVideo)(image)) {\n                                timestamp = image.currentTime * constants_2.SECOND_TO_MICRO_SECONDS;\n                            }\n                        }\n                        else {\n                            timestamp = timestamp * constants_2.MILLISECOND_TO_MICRO_SECONDS;\n                        }\n                        imageTensor3D = (0, image_utils_1.toImageTensor)(image);\n                        imageSize = (0, image_utils_1.getImageSize)(imageTensor3D);\n                        imageTensor4D = tf.expandDims(imageTensor3D, 0);\n                        // Make sure we don't dispose the input image if it's already a tensor.\n                        if (!(image instanceof tf.Tensor)) {\n                            imageTensor3D.dispose();\n                        }\n                        poses = [];\n                        if (!!this.multiPoseModel) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.estimateSinglePose(imageTensor4D, imageSize, timestamp)];\n                    case 1:\n                        poses =\n                            _a.sent();\n                        return [3 /*break*/, 4];\n                    case 2: return [4 /*yield*/, this.estimateMultiplePoses(imageTensor4D, imageSize, timestamp)];\n                    case 3:\n                        poses =\n                            _a.sent();\n                        _a.label = 4;\n                    case 4:\n                        // Convert keypoint coordinates from normalized coordinates to image space\n                        // and add keypoint names.\n                        for (poseIdx = 0; poseIdx < poses.length; ++poseIdx) {\n                            for (keypointIdx = 0; keypointIdx < poses[poseIdx].keypoints.length; ++keypointIdx) {\n                                poses[poseIdx].keypoints[keypointIdx].name =\n                                    constants_1.COCO_KEYPOINTS[keypointIdx];\n                                poses[poseIdx].keypoints[keypointIdx].y *= imageSize.height;\n                                poses[poseIdx].keypoints[keypointIdx].x *= imageSize.width;\n                            }\n                        }\n                        return [2 /*return*/, poses];\n                }\n            });\n        });\n    };\n    /**\n     * Runs a single-person keypoint model on an image, including the image\n     * cropping and keypoint filtering logic.\n     *\n     * @param imageTensor4D A tf.Tensor4D that contains the input image.\n     * @param imageSize: The width and height of the input image.\n     * @param timestamp Image timestamp in microseconds.\n     * @return An array of `Pose`s.\n     */\n    MoveNetDetector.prototype.estimateSinglePose = function (imageTensor4D, imageSize, timestamp) {\n        return __awaiter(this, void 0, void 0, function () {\n            var croppedImage, pose, i, nextCropRegion;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!this.cropRegion) {\n                            this.cropRegion = (0, crop_utils_1.initCropRegion)(this.cropRegion == null, imageSize);\n                        }\n                        croppedImage = tf.tidy(function () {\n                            // Crop region is a [batch, 4] size tensor.\n                            var cropRegionTensor = tf.tensor2d([[\n                                    _this.cropRegion.yMin, _this.cropRegion.xMin, _this.cropRegion.yMax,\n                                    _this.cropRegion.xMax\n                                ]]);\n                            // The batch index that the crop should operate on. A [batch] size\n                            // tensor.\n                            var boxInd = tf.zeros([1], 'int32');\n                            // Target size of each crop.\n                            var cropSize = [_this.modelInputResolution.height, _this.modelInputResolution.width];\n                            return tf.cast(tf.image.cropAndResize(imageTensor4D, cropRegionTensor, boxInd, cropSize, 'bilinear', 0), 'int32');\n                        });\n                        imageTensor4D.dispose();\n                        return [4 /*yield*/, this.runSinglePersonPoseModel(croppedImage)];\n                    case 1:\n                        pose = _a.sent();\n                        croppedImage.dispose();\n                        if (pose.score < this.minPoseScore) {\n                            this.reset();\n                            return [2 /*return*/, []];\n                        }\n                        // Convert keypoints from crop coordinates to image coordinates.\n                        for (i = 0; i < pose.keypoints.length; ++i) {\n                            pose.keypoints[i].y =\n                                this.cropRegion.yMin + pose.keypoints[i].y * this.cropRegion.height;\n                            pose.keypoints[i].x =\n                                this.cropRegion.xMin + pose.keypoints[i].x * this.cropRegion.width;\n                        }\n                        // Apply the sequential filter before estimating the cropping area to make\n                        // it more stable.\n                        if (timestamp != null && this.enableSmoothing) {\n                            pose.keypoints = this.keypointFilter.apply(pose.keypoints, timestamp, 1 /* objectScale */);\n                        }\n                        nextCropRegion = (0, crop_utils_1.determineNextCropRegion)(this.cropRegion, pose.keypoints, this.keypointIndexByName, imageSize);\n                        this.cropRegion = this.filterCropRegion(nextCropRegion);\n                        return [2 /*return*/, [pose]];\n                }\n            });\n        });\n    };\n    /**\n     * Runs a multi-person keypoint model on an image, including image\n     * preprocessing.\n     *\n     * @param imageTensor4D A tf.Tensor4D that contains the input image.\n     * @param imageSize: The width and height of the input image.\n     * @param timestamp Image timestamp in microseconds.\n     * @return An array of `Pose`s.\n     */\n    MoveNetDetector.prototype.estimateMultiplePoses = function (imageTensor4D, imageSize, timestamp) {\n        return __awaiter(this, void 0, void 0, function () {\n            var resizedImage, resizedWidth, resizedHeight, paddedImage, paddedWidth, paddedHeight, dimensionDivisor, paddedImageInt32, poses, i, j, i, trackIDs_1;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        dimensionDivisor = 32;\n                        if (imageSize.width > imageSize.height) {\n                            resizedWidth = this.multiPoseMaxDimension;\n                            resizedHeight = Math.round(this.multiPoseMaxDimension * imageSize.height / imageSize.width);\n                            resizedImage =\n                                tf.image.resizeBilinear(imageTensor4D, [resizedHeight, resizedWidth]);\n                            paddedWidth = resizedWidth;\n                            paddedHeight =\n                                Math.ceil(resizedHeight / dimensionDivisor) * dimensionDivisor;\n                            paddedImage = tf.pad(resizedImage, [[0, 0], [0, paddedHeight - resizedHeight], [0, 0], [0, 0]]);\n                        }\n                        else {\n                            resizedWidth = Math.round(this.multiPoseMaxDimension * imageSize.width / imageSize.height);\n                            resizedHeight = this.multiPoseMaxDimension;\n                            resizedImage =\n                                tf.image.resizeBilinear(imageTensor4D, [resizedHeight, resizedWidth]);\n                            paddedWidth =\n                                Math.ceil(resizedWidth / dimensionDivisor) * dimensionDivisor;\n                            paddedHeight = resizedHeight;\n                            paddedImage = tf.pad(resizedImage, [[0, 0], [0, 0], [0, paddedWidth - resizedWidth], [0, 0]]);\n                        }\n                        resizedImage.dispose();\n                        imageTensor4D.dispose();\n                        paddedImageInt32 = tf.cast(paddedImage, 'int32');\n                        paddedImage.dispose();\n                        return [4 /*yield*/, this.runMultiPersonPoseModel(paddedImageInt32)];\n                    case 1:\n                        poses = _a.sent();\n                        paddedImageInt32.dispose();\n                        poses = poses.filter(function (pose) { return pose.score >= _this.minPoseScore; });\n                        // Convert keypoints from padded coordinates to normalized coordinates.\n                        for (i = 0; i < poses.length; ++i) {\n                            for (j = 0; j < poses[i].keypoints.length; ++j) {\n                                poses[i].keypoints[j].y *= paddedHeight / resizedHeight;\n                                poses[i].keypoints[j].x *= paddedWidth / resizedWidth;\n                            }\n                        }\n                        if (this.enableTracking) {\n                            this.tracker.apply(poses, timestamp);\n                            if (this.enableSmoothing) {\n                                for (i = 0; i < poses.length; ++i) {\n                                    if (!this.keypointFilterMap.has(poses[i].id)) {\n                                        this.keypointFilterMap.set(poses[i].id, new keypoints_one_euro_filter_1.KeypointsOneEuroFilter(constants_3.KEYPOINT_FILTER_CONFIG));\n                                    }\n                                    poses[i].keypoints =\n                                        this.keypointFilterMap.get(poses[i].id)\n                                            .apply(poses[i].keypoints, timestamp, 1 /* objectScale */);\n                                }\n                                trackIDs_1 = this.tracker.getTrackIDs();\n                                this.keypointFilterMap.forEach(function (_, trackID) {\n                                    if (!trackIDs_1.has(trackID)) {\n                                        _this.keypointFilterMap.delete(trackID);\n                                    }\n                                });\n                            }\n                        }\n                        return [2 /*return*/, poses];\n                }\n            });\n        });\n    };\n    MoveNetDetector.prototype.filterCropRegion = function (newCropRegion) {\n        if (!newCropRegion) {\n            this.cropRegionFilterYMin.reset();\n            this.cropRegionFilterXMin.reset();\n            this.cropRegionFilterYMax.reset();\n            this.cropRegionFilterXMax.reset();\n            return null;\n        }\n        else {\n            var filteredYMin = this.cropRegionFilterYMin.apply(newCropRegion.yMin);\n            var filteredXMin = this.cropRegionFilterXMin.apply(newCropRegion.xMin);\n            var filteredYMax = this.cropRegionFilterYMax.apply(newCropRegion.yMax);\n            var filteredXMax = this.cropRegionFilterXMax.apply(newCropRegion.xMax);\n            return {\n                yMin: filteredYMin,\n                xMin: filteredXMin,\n                yMax: filteredYMax,\n                xMax: filteredXMax,\n                height: filteredYMax - filteredYMin,\n                width: filteredXMax - filteredXMin\n            };\n        }\n    };\n    MoveNetDetector.prototype.dispose = function () {\n        this.moveNetModel.dispose();\n    };\n    MoveNetDetector.prototype.reset = function () {\n        this.cropRegion = null;\n        this.resetFilters();\n    };\n    MoveNetDetector.prototype.resetFilters = function () {\n        this.keypointFilter.reset();\n        this.cropRegionFilterYMin.reset();\n        this.cropRegionFilterXMin.reset();\n        this.cropRegionFilterYMax.reset();\n        this.cropRegionFilterXMax.reset();\n    };\n    return MoveNetDetector;\n}());\n/**\n * Loads the MoveNet model instance from a checkpoint. The model to be loaded\n * is configurable using the config dictionary `ModelConfig`. Please find more\n * details in the documentation of the `ModelConfig`.\n *\n * @param config `ModelConfig` dictionary that contains parameters for\n * the MoveNet loading process. Please find more details of each parameter\n * in the documentation of the `ModelConfig` interface.\n */\nfunction load(modelConfig) {\n    if (modelConfig === void 0) { modelConfig = constants_3.MOVENET_CONFIG; }\n    return __awaiter(this, void 0, void 0, function () {\n        var config, model, fromTFHub, modelUrl;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    config = (0, detector_utils_1.validateModelConfig)(modelConfig);\n                    fromTFHub = true;\n                    if (!!!config.modelUrl) return [3 /*break*/, 2];\n                    fromTFHub = typeof config.modelUrl === 'string' &&\n                        config.modelUrl.indexOf('https://tfhub.dev') > -1;\n                    return [4 /*yield*/, tfc.loadGraphModel(config.modelUrl, { fromTFHub: fromTFHub })];\n                case 1:\n                    model = _a.sent();\n                    return [3 /*break*/, 4];\n                case 2:\n                    modelUrl = void 0;\n                    if (config.modelType === constants_3.SINGLEPOSE_LIGHTNING) {\n                        modelUrl = constants_3.MOVENET_SINGLEPOSE_LIGHTNING_URL;\n                    }\n                    else if (config.modelType === constants_3.SINGLEPOSE_THUNDER) {\n                        modelUrl = constants_3.MOVENET_SINGLEPOSE_THUNDER_URL;\n                    }\n                    else if (config.modelType === constants_3.MULTIPOSE_LIGHTNING) {\n                        modelUrl = constants_3.MOVENET_MULTIPOSE_LIGHTNING_URL;\n                    }\n                    return [4 /*yield*/, tfc.loadGraphModel(modelUrl, { fromTFHub: fromTFHub })];\n                case 3:\n                    model = _a.sent();\n                    _a.label = 4;\n                case 4:\n                    if (tf.getBackend() === 'webgl') {\n                        // MoveNet has a top-k op that runs faster on GPU for the size of our last\n                        // dimension (6400). There are three checks that could make the top-k op run\n                        // on CPU (see\n                        // https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-webgl/src/kernels/TopK.ts)\n                        //\n                        // 1. All input shapes < 128\n                        // 2. lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD\n                        // 3. k > TOPK_K_CPU_HANDOFF_THRESHOLD\n                        //\n                        // In our case, setting TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = 0 will\n                        // will disable the CPU forwarding.\n                        tf.env().set('TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD', 0);\n                    }\n                    return [2 /*return*/, new MoveNetDetector(model, config)];\n            }\n        });\n    });\n}\nexports.load = load;\n"},"sourceMaps":{"js":{"version":3,"file":"detector.js","sourceRoot":"","sources":["../../src/movenet/detector.ts"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;;GAeG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH,gDAAkD;AAClD,0CAA4C;AAE5C,4EAAuE;AACvE,oEAAgE;AAEhE,8CAAiD;AACjD,0CAA4C;AAE5C,6DAAsG;AACtG,iEAA8E;AAG9E,2DAAuD;AACvD,yFAAmF;AACnF,qEAAgE;AAChE,kCAAmF;AACnF,gCAA+C;AAE/C,yCAAsiB;AACtiB,2CAAqE;AACrE,mDAA+E;AAG/E;;GAEG;AACH;IAwBE,yBACqB,YAA4B,EAC7C,MAA0B;QADT,iBAAY,GAAZ,YAAY,CAAgB;QAxBhC,yBAAoB,GACf,EAAC,MAAM,EAAE,CAAC,EAAE,KAAK,EAAE,CAAC,EAAC,CAAC;QAC3B,wBAAmB,GAChC,IAAA,6BAAsB,EAAC,uBAAe,CAAC,OAAO,CAAC,CAAC;QAuBlD,yDAAyD;QACzD,IAAI,MAAM,CAAC,SAAS,KAAK,gCAAoB,EAAE;YAC7C,IAAI,CAAC,oBAAoB,CAAC,KAAK,GAAG,mDAAuC,CAAC;YAC1E,IAAI,CAAC,oBAAoB,CAAC,MAAM;gBAC5B,mDAAuC,CAAC;SAC7C;aAAM,IAAI,MAAM,CAAC,SAAS,KAAK,8BAAkB,EAAE;YAClD,IAAI,CAAC,oBAAoB,CAAC,KAAK,GAAG,iDAAqC,CAAC;YACxE,IAAI,CAAC,oBAAoB,CAAC,MAAM,GAAG,iDAAqC,CAAC;SAC1E;QACD,IAAI,CAAC,cAAc,GAAG,MAAM,CAAC,SAAS,KAAK,+BAAmB,CAAC;QAC/D,IAAI,CAAC,IAAI,CAAC,cAAc,EAAE;YACxB,IAAI,CAAC,cAAc,GAAG,IAAI,kDAAsB,CAAC,kCAAsB,CAAC,CAAC;YACzE,IAAI,CAAC,oBAAoB,GAAG,IAAI,+BAAa,CAAC,6BAAiB,CAAC,CAAC;YACjE,IAAI,CAAC,oBAAoB,GAAG,IAAI,+BAAa,CAAC,6BAAiB,CAAC,CAAC;YACjE,IAAI,CAAC,oBAAoB,GAAG,IAAI,+BAAa,CAAC,6BAAiB,CAAC,CAAC;YACjE,IAAI,CAAC,oBAAoB,GAAG,IAAI,+BAAa,CAAC,6BAAiB,CAAC,CAAC;SAClE;QACD,IAAI,CAAC,eAAe,GAAG,MAAM,CAAC,eAAe,CAAC;QAC9C,IAAI,MAAM,CAAC,YAAY,EAAE;YACvB,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC,YAAY,CAAC;SACzC;aAAM;YACL,IAAI,CAAC,YAAY,GAAG,kCAAsB,CAAC;SAC5C;QACD,IAAI,MAAM,CAAC,qBAAqB,EAAE;YAChC,IAAI,CAAC,qBAAqB,GAAG,MAAM,CAAC,qBAAqB,CAAC;SAC3D;aAAM;YACL,IAAI,CAAC,qBAAqB,GAAG,mDAAuC,CAAC;SACtE;QACD,IAAI,CAAC,cAAc,GAAG,MAAM,CAAC,cAAc,CAAC;QAC5C,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,EAAE;YAC9C,IAAI,MAAM,CAAC,WAAW,KAAK,mBAAW,CAAC,QAAQ,EAAE;gBAC/C,IAAI,CAAC,OAAO,GAAG,IAAI,kCAAe,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;aAC1D;iBAAM,IAAI,MAAM,CAAC,WAAW,KAAK,mBAAW,CAAC,WAAW,EAAE;gBACzD,IAAI,CAAC,OAAO,GAAG,IAAI,yCAAkB,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;aAC7D;YACD,IAAI,IAAI,CAAC,eAAe,EAAE;gBACxB,IAAI,CAAC,iBAAiB,GAAG,IAAI,GAAG,EAAE,CAAC;aACpC;SACF;IACH,CAAC;IAED;;;;;;;OAOG;IACG,kDAAwB,GAA9B,UAA+B,UAAuB;;;;;;wBAC9C,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,UAAU,CAAc,CAAC;wBAExE,oEAAoE;wBACpE,4BAA4B;wBAC5B,IAAI,YAAY,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;4BAC9D,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;4BAC3B,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,yBAAa;4BACvC,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,+BAAmB,EAAE;4BACjD,YAAY,CAAC,OAAO,EAAE,CAAC;4BACvB,MAAM,IAAI,KAAK,CACX,+CAAwC,YAAY,CAAC,KAAK,MAAG,CAAC,CAAC;yBACpE;6BAMG,CAAA,EAAE,CAAC,UAAU,EAAE,KAAK,QAAQ,CAAA,EAA5B,wBAA4B;wBAC9B,eAAe,GAAG,YAAY,CAAC,QAAQ,EAAE,CAAC;;4BAExB,qBAAM,YAAY,CAAC,IAAI,EAAE,EAAA;;wBAA3C,eAAe,GAAG,SAAyB,CAAC;;;wBAE9C,YAAY,CAAC,OAAO,EAAE,CAAC;wBAEjB,IAAI,GAAS,EAAC,SAAS,EAAE,EAAE,EAAE,KAAK,EAAE,GAAG,EAAC,CAAC;wBAC3C,iBAAiB,GAAG,CAAC,CAAC;wBAC1B,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,yBAAa,EAAE,EAAE,CAAC,EAAE;4BACtC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG;gCAClB,CAAC,EAAE,eAAe,CAAC,CAAC,GAAG,+BAAmB,CAAC;gCAC3C,CAAC,EAAE,eAAe,CAAC,CAAC,GAAG,+BAAmB,GAAG,CAAC,CAAC;gCAC/C,KAAK,EAAE,eAAe,CAAC,CAAC,GAAG,+BAAmB,GAAG,CAAC,CAAC;6BACpD,CAAC;4BACF,IAAI,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,GAAG,mCAAuB,EAAE;gCACrD,EAAE,iBAAiB,CAAC;gCACpB,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;6BACvC;yBACF;wBAED,IAAI,iBAAiB,GAAG,CAAC,EAAE;4BACzB,IAAI,CAAC,KAAK,IAAI,iBAAiB,CAAC;yBACjC;wBAED,sBAAO,IAAI,EAAC;;;;KACb;IAED;;;;;;;;OAQG;IACG,iDAAuB,GAA7B,UAA8B,UAAuB;;;;;;wBAC7C,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,UAAU,CAAc,CAAC;wBAExE,yEAAyE;wBACzE,gCAAgC;wBAChC,IAAI,YAAY,CAAC,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;4BAC9D,YAAY,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,mCAAuB,EAAE;4BACrD,YAAY,CAAC,OAAO,EAAE,CAAC;4BACvB,MAAM,IAAI,KAAK,CACX,+CAAwC,YAAY,CAAC,KAAK,MAAG,CAAC,CAAC;yBACpE;6BAMG,CAAA,EAAE,CAAC,UAAU,EAAE,KAAK,QAAQ,CAAA,EAA5B,wBAA4B;wBAC9B,eAAe,GAAG,YAAY,CAAC,QAAQ,EAAE,CAAC;;4BAExB,qBAAM,YAAY,CAAC,IAAI,EAAE,EAAA;;wBAA3C,eAAe,GAAG,SAAyB,CAAC;;;wBAE9C,YAAY,CAAC,OAAO,EAAE,CAAC;wBAEjB,KAAK,GAAW,EAAE,CAAC;wBAEnB,YAAY,GAAG,eAAe,CAAC,MAAM,GAAG,mCAAuB,CAAC;wBACtE,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,EAAE,EAAE,CAAC,EAAE;4BACrC,KAAK,CAAC,CAAC,CAAC,GAAG,EAAC,SAAS,EAAE,EAAE,EAAC,CAAC;4BACrB,QAAQ,GAAG,CAAC,GAAG,mCAAuB,GAAG,6BAAiB,CAAC;4BACjE,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG;gCACb,IAAI,EAAE,eAAe,CAAC,QAAQ,CAAC;gCAC/B,IAAI,EAAE,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC;gCACnC,IAAI,EAAE,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC;gCACnC,IAAI,EAAE,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC;gCACnC,KAAK,EAAE,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC;gCACpE,MAAM,EAAE,eAAe,CAAC,QAAQ,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,QAAQ,CAAC;6BAClE,CAAC;4BACI,UAAU,GAAG,CAAC,GAAG,mCAAuB,GAAG,mCAAuB,CAAC;4BACzE,KAAK,CAAC,CAAC,CAAC,CAAC,KAAK,GAAG,eAAe,CAAC,UAAU,CAAC,CAAC;4BAC7C,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,EAAE,CAAC;4BACxB,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,yBAAa,EAAE,EAAE,CAAC,EAAE;gCACtC,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG;oCACtB,CAAC,EAAE,eAAe,CACb,CAAC,GAAG,mCAAuB,GAAG,CAAC,GAAG,+BAAmB,CAAC;oCAC3D,CAAC,EAAE,eAAe,CACb,CAAC,GAAG,mCAAuB,GAAG,CAAC,GAAG,+BAAmB,GAAG,CAAC,CAAC;oCAC/D,KAAK,EAAE,eAAe,CACjB,CAAC,GAAG,mCAAuB,GAAG,CAAC,GAAG,+BAAmB,GAAG,CAAC,CAAC;iCAChE,CAAC;6BACH;yBACF;wBAED,sBAAO,KAAK,EAAC;;;;KACd;IAED;;;;;;;;;;;;OAYG;IACG,uCAAa,GAAnB,UACI,KAAwB,EACxB,gBAAqE,EACrE,SAAkB;QADlB,iCAAA,EAAA,mBAA4C,qCAAyB;;;;;;wBAEvE,gBAAgB,GAAG,IAAA,yCAAwB,EAAC,gBAAgB,CAAC,CAAC;wBAE9D,IAAI,KAAK,IAAI,IAAI,EAAE;4BACjB,IAAI,CAAC,KAAK,EAAE,CAAC;4BACb,sBAAO,EAAE,EAAC;yBACX;wBAED,IAAI,SAAS,IAAI,IAAI,EAAE;4BACrB,IAAI,IAAA,kBAAO,EAAC,KAAK,CAAC,EAAE;gCAClB,SAAS,GAAG,KAAK,CAAC,WAAW,GAAG,mCAAuB,CAAC;6BACzD;yBACF;6BAAM;4BACL,SAAS,GAAG,SAAS,GAAG,wCAA4B,CAAC;yBACtD;wBAEK,aAAa,GAAG,IAAA,2BAAa,EAAC,KAAK,CAAC,CAAC;wBACrC,SAAS,GAAG,IAAA,0BAAY,EAAC,aAAa,CAAC,CAAC;wBACxC,aAAa,GAAgB,EAAE,CAAC,UAAU,CAAC,aAAa,EAAE,CAAC,CAAC,CAAC;wBAEnE,uEAAuE;wBACvE,IAAI,CAAC,CAAC,KAAK,YAAY,EAAE,CAAC,MAAM,CAAC,EAAE;4BACjC,aAAa,CAAC,OAAO,EAAE,CAAC;yBACzB;wBAEG,KAAK,GAAW,EAAE,CAAC;6BACnB,CAAC,IAAI,CAAC,cAAc,EAApB,wBAAoB;wBAElB,qBAAM,IAAI,CAAC,kBAAkB,CAAC,aAAa,EAAE,SAAS,EAAE,SAAS,CAAC,EAAA;;wBADtE,KAAK;4BACD,SAAkE,CAAC;;4BAGnE,qBAAM,IAAI,CAAC,qBAAqB,CAAC,aAAa,EAAE,SAAS,EAAE,SAAS,CAAC,EAAA;;wBADzE,KAAK;4BACD,SAAqE,CAAC;;;wBAG5E,0EAA0E;wBAC1E,0BAA0B;wBAC1B,KAAS,OAAO,GAAG,CAAC,EAAE,OAAO,GAAG,KAAK,CAAC,MAAM,EAAE,EAAE,OAAO,EAAE;4BACvD,KAAS,WAAW,GAAG,CAAC,EAAE,WAAW,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,SAAS,CAAC,MAAM,EAClE,EAAE,WAAW,EAAE;gCAClB,KAAK,CAAC,OAAO,CAAC,CAAC,SAAS,CAAC,WAAW,CAAC,CAAC,IAAI;oCACtC,0BAAc,CAAC,WAAW,CAAC,CAAC;gCAChC,KAAK,CAAC,OAAO,CAAC,CAAC,SAAS,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,SAAS,CAAC,MAAM,CAAC;gCAC5D,KAAK,CAAC,OAAO,CAAC,CAAC,SAAS,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,SAAS,CAAC,KAAK,CAAC;6BAC5D;yBACF;wBAED,sBAAO,KAAK,EAAC;;;;KACd;IAED;;;;;;;;OAQG;IACG,4CAAkB,GAAxB,UACI,aAA0B,EAAE,SAAoB,EAChD,SAAiB;;;;;;;wBACnB,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE;4BACpB,IAAI,CAAC,UAAU,GAAG,IAAA,2BAAc,EAAC,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE,SAAS,CAAC,CAAC;yBACtE;wBAEK,YAAY,GAAG,EAAE,CAAC,IAAI,CAAC;4BAC3B,2CAA2C;4BAC3C,IAAM,gBAAgB,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC;oCACpC,KAAI,CAAC,UAAU,CAAC,IAAI,EAAE,KAAI,CAAC,UAAU,CAAC,IAAI,EAAE,KAAI,CAAC,UAAU,CAAC,IAAI;oCAChE,KAAI,CAAC,UAAU,CAAC,IAAI;iCACrB,CAAC,CAAC,CAAC;4BACJ,kEAAkE;4BAClE,UAAU;4BACV,IAAM,MAAM,GAAgB,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;4BACnD,4BAA4B;4BAC5B,IAAM,QAAQ,GACV,CAAC,KAAI,CAAC,oBAAoB,CAAC,MAAM,EAAE,KAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,CAAC;4BACxE,OAAO,EAAE,CAAC,IAAI,CACV,EAAE,CAAC,KAAK,CAAC,aAAa,CAClB,aAAa,EAAE,gBAAgB,EAAE,MAAM,EAAE,QAAQ,EAAE,UAAU,EAAE,CAAC,CAAC,EACrE,OAAO,CAAC,CAAC;wBACf,CAAC,CAAC,CAAC;wBACH,aAAa,CAAC,OAAO,EAAE,CAAC;wBAEX,qBAAM,IAAI,CAAC,wBAAwB,CAAC,YAAY,CAAC,EAAA;;wBAAxD,IAAI,GAAG,SAAiD;wBAC9D,YAAY,CAAC,OAAO,EAAE,CAAC;wBAEvB,IAAI,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,YAAY,EAAE;4BAClC,IAAI,CAAC,KAAK,EAAE,CAAC;4BACb,sBAAO,EAAE,EAAC;yBACX;wBAED,gEAAgE;wBAChE,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;4BAC9C,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;gCACf,IAAI,CAAC,UAAU,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;4BACxE,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;gCACf,IAAI,CAAC,UAAU,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC;yBACxE;wBAED,0EAA0E;wBAC1E,kBAAkB;wBAClB,IAAI,SAAS,IAAI,IAAI,IAAI,IAAI,CAAC,eAAe,EAAE;4BAC7C,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,cAAc,CAAC,KAAK,CACtC,IAAI,CAAC,SAAS,EAAE,SAAS,EAAE,CAAC,CAAC,iBAAiB,CAAC,CAAC;yBACrD;wBAKK,cAAc,GAAG,IAAA,oCAAuB,EAC1C,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,mBAAmB,EAAE,SAAS,CAAC,CAAC;wBAE1E,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,gBAAgB,CAAC,cAAc,CAAC,CAAC;wBAExD,sBAAO,CAAC,IAAI,CAAC,EAAC;;;;KACf;IAED;;;;;;;;OAQG;IACG,+CAAqB,GAA3B,UACI,aAA0B,EAAE,SAAoB,EAChD,SAAiB;;;;;;;wBAOb,gBAAgB,GAAG,EAAE,CAAC;wBAC5B,IAAI,SAAS,CAAC,KAAK,GAAG,SAAS,CAAC,MAAM,EAAE;4BACtC,YAAY,GAAG,IAAI,CAAC,qBAAqB,CAAC;4BAC1C,aAAa,GAAG,IAAI,CAAC,KAAK,CACtB,IAAI,CAAC,qBAAqB,GAAG,SAAS,CAAC,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,CAAC;4BACrE,YAAY;gCACR,EAAE,CAAC,KAAK,CAAC,cAAc,CAAC,aAAa,EAAE,CAAC,aAAa,EAAE,YAAY,CAAC,CAAC,CAAC;4BAE1E,WAAW,GAAG,YAAY,CAAC;4BAC3B,YAAY;gCACR,IAAI,CAAC,IAAI,CAAC,aAAa,GAAG,gBAAgB,CAAC,GAAG,gBAAgB,CAAC;4BACnE,WAAW,GAAG,EAAE,CAAC,GAAG,CAChB,YAAY,EACZ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,YAAY,GAAG,aAAa,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;yBAClE;6BAAM;4BACL,YAAY,GAAG,IAAI,CAAC,KAAK,CACrB,IAAI,CAAC,qBAAqB,GAAG,SAAS,CAAC,KAAK,GAAG,SAAS,CAAC,MAAM,CAAC,CAAC;4BACrE,aAAa,GAAG,IAAI,CAAC,qBAAqB,CAAC;4BAC3C,YAAY;gCACR,EAAE,CAAC,KAAK,CAAC,cAAc,CAAC,aAAa,EAAE,CAAC,aAAa,EAAE,YAAY,CAAC,CAAC,CAAC;4BAE1E,WAAW;gCACP,IAAI,CAAC,IAAI,CAAC,YAAY,GAAG,gBAAgB,CAAC,GAAG,gBAAgB,CAAC;4BAClE,YAAY,GAAG,aAAa,CAAC;4BAC7B,WAAW,GAAG,EAAE,CAAC,GAAG,CAChB,YAAY,EACZ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,WAAW,GAAG,YAAY,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;yBAChE;wBACD,YAAY,CAAC,OAAO,EAAE,CAAC;wBACvB,aAAa,CAAC,OAAO,EAAE,CAAC;wBAElB,gBAAgB,GAAG,EAAE,CAAC,IAAI,CAAC,WAAW,EAAE,OAAO,CAAC,CAAC;wBACvD,WAAW,CAAC,OAAO,EAAE,CAAC;wBACV,qBAAM,IAAI,CAAC,uBAAuB,CAAC,gBAAgB,CAAC,EAAA;;wBAA5D,KAAK,GAAG,SAAoD;wBAChE,gBAAgB,CAAC,OAAO,EAAE,CAAC;wBAE3B,KAAK,GAAG,KAAK,CAAC,MAAM,CAAC,UAAA,IAAI,IAAI,OAAA,IAAI,CAAC,KAAK,IAAI,KAAI,CAAC,YAAY,EAA/B,CAA+B,CAAC,CAAC;wBAE9D,uEAAuE;wBACvE,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;4BACrC,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gCAClD,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,YAAY,GAAG,aAAa,CAAC;gCACxD,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,WAAW,GAAG,YAAY,CAAC;6BACvD;yBACF;wBAED,IAAI,IAAI,CAAC,cAAc,EAAE;4BACvB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;4BAErC,IAAI,IAAI,CAAC,eAAe,EAAE;gCACxB,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oCACrC,IAAI,CAAC,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE;wCAC5C,IAAI,CAAC,iBAAiB,CAAC,GAAG,CACtB,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,EACX,IAAI,kDAAsB,CAAC,kCAAsB,CAAC,CAAC,CAAC;qCACzD;oCACD,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS;wCACd,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;6CAClC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,CAAC,CAAC,iBAAiB,CAAC,CAAC;iCACpE;gCAEK,aAAW,IAAI,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC;gCAC5C,IAAI,CAAC,iBAAiB,CAAC,OAAO,CAAC,UAAC,CAAC,EAAE,OAAO;oCACxC,IAAI,CAAC,UAAQ,CAAC,GAAG,CAAC,OAAO,CAAC,EAAE;wCAC1B,KAAI,CAAC,iBAAiB,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;qCACxC;gCACH,CAAC,CAAC,CAAC;6BACJ;yBACF;wBAED,sBAAO,KAAK,EAAC;;;;KACd;IAED,0CAAgB,GAAhB,UAAiB,aAA0B;QACzC,IAAI,CAAC,aAAa,EAAE;YAClB,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;YAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;YAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;YAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;YAClC,OAAO,IAAI,CAAC;SACb;aAAM;YACL,IAAM,YAAY,GAAG,IAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;YACzE,IAAM,YAAY,GAAG,IAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;YACzE,IAAM,YAAY,GAAG,IAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;YACzE,IAAM,YAAY,GAAG,IAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;YACzE,OAAO;gBACL,IAAI,EAAE,YAAY;gBAClB,IAAI,EAAE,YAAY;gBAClB,IAAI,EAAE,YAAY;gBAClB,IAAI,EAAE,YAAY;gBAClB,MAAM,EAAE,YAAY,GAAG,YAAY;gBACnC,KAAK,EAAE,YAAY,GAAG,YAAY;aACnC,CAAC;SACH;IACH,CAAC;IAED,iCAAO,GAAP;QACE,IAAI,CAAC,YAAY,CAAC,OAAO,EAAE,CAAC;IAC9B,CAAC;IAED,+BAAK,GAAL;QACE,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC;QACvB,IAAI,CAAC,YAAY,EAAE,CAAC;IACtB,CAAC;IAED,sCAAY,GAAZ;QACE,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,CAAC;QAC5B,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;QAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;QAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;QAClC,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,CAAC;IACpC,CAAC;IACH,sBAAC;AAAD,CAAC,AAlcD,IAkcC;AAED;;;;;;;;GAQG;AACH,SAAsB,IAAI,CAAC,WAAgD;IAAhD,4BAAA,EAAA,cAAkC,0BAAc;;;;;;oBAEnE,MAAM,GAAG,IAAA,oCAAmB,EAAC,WAAW,CAAC,CAAC;oBAG5C,SAAS,GAAG,IAAI,CAAC;yBAEjB,CAAC,CAAC,MAAM,CAAC,QAAQ,EAAjB,wBAAiB;oBACnB,SAAS,GAAG,OAAO,MAAM,CAAC,QAAQ,KAAK,QAAQ;wBAC3C,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,mBAAmB,CAAC,GAAG,CAAC,CAAC,CAAC;oBAC9C,qBAAM,GAAG,CAAC,cAAc,CAAC,MAAM,CAAC,QAAQ,EAAE,EAAC,SAAS,WAAA,EAAC,CAAC,EAAA;;oBAA9D,KAAK,GAAG,SAAsD,CAAC;;;oBAE3D,QAAQ,SAAA,CAAC;oBACb,IAAI,MAAM,CAAC,SAAS,KAAK,gCAAoB,EAAE;wBAC7C,QAAQ,GAAG,4CAAgC,CAAC;qBAC7C;yBAAM,IAAI,MAAM,CAAC,SAAS,KAAK,8BAAkB,EAAE;wBAClD,QAAQ,GAAG,0CAA8B,CAAC;qBAC3C;yBAAM,IAAI,MAAM,CAAC,SAAS,KAAK,+BAAmB,EAAE;wBACnD,QAAQ,GAAG,2CAA+B,CAAC;qBAC5C;oBACO,qBAAM,GAAG,CAAC,cAAc,CAAC,QAAQ,EAAE,EAAC,SAAS,WAAA,EAAC,CAAC,EAAA;;oBAAvD,KAAK,GAAG,SAA+C,CAAC;;;oBAG1D,IAAI,EAAE,CAAC,UAAU,EAAE,KAAK,OAAO,EAAE;wBAC/B,0EAA0E;wBAC1E,4EAA4E;wBAC5E,cAAc;wBACd,yFAAyF;wBACzF,EAAE;wBACF,4BAA4B;wBAC5B,wDAAwD;wBACxD,sCAAsC;wBACtC,EAAE;wBACF,yEAAyE;wBACzE,mCAAmC;wBACnC,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,0CAA0C,EAAE,CAAC,CAAC,CAAC;qBAC7D;oBAED,sBAAO,IAAI,eAAe,CAAC,KAAK,EAAE,MAAM,CAAC,EAAC;;;;CAC3C;AAvCD,oBAuCC","sourcesContent":[null]}},"error":null,"hash":"d2d81da769374e54dff16bd38b0cb69a","cacheData":{"env":{}}}