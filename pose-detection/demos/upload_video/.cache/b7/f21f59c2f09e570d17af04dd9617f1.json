{"id":"node_modules/@tensorflow-models/pose-detection/posenet/detector.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js.map","includedInParent":true,"mtime":1701727604739},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1705897977865},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"@tensorflow/tfjs-converter","loc":{"line":56,"column":21,"index":3297},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow/tfjs-converter/dist/index.js"},{"name":"@tensorflow/tfjs-core","loc":{"line":57,"column":17,"index":3345},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow/tfjs-core/dist/index.js"},{"name":"../shared/calculators/convert_image_to_tensor","loc":{"line":58,"column":40,"index":3411},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/convert_image_to_tensor.js"},{"name":"../shared/calculators/image_utils","loc":{"line":59,"column":28,"index":3489},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/image_utils.js"},{"name":"../shared/calculators/shift_image_value","loc":{"line":60,"column":34,"index":3561},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/shared/calculators/shift_image_value.js"},{"name":"./calculators/decode_multiple_poses","loc":{"line":61,"column":38,"index":3643},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_multiple_poses.js"},{"name":"./calculators/decode_single_pose","loc":{"line":62,"column":35,"index":3718},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/decode_single_pose.js"},{"name":"./calculators/flip_poses","loc":{"line":63,"column":27,"index":3782},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/flip_poses.js"},{"name":"./calculators/scale_poses","loc":{"line":64,"column":28,"index":3839},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/calculators/scale_poses.js"},{"name":"./constants","loc":{"line":65,"column":26,"index":3895},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/constants.js"},{"name":"./detector_utils","loc":{"line":66,"column":31,"index":3942},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector_utils.js"},{"name":"./load_utils","loc":{"line":67,"column":27,"index":3990},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/detector.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/@tensorflow-models/pose-detection/posenet/load_utils.js"}],"generated":{"js":"\"use strict\";\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.load = void 0;\nvar tfconv = require(\"@tensorflow/tfjs-converter\");\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar convert_image_to_tensor_1 = require(\"../shared/calculators/convert_image_to_tensor\");\nvar image_utils_1 = require(\"../shared/calculators/image_utils\");\nvar shift_image_value_1 = require(\"../shared/calculators/shift_image_value\");\nvar decode_multiple_poses_1 = require(\"./calculators/decode_multiple_poses\");\nvar decode_single_pose_1 = require(\"./calculators/decode_single_pose\");\nvar flip_poses_1 = require(\"./calculators/flip_poses\");\nvar scale_poses_1 = require(\"./calculators/scale_poses\");\nvar constants_1 = require(\"./constants\");\nvar detector_utils_1 = require(\"./detector_utils\");\nvar load_utils_1 = require(\"./load_utils\");\n/**\n * PoseNet detector class.\n */\nvar PosenetDetector = /** @class */ (function () {\n    function PosenetDetector(posenetModel, config) {\n        this.posenetModel = posenetModel;\n        // validate params.\n        var inputShape = this.posenetModel.inputs[0].shape;\n        tf.util.assert((inputShape[1] === -1) && (inputShape[2] === -1), function () { return \"Input shape [\".concat(inputShape[1], \", \").concat(inputShape[2], \"] \") +\n            \"must both be equal to or -1\"; });\n        var validInputResolution = (0, load_utils_1.getValidInputResolutionDimensions)(config.inputResolution, config.outputStride);\n        (0, detector_utils_1.assertValidOutputStride)(config.outputStride);\n        (0, detector_utils_1.assertValidResolution)(validInputResolution, config.outputStride);\n        this.inputResolution = validInputResolution;\n        this.outputStride = config.outputStride;\n        this.architecture = config.architecture;\n    }\n    /**\n     * Estimates poses for an image or video frame.\n     *\n     * This does standard ImageNet pre-processing before inferring through the\n     * model. The image should pixels should have values [0-255]. It returns a\n     * single pose or multiple poses based on the maxPose parameter from the\n     * `config`.\n     *\n     * @param image\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input\n     * image to feed through the network.\n     *\n     * @param estimationConfig\n     *       maxPoses: Optional. Max number of poses to estimate.\n     *       When maxPoses = 1, a single pose is detected, it is usually much more\n     *       efficient than maxPoses > 1. When maxPoses > 1, multiple poses are\n     *       detected.\n     *\n     *       flipHorizontal: Optional. Default to false. When image data comes\n     *       from camera, the result has to flip horizontally.\n     *\n     * @return An array of `Pose`s.\n     */\n    PosenetDetector.prototype.estimatePoses = function (image, estimationConfig) {\n        if (estimationConfig === void 0) { estimationConfig = constants_1.SINGLE_PERSON_ESTIMATION_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.estimatePosesGPU(image, estimationConfig, false)];\n            });\n        });\n    };\n    /**\n     * Estimates poses for an image or video frame, optionally supports gpu\n     * rendering.\n     *\n     * This does standard ImageNet pre-processing before inferring through the\n     * model. The image should pixels should have values [0-255]. It returns a\n     * single pose or multiple poses based on the maxPose parameter from the\n     * `config`.\n     *\n     * @param image\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input\n     * image to feed through the network.\n     *\n     * @param estimationConfig\n     *       maxPoses: Optional. Max number of poses to estimate.\n     *       When maxPoses = 1, a single pose is detected, it is usually much more\n     *       efficient than maxPoses > 1. When maxPoses > 1, multiple poses are\n     *       detected.\n     *\n     *       flipHorizontal: Optional. Default to false. When image data comes\n     *       from camera, the result has to flip horizontally.\n     *\n     * @param useGpuRenderer\n     *        Whether rendering predict results with gpu or not.\n     *\n     * @return If not rendering with gpu, an array of poses, each pose contains an\n     *     array of `Keypoint`s. Otherwise an array of tensor, and canvas info.\n     */\n    PosenetDetector.prototype.estimatePosesGPU = function (image, estimationConfig, useGpuRenderer) {\n        if (estimationConfig === void 0) { estimationConfig = constants_1.SINGLE_PERSON_ESTIMATION_CONFIG; }\n        if (useGpuRenderer === void 0) { useGpuRenderer = false; }\n        return __awaiter(this, void 0, void 0, function () {\n            var config, _a, imageTensor, padding, imageValueShifted, results, offsets, heatmap, displacementFwd, displacementBwd, heatmapScores, poses, _b, pose, score, pose, canvasInfo, scaledPoses, imageSize;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        config = (0, detector_utils_1.validateEstimationConfig)(estimationConfig);\n                        if (image == null) {\n                            return [2 /*return*/, useGpuRenderer ? [[], []] : []];\n                        }\n                        this.maxPoses = config.maxPoses;\n                        _a = (0, convert_image_to_tensor_1.convertImageToTensor)(image, {\n                            outputTensorSize: this.inputResolution,\n                            keepAspectRatio: true,\n                            borderMode: 'replicate'\n                        }), imageTensor = _a.imageTensor, padding = _a.padding;\n                        imageValueShifted = this.architecture === 'ResNet50' ?\n                            tf.add(imageTensor, constants_1.RESNET_MEAN) :\n                            (0, shift_image_value_1.shiftImageValue)(imageTensor, [-1, 1]);\n                        results = this.posenetModel.predict(imageValueShifted);\n                        if (this.architecture === 'ResNet50') {\n                            offsets = tf.squeeze(results[2], [0]);\n                            heatmap = tf.squeeze(results[3], [0]);\n                            displacementFwd = tf.squeeze(results[0], [0]);\n                            displacementBwd = tf.squeeze(results[1], [0]);\n                        }\n                        else {\n                            offsets = tf.squeeze(results[0], [0]);\n                            heatmap = tf.squeeze(results[1], [0]);\n                            displacementFwd = tf.squeeze(results[2], [0]);\n                            displacementBwd = tf.squeeze(results[3], [0]);\n                        }\n                        heatmapScores = tf.sigmoid(heatmap);\n                        if (!(this.maxPoses === 1)) return [3 /*break*/, 5];\n                        if (!useGpuRenderer) return [3 /*break*/, 2];\n                        return [4 /*yield*/, (0, decode_single_pose_1.decodeSinglePoseGPU)(heatmapScores, offsets, this.outputStride)];\n                    case 1:\n                        _b = _c.sent(), pose = _b[0], score = _b[1];\n                        poses = [pose, score];\n                        return [3 /*break*/, 4];\n                    case 2: return [4 /*yield*/, (0, decode_single_pose_1.decodeSinglePose)(heatmapScores, offsets, this.outputStride)];\n                    case 3:\n                        pose = _c.sent();\n                        poses = [pose];\n                        _c.label = 4;\n                    case 4: return [3 /*break*/, 7];\n                    case 5:\n                        if (useGpuRenderer) {\n                            throw new Error('GPU renderer only supports single pose!');\n                        }\n                        return [4 /*yield*/, (0, decode_multiple_poses_1.decodeMultiplePoses)(heatmapScores, offsets, displacementFwd, displacementBwd, this.outputStride, this.maxPoses, config.scoreThreshold, config.nmsRadius)];\n                    case 6:\n                        poses = _c.sent();\n                        _c.label = 7;\n                    case 7:\n                        if (useGpuRenderer) {\n                            // TODO: handle flipPosesHorizontal in GPU.\n                            if (config.flipHorizontal === true) {\n                                throw new Error('flipHorizontal is not supported!');\n                            }\n                            canvasInfo = this.getCanvasInfo((0, image_utils_1.getImageSize)(image), this.inputResolution, padding);\n                        }\n                        else {\n                            imageSize = (0, image_utils_1.getImageSize)(image);\n                            scaledPoses =\n                                (0, scale_poses_1.scalePoses)(poses, imageSize, this.inputResolution, padding);\n                            if (config.flipHorizontal) {\n                                scaledPoses = (0, flip_poses_1.flipPosesHorizontal)(scaledPoses, imageSize);\n                            }\n                        }\n                        imageTensor.dispose();\n                        imageValueShifted.dispose();\n                        tf.dispose(results);\n                        offsets.dispose();\n                        heatmap.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        heatmapScores.dispose();\n                        return [2 /*return*/, useGpuRenderer ? [poses, canvasInfo] : scaledPoses];\n                }\n            });\n        });\n    };\n    PosenetDetector.prototype.getCanvasInfo = function (imageSize, inputResolution, padding) {\n        var height = imageSize.height, width = imageSize.width;\n        var scaleY = height / (inputResolution.height * (1 - padding.top - padding.bottom));\n        var scaleX = width / (inputResolution.width * (1 - padding.left - padding.right));\n        var offsetY = -padding.top * inputResolution.height;\n        var offsetX = -padding.left * inputResolution.width;\n        return [\n            offsetX, offsetY, scaleX, scaleY, imageSize.width, imageSize.height\n        ];\n    };\n    PosenetDetector.prototype.dispose = function () {\n        this.posenetModel.dispose();\n    };\n    PosenetDetector.prototype.reset = function () {\n        // No-op. There's no global state.\n    };\n    return PosenetDetector;\n}());\n/**\n * Loads the PoseNet model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the PoseNet loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nfunction load(modelConfig) {\n    if (modelConfig === void 0) { modelConfig = constants_1.MOBILENET_V1_CONFIG; }\n    return __awaiter(this, void 0, void 0, function () {\n        var config, defaultUrl_1, model_1, defaultUrl, model;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    config = (0, detector_utils_1.validateModelConfig)(modelConfig);\n                    if (!(config.architecture === 'ResNet50')) return [3 /*break*/, 2];\n                    defaultUrl_1 = (0, load_utils_1.resNet50Checkpoint)(config.outputStride, config.quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || defaultUrl_1)];\n                case 1:\n                    model_1 = _a.sent();\n                    return [2 /*return*/, new PosenetDetector(model_1, config)];\n                case 2:\n                    defaultUrl = (0, load_utils_1.mobileNetCheckpoint)(config.outputStride, config.multiplier, config.quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || defaultUrl)];\n                case 3:\n                    model = _a.sent();\n                    return [2 /*return*/, new PosenetDetector(model, config)];\n            }\n        });\n    });\n}\nexports.load = load;\n"},"sourceMaps":{"js":{"version":3,"file":"detector.js","sourceRoot":"","sources":["../../src/posenet/detector.ts"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;;GAeG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH,mDAAqD;AACrD,0CAA4C;AAG5C,yFAAmF;AACnF,iEAA+D;AAE/D,6EAAwE;AAGxE,6EAAwE;AACxE,uEAAuF;AACvF,uDAA6D;AAC7D,yDAAqD;AACrD,yCAA8F;AAC9F,mDAA+H;AAC/H,2CAAwG;AAGxG;;GAEG;AACH;IAOE,yBACqB,YAA+B,EAChD,MAA0B;QADT,iBAAY,GAAZ,YAAY,CAAmB;QAElD,mBAAmB;QACnB,IAAM,UAAU,GACZ,IAAI,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAyC,CAAC;QAC1E,EAAE,CAAC,IAAI,CAAC,MAAM,CACV,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAChD,cAAM,OAAA,uBAAgB,UAAU,CAAC,CAAC,CAAC,eAAK,UAAU,CAAC,CAAC,CAAC,OAAI;YACrD,6BAA6B,EAD3B,CAC2B,CAAC,CAAC;QAEvC,IAAM,oBAAoB,GAAG,IAAA,8CAAiC,EAC1D,MAAM,CAAC,eAAe,EAAE,MAAM,CAAC,YAAY,CAAC,CAAC;QAEjD,IAAA,wCAAuB,EAAC,MAAM,CAAC,YAAY,CAAC,CAAC;QAC7C,IAAA,sCAAqB,EAAC,oBAAoB,EAAE,MAAM,CAAC,YAAY,CAAC,CAAC;QAEjE,IAAI,CAAC,eAAe,GAAG,oBAAoB,CAAC;QAC5C,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC,YAAY,CAAC;QACxC,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC,YAAY,CAAC;IAC1C,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;OAsBG;IACG,uCAAa,GAAnB,UACI,KAAwB,EACxB,gBAC6D;QAD7D,iCAAA,EAAA,mBAC8B,2CAA+B;;;gBAE/D,sBAAO,IAAI,CAAC,gBAAgB,CAAC,KAAK,EAAE,gBAAgB,EAAE,KAAK,CACxC,EAAC;;;KACrB;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;OA2BG;IACG,0CAAgB,GAAtB,UACI,KAAwB,EACxB,gBAC6D,EAC7D,cAAsB;QAFtB,iCAAA,EAAA,mBAC8B,2CAA+B;QAC7D,+BAAA,EAAA,sBAAsB;;;;;;wBAClB,MAAM,GAAG,IAAA,yCAAwB,EAAC,gBAAgB,CAAC,CAAC;wBAE1D,IAAI,KAAK,IAAI,IAAI,EAAE;4BACjB,sBAAO,cAAc,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,EAAC;yBACvC;wBAED,IAAI,CAAC,QAAQ,GAAG,MAAM,CAAC,QAAQ,CAAC;wBAE1B,KAAyB,IAAA,8CAAoB,EAAC,KAAK,EAAE;4BACzD,gBAAgB,EAAE,IAAI,CAAC,eAAe;4BACtC,eAAe,EAAE,IAAI;4BACrB,UAAU,EAAE,WAAW;yBACxB,CAAC,EAJK,WAAW,iBAAA,EAAE,OAAO,aAAA,CAIxB;wBAEG,iBAAiB,GAAG,IAAI,CAAC,YAAY,KAAK,UAAU,CAAC,CAAC;4BACxD,EAAE,CAAC,GAAG,CAAC,WAAW,EAAE,uBAAW,CAAC,CAAC,CAAC;4BAClC,IAAA,mCAAe,EAAC,WAAW,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;wBAEpC,OAAO,GACT,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,iBAAiB,CAAkB,CAAC;wBAGlE,IAAI,IAAI,CAAC,YAAY,KAAK,UAAU,EAAE;4BACpC,OAAO,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BACtC,OAAO,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BACtC,eAAe,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BAC9C,eAAe,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;yBAC/C;6BAAM;4BACL,OAAO,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BACtC,OAAO,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BACtC,eAAe,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;4BAC9C,eAAe,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;yBAC/C;wBACK,aAAa,GAAG,EAAE,CAAC,OAAO,CAAC,OAAO,CAAgB,CAAC;6BAIrD,CAAA,IAAI,CAAC,QAAQ,KAAK,CAAC,CAAA,EAAnB,wBAAmB;6BACjB,cAAc,EAAd,wBAAc;wBACM,qBAAM,IAAA,wCAAmB,EAC3C,aAAa,EAAE,OAAsB,EAAE,IAAI,CAAC,YAAY,CAAC,EAAA;;wBADvD,KAAgB,SACuC,EADtD,IAAI,QAAA,EAAE,KAAK,QAAA;wBAElB,KAAK,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;;4BAGT,qBAAM,IAAA,qCAAgB,EAC/B,aAAa,EAAE,OAAsB,EAAE,IAAI,CAAC,YAAY,CAAC,EAAA;;wBADvD,IAAI,GAAG,SACgD;wBAC7D,KAAK,GAAG,CAAC,IAAI,CAAC,CAAC;;;;wBAGjB,IAAI,cAAc,EAAE;4BAClB,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;yBAC5D;wBACO,qBAAM,IAAA,2CAAmB,EAC7B,aAAa,EAAE,OAAsB,EAAE,eAA8B,EACrE,eAA8B,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,QAAQ,EAChE,MAAM,CAAC,cAAc,EAAE,MAAM,CAAC,SAAS,CAAC,EAAA;;wBAH5C,KAAK,GAAG,SAGoC,CAAC;;;wBAK/C,IAAI,cAAc,EAAE;4BAClB,2CAA2C;4BAC3C,IAAI,MAAM,CAAC,cAAc,KAAK,IAAI,EAAE;gCAClC,MAAM,IAAI,KAAK,CAAC,kCAAkC,CAAC,CAAC;6BACrD;4BAED,UAAU,GAAG,IAAI,CAAC,aAAa,CAC3B,IAAA,0BAAY,EAAC,KAAK,CAAC,EAAE,IAAI,CAAC,eAAe,EAAE,OAAO,CAAC,CAAC;yBAEzD;6BAAM;4BACC,SAAS,GAAG,IAAA,0BAAY,EAAC,KAAK,CAAC,CAAC;4BACtC,WAAW;gCACP,IAAA,wBAAU,EAAC,KAAe,EAAE,SAAS,EAAE,IAAI,CAAC,eAAe,EAAE,OAAO,CAAC,CAAC;4BAE1E,IAAI,MAAM,CAAC,cAAc,EAAE;gCACzB,WAAW,GAAG,IAAA,gCAAmB,EAAC,WAAW,EAAE,SAAS,CAAC,CAAC;6BAC3D;yBACF;wBAED,WAAW,CAAC,OAAO,EAAE,CAAC;wBACtB,iBAAiB,CAAC,OAAO,EAAE,CAAC;wBAC5B,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;wBACpB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAClB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAClB,eAAe,CAAC,OAAO,EAAE,CAAC;wBAC1B,eAAe,CAAC,OAAO,EAAE,CAAC;wBAC1B,aAAa,CAAC,OAAO,EAAE,CAAC;wBAExB,sBAAO,cAAc,CAAC,CAAC,CAAC,CAAC,KAAoB,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,WAAW,EAAC;;;;KAC1E;IAED,uCAAa,GAAb,UACI,SAAoB,EAAE,eAAgC,EACtD,OAAgB;QACX,IAAA,MAAM,GAAW,SAAS,OAApB,EAAE,KAAK,GAAI,SAAS,MAAb,CAAc;QAClC,IAAM,MAAM,GACR,MAAM,GAAG,CAAC,eAAe,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,OAAO,CAAC,GAAG,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC;QAC3E,IAAM,MAAM,GACR,KAAK,GAAG,CAAC,eAAe,CAAC,KAAK,GAAG,CAAC,CAAC,GAAG,OAAO,CAAC,IAAI,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC;QAEzE,IAAM,OAAO,GAAG,CAAC,OAAO,CAAC,GAAG,GAAG,eAAe,CAAC,MAAM,CAAC;QACtD,IAAM,OAAO,GAAG,CAAC,OAAO,CAAC,IAAI,GAAG,eAAe,CAAC,KAAK,CAAC;QAEtD,OAAO;YACL,OAAO,EAAE,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,CAAC,KAAK,EAAE,SAAS,CAAC,MAAM;SACpE,CAAC;IACJ,CAAC;IAED,iCAAO,GAAP;QACE,IAAI,CAAC,YAAY,CAAC,OAAO,EAAE,CAAC;IAC9B,CAAC;IAED,+BAAK,GAAL;QACE,kCAAkC;IACpC,CAAC;IACH,sBAAC;AAAD,CAAC,AAjND,IAiNC;AAED;;;;;;;;;;;GAWG;AACH,SAAsB,IAAI,CACtB,WACuB;IADvB,4BAAA,EAAA,cACI,+BAAmB;;;;;;oBACnB,MAAM,GAAG,IAAA,oCAAmB,EAAC,WAAW,CAAC,CAAC;yBAC5C,CAAA,MAAM,CAAC,YAAY,KAAK,UAAU,CAAA,EAAlC,wBAAkC;oBAE9B,eACF,IAAA,+BAAkB,EAAC,MAAM,CAAC,YAAY,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC;oBACjD,qBAAM,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,QAAQ,IAAI,YAAU,CAAC,EAAA;;oBAAlE,UAAQ,SAA0D;oBAExE,sBAAO,IAAI,eAAe,CAAC,OAAK,EAAE,MAAM,CAAC,EAAC;;oBAItC,UAAU,GAAG,IAAA,gCAAmB,EAClC,MAAM,CAAC,YAAY,EAAE,MAAM,CAAC,UAAU,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC;oBACjD,qBAAM,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,QAAQ,IAAI,UAAU,CAAC,EAAA;;oBAAlE,KAAK,GAAG,SAA0D;oBAExE,sBAAO,IAAI,eAAe,CAAC,KAAK,EAAE,MAAM,CAAC,EAAC;;;;CAC3C;AAnBD,oBAmBC","sourcesContent":[null]}},"error":null,"hash":"a0c3fe8521b7c725b070965f41895874","cacheData":{"env":{}}}