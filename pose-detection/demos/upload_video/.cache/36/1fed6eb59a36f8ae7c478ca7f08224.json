{"id":"node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","dependencies":[{"name":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\package.json","includedInParent":true,"mtime":1702881059798},{"name":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\.babelrc","includedInParent":true,"mtime":1699931790989},{"name":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\node_modules\\@tensorflow\\tfjs-core\\package.json","includedInParent":true,"mtime":1703654060392},{"name":"../tensor_util_env","loc":{"line":17,"column":27,"index":746},"parent":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\tensor.js","resolved":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\node_modules\\@tensorflow\\tfjs-core\\dist\\tensor_util_env.js"},{"name":"./tensor_ops_util","loc":{"line":18,"column":27,"index":796},"parent":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\tensor.js","resolved":"C:\\Users\\Lenovo\\Documents\\ASA_Fencing_Project\\pose-detection\\demos\\upload_video\\node_modules\\@tensorflow\\tfjs-core\\dist\\ops\\tensor_ops_util.js"}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.tensor = tensor;\nvar _tensor_util_env = require(\"../tensor_util_env\");\nvar _tensor_ops_util = require(\"./tensor_ops_util\");\n/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\n\n/**\r\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\r\n *\r\n * ```js\r\n * // Pass an array of values to create a vector.\r\n * tf.tensor([1, 2, 3, 4]).print();\r\n * ```\r\n *\r\n * ```js\r\n * // Pass a nested array of values to make a matrix or a higher\r\n * // dimensional tensor.\r\n * tf.tensor([[1, 2], [3, 4]]).print();\r\n * ```\r\n *\r\n * ```js\r\n * // Pass a flat array and specify a shape yourself.\r\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\r\n * ```\r\n *\r\n * ```js\r\n * // Pass a `WebGLData` object and specify a shape yourself.\r\n *\r\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\r\n * // For example, if your application includes a preprocessing step on the GPU,\r\n * // you could upload the GPU output directly to TF.js, rather than first\r\n * // downloading the values.\r\n *\r\n * // Example for WebGL2:\r\n * if (tf.findBackend('custom-webgl') == null) {\r\n *   const customCanvas = document.createElement('canvas');\r\n *   const customBackend = new tf.MathBackendWebGL(customCanvas);\r\n *   tf.registerBackend('custom-webgl', () => customBackend);\r\n * }\r\n * const savedBackend = tf.getBackend();\r\n * await tf.setBackend('custom-webgl');\r\n * const gl = tf.backend().gpgpu.gl;\r\n * const texture = gl.createTexture();\r\n * const tex2d = gl.TEXTURE_2D;\r\n * const width = 2;\r\n * const height = 2;\r\n *\r\n * gl.bindTexture(tex2d, texture);\r\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\r\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\r\n * gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\r\n * gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\r\n * gl.texImage2D(\r\n *   tex2d, 0, gl.RGBA32F, // internalFormat\r\n *   width, height, 0,\r\n *   gl.RGBA, // textureFormat\r\n *   gl.FLOAT, // textureType\r\n *   new Float32Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\r\n * );\r\n *\r\n * // Currently, the `texture` has 4 pixels:\r\n * // Pixel0 is {R:0, G:1, B:2, A:3}\r\n * // Pixel1 is {R:4, G:5, B:6, A:7}\r\n * // Pixel2 is {R:8, G:9, B:10, A:11}\r\n * // Pixel3 is {R:12, G:13, B:14, A:15}\r\n *\r\n * const logicalShape = [height * width * 2];\r\n * const a = tf.tensor({texture, height, width, channels: 'BR'}, logicalShape);\r\n * a.print();\r\n * // Tensor value will be [2, 0, 6, 4, 10, 8, 14, 12], since [2, 0] is the\r\n * // values of 'B' and 'R' channels of Pixel0, [6, 4] is the values of 'B' and\r\n * 'R'\r\n * // channels of Pixel1...\r\n *\r\n * // For postprocessing on the GPU, it's possible to retrieve the texture\r\n * // backing any tensor by calling the tensor's `dataToGPU` method like\r\n * // so:\r\n *\r\n * const tex = a.dataToGPU();\r\n * await tf.setBackend(savedBackend);\r\n * ```\r\n *\r\n * ```js\r\n * // Pass a `WebGPUData` object and specify a shape yourself.\r\n *\r\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\r\n * // For example, if your application includes a preprocessing step on the GPU,\r\n * // you could upload the GPU output directly to TF.js, rather than first\r\n * // downloading the values. Unlike WebGL, this optionally supports zero copy\r\n * // by WebGPUData.zeroCopy. When zeroCopy is false or undefined(default), this\r\n * // passing GPUBuffer can be destroyed after tensor is created. When zeroCopy\r\n * // is true, this GPUBuffer is bound directly by the tensor, so do not destroy\r\n * // this GPUBuffer until all access is done.\r\n *\r\n * // Example for WebGPU:\r\n * function createGPUBufferFromData(device, data, dtype) {\r\n *   const bytesPerElement = 4;\r\n *   const sizeInBytes = data.length * bytesPerElement;\r\n *\r\n *   const gpuWriteBuffer = device.createBuffer({\r\n *     mappedAtCreation: true,\r\n *     size: sizeInBytes,\r\n *     usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC\r\n *   });\r\n *   const arrayBuffer = gpuWriteBuffer.getMappedRange();\r\n *   if (dtype === 'float32') {\r\n *     new Float32Array(arrayBuffer).set(data);\r\n *   } else if (dtype === 'int32') {\r\n *     new Int32Array(arrayBuffer).set(data);\r\n *   } else {\r\n *     throw new Error(\r\n *         `Creating tensor from GPUBuffer only supports` +\r\n *         `'float32'|'int32' dtype, while the dtype is ${dtype}.`);\r\n *   }\r\n *   gpuWriteBuffer.unmap();\r\n *\r\n *   const gpuReadBuffer = device.createBuffer({\r\n *     mappedAtCreation: false,\r\n *     size: sizeInBytes,\r\n *     usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.STORAGE |\r\n *         GPUBufferUsage.COPY_SRC\r\n *   });\r\n *\r\n *   const copyEncoder = device.createCommandEncoder();\r\n *   copyEncoder.copyBufferToBuffer(\r\n *       gpuWriteBuffer, 0, gpuReadBuffer, 0, sizeInBytes);\r\n *   const copyCommands = copyEncoder.finish();\r\n *   device.queue.submit([copyCommands]);\r\n *   gpuWriteBuffer.destroy();\r\n *   return gpuReadBuffer;\r\n * }\r\n *\r\n * const savedBackend = tf.getBackend();\r\n * await tf.setBackend('webgpu').catch(\r\n *     () => {throw new Error(\r\n *         'Failed to use WebGPU backend. Please use Chrome Canary to run.')});\r\n * const dtype = 'float32';\r\n * const device = tf.backend().device;\r\n * const aData = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\r\n * const bData = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4];\r\n * const expected = [2, 4, 6, 8, 6, 8, 10, 12, 10, 12, 14, 16, 14, 16, 18, 20];\r\n * const aBuffer = createGPUBufferFromData(device, aData, dtype);\r\n * const shape = [aData.length];\r\n * // To use zeroCopy, use {buffer: aBuffer, zeroCopy: true} instead and destroy\r\n * // aBuffer untill all access is done.\r\n * const a = tf.tensor({buffer: aBuffer}, shape, dtype);\r\n * const b = tf.tensor(bData, shape, dtype);\r\n * const result = tf.add(a, b);\r\n * result.print();\r\n * a.dispose();\r\n * b.dispose();\r\n * result.dispose();\r\n * aBuffer.destroy();\r\n * await tf.setBackend(savedBackend);\r\n * ```\r\n * @param values The values of the tensor. Can be nested array of numbers,\r\n *     or a flat array, or a `TypedArray`, or a `WebGLData` object, or a\r\n * `WebGPUData` object. If the values are strings, they will be encoded as utf-8\r\n * and kept as `Uint8Array[]`. If the values is a `WebGLData` object, the dtype\r\n * could only be 'float32' or 'int32' and the object has to have: 1. texture, a\r\n * `WebGLTexture`, the texture must share the same `WebGLRenderingContext` with\r\n * TFJS's WebGL backend (you could create a custom WebGL backend from your\r\n * texture's canvas) and the internal texture format for the input texture must\r\n * be floating point or normalized integer; 2. height, the height of the\r\n * texture; 3. width, the width of the texture; 4. channels, a non-empty subset\r\n * of 'RGBA', indicating the values of which channels will be passed to the\r\n * tensor, such as 'R' or 'BR' (The order of the channels affect the order of\r\n * tensor values. ). (If the values passed from texture is less than the tensor\r\n * size, zeros will be padded at the rear.). If the values is a `WebGPUData`\r\n * object, the dtype could only be 'float32' or 'int32 and the object has to\r\n * have: buffer, a `GPUBuffer`. The buffer must: 1. share the same `GPUDevice`\r\n * with TFJS's WebGPU backend; 2. buffer.usage should at least support\r\n * GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC; 3. buffer.size should not\r\n * be smaller than the byte size of tensor shape. WebGPUData optionally supports\r\n * zero copy by flag zeroCopy. When zeroCopy is false or undefined(default),\r\n * this passing GPUBuffer can be destroyed after tensor is created. When\r\n * zeroCopy is true, this GPUBuffer is bound directly by the tensor, so do not\r\n * destroy this GPUBuffer until all access is done.\r\n * @param shape The shape of the tensor. Optional. If not provided,\r\n *   it is inferred from `values`.\r\n * @param dtype The data type.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Creation'}\r\n */\nfunction tensor(values, shape, dtype) {\n  const inferredShape = (0, _tensor_util_env.inferShape)(values, dtype);\n  return (0, _tensor_ops_util.makeTensor)(values, shape, inferredShape, dtype);\n}"},"sourceMaps":{"js":{"mappings":[{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":7,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":7,"column":4}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":7,"column":20}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":7,"column":23}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":19,"column":0},"generated":{"line":7,"column":30}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":8,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":8,"column":4}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":8,"column":20}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":8,"column":23}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":23,"column":0},"generated":{"line":8,"column":30}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":1,"column":0},"generated":{"line":9,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":25,"column":0},"generated":{"line":26,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":203,"column":6},"generated":{"line":204,"column":0}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":203,"column":16},"generated":{"line":204,"column":9}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":203,"column":22},"generated":{"line":204,"column":15}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":204,"column":4},"generated":{"line":204,"column":16}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":204,"column":43},"generated":{"line":204,"column":22}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":204,"column":45},"generated":{"line":204,"column":24}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":204,"column":64},"generated":{"line":204,"column":29}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":205,"column":4},"generated":{"line":204,"column":31}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":205,"column":20},"generated":{"line":204,"column":36}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":205,"column":20},"generated":{"line":204,"column":38}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":2},"generated":{"line":205,"column":2}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":8},"generated":{"line":205,"column":8}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":21},"generated":{"line":205,"column":21}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":24},"generated":{"line":205,"column":24}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":24},"generated":{"line":205,"column":28}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":34},"generated":{"line":205,"column":55}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":35},"generated":{"line":205,"column":57}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":41},"generated":{"line":205,"column":63}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":43},"generated":{"line":205,"column":65}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":48},"generated":{"line":205,"column":70}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":206,"column":49},"generated":{"line":205,"column":71}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":2},"generated":{"line":206,"column":2}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":9},"generated":{"line":206,"column":9}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":9},"generated":{"line":206,"column":13}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":19},"generated":{"line":206,"column":40}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":20},"generated":{"line":206,"column":42}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":26},"generated":{"line":206,"column":48}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":28},"generated":{"line":206,"column":50}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":33},"generated":{"line":206,"column":55}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":35},"generated":{"line":206,"column":57}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":48},"generated":{"line":206,"column":70}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":50},"generated":{"line":206,"column":72}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":55},"generated":{"line":206,"column":77}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":207,"column":69},"generated":{"line":206,"column":78}},{"source":"../../../../../../tfjs-core/src/ops/tensor.ts","name":null,"original":{"line":208,"column":0},"generated":{"line":207,"column":0}}],"sources":{"../../../../../../tfjs-core/src/ops/tensor.ts":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '../tensor';\nimport {inferShape} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport {DataType, Rank, ShapeMap, WebGLData, WebGPUData} from '../types';\n\nimport {makeTensor} from './tensor_ops_util';\n\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * ```js\n * // Pass a `WebGLData` object and specify a shape yourself.\n *\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n * // For example, if your application includes a preprocessing step on the GPU,\n * // you could upload the GPU output directly to TF.js, rather than first\n * // downloading the values.\n *\n * // Example for WebGL2:\n * if (tf.findBackend('custom-webgl') == null) {\n *   const customCanvas = document.createElement('canvas');\n *   const customBackend = new tf.MathBackendWebGL(customCanvas);\n *   tf.registerBackend('custom-webgl', () => customBackend);\n * }\n * const savedBackend = tf.getBackend();\n * await tf.setBackend('custom-webgl');\n * const gl = tf.backend().gpgpu.gl;\n * const texture = gl.createTexture();\n * const tex2d = gl.TEXTURE_2D;\n * const width = 2;\n * const height = 2;\n *\n * gl.bindTexture(tex2d, texture);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n * gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n * gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n * gl.texImage2D(\n *   tex2d, 0, gl.RGBA32F, // internalFormat\n *   width, height, 0,\n *   gl.RGBA, // textureFormat\n *   gl.FLOAT, // textureType\n *   new Float32Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n * );\n *\n * // Currently, the `texture` has 4 pixels:\n * // Pixel0 is {R:0, G:1, B:2, A:3}\n * // Pixel1 is {R:4, G:5, B:6, A:7}\n * // Pixel2 is {R:8, G:9, B:10, A:11}\n * // Pixel3 is {R:12, G:13, B:14, A:15}\n *\n * const logicalShape = [height * width * 2];\n * const a = tf.tensor({texture, height, width, channels: 'BR'}, logicalShape);\n * a.print();\n * // Tensor value will be [2, 0, 6, 4, 10, 8, 14, 12], since [2, 0] is the\n * // values of 'B' and 'R' channels of Pixel0, [6, 4] is the values of 'B' and\n * 'R'\n * // channels of Pixel1...\n *\n * // For postprocessing on the GPU, it's possible to retrieve the texture\n * // backing any tensor by calling the tensor's `dataToGPU` method like\n * // so:\n *\n * const tex = a.dataToGPU();\n * await tf.setBackend(savedBackend);\n * ```\n *\n * ```js\n * // Pass a `WebGPUData` object and specify a shape yourself.\n *\n * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n * // For example, if your application includes a preprocessing step on the GPU,\n * // you could upload the GPU output directly to TF.js, rather than first\n * // downloading the values. Unlike WebGL, this optionally supports zero copy\n * // by WebGPUData.zeroCopy. When zeroCopy is false or undefined(default), this\n * // passing GPUBuffer can be destroyed after tensor is created. When zeroCopy\n * // is true, this GPUBuffer is bound directly by the tensor, so do not destroy\n * // this GPUBuffer until all access is done.\n *\n * // Example for WebGPU:\n * function createGPUBufferFromData(device, data, dtype) {\n *   const bytesPerElement = 4;\n *   const sizeInBytes = data.length * bytesPerElement;\n *\n *   const gpuWriteBuffer = device.createBuffer({\n *     mappedAtCreation: true,\n *     size: sizeInBytes,\n *     usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC\n *   });\n *   const arrayBuffer = gpuWriteBuffer.getMappedRange();\n *   if (dtype === 'float32') {\n *     new Float32Array(arrayBuffer).set(data);\n *   } else if (dtype === 'int32') {\n *     new Int32Array(arrayBuffer).set(data);\n *   } else {\n *     throw new Error(\n *         `Creating tensor from GPUBuffer only supports` +\n *         `'float32'|'int32' dtype, while the dtype is ${dtype}.`);\n *   }\n *   gpuWriteBuffer.unmap();\n *\n *   const gpuReadBuffer = device.createBuffer({\n *     mappedAtCreation: false,\n *     size: sizeInBytes,\n *     usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.STORAGE |\n *         GPUBufferUsage.COPY_SRC\n *   });\n *\n *   const copyEncoder = device.createCommandEncoder();\n *   copyEncoder.copyBufferToBuffer(\n *       gpuWriteBuffer, 0, gpuReadBuffer, 0, sizeInBytes);\n *   const copyCommands = copyEncoder.finish();\n *   device.queue.submit([copyCommands]);\n *   gpuWriteBuffer.destroy();\n *   return gpuReadBuffer;\n * }\n *\n * const savedBackend = tf.getBackend();\n * await tf.setBackend('webgpu').catch(\n *     () => {throw new Error(\n *         'Failed to use WebGPU backend. Please use Chrome Canary to run.')});\n * const dtype = 'float32';\n * const device = tf.backend().device;\n * const aData = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n * const bData = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4];\n * const expected = [2, 4, 6, 8, 6, 8, 10, 12, 10, 12, 14, 16, 14, 16, 18, 20];\n * const aBuffer = createGPUBufferFromData(device, aData, dtype);\n * const shape = [aData.length];\n * // To use zeroCopy, use {buffer: aBuffer, zeroCopy: true} instead and destroy\n * // aBuffer untill all access is done.\n * const a = tf.tensor({buffer: aBuffer}, shape, dtype);\n * const b = tf.tensor(bData, shape, dtype);\n * const result = tf.add(a, b);\n * result.print();\n * a.dispose();\n * b.dispose();\n * result.dispose();\n * aBuffer.destroy();\n * await tf.setBackend(savedBackend);\n * ```\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`, or a `WebGLData` object, or a\n * `WebGPUData` object. If the values are strings, they will be encoded as utf-8\n * and kept as `Uint8Array[]`. If the values is a `WebGLData` object, the dtype\n * could only be 'float32' or 'int32' and the object has to have: 1. texture, a\n * `WebGLTexture`, the texture must share the same `WebGLRenderingContext` with\n * TFJS's WebGL backend (you could create a custom WebGL backend from your\n * texture's canvas) and the internal texture format for the input texture must\n * be floating point or normalized integer; 2. height, the height of the\n * texture; 3. width, the width of the texture; 4. channels, a non-empty subset\n * of 'RGBA', indicating the values of which channels will be passed to the\n * tensor, such as 'R' or 'BR' (The order of the channels affect the order of\n * tensor values. ). (If the values passed from texture is less than the tensor\n * size, zeros will be padded at the rear.). If the values is a `WebGPUData`\n * object, the dtype could only be 'float32' or 'int32 and the object has to\n * have: buffer, a `GPUBuffer`. The buffer must: 1. share the same `GPUDevice`\n * with TFJS's WebGPU backend; 2. buffer.usage should at least support\n * GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC; 3. buffer.size should not\n * be smaller than the byte size of tensor shape. WebGPUData optionally supports\n * zero copy by flag zeroCopy. When zeroCopy is false or undefined(default),\n * this passing GPUBuffer can be destroyed after tensor is created. When\n * zeroCopy is true, this GPUBuffer is bound directly by the tensor, so do not\n * destroy this GPUBuffer until all access is done.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor<R extends Rank>(\n    values: TensorLike|WebGLData|WebGPUData, shape?: ShapeMap[R],\n    dtype?: DataType): Tensor<R> {\n  const inferredShape = inferShape(values, dtype);\n  return makeTensor(values, shape, inferredShape, dtype) as Tensor<R>;\n}\n"},"lineCount":null}},"error":null,"hash":"5a47dfba074728ca6460f86542944dfb","cacheData":{"env":{}}}