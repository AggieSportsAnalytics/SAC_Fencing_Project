{"id":"node_modules/openai/resources/moderations.js","dependencies":[{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/moderations.js.map","includedInParent":true,"mtime":1705657321526},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/src/resources/moderations.ts","includedInParent":true,"mtime":1705657321526},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/package.json","includedInParent":true,"mtime":1705897977865},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/.babelrc","includedInParent":true,"mtime":1701727604305},{"name":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/package.json","includedInParent":true,"mtime":1705657321526},{"name":"openai/resource","loc":{"line":5,"column":27,"index":188},"parent":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resources/moderations.js","resolved":"/Users/vpenumarti/Desktop/CS/Aggie_Sports_Analytics/SAC_Fencing_Project/pose-detection/demos/upload_video/node_modules/openai/resource.js"}],"generated":{"js":"\"use strict\";\n// File generated from our OpenAPI spec by Stainless.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Moderations = void 0;\nconst resource_1 = require(\"openai/resource\");\nclass Moderations extends resource_1.APIResource {\n    /**\n     * Classifies if text violates OpenAI's Content Policy\n     */\n    create(body, options) {\n        return this._client.post('/moderations', { body, ...options });\n    }\n}\nexports.Moderations = Moderations;\n(function (Moderations) {\n})(Moderations = exports.Moderations || (exports.Moderations = {}));\n"},"sourceMaps":{"js":{"version":3,"file":"moderations.js","sourceRoot":"","sources":["../src/resources/moderations.ts"],"names":[],"mappings":";AAAA,qDAAqD;;;AAGrD,8CAA8C;AAG9C,MAAa,WAAY,SAAQ,sBAAW;IAC1C;;OAEG;IACH,MAAM,CACJ,IAA4B,EAC5B,OAA6B;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,cAAc,EAAE,EAAE,IAAI,EAAE,GAAG,OAAO,EAAE,CAAC,CAAC;IACjE,CAAC;CACF;AAVD,kCAUC;AAmMD,WAAiB,WAAW;AAI5B,CAAC,EAJgB,WAAW,GAAX,mBAAW,KAAX,mBAAW,QAI3B","sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from \"../core\";\nimport { APIResource } from \"../resource\";\nimport * as ModerationsAPI from \"./moderations\";\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text violates OpenAI's Content Policy\n   */\n  create(\n    body: ModerationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether the content violates\n   * [OpenAI's usage policies](/policies/usage-policies).\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * Represents policy compliance report by OpenAI's content moderation model against\n * a given input.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * The input text to classify\n   */\n  input: string | Array<string>;\n\n  /**\n   * Two content moderations models are available: `text-moderation-stable` and\n   * `text-moderation-latest`.\n   *\n   * The default is `text-moderation-latest` which will be automatically upgraded\n   * over time. This ensures you are always using our most accurate model. If you use\n   * `text-moderation-stable`, we will provide advanced notice before updating the\n   * model. Accuracy of `text-moderation-stable` may be slightly lower than for\n   * `text-moderation-latest`.\n   */\n  model?: (string & {}) | 'text-moderation-latest' | 'text-moderation-stable';\n}\n\nexport namespace Moderations {\n  export import Moderation = ModerationsAPI.Moderation;\n  export import ModerationCreateResponse = ModerationsAPI.ModerationCreateResponse;\n  export import ModerationCreateParams = ModerationsAPI.ModerationCreateParams;\n}\n"]}},"error":null,"hash":"8ee44f456dd95c0c73f7160f9de26c99","cacheData":{"env":{}}}