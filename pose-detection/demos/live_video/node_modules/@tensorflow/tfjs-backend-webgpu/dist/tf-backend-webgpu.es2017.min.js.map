{"version":3,"file":"tf-backend-webgpu.es2017.min.js","sources":["../../../../tfjs-backend-webgpu/src/flags_webgpu.ts","../../../../tfjs-backend-webgpu/src/adapter_info.ts","../../../../tfjs-backend-webgpu/src/buffer_manager.ts","../../../../tfjs-backend-webgpu/src/texture_manager.ts","../../../../tfjs-backend-webgpu/src/shader_util.ts","../../../../tfjs-backend-webgpu/src/webgpu_program.ts","../../../../tfjs-backend-webgpu/src/webgpu_util.ts","../../../../tfjs-backend-webgpu/src/backend_webgpu.ts","../../../../tfjs-backend-webgpu/src/binary_op_util.ts","../../../../tfjs-backend-webgpu/src/base.ts","../../../../tfjs-backend-webgpu/src/unary_op_util.ts","../../../../tfjs-backend-webgpu/src/activation_util.ts","../../../../tfjs-backend-webgpu/src/matmul_packed_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_reduce_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_small_output_size_webgpu.ts","../../../../tfjs-backend-webgpu/src/matmul_splitK_webgpu.ts","../../../../tfjs-backend-webgpu/src/fill_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Fill.ts","../../../../tfjs-backend-webgpu/src/kernels/Reshape.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/_FusedMatMul.ts","../../../../tfjs-backend-webgpu/src/binary_op_complex_webgpu.ts","../../../../tfjs-backend-webgpu/src/binary_op_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Identity.ts","../../../../tfjs-backend-webgpu/src/kernels/Complex.ts","../../../../tfjs-backend-webgpu/src/unary_op_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/kernel_funcs_utils.ts","../../../../../tfjs-backend-cpu/src/utils/binary_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Add.ts","../../../../../tfjs-backend-cpu/src/kernels/BitwiseAnd.ts","../../../../../tfjs-backend-cpu/src/utils/unary_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Ceil.ts","../../../../../tfjs-backend-cpu/src/kernels/Equal.ts","../../../../../tfjs-backend-cpu/src/kernels/Exp.ts","../../../../../tfjs-backend-cpu/src/kernels/Expm1.ts","../../../../../tfjs-backend-cpu/src/kernels/Floor.ts","../../../../../tfjs-backend-cpu/src/kernels/FloorDiv.ts","../../../../../tfjs-backend-cpu/src/kernels/Greater.ts","../../../../../tfjs-backend-cpu/src/kernels/GreaterEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/Less.ts","../../../../../tfjs-backend-cpu/src/kernels/LessEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/Log.ts","../../../../../tfjs-backend-cpu/src/kernels/Maximum.ts","../../../../../tfjs-backend-cpu/src/kernels/Minimum.ts","../../../../../tfjs-backend-cpu/src/kernels/Multiply.ts","../../../../../tfjs-backend-cpu/src/kernels/NotEqual.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedGather_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedRange_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Rsqrt.ts","../../../../../tfjs-backend-cpu/src/kernels/Sigmoid.ts","../../../../../tfjs-backend-cpu/src/kernels/Sqrt.ts","../../../../../tfjs-backend-cpu/src/kernels/SquaredDifference.ts","../../../../../tfjs-backend-cpu/src/kernels/StaticRegexReplace.ts","../../../../../tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringSplit_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Sub.ts","../../../../../tfjs-backend-cpu/src/kernels/TopK_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Bincount_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Cast.ts","../../../../../tfjs-backend-cpu/src/kernels/Concat_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/GatherNd_Impl.ts","../../../../../tfjs-backend-cpu/src/kernels/GatherV2_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/LinSpace_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Max_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Neg.ts","../../../../../tfjs-backend-cpu/src/kernels/Prod.ts","../../../../../tfjs-backend-cpu/src/kernels/Range_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Scatter_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Abs.ts","../../../../../tfjs-backend-cpu/src/kernels/Slice.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseReshape_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/SparseSegmentReduction_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StridedSlice_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Tile_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Transpose_impl.ts","../../../../../tfjs-backend-cpu/src/kernels/Unique_impl.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/shared.ts","../../../../tfjs-backend-webgpu/src/kernels/Abs.ts","../../../../tfjs-backend-webgpu/src/kernels/Acos.ts","../../../../tfjs-backend-webgpu/src/kernels/Acosh.ts","../../../../tfjs-backend-webgpu/src/kernels/Add.ts","../../../../tfjs-backend-webgpu/src/addn_packed_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/AddN.ts","../../../../tfjs-backend-webgpu/src/transpose_shared_webgpu.ts","../../../../tfjs-backend-webgpu/src/transpose_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Transpose.ts","../../../../tfjs-backend-webgpu/src/reduce_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/reduce.ts","../../../../tfjs-backend-webgpu/src/kernels/All.ts","../../../../tfjs-backend-webgpu/src/kernels/Any.ts","../../../../tfjs-backend-webgpu/src/argminmax_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ArgMax.ts","../../../../tfjs-backend-webgpu/src/kernels/ArgMin.ts","../../../../tfjs-backend-webgpu/src/kernels/Asin.ts","../../../../tfjs-backend-webgpu/src/kernels/Asinh.ts","../../../../tfjs-backend-webgpu/src/kernels/Atan.ts","../../../../tfjs-backend-webgpu/src/kernels/Atan2.ts","../../../../tfjs-backend-webgpu/src/kernels/Atanh.ts","../../../../tfjs-backend-webgpu/src/pool_filtersizeone_webgpu.ts","../../../../tfjs-backend-webgpu/src/pool_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Max.ts","../../../../tfjs-backend-webgpu/src/kernels/Mean.ts","../../../../tfjs-backend-webgpu/src/kernels/Pool_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/AvgPool.ts","../../../../tfjs-backend-webgpu/src/kernels/AvgPool3D.ts","../../../../tfjs-backend-webgpu/src/avg_pool_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/AvgPool3DGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/AvgPoolGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchMatMul.ts","../../../../tfjs-backend-webgpu/src/slice_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Slice.ts","../../../../tfjs-backend-webgpu/src/kernels/BatchToSpaceND.ts","../../../../tfjs-backend-webgpu/src/bincount_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Bincount.ts","../../../../tfjs-backend-webgpu/src/broadcast_args_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/BroadcastArgs.ts","../../../../tfjs-backend-webgpu/src/kernels/NotEqual.ts","../../../../tfjs-backend-webgpu/src/kernels/Real.ts","../../../../tfjs-backend-webgpu/src/kernels/Cast.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/int.ts","../../../../tfjs-backend-webgpu/src/kernels/Ceil.ts","../../../../tfjs-backend-webgpu/src/clip_vec4_webgpu.ts","../../../../tfjs-backend-webgpu/src/clip_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ClipByValue.ts","../../../../tfjs-backend-webgpu/src/complex_abs_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ComplexAbs.ts","../../../../tfjs-backend-webgpu/src/concat_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Imag.ts","../../../../tfjs-backend-webgpu/src/kernels/Concat_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Concat.ts","../../../../tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts","../../../../tfjs-backend-webgpu/src/conv2d_naive_webgpu.ts","../../../../tfjs-backend-webgpu/src/im2col_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2D_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2D.ts","../../../../tfjs-backend-webgpu/src/conv_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2DBackpropFilter.ts","../../../../tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv2DBackpropInput.ts","../../../../tfjs-backend-webgpu/src/conv3d_naive_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv3D.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv3DBackpropFilterV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Conv3DBackpropInputV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Cos.ts","../../../../tfjs-backend-webgpu/src/kernels/Cosh.ts","../../../../tfjs-backend-webgpu/src/crop_and_resize_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/CropAndResize.ts","../../../../tfjs-backend-webgpu/src/cum_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Cum_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/Cumprod.ts","../../../../tfjs-backend-webgpu/src/kernels/Cumsum.ts","../../../../tfjs-backend-webgpu/src/kernels/DenseBincount.ts","../../../../tfjs-backend-webgpu/src/depth_to_space_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthToSpace.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_nchw_shared_webgpu.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_vec4_webgpu.ts","../../../../tfjs-backend-webgpu/src/depthwise_conv2d_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNative.ts","../../../../tfjs-backend-webgpu/src/conv_backprop_depthwise_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts","../../../../tfjs-backend-webgpu/src/kernels/DepthwiseConv2dNativeBackpropInput.ts","../../../../tfjs-backend-webgpu/src/diag_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Diag.ts","../../../../tfjs-backend-webgpu/src/dilation_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Dilation2D.ts","../../../../tfjs-backend-webgpu/src/dilation_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Dilation2DBackpropFilter.ts","../../../../tfjs-backend-webgpu/src/kernels/Dilation2DBackpropInput.ts","../../../../tfjs-backend-webgpu/src/draw_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Draw.ts","../../../../tfjs-backend-webgpu/src/kernels/Multiply.ts","../../../../tfjs-backend-webgpu/src/kernels/Sum.ts","../../../../tfjs-backend-webgpu/src/kernels/Einsum.ts","../../../../tfjs-backend-webgpu/src/kernels/Elu.ts","../../../../tfjs-backend-webgpu/src/kernels/EluGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/Equal.ts","../../../../tfjs-backend-webgpu/src/kernels/Erf.ts","../../../../tfjs-backend-webgpu/src/kernels/Exp.ts","../../../../tfjs-backend-webgpu/src/kernels/ExpandDims.ts","../../../../tfjs-backend-webgpu/src/kernels/Expm1.ts","../../../../tfjs-backend-webgpu/src/fft_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FFT_impl.ts","../../../../tfjs-backend-webgpu/src/kernels/FFT.ts","../../../../tfjs-backend-webgpu/src/flip_left_right_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FlipLeftRight.ts","../../../../tfjs-backend-webgpu/src/kernels/Floor.ts","../../../../tfjs-backend-webgpu/src/kernels/FloorDiv.ts","../../../../tfjs-backend-webgpu/src/from_pixels_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FromPixels.ts","../../../../tfjs-backend-webgpu/src/batchnorm_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedBatchNorm.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedConv2D.ts","../../../../tfjs-backend-webgpu/src/kernels/FusedDepthwiseConv2D.ts","../../../../tfjs-backend-webgpu/src/gather_nd_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/GatherNd.ts","../../../../tfjs-backend-webgpu/src/gather_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/GatherV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Greater.ts","../../../../tfjs-backend-webgpu/src/kernels/GreaterEqual.ts","../../../../tfjs-backend-webgpu/src/kernels/IFFT.ts","../../../../tfjs-backend-webgpu/src/kernels/IsFinite.ts","../../../../tfjs-backend-webgpu/src/kernels/IsInf.ts","../../../../tfjs-backend-webgpu/src/kernels/IsNaN.ts","../../../../tfjs-backend-webgpu/src/kernels/LeakyRelu.ts","../../../../tfjs-backend-webgpu/src/kernels/Less.ts","../../../../tfjs-backend-webgpu/src/kernels/LessEqual.ts","../../../../tfjs-backend-webgpu/src/lin_space_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/LinSpace.ts","../../../../tfjs-backend-webgpu/src/kernels/Log.ts","../../../../tfjs-backend-webgpu/src/kernels/Log1p.ts","../../../../tfjs-backend-webgpu/src/kernels/LogicalAnd.ts","../../../../tfjs-backend-webgpu/src/kernels/LogicalNot.ts","../../../../tfjs-backend-webgpu/src/kernels/LogicalOr.ts","../../../../tfjs-backend-webgpu/src/lrn_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/LRN.ts","../../../../tfjs-backend-webgpu/src/lrn_grad_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/LRNGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/Maximum.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPool.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPool3D.ts","../../../../tfjs-backend-webgpu/src/max_pool_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPool3DGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPoolGrad.ts","../../../../tfjs-backend-webgpu/src/kernels/MaxPoolWithArgmax.ts","../../../../tfjs-backend-webgpu/src/kernels/Min.ts","../../../../tfjs-backend-webgpu/src/kernels/Minimum.ts","../../../../tfjs-backend-webgpu/src/mirror_pad_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/MirrorPad.ts","../../../../tfjs-backend-webgpu/src/kernels/Mod.ts","../../../../tfjs-backend-webgpu/src/multinomial_webgpu.ts","../../../../tfjs-backend-webgpu/src/softmax_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Softmax.ts","../../../../tfjs-backend-webgpu/src/kernels/Multinomial.ts","../../../../tfjs-backend-webgpu/src/kernels/Neg.ts","../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV3.ts","../../../../tfjs-backend-webgpu/src/kernels/NonMaxSuppressionV5.ts","../../../../tfjs-backend-webgpu/src/onehot_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/OneHot.ts","../../../../tfjs-backend-webgpu/src/kernels/ZerosLike.ts","../../../../tfjs-backend-webgpu/src/kernels/OnesLike.ts","../../../../tfjs-backend-webgpu/src/kernels/Pack.ts","../../../../tfjs-backend-webgpu/src/pad_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/PadV2.ts","../../../../tfjs-backend-webgpu/src/kernels/Pow.ts","../../../../tfjs-backend-webgpu/src/kernels/Prelu.ts","../../../../tfjs-backend-webgpu/src/kernels/Prod.ts","../../../../tfjs-backend-webgpu/src/kernels/Range.ts","../../../../tfjs-backend-webgpu/src/kernels/RealDiv.ts","../../../../tfjs-backend-webgpu/src/kernels/Reciprocal.ts","../../../../tfjs-backend-webgpu/src/kernels/Relu.ts","../../../../tfjs-backend-webgpu/src/kernels/Relu6.ts","../../../../tfjs-backend-webgpu/src/resize_bilinear_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeBilinear.ts","../../../../tfjs-backend-webgpu/src/resize_bilinear_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeBilinearGrad.ts","../../../../tfjs-backend-webgpu/src/resize_nearest_neighbor_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeNearestNeighbor.ts","../../../../tfjs-backend-webgpu/src/resize_nearest_neighbor_backprop_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ResizeNearestNeighborGrad.ts","../../../../tfjs-backend-webgpu/src/reverse_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Reverse.ts","../../../../tfjs-backend-webgpu/src/rotate_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/RotateWithOffset.ts","../../../../tfjs-backend-webgpu/src/kernels/Round.ts","../../../../tfjs-backend-webgpu/src/kernels/Rsqrt.ts","../../../../tfjs-backend-webgpu/src/scatter_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/ScatterNd.ts","../../../../tfjs-backend-webgpu/src/search_sorted_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/SearchSorted.ts","../../../../tfjs-backend-webgpu/src/select_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Select.ts","../../../../tfjs-backend-webgpu/src/kernels/Selu.ts","../../../../tfjs-backend-webgpu/src/kernels/Sigmoid.ts","../../../../tfjs-backend-webgpu/src/kernels/Sign.ts","../../../../tfjs-backend-webgpu/src/kernels/Sin.ts","../../../../tfjs-backend-webgpu/src/kernels/Sinh.ts","../../../../tfjs-backend-webgpu/src/kernels/Softplus.ts","../../../../tfjs-backend-webgpu/src/space_to_batchND_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/SpaceToBatchND.ts","../../../../tfjs-backend-webgpu/src/sparse_segment_reduce_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernel_utils/sparse_segment_reduce.ts","../../../../tfjs-backend-webgpu/src/kernels/SparseSegmentMean.ts","../../../../tfjs-backend-webgpu/src/kernels/SparseSegmentSum.ts","../../../../tfjs-backend-webgpu/src/tile_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Tile.ts","../../../../tfjs-backend-webgpu/src/kernels/SparseToDense.ts","../../../../tfjs-backend-webgpu/src/kernels/SplitV.ts","../../../../tfjs-backend-webgpu/src/kernels/Sqrt.ts","../../../../tfjs-backend-webgpu/src/kernels/Square.ts","../../../../tfjs-backend-webgpu/src/kernels/SquaredDifference.ts","../../../../tfjs-backend-webgpu/src/kernels/Step.ts","../../../../tfjs-backend-webgpu/src/strided_slice_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/StridedSlice.ts","../../../../tfjs-backend-webgpu/src/kernels/StringNGrams.ts","../../../../tfjs-backend-webgpu/src/kernels/Sub.ts","../../../../tfjs-backend-webgpu/src/kernels/Tan.ts","../../../../tfjs-backend-webgpu/src/kernels/Tanh.ts","../../../../tfjs-backend-webgpu/src/kernels/TensorScatterUpdate.ts","../../../../tfjs-backend-webgpu/src/top_k_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/TopK.ts","../../../../tfjs-backend-webgpu/src/transform_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/Transform.ts","../../../../tfjs-backend-webgpu/src/kernels/Unpack.ts","../../../../tfjs-backend-webgpu/src/unsorted_segment_sum_webgpu.ts","../../../../tfjs-backend-webgpu/src/kernels/UnsortedSegmentSum.ts","../../../../tfjs-backend-webgpu/src/register_all_kernels.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/** The batched dispatching calls size in the device queue. */\nENV.registerFlag('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE', () => 15);\n\n/**\n * Whether we forward execution to the CPU backend if tensors are small and\n * reside on the CPU.\n */\nENV.registerFlag('WEBGPU_CPU_FORWARD', () => true);\n\n/**\n * This flag is used to test different types of matmul programs.\n *\n * See MatMulProgramType in webgpu_util.ts for a list of available values.\n */\nENV.registerFlag('WEBGPU_MATMUL_PROGRAM_TYPE', () => -1);\n\n/**\n * Whether to use conv2dTranspose_naive which directly implement the\n * conv2dTranspose logic rather than using a matmul to simulate.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE', () => true);\n\n/**\n * Whether we use low power GPU. Otherwise, a high performance GPU will be\n * requested.\n */\nENV.registerFlag('WEBGPU_USE_LOW_POWER_GPU', () => false);\n\n/**\n * Threshold for input tensor size that determines whether WebGPU backend will\n * delegate computation to CPU.\n *\n * Default value is 1000.\n */\nENV.registerFlag('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD', () => 1000);\n\n/**\n * Whether to use a dummy canvas to make profiling tools like PIX work with\n * TFJS webgpu backend.\n */\nENV.registerFlag('WEBGPU_USE_PROFILE_TOOL', () => false);\n\n/**\n * Whether to use import API.\n */\nENV.registerFlag('WEBGPU_IMPORT_EXTERNAL_TEXTURE', () => true);\n\n/**\n * Whether to use conv2dNaive for debugging.\n */\nENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_DEBUG', () => false);\n\n/**\n * Threshold to increase dispatched workgroups for matmul. If too few workgroups\n * are dispatched, it means the hardware may be in low occupancy.\n * 0 means it's not set by the user. A default strategy will be applied.\n */\nENV.registerFlag('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL', () => 0);\n\n/**\n * Whether we will run im2col as a separate shader for convolution.\n */\nENV.registerFlag('WEBGPU_CONV_SEPARATE_IM2COL_SHADER', () => false);\n\n/**\n * A string used to match shader key. If any matches, print the related shader.\n * Seperated by comma. 'all' to print all. 'binary' to print binary(add, mul,\n * etc.). 'unary,conv2d' to print both unary and conv2d.\n */\nENV.registerFlag('WEBGPU_PRINT_SHADER', () => '');\n\n/** Experimental flag, whether enter compile only phase. */\nENV.registerFlag('WEBGPU_ENGINE_COMPILE_ONLY', () => false);\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class AdapterInfo {\n  private vendor: string;\n  private architecture: string;\n  public intelGPUGeneration: number;\n\n  constructor(adapterInfo: GPUAdapterInfo) {\n    if (adapterInfo) {\n      this.vendor = adapterInfo.vendor;\n      this.architecture = adapterInfo.architecture;\n      this.intelGPUGeneration = this.getIntelGPUGeneration();\n    }\n  }\n\n  private getIntelGPUGeneration() {\n    if (this.isIntel()) {\n      if (this.architecture.startsWith('gen')) {\n        return Number(this.architecture.match(/\\d+/));\n      } else if (this.architecture.startsWith('xe')) {\n        return 12;\n      }\n    }\n    return 0;\n  }\n\n  isIntel(): boolean {\n    return this.vendor === 'intel';\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class BufferManager {\n  private numUsedBuffers = 0;\n  private numFreeBuffers = 0;\n  private freeBuffers: Map<string, GPUBuffer[]> = new Map();\n  private usedBuffers: Map<string, GPUBuffer[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireBuffer(\n      size: number, usage: GPUBufferUsageFlags, mappedAtCreation = false,\n      reuse = true) {\n    let buffer;\n    const key = getBufferKey(size, usage);\n\n    if (reuse) {\n      if (!this.freeBuffers.has(key)) {\n        this.freeBuffers.set(key, []);\n      }\n\n      if (this.freeBuffers.get(key).length > 0) {\n        buffer = this.freeBuffers.get(key).pop();\n        this.numFreeBuffers--;\n      } else {\n        buffer = this.device.createBuffer({size, usage, mappedAtCreation});\n        this.numBytesAllocated += size;\n      }\n    } else {\n      buffer = this.device.createBuffer({size, usage, mappedAtCreation});\n      this.numBytesAllocated += size;\n    }\n\n    if (!this.usedBuffers.has(key)) {\n      this.usedBuffers.set(key, []);\n    }\n    this.usedBuffers.get(key).push(buffer);\n    this.numUsedBuffers++;\n    this.numBytesUsed += size;\n\n    return buffer;\n  }\n\n  releaseBuffer(buffer: GPUBuffer, reuse = true) {\n    if (this.freeBuffers.size === 0) {\n      return;\n    }\n\n    const size = buffer.size;\n    const usage = buffer.usage;\n\n    const key = getBufferKey(size, usage);\n    const bufferArray = this.usedBuffers.get(key);\n    const index = bufferArray.indexOf(buffer);\n    if (index < 0) {\n      throw new Error('Cannot find the buffer in buffer manager');\n    }\n    bufferArray[index] = bufferArray[bufferArray.length - 1];\n    bufferArray.pop();\n    this.numUsedBuffers--;\n    this.numBytesUsed -= size;\n\n    if (reuse) {\n      this.freeBuffers.get(key).push(buffer);\n      this.numFreeBuffers++;\n    } else {\n      buffer.destroy();\n      this.numBytesAllocated -= size;\n    }\n  }\n\n  getNumUsedBuffers(): number {\n    return this.numUsedBuffers;\n  }\n\n  getNumFreeBuffers(): number {\n    return this.numFreeBuffers;\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.usedBuffers.forEach((buffers, key) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.freeBuffers = new Map();\n    this.usedBuffers = new Map();\n    this.numUsedBuffers = 0;\n    this.numFreeBuffers = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getBufferKey(size: number, usage: GPUBufferUsageFlags) {\n  return `${size}_${usage}`;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport class TextureManager {\n  private numUsedTextures = 0;\n  private numFreeTextures = 0;\n  private freeTextures: Map<string, GPUTexture[]> = new Map();\n  private usedTextures: Map<string, GPUTexture[]> = new Map();\n\n  public numBytesUsed = 0;\n  public numBytesAllocated = 0;\n\n  constructor(private device: GPUDevice) {}\n\n  acquireTexture(\n      width: number, height: number, format: GPUTextureFormat,\n      usage: GPUTextureUsageFlags) {\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    if (!this.usedTextures.has(key)) {\n      this.usedTextures.set(key, []);\n    }\n\n    this.numBytesUsed += byteSize;\n    this.numUsedTextures++;\n\n    if (this.freeTextures.get(key).length > 0) {\n      this.numFreeTextures--;\n\n      const newTexture = this.freeTextures.get(key).shift();\n      this.usedTextures.get(key).push(newTexture);\n      return newTexture;\n    }\n\n    this.numBytesAllocated += byteSize;\n\n    const newTexture = this.device.createTexture({\n      size: [width, height],\n      format,\n      usage,\n    });\n    this.usedTextures.get(key).push(newTexture);\n\n    return newTexture;\n  }\n\n  releaseTexture(texture: GPUTexture) {\n    if (this.freeTextures.size === 0) {\n      return;\n    }\n\n    const width = texture.width;\n    const height = texture.height;\n    const format = texture.format;\n    const usage = texture.usage;\n\n    const key = getTextureKey(width, height, format, usage);\n    if (!this.freeTextures.has(key)) {\n      this.freeTextures.set(key, []);\n    }\n\n    this.freeTextures.get(key).push(texture);\n    this.numFreeTextures++;\n    this.numUsedTextures--;\n\n    const textureList = this.usedTextures.get(key);\n    const textureIndex = textureList.indexOf(texture);\n    if (textureIndex < 0) {\n      throw new Error(\n          'Cannot release a texture that was never provided by this ' +\n          'texture manager');\n    }\n    textureList.splice(textureIndex, 1);\n    const bytesPerElement = getBytesPerElement(format);\n    const byteSize = width * height * bytesPerElement;\n    this.numBytesUsed -= byteSize;\n  }\n\n  getNumUsedTextures(): number {\n    return this.numUsedTextures;\n  }\n\n  getNumFreeTextures(): number {\n    return this.numFreeTextures;\n  }\n\n  dispose() {\n    this.freeTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.usedTextures.forEach((textures, key) => {\n      textures.forEach(texture => {\n        texture.destroy();\n      });\n    });\n\n    this.freeTextures = new Map();\n    this.usedTextures = new Map();\n    this.numUsedTextures = 0;\n    this.numFreeTextures = 0;\n    this.numBytesUsed = 0;\n    this.numBytesAllocated = 0;\n  }\n}\n\nfunction getTextureKey(\n    width: number, height: number, format: GPUTextureFormat,\n    usage: GPUTextureUsageFlags) {\n  return `${width}_${height}_${format}_${usage}`;\n}\n\nfunction getBytesPerElement(format: GPUTextureFormat) {\n  if (format === 'rgba8unorm') {\n    return 16;\n  } else {\n    throw new Error(`${format} is not supported!`);\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Generates WGSL that computes strides.\nexport function symbolicallyComputeStrides(\n    indicesArr: number[], variableName: string): string[] {\n  if (Math.max(...indicesArr) > 5) {\n    throw new Error('Cannot symbolically compute strides for rank > 6 tensor.');\n  }\n\n  const numCoords = indicesArr.length;\n  const indicesStr = 'xyzwuv';\n  const shape = indicesArr.map(d => `${variableName}.${indicesStr[d]}`);\n  const strides = new Array(numCoords - 1);\n  strides[numCoords - 2] = shape[numCoords - 1];\n  for (let i = numCoords - 3; i >= 0; --i) {\n    strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;\n  }\n\n  return strides;\n}\n\nexport const atomicAddSnippet =\n    (ptr: string, v: string, type: 'int32'|'float32') => {\n      if (type === 'int32') {\n        return `atomicAdd(${ptr}, bitcast<i32>(${v}));`;\n      } else {\n        // atomicAdd only supports uint/int type. For float, we use\n        // atomicCompareExchangeWeak to simulate.\n        return `\n          {\n            var oldValue = 0;\n            loop {\n              let newValueF32 = bitcast<f32>(oldValue) + (${v});\n              let newValue = bitcast<i32>(newValueF32);\n              let res = atomicCompareExchangeWeak(${ptr}, oldValue, newValue);\n              if res.exchanged {\n                break;\n              }\n              oldValue = res.old_value;\n            }\n          }`;\n      }\n    };\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataTypeMap, env, Rank, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {symbolicallyComputeStrides} from './shader_util';\n\nexport enum PixelsOpType {\n  FROM_PIXELS,\n  DRAW\n}\n\nexport interface WebGPUProgram {\n  // Whether to use atomic built-in functions.\n  atomic?: boolean;\n  // dispatch specifies geometry of thread groups - derived from dispatchLayout.\n  dispatch: [number, number, number];\n  // dispatchLayout enumerates how tensor dimensions are distributed among\n  // dispatch x,y,z dimensions.\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  // By default, the output data component is 1.\n  outputComponent?: number;\n  outputShape: number[];\n  pixelsOpType?: PixelsOpType;\n  // The unique key to distinguish different shader source code.\n  shaderKey: string;\n  // Whether to use output size for bounds checking.\n  size?: boolean;\n  uniforms?: string;\n  variableNames: string[];\n  // Describe each variable's component and must have one-one mapping with\n  // variableNames. If not set, all variables component will be same with output\n  // component member.\n  variableComponents?: number[];\n  // workgroupSize.x * workgroupSize.y * workgroupSize.z = the number of threads\n  // in a thread group. Individual dimensions determines thread layout within\n  // the group.\n  workgroupSize: [number, number, number];\n  // Size of register cache in one dimension (assumes square cache).\n  // Each thread writes to workPerThread * workPerThread locations in the output\n  // buffer.\n  workPerThread?: number;\n  pipeline?: GPUComputePipeline|Promise<GPUComputePipeline>;\n  getUserCode: () => string;\n}\n\nexport const compileProgram =\n    (device: GPUDevice, program: WebGPUProgram, inputsData: InputInfo[],\n     output: TensorInfo, parallelCompilation: boolean): GPUComputePipeline|\n    Promise<GPUComputePipeline> => {\n      const outputData = {dtype: output.dtype, shape: output.shape};\n      const source = makeShader(inputsData, outputData, program);\n      const module = device.createShaderModule(\n          {code: source, label: program.constructor.name});\n\n      let printShaderString = env().get('WEBGPU_PRINT_SHADER') as string;\n      if (printShaderString !== '') {\n        printShaderString = printShaderString.toLowerCase();\n        const printShaderArray = printShaderString.split(',');\n        if (printShaderString === 'all' ||\n            printShaderArray.some(\n                item => program.shaderKey.toLowerCase().includes(item))) {\n          console.group(program.shaderKey);\n          console.debug(source);\n          console.groupEnd();\n        }\n      }\n\n      if (parallelCompilation) {\n        return device.createComputePipelineAsync({\n          compute: {module, entryPoint: '_start'},\n          label: program.constructor.name,\n          layout: 'auto'\n        });\n      } else {\n        return device.createComputePipeline({\n          compute: {module, entryPoint: '_start'},\n          label: program.constructor.name,\n          layout: 'auto'\n        });\n      }\n    };\n\nexport const typeSnippet = (component: number, type = 'f32') => {\n  switch (component) {\n    case 1:\n      return `${type}`;\n    case 2:\n      return `vec2<${type}>`;\n    case 3:\n      return `vec3<${type}>`;\n    case 4:\n      return `vec4<${type}>`;\n    default:\n      throw new Error(`${component}-component ${type} is not supported.`);\n  }\n};\n\nexport function getCoordsDataType(rank: number): string {\n  if (rank <= 1) {\n    return 'i32';\n  } else if (rank === 2) {\n    return `vec2<i32>`;\n  } else if (rank === 3) {\n    return `vec3<i32>`;\n  } else if (rank === 4) {\n    return `vec4<i32>`;\n  } else if (rank === 5) {\n    return `vec5`;\n  } else if (rank === 6) {\n    return `vec6`;\n  } else {\n    throw Error(`GPU for rank ${rank} is not yet supported`);\n  }\n}\n\nexport function getCoordsXYZ(index: number): string {\n  if (index === 0) {\n    return 'x';\n  } else if (index === 1) {\n    return 'y';\n  } else if (index === 2) {\n    return 'z';\n  } else if (index === 3) {\n    return 'w';\n  } else if (index === 4) {\n    return 'u';\n  } else if (index === 5) {\n    return 'v';\n  } else {\n    throw Error(`Index ${index} is not yet supported`);\n  }\n}\n\nexport function getMainHeaderString(): string;\nexport function getMainHeaderString(index: string): string;\nexport function getMainHeaderString(...params: string[]): string {\n  let snippet: string;\n  switch (params.length) {\n    case 0:\n      snippet = `\n        fn main()\n      `;\n      break;\n    case 1:\n      snippet = `\n        fn main(${params[0]} : i32)\n      `;\n      break;\n    default:\n      throw Error('Unreachable');\n  }\n  return snippet;\n}\n\nexport function getStartHeaderString(\n    useGlobalIndex: boolean, program: WebGPUProgram): string {\n  let snippet: string;\n  snippet = `\n     ${getWorkgroupSizeString(program)}\n      fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,\n                @builtin(global_invocation_id) GlobalId : vec3<u32>,\n                @builtin(local_invocation_index) LocalIndex: u32,\n                @builtin(workgroup_id) WorkgroupId : vec3<u32>,\n                @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {\n        localId = LocalId;\n        localIndex = LocalIndex;\n        globalId = GlobalId;\n        numWorkgroups = NumWorkgroups;\n        workgroupId = WorkgroupId;\n        ${useGlobalIndex ? `main(getGlobalIndex());` : `main();`};\n      }\n    `;\n  return snippet;\n}\n\nexport function getWorkgroupSizeString(program: WebGPUProgram): string {\n  return `\n  @compute @workgroup_size(${program.workgroupSize[0]}, ${\n      program.workgroupSize[1]}, ${program.workgroupSize[2]})\n`;\n}\n\nfunction makeShader(\n    inputInfo: InputInfo[], outputData: {dtype: DataType, shape: number[]},\n    program: WebGPUProgram): string {\n  const prefixSnippets: string[] = [];\n  const flatWorkgroupSize = program.workgroupSize[0] *\n      program.workgroupSize[1] * program.workgroupSize[2];\n  program.outputComponent =\n      program.outputComponent ? program.outputComponent : 1;\n  prefixSnippets.push(`\n\n      var<private> localId: vec3<u32>;\n      var<private> localIndex: u32;\n      var<private> globalId: vec3<u32>;\n      var<private> numWorkgroups: vec3<u32>;\n      var<private> workgroupId: vec3<u32>;\n\n      // Only used when the y/z dimension of workgroup size is 1.\n      fn getGlobalIndex() -> i32 {\n        ${\n      isFlatDispatch(program) ?\n          `  return i32(globalId.x);` :\n          `  return i32((workgroupId.z * numWorkgroups.x * numWorkgroups.y +\n                workgroupId.y * numWorkgroups.x + workgroupId.x) * ${\n              flatWorkgroupSize}u +\n                localIndex);\n        `}\n      }\n    `);\n\n  if (program.pixelsOpType != null) {\n    const inoutSnippet = program.pixelsOpType === PixelsOpType.FROM_PIXELS ?\n        `@group(0) @binding(0) var<storage, read_write> result: array<${\n            dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;` :\n        `@group(0) @binding(1) var<storage, read> inBuf : array<${\n            dataTypeToGPUType(inputInfo[0].dtype, program.outputComponent)}>;`;\n    const outShapeStridesType =\n        outputData.shape.length === 3 ? 'vec2<i32>' : 'i32';\n    prefixSnippets.push(`\n        struct Uniform {\n          outShapeStrides : ${outShapeStridesType},\n          size            : i32,\n          numChannels     : i32,\n          alpha           : f32,\n        };\n\n        ${inoutSnippet}\n        @group(0) @binding(2) var<uniform> uniforms: Uniform;\n      `);\n    const useGlobalIndex = isFlatDispatchLayout(program);\n    return [\n      commonSnippet,\n      prefixSnippets.join('\\n'),\n      getCoordsFromIndexSnippet(outputData.shape),\n      program.getUserCode(),\n      getStartHeaderString(useGlobalIndex, program),\n    ].join('\\n');\n  }\n\n  let stridesLength: number;\n  let stridesDataType: string;\n  let uniformDeclaration = 'struct Uniforms { NAN : f32, INFINITY : f32, ';\n  program.variableNames.forEach((x, i) => {\n    const perDataType = getCoordsDataType(inputInfo[i].shape.length);\n    uniformDeclaration +=\n        `${x.charAt(0).toLowerCase() + x.slice(1)}Shape : ${perDataType}, `;\n    stridesLength = inputInfo[i].shape.length - 1;\n    stridesDataType = getCoordsDataType(stridesLength);\n    uniformDeclaration +=\n        `${x.charAt(0).toLowerCase() + x.slice(1)}ShapeStrides: ${\n            stridesDataType}, `;\n  });\n  const outputDataType = getCoordsDataType(outputData.shape.length);\n  uniformDeclaration += `outShape : ${outputDataType}, `;\n  stridesLength = outputData.shape.length - 1;\n  stridesDataType = getCoordsDataType(stridesLength);\n  uniformDeclaration += `\n         outShapeStrides: ${stridesDataType}, `;\n\n  if (program.size) {\n    uniformDeclaration += 'size : i32, ';\n  }\n\n  if (program.uniforms) {\n    uniformDeclaration += program.uniforms;\n  }\n  uniformDeclaration += '};';\n  uniformDeclaration = insertAlignment(uniformDeclaration);\n\n  prefixSnippets.push(uniformDeclaration);\n\n  // Output buffer.\n  if (program.atomic) {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<atomic<i32>>;\n    `);\n  } else {\n    prefixSnippets.push(`\n      @group(0) @binding(0) var<storage, read_write> result: array<${\n        dataTypeToGPUType(outputData.dtype, program.outputComponent)}>;\n    `);\n  }\n  program.variableNames.forEach((x, i) => {\n    prefixSnippets.push(`\n      @group(0) @binding(${1 + i}) var<storage, read> ${x}: array<${\n        program.variableComponents ?\n            dataTypeToGPUType(\n                inputInfo[i].dtype, program.variableComponents[i]) :\n            dataTypeToGPUType(inputInfo[i].dtype, program.outputComponent)}>;\n        `);\n  });\n\n  if (uniformDeclaration !== '') {\n    prefixSnippets.push(`\n      @group(0) @binding(${\n        1 + program.variableNames.length}) var<uniform> uniforms: Uniforms;\n      `);\n  }\n\n  const coordsSnippet =\n      getOutputCoordsSnippet(outputData.shape, program.dispatchLayout);\n\n  const sources = [\n    commonSnippet, prefixSnippets.join('\\n') + isInfSnippet,\n    getCoordsFromIndexSnippet(outputData.shape), coordsSnippet,\n    getOutputIndexFromCoordsSnippet(outputData.shape.length)\n  ];\n  if (!program.atomic) {\n    sources.push(setOutputSnippet(\n        outputData.shape, outputData.dtype, program.outputComponent));\n  }\n\n  program.variableNames.forEach((x, i) => {\n    sources.push(`${getCoordsFromIndexSnippet(inputInfo[i].shape, x)}`);\n  });\n\n  const inputSnippet =\n      inputInfo\n          .map(\n              (x, i) => getInputSnippet(\n                  x, outputData.shape,\n                  program.variableComponents ? program.variableComponents[i] :\n                                               program.outputComponent,\n                  program.dispatchLayout.x.length === outputData.shape.length))\n          .join('\\n');\n  sources.push(inputSnippet);\n  sources.push(program.getUserCode());\n  const useGlobalIndex = isFlatDispatchLayout(program);\n  sources.push(getStartHeaderString(useGlobalIndex, program));\n  const source = sources.join('\\n');\n  return source;\n}\n\nexport function makeShaderKey<R extends Rank>(\n    program: WebGPUProgram, inputsData: InputInfo[],\n    output: TensorInfo): string {\n  let key = program.shaderKey;\n  if (program.pixelsOpType != null) {\n    return key;\n  }\n\n  const shapes: number[][] = [];\n  const types: Array<keyof DataTypeMap> = [];\n  inputsData.forEach(element => {\n    shapes.push(element.shape);\n    types.push(element.dtype);\n  });\n  shapes.push(output.shape);\n  types.push(output.dtype);\n\n  const broadcastDims =\n      inputsData.map(d => backend_util.getBroadcastDims(d.shape, output.shape));\n  const inputShapesEqualsOutShape =\n      inputsData.map(d => util.arraysEqual(d.shape, output.shape)).join('_');\n  const broadcastDimsKey = broadcastDims.map(d => d.join('_')).join(';');\n\n  const flatDispatchString = isFlatDispatch(program) ? 'flatDispatch' : '';\n\n  key += '_' + (program.workgroupSize ? program.workgroupSize.join(',') : '') +\n      shapes.map(shape => shape.length).join(',') + types.join(',') +\n      program.variableNames.join(',') + broadcastDimsKey +\n      inputShapesEqualsOutShape + flatDispatchString;\n\n  return key;\n}\n\nconst commonSnippet = `\n  struct vec5 {x: i32, y: i32, z: i32, w: i32, u: i32};\n  struct vec6 {x: i32, y: i32, z: i32, w: i32, u: i32, v: i32};\n\n  // Checks whether coordinates lie within the bounds of the shape.\n  fn coordsInBounds2D(coord : vec2<i32>, shape : vec2<i32>) -> bool {\n    return all(coord >= vec2<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds3D(coord : vec3<i32>, shape : vec3<i32>) -> bool {\n    return all(coord >= vec3<i32>(0)) && all(coord < shape);\n  }\n  fn coordsInBounds4D(coord : vec4<i32>, shape : vec4<i32>) -> bool {\n    return all(coord >= vec4<i32>(0)) && all(coord < shape);\n  }\n\n  fn getIndexFromCoords1D(coord : i32, shape : i32) -> i32 {\n    return coord;\n  }\n  fn getIndexFromCoords2D(coords : vec2<i32>, shape : vec2<i32>) -> i32 {\n    return dot(coords, vec2<i32>(shape.y, 1));\n  }\n  fn getIndexFromCoords3D(coords : vec3<i32>, shape : vec3<i32>) -> i32 {\n    return dot(coords, vec3<i32>(shape.y * shape.z, shape.z, 1));\n  }\n  fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n    return dot(coords, vec4<i32>(\n        shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n  }\n  fn getIndexFromCoords5D(coords : vec5, shape : vec5) -> i32 {\n    let shapeStrides: vec5 = vec5(shape.y * shape.z * shape.w * shape.u, shape.z * shape.w * shape.u, shape.w * shape.u, shape.u, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u;\n  }\n  fn getIndexFromCoords6D(coords : vec6, shape : vec6) -> i32 {\n    let shapeStrides: vec6 = vec6(shape.y * shape.z * shape.w * shape.u * shape.v, shape.z * shape.w * shape.u * shape.v, shape.w * shape.u * shape.v, shape.u * shape.v, shape.v, 1);\n    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u + coords.v*shapeStrides.v;\n  }\n\n  // NaN defination in IEEE 754-1985 is :\n  //   - sign = either 0 or 1.\n  //   - biased exponent = all 1 bits.\n  //   - fraction = anything except all 0 bits (since all 0 bits represents infinity).\n  // https://en.wikipedia.org/wiki/IEEE_754-1985#Representation_of_non-numbers\n  fn isnan(val: f32) -> bool {\n    let floatToUint: u32 = bitcast<u32>(val);\n    return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n  }\n  fn isnanVec4(val : vec4<f32>) -> vec4<bool> {\n    let floatToUint: vec4<u32> = bitcast<vec4<u32>>(val);\n    return (floatToUint & vec4<u32>(0x7fffffffu)) > vec4<u32>(0x7f800000u);\n  }\n`;\n\nconst isInfSnippet = `\n  fn isinf(val: f32) -> bool {\n    return abs(val) == uniforms.INFINITY;\n  }\n`;\n\ntype InputInfo = {\n  dtype: DataType; shape: number[]; name: string;\n};\n\n/**\n * Derives logical coordinates from a flat index. Performs integer division\n * with each stride and decrements the index until the index equals the final\n * dimension coordinate.\n */\nexport function getCoordsFromIndexSnippet(shape: number[], name = ''): string {\n  const rank = shape.length;\n  const funcName = name !== '' ?\n      `get${name.charAt(0).toUpperCase() + name.slice(1)}CoordsFromIndex` :\n      'getCoordsFromIndex';\n  const stridesName = name !== '' ?\n      `${name.charAt(0).toLowerCase() + name.slice(1)}ShapeStrides` :\n      `outShapeStrides`;\n\n  if (rank <= 1) {\n    return `fn ${funcName}(index : i32) -> i32 { return index; }`;\n  }\n\n  const strides = util.computeStrides(shape);\n  const dtype = getCoordsDataType(rank);\n\n  const coords: string[] = [];\n  for (let i = 0; i < rank; i++) {\n    coords.push(`d${i}`);\n  }\n\n  if (strides.length === 1) {\n    return `    fn ${funcName}(index : i32) -> vec2<i32> {\n      let d0 = index / uniforms.${\n        stridesName}; let d1 = index - d0 * uniforms.${stridesName};\n      return vec2<i32>(d0, d1);\n    }`;\n  }\n  let snippet;\n  snippet = 'var index2 = index;' +\n      strides\n          .map((_, i) => {\n            const line1 = `let ${coords[i]} = index2 / uniforms.${\n                stridesName}.${getCoordsXYZ(i)}`;\n            const line2 = i === strides.length - 1 ?\n                `let ${coords[i + 1]} = index2 - ${coords[i]} * uniforms.${\n                    stridesName}.${getCoordsXYZ(i)}` :\n                `index2 = index2 - ${coords[i]} * uniforms.${stridesName}.${\n                    getCoordsXYZ(i)}`;\n            return `${line1}; ${line2};`;\n          })\n          .join('');\n\n  return `\n    fn ${funcName}(index : i32) -> ${dtype} {\n      ${snippet}\n      return ${dtype}(${coords.join(',')});\n    }\n  `;\n}\n\nfunction getInputAtCoordsSnippet(\n    inputInfo: InputInfo, component: number): string {\n  const texName = inputInfo.name;\n  const rank = inputInfo.shape.length;\n  const type = getCoordsDataType(rank);\n  const funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n  const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, rank);\n  const inputs = dims.map(d => `${d} : i32`).join(', ');\n\n  if (rank < 1) {\n    return `\n      fn ${funcName}() -> ${typeSnippet(component)} {\n        return ${typeSnippet(component)}(${texName}[0]);\n      }\n    `;\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  let rankStr = `${rank}D`;\n  if (rank === 0) {\n    rankStr = '1D';\n  }\n\n  return `\n    fn ${funcName}(${inputs}) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[getIndexFromCoords${\n      rankStr}(${type}(${dims.join(',')}),\n        ${shapeStr})${component === 1 ? '' : ` / ${component}`}]);\n    }\n   `;\n}\n\nfunction getInputByOutputSnippet(\n    inputInfo: InputInfo, outShape: number[], component: number,\n    isFlatDispatchLayout: boolean): string {\n  const texName = inputInfo.name;\n  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n\n  const funcName = 'get' + texFuncSnippet + 'ByOutput';\n\n  const inRank = inputInfo.shape.length;\n  const outRank = outShape.length;\n  const type = getCoordsDataType(outRank);\n\n  // If the inShape equals the outShape and the dispatch layout is flat, we can\n  // directly use |gl_GlobalInvocationID.x| as the index and don't need coords\n  // conversion between these two shapes.\n  if (util.arraysEqual(inputInfo.shape, outShape) && isFlatDispatchLayout) {\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[globalIndex]);\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)} {\n      return ${typeSnippet(component)}(${texName}[${\n        outRank > 1 ? 'getOutputIndexFromCoords(coords)' :\n                      'coords'}${component === 1 ? '' : ` / ${component}`}]);\n    }\n    `;\n  }\n\n  const broadcastDims =\n      backend_util.getBroadcastDims(inputInfo.shape, outShape);\n  const rankDiff = outRank - inRank;\n\n  let coordsSnippet = '';\n\n  if (inRank === 0) {\n    return `\n    fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)}{\n      return get${texFuncSnippet}();\n    }\n\n    fn ${funcName}Coords(coords : ${type}) -> ${typeSnippet(component)}{\n      return get${texFuncSnippet}();\n    }\n  `;\n  } else {\n    if (outRank < 2 && broadcastDims.length >= 1) {\n      coordsSnippet = 'coords = 0;';\n    } else {\n      coordsSnippet =\n          broadcastDims.map(d => `coords.${getCoordsXYZ(d + rankDiff)} = 0;`)\n              .join('\\n');\n    }\n  }\n\n  let unpackedCoordsSnippet = '';\n  if (outRank < 2 && inRank > 0) {\n    unpackedCoordsSnippet = 'coords';\n  } else {\n    if (outRank > 1) {\n      const coordsType = getCoordsDataType(inRank);\n      const coordsValues =\n          inputInfo.shape.map((s, i) => `coords.${getCoordsXYZ(i + rankDiff)}`)\n              .join(', ');\n      unpackedCoordsSnippet = `${coordsType}(${coordsValues})`;\n    } else {\n      unpackedCoordsSnippet = 'coords';\n    }\n  }\n\n  const shapeStr =\n      `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;\n  const rankStr = `${inRank}D`;\n\n  return `\n  fn ${funcName}Index(globalIndex : i32) -> ${typeSnippet(component)} {\n    var coords = getCoordsFromIndex(globalIndex);\n    ${coordsSnippet}\n    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})${\n      component === 1 ? '' : ` / ${component}`}]);\n  }\n\n  fn ${funcName}Coords(coordsIn : ${type}) -> ${typeSnippet(component)} {\n    var coords = coordsIn;\n    ${coordsSnippet}\n    return ${typeSnippet(component)}(${texName}[getIndexFromCoords${rankStr}(${\n      unpackedCoordsSnippet}, ${shapeStr})${\n      component === 1 ? '' : ` / ${component}`}]);\n  }\n`;\n}\n\nfunction getInputSnippet(\n    inputInfo: InputInfo, outShape: number[], component: number,\n    isFlatDispatchLayout: boolean): string {\n  let res = getInputAtCoordsSnippet(inputInfo, component);\n\n  const inShape = inputInfo.shape;\n  if (inShape.length <= outShape.length) {\n    res += getInputByOutputSnippet(\n        inputInfo, outShape, component, isFlatDispatchLayout);\n  }\n\n  return res;\n}\n\n/**\n * Generates getOutputCoords() function that computes output coordinates\n * from dispatch geometry to reduce arithmetic.\n */\nfunction getOutputCoordsSnippet(\n    outShape: number[],\n    dispatchLayout: {x: number[], y?: number[], z?: number[]}): string {\n  const {x, y = [], z = []} = dispatchLayout;\n\n  const outRank = outShape.length;\n  const rank = x.length + y.length + z.length;\n  // getOutputCoords is only meaningful when the output rank is same with\n  // dispatch layout rank.\n  if (rank !== outRank) {\n    return '';\n  }\n\n  if (x.length === outRank) {\n    const dtype = getCoordsDataType(outRank);\n    const snippet = `fn getOutputCoords() -> ${dtype}{\n    let globalIndex = getGlobalIndex();\n    return getCoordsFromIndex(globalIndex);\n  }\n  `;\n    return snippet;\n  }\n\n  let gatherDimensionsStr = '';\n  const dims = [x, y, z];\n\n  for (let i = 0; i < dims.length; i++) {\n    const arr = dims[i];\n\n    if (arr.length === 0) {\n      continue;\n    }\n\n    if (arr.length === 1) {\n      gatherDimensionsStr += `let d${arr[0]} = i32(globalId[${i}]);`;\n    } else {\n      const strides = symbolicallyComputeStrides(arr, 'uniforms.outShape');\n      gatherDimensionsStr += `var index${i} = i32(globalId[${i}]);`;\n      for (let j = 0; j < strides.length; j++) {\n        gatherDimensionsStr += `let d${arr[j]} = index${i} / ${strides[j]};`;\n\n        if (j === strides.length - 1) {\n          gatherDimensionsStr += `let d${arr[j + 1]} = ` +\n              `index${i} - d${arr[j]} * ${strides[j]};`;\n        } else {\n          gatherDimensionsStr +=\n              `index${i} = index${i} - d${arr[j]} * ${strides[j]};`;\n        }\n      }\n    }\n  }\n\n  const dimensions = [];\n  for (let i = 0; i < rank; i++) {\n    dimensions.push(`d${i}`);\n  }\n\n  const dtype = getCoordsDataType(rank);\n  let snippet = `fn getOutputCoords() -> ${dtype} {\n  ${gatherDimensionsStr}\n`;\n  if (dimensions.length === 0) {\n    snippet += `return ${dtype}(0); }`;\n  } else {\n    snippet += `return ${dtype}(${dimensions.join(',')}); }`;\n  }\n\n  return snippet;\n}\n\nfunction getOutputIndexFromCoordsSnippet(outRank: number) {\n  let snippet = '';\n  switch (outRank) {\n    case 0:\n    case 1:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : i32) -> i32 {\n          return coords;\n        }\n        `;\n      break;\n    case 2:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec2<i32>) -> i32 {\n          return dot(coords, vec2<i32>(uniforms.outShapeStrides, 1));\n        }\n        `;\n      break;\n    case 3:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec3<i32>) -> i32 {\n          return dot(coords, vec3<i32>(uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, 1));\n        }\n        `;\n      break;\n    case 4:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n          return dot(coords, vec4<i32>(\n            uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, uniforms.outShapeStrides.z, 1));\n        }\n        `;\n      break;\n    case 5:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec5) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u;\n        }\n        `;\n      break;\n    case 6:\n      snippet += `\n        fn getOutputIndexFromCoords(coords : vec6) -> i32 {\n          return coords.x * uniforms.outShapeStrides.x +\n              coords.y * uniforms.outShapeStrides.y +\n              coords.z * uniforms.outShapeStrides.z +\n              coords.w * uniforms.outShapeStrides.w +\n              coords.u * uniforms.outShapeStrides.u +\n              coords.v;\n        }\n        `;\n      break;\n    default:\n      util.assert(false, () => `Unsupported ${outRank}D shape`);\n      break;\n  }\n  return snippet;\n}\n\nfunction isFlatDispatch(program: WebGPUProgram): boolean {\n  return program.dispatch[1] === 1 && program.dispatch[2] === 1;\n}\n\nexport function dataTypeToGPUType(type: DataType, component = 1) {\n  if (type === 'float32') {\n    return typeSnippet(component, 'f32');\n  } else if (type === 'int32' || type === 'bool') {\n    return typeSnippet(component, 'i32');\n  }\n  throw new Error(`type ${type} is not supported.`);\n}\n\nfunction setOutputSnippet(\n    outShape: number[], outBufferType: DataType, component: number): string {\n  const outRank = outShape.length;\n  const gpuType = dataTypeToGPUType(outBufferType, component);\n  let snippet =\n      `fn setOutputAtIndex(flatIndex : i32, value : ${typeSnippet(component)}) {\n      result[flatIndex] = ${gpuType}(value);\n    }\n\n    fn setOutputAtIndexI32(flatIndex : i32, value : ${\n          typeSnippet(component, 'i32')}) {\n      result[flatIndex] = ${gpuType}(value);\n    }\n    `;\n  if (outRank >= 2) {\n    const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, outRank);\n    const type = getCoordsDataType(outRank);\n\n    snippet += `\n      fn setOutputAtCoords(${dims.map(d => `${d} : i32`).join(', ')}, value : ${\n        typeSnippet(component)}) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndex(flatIndex${\n        component === 1 ? '' : ` / ${component}`}, value);\n      }\n      fn setOutputAtCoordsI32(${\n        dims.map(d => `${d} : i32`).join(', ')}, value : ${\n        typeSnippet(component, 'i32')}) {\n        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));\n        setOutputAtIndexI32(flatIndex${\n        component === 1 ? '' : ` / ${component}`}, value);\n      }\n    `;\n  }\n\n  return snippet;\n}\n\nfunction insertAlignment(uniformShader: string) {\n  // insert alignment when current pattern is vec5 or vec6\n  const curInsertRe = /(\\w+)\\s*:\\s*vec(5|6)/g;\n  uniformShader = uniformShader.replace(curInsertRe, (match) => {\n    return '@align(16) ' + match;\n  });\n\n  // insert alignment when previous pattern is vec5 or vec6\n  const preInsertRe = /vec(5|6)\\s*,\\s*(\\w+)/g;\n  uniformShader = uniformShader.replace(preInsertRe, (_, p1, p2) => {\n    return `vec${p1}, @align(16) ${p2}`;\n  });\n  return uniformShader;\n}\nfunction isFlatDispatchLayout(program: WebGPUProgram): boolean {\n  if (program.dispatchLayout.hasOwnProperty('y') &&\n      program.dispatchLayout.y.length !== 0) {\n    return false;\n  }\n  if (program.dispatchLayout.hasOwnProperty('z') &&\n      program.dispatchLayout.z.length !== 0) {\n    return false;\n  }\n  return true;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nconst arrayProduct = (arr: number[]) => {\n  let product = 1;\n  for (let i = 0; i < arr.length; i++) {\n    product *= arr[i];\n  }\n  return product;\n};\n\nexport function tilesFitEvenlyIntoShape(\n    tileSize: number[], shape: number[]): boolean {\n  if (tileSize.length !== shape.length) {\n    throw new Error(\n        `Cannot compute whether rank ${tileSize.length}` +\n        ` tiles fit evenly into rank ${shape.length} shape` +\n        ` - ranks must match.`);\n  }\n  return shape.every(\n      (dim: number, dimIdx: number) => dim % tileSize[dimIdx] === 0);\n}\n\n// Computes dispatch geometry based on layout of output dimensions and\n// workgroupSize.\nexport function computeDispatch(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    workgroupSize: [number, number, number] = [1, 1, 1],\n    elementsPerThread: [number, number, number] =\n        [1, 1, 1]): [number, number, number] {\n  const [dispatchX, dispatchY, dispatchZ] = [\n    Math.ceil(\n        arrayProduct(layout.x.map(d => outputShape[d])) /\n        (workgroupSize[0] * elementsPerThread[0])),\n    layout.y ? Math.ceil(\n                   arrayProduct(layout.y.map(d => outputShape[d])) /\n                   (workgroupSize[1] * elementsPerThread[1])) :\n               1,\n    layout.z ? Math.ceil(\n                   arrayProduct(layout.z.map(d => outputShape[d])) /\n                   (workgroupSize[2] * elementsPerThread[2])) :\n               1\n  ];\n  return [dispatchX, dispatchY, dispatchZ];\n}\n\nexport type WorkgroupInfo = {\n  workgroupSize: [number, number, number],\n  elementsPerThread: [number, number, number],\n};\n\nexport function computeWorkgroupInfoForMatMul(\n    dimAOuter: number, dimInner: number, dimBOuter: number,\n    transposeA = false): WorkgroupInfo {\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the input shapes to improve the EU occupancy.\n  // TODO: WebGPU limits the maximum allowed shared memory size as 16K. To make\n  // sure it doesn't exceed this limitations. Temporarily reduce the work group\n  // size to [8, 8, 1] and the work per thread size is [4, 4, 1]. But we should\n  // revisit it and find the balance between work group size and work per thread\n  // size.\n  const workgroupSize: [number, number, number] = [8, 8, 1];\n  const elementsPerThread: [number, number, number] = [4, 4, 1];\n\n  if (!transposeA) {\n    if (dimAOuter <= 8) {\n      elementsPerThread[1] = 1;\n    }\n\n    if (dimInner <= 16 && dimBOuter <= 16) {\n      workgroupSize[0] = 4;\n    }\n  }\n\n  return {workgroupSize, elementsPerThread};\n}\n\nexport function computeWorkgroupSizeForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [8, 8, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // These are experimental values. Usually, we need to adjust the work group\n  // size based on the output shape. For example, when one dimension is smaller\n  // than 4, it will be wasteful if we assign a larger size for this dimension,\n  // which results lots of threads doing useless work and reduces parallelism\n  // of hardware threads. But it is always a balance between work group size\n  // and shared memory. If one dimension is too small, such as 1, shared memory\n  // will won't be fully utilized.\n  if (dim0 <= 4) {\n    return [4, 16, 1];\n  }\n  if (dim1 <= 4) {\n    return [16, 4, 1];\n  }\n\n  return [16, 16, 1];\n}\n\nexport function computeWorkPerThreadForConv2d(\n    layout: {x: number[], y?: number[], z?: number[]}, outputShape: number[],\n    isVec4 = false): [number, number, number] {\n  if (isVec4) {\n    return [4, 4, 1];\n  }\n\n  const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));\n  const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));\n  // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.\n  // The following conditions correspond to the values set in\n  // computeWorkgroupSizeForConv2d.\n  if (dim0 <= 4) {\n    return [1, 2, 1];\n  }\n  if (dim1 <= 4) {\n    return [2, 1, 1];\n  }\n\n  return [2, 2, 1];\n}\n\nexport function flatDispatchLayout(shape: number[]) {\n  return {x: shape.map((d, i) => i)};\n}\n\nexport function GPUBytesPerElement(dtype: DataType): number {\n  if (dtype === 'float32' || dtype === 'int32' || dtype === 'bool' ||\n      dtype === 'string') {\n    return 4;\n  } else if (dtype === 'complex64') {\n    return 8;\n  } else {\n    throw new Error(`Unknown dtype ${dtype}`);\n  }\n}\n\nexport function isWebGPUSupported(): boolean {\n  return ((typeof window !== 'undefined') ||\n          //@ts-ignore\n          (typeof WorkerGlobalScope !== 'undefined')) &&\n      !!navigator.gpu;\n}\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${opName} does not support complex64 tensors ` +\n              'in the WebGPU backend.');\n    }\n  });\n}\n\nexport enum MatMulProgramType {\n  MatMulReduceProgram,\n  MatMulSplitKProgram,\n  MatMulSmallOutputSizeProgram,\n  MatMulPackedProgram,\n  MatMulMax\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {backend_util, BackendValues, buffer, DataStorage, DataType, engine, env, GPUData, KernelBackend, Rank, RecursiveArray, ShapeMap, Tensor, TensorBuffer, TensorInfo, TimingInfo, TypedArray, util, WebGPUData} from '@tensorflow/tfjs-core';\n\nimport {AdapterInfo} from './adapter_info';\nimport {BufferManager} from './buffer_manager';\nimport {TextureManager} from './texture_manager';\nimport * as webgpu_program from './webgpu_program';\nimport * as webgpu_util from './webgpu_util';\n\nexport interface WebGPUMemoryInfo extends backend_util.MemoryInfo {\n  numBytesInGPU: number;\n  numBytesAllocatedInGPU: number;\n  unreliable: boolean;\n}\n\ntype TensorData = {\n  values: BackendValues,\n  dtype: DataType,\n  shape: number[],\n  refCount: number,\n  resource?: GPUBuffer|GPUTexture|GPUExternalTexture,\n  // external is true means we use the resource provided by users directly\n  // (without a copy), so users should be responsible for its release.\n  external?: boolean,\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo}\n};\n\ninterface DataId {}\n\nexport type WebGPUKernelInfo = {\n  name: string,\n  query: Promise<number>,\n};\n\nexport type TimerNode = RecursiveArray<WebGPUKernelInfo>|WebGPUKernelInfo;\n\nexport interface WebGPUTimingInfo extends TimingInfo {\n  uploadWaitMs: number;\n  downloadWaitMs: number;\n}\n\ntype ProgramUniform = Array<{type: string; data: number[]}>;\n\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nconst CPU_HANDOFF_SIZE_THRESHOLD =\n    env().getNumber('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD');\n\n// Reshape dispatch, not to exceed device limits.\nconst reshapeDispatch =\n    (device: GPUDevice,\n     program: webgpu_program.WebGPUProgram): [number, number, number] => {\n      const MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE =\n          device.limits.maxComputeWorkgroupsPerDimension;\n      const layout = program['dispatchLayout'];\n      const dispatch = program['dispatch'];\n      if (dispatch.every((d) => d <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE)) {\n        return dispatch;\n      }\n\n      util.assert(\n          dispatch[0] > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE &&\n              layout.y === undefined && layout.z === undefined,\n          () => 'Dispatch size exceeds WebGPU limits in Y or Z dimension.');\n\n      let dispatchAverage = Math.ceil(Math.sqrt(dispatch[0]));\n      if (dispatchAverage > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE) {\n        dispatchAverage = Math.ceil(Math.cbrt(dispatch[0]));\n        util.assert(\n            dispatchAverage <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE,\n            () => 'Total dispatch size exceeds WebGPU maximum.');\n        return [dispatchAverage, dispatchAverage, dispatchAverage];\n      } else {\n        return [dispatchAverage, dispatchAverage, 1];\n      }\n    };\n\nexport class WebGPUBackend extends KernelBackend {\n  bufferManager: BufferManager;\n  adapterInfo: AdapterInfo;\n  device: GPUDevice;\n  queue: GPUQueue;\n  tensorMap: DataStorage<TensorData>;\n  textureManager: TextureManager;\n  thresholdToIncreaseWorkgroups: number;\n\n  private activeTimers: TimerNode[];\n  private commandEncoder: GPUCommandEncoder;\n  private computePassEncoder: GPUComputePassEncoder;\n  private commandQueueOwnedIds = new WeakSet<DataId>();\n  private dispatchCountInPass = 0;\n  private disposed = false;\n  private downloadWaitMs = 0;\n  private dummyCanvas: HTMLCanvasElement;\n  private dummyContext: GPUCanvasContext;\n  private tensorDataPendingDisposal: DataId[] = [];\n  private static nextDataId = 0;\n  private pipelineCache:\n      {[key: string]: GPUComputePipeline|Promise<GPUComputePipeline>};\n  private programTimersStack: TimerNode[];\n  private queryResolveBuffer: GPUBuffer = null;\n  private querySet: GPUQuerySet = null;\n  private querySetCount = 2;\n  private stagingPendingDisposal: GPUBuffer[] = [];\n  private supportTimestampQuery: boolean;\n  private uniformPendingDisposal: GPUBuffer[] = [];\n  private uploadWaitMs = 0;\n  private hasReadSyncWarned = false;\n  private hasTimestampQueryWarned = false;\n\n  private nextDataId(): number {\n    return WebGPUBackend.nextDataId++;\n  }\n\n  constructor(device: GPUDevice, adapterInfo?: GPUAdapterInfo) {\n    super();\n    if (!webgpu_util.isWebGPUSupported()) {\n      throw new Error('WebGPU is not supported on this device');\n    }\n    this.pipelineCache = {};\n    this.device = device;\n    this.queue = device.queue;\n    this.commandEncoder = null;\n    this.computePassEncoder = null;\n    this.adapterInfo = new AdapterInfo(adapterInfo);\n    this.supportTimestampQuery = this.device.features.has('timestamp-query');\n    this.thresholdToIncreaseWorkgroups =\n        this.adapterInfo.intelGPUGeneration >= 12 ? 16 : 8;\n\n    this.bufferManager = new BufferManager(this.device);\n    this.textureManager = new TextureManager(this.device);\n    this.tensorMap = new DataStorage(this, engine());\n\n    // Profiling tools like PIX needs this dummy canvas to\n    // trigger capturing a frame.\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      this.dummyCanvas = document.createElement('canvas');\n      this.dummyCanvas.width = 1;\n      this.dummyCanvas.height = 1;\n\n      this.dummyContext = this.dummyCanvas.getContext('webgpu');\n      this.dummyContext.configure({\n        device,\n        format: 'bgra8unorm',\n      });\n\n      document.body.appendChild(this.dummyCanvas);\n    }\n  }\n\n  override floatPrecision(): 32 {\n    return 32;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or delayed in this backend, false if there are still\n   * references.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  override disposeData(dataId: DataId, force = false): boolean {\n    // No-op if already disposed.\n    if (!this.tensorMap.has(dataId)) {\n      return true;\n    }\n\n    const tensorData = this.tensorMap.get(dataId);\n    if (force) {\n      tensorData.refCount = 0;\n    } else {\n      tensorData.refCount--;\n    }\n\n    if (tensorData.refCount > 0) {\n      return false;\n    }\n\n    if (tensorData.complexTensorInfos != null) {\n      this.disposeData(tensorData.complexTensorInfos.real.dataId);\n      this.disposeData(tensorData.complexTensorInfos.imag.dataId);\n    }\n\n    if (this.commandQueueOwnedIds.has(dataId)) {\n      this.tensorDataPendingDisposal.push(dataId);\n      return true;\n    }\n\n    this.releaseResource(dataId);\n    this.tensorMap.delete(dataId);\n\n    return true;\n  }\n\n  override memory(): WebGPUMemoryInfo {\n    return {\n      numBytesInGPU: this.bufferManager.numBytesUsed,\n      numBytesAllocatedInGPU: this.bufferManager.numBytesAllocated,\n      unreliable: false\n    } as WebGPUMemoryInfo;\n  }\n\n  private releaseResource(dataId: DataId) {\n    const tensorData = this.tensorMap.get(dataId);\n    if (!tensorData || !tensorData.resource) {\n      return;\n    }\n\n    // If tensor's resource is from external, do not release.\n    if (tensorData.external) {\n      tensorData.resource = null;\n      return;\n    }\n    if (tensorData.resource instanceof GPUBuffer) {\n      this.bufferManager.releaseBuffer(tensorData.resource);\n    } else if (tensorData.resource instanceof GPUTexture) {\n      this.textureManager.releaseTexture(tensorData.resource);\n    }\n    tensorData.resource = null;\n  }\n\n  /** Return refCount of a `TensorData`. */\n  override refCount(dataId: DataId): number {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  override incRef(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.tensorMap.has(dataId)) {\n      const tensorData = this.tensorMap.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  override write(values: BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (dtype === 'complex64' && values != null) {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    const dataId = {id: this.nextDataId()};\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount: 1});\n    return dataId;\n  }\n\n  override move(\n      dataId: DataId, values: BackendValues, shape: number[], dtype: DataType,\n      refCount: number): void {\n    if (dtype === 'complex64') {\n      throw new Error(\n          `Cannot write to a complex64 dtype. ` +\n          `Please use tf.complex(real, imag).`);\n    }\n    this.tensorMap.set(dataId, {dtype, shape, values, refCount});\n  }\n\n  submitQueue() {\n    this.queue.submit([this.commandEncoder.finish()]);\n    this.commandEncoder = null;\n    this.dispatchCountInPass = 0;\n\n    this.commandQueueOwnedIds = new WeakSet<DataId>();\n\n    this.tensorDataPendingDisposal.forEach(d => {\n      this.releaseResource(d);\n      this.tensorMap.delete(d);\n    });\n\n    this.uniformPendingDisposal.forEach(\n        b => this.bufferManager.releaseBuffer(b));\n    this.stagingPendingDisposal.forEach(\n        b => this.bufferManager.releaseBuffer(b, false));\n\n    this.tensorDataPendingDisposal = [];\n    this.uniformPendingDisposal = [];\n    this.stagingPendingDisposal = [];\n  }\n\n  ensureCommandEncoderReady() {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n  }\n\n  endComputePassEncoder() {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  // Check if parallel compilation is done.\n  async checkCompileCompletionAsync() {\n    let pipelines: GPUComputePipeline[];\n    try {\n      pipelines = await Promise.all(Object.values(this.pipelineCache));\n    } catch (e) {\n      // TODO: Add test case to catch this exception.\n      throw new Error(e.message);\n    }\n    Object.keys(this.pipelineCache).map((key, i) => {\n      this.pipelineCache[key] = pipelines[i];\n    });\n  }\n\n  public async getBufferData(buffer: GPUBuffer): Promise<ArrayBuffer> {\n    if (env().getBool('WEBGPU_ENGINE_COMPILE_ONLY')) {\n      console.warn(\n          'The data may be invalid since WEBGPU_ENGINE_COMPILE_ONLY is true, this can only be called when WEBGPU_ENGINE_COMPILE_ONLY is false');\n      return null;\n    }\n    const size = buffer.size;\n    const stagingBuffer = this.bufferManager.acquireBuffer(\n        size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(buffer, 0, stagingBuffer, 0, size);\n    this.submitQueue();\n\n    await stagingBuffer.mapAsync(GPUMapMode.READ);\n    const values = stagingBuffer.getMappedRange().slice(0);\n\n    stagingBuffer.unmap();\n    if (stagingBuffer != null) {\n      this.bufferManager.releaseBuffer(stagingBuffer);\n    }\n\n    // Need to get texture from swapChain to enable profiling tool\n    // to capture a frame\n    if (env().getBool('WEBGPU_USE_PROFILE_TOOL')) {\n      util.assert(\n          this.dummyContext !== undefined,\n          () => `Fail to get context for profiling tool`);\n      this.dummyContext.getCurrentTexture();\n    }\n\n    return values;\n  }\n\n  private convertAndCacheOnCPU(dataId: DataId, data: BackendValues):\n      BackendValues {\n    const tensorData = this.tensorMap.get(dataId);\n    tensorData.values = data;\n    return tensorData.values;\n  }\n\n  override readSync(dataId: object): BackendValues {\n    const tensorData = this.tensorMap.get(dataId);\n    const {values, complexTensorInfos} = tensorData;\n\n    if (values != null || tensorData.dtype === 'string') {\n      return values;\n    }\n\n    if (tensorData.dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      const complexVals = util.convertBackendValuesAndArrayBuffer(\n          backend_util.mergeRealAndImagArrays(realValues, imagValues).buffer,\n          'float32');\n      this.convertAndCacheOnCPU(dataId, complexVals);\n      return complexVals;\n    }\n\n    if (!this.hasReadSyncWarned) {\n      this.hasReadSyncWarned = true;\n      console.warn(\n          `The performance of synchronously reading data from GPU to CPU is ` +\n          `poor on the webgpu backend, please use asynchronous APIs instead.`);\n    }\n\n    const alphaModes: GPUCanvasAlphaMode[] = ['opaque', 'premultiplied'];\n\n    const buffer = tensorData.resource as GPUBuffer;\n    const bufferSize = buffer.size;\n    util.assert(\n        bufferSize % 4 === 0,\n        () => 'Because there is 4 bytes for ' +\n            'one pixel, buffer size must be multiple of 4.');\n    const pixelsSize = bufferSize / 4;\n    const valsGPU = new ArrayBuffer(bufferSize);\n    // TODO: adjust the reading window size according the `bufferSize`.\n    const canvasWidth = 256, canvasHeight = 256;\n    const stagingDeviceStorage: OffscreenCanvas[] =\n        alphaModes.map(_ => new OffscreenCanvas(canvasWidth, canvasHeight));\n    const stagingHostStorage = new OffscreenCanvas(canvasWidth, canvasHeight);\n\n    this.endComputePassEncoder();\n    stagingDeviceStorage\n        .map((storage, index) => {\n          const context = storage.getContext('webgpu');\n          // TODO: use rgba8unorm format when this format is supported on Mac.\n          // https://bugs.chromium.org/p/chromium/issues/detail?id=1298618\n          context.configure({\n            device: this.device,\n            format: 'bgra8unorm',\n            usage: GPUTextureUsage.COPY_DST,\n            alphaMode: alphaModes[index],\n          });\n          return context.getCurrentTexture();\n        })\n        .map((texture, index) => {\n          const bytesPerRow = canvasWidth * 4;\n          const readDataGPUToCPU =\n              (width: number, height: number, offset: number) => {\n                this.ensureCommandEncoderReady();\n                this.commandEncoder.copyBufferToTexture(\n                    {\n                      buffer,\n                      bytesPerRow,\n                      offset,\n                    },\n                    {\n                      texture,\n                    },\n                    {\n                      width,\n                      height,\n                    });\n                this.submitQueue();\n\n                const context = stagingHostStorage.getContext('2d', {\n                  willReadFrequently: true,\n                });\n                context.clearRect(0, 0, width, height);\n                context.drawImage(stagingDeviceStorage[index], 0, 0);\n                const stagingValues =\n                    context.getImageData(0, 0, width, height).data;\n                const alphaMode = alphaModes[index];\n                const span =\n                    new Uint8ClampedArray(valsGPU, offset, width * height * 4);\n                for (let k = 0; k < span.length; k += 4) {\n                  if (alphaMode === 'premultiplied') {\n                    span[k + 3] = stagingValues[k + 3];\n                  } else {\n                    const value = stagingValues[k];\n                    span[k] = stagingValues[k + 2];\n                    span[k + 1] = stagingValues[k + 1];\n                    span[k + 2] = value;\n                  }\n                }\n              };\n\n          const fullyReadCount =\n              Math.floor(pixelsSize / (canvasWidth * canvasHeight));\n          let width = canvasWidth, height = canvasHeight, offset = 0;\n          for (let i = 0; i < fullyReadCount; i++) {\n            // Read the buffer data, which fully fill the whole canvas.\n            readDataGPUToCPU(width, height, offset);\n            offset += canvasWidth * canvasHeight * 4;\n          }\n\n          const remainSize = pixelsSize % (canvasWidth * canvasHeight);\n          height = Math.floor(remainSize / canvasWidth);\n          if (height > 0) {\n            // Read the buffer data, which fully fill certain rows of canvas.\n            readDataGPUToCPU(width, height, offset);\n            offset += height * (canvasWidth * 4);\n          }\n\n          width = remainSize % canvasWidth;\n          if (width > 0) {\n            // Read the buffer data, which not fully fill one row of canvas.\n            readDataGPUToCPU(width, 1, offset);\n          }\n        });\n\n    const vals =\n        util.convertBackendValuesAndArrayBuffer(valsGPU, tensorData.dtype);\n    this.convertAndCacheOnCPU(dataId, vals);\n    return vals;\n  }\n\n  override async read(dataId: object): Promise<BackendValues> {\n    if (!this.tensorMap.has(dataId)) {\n      throw new Error(`Tensor ${dataId} was not registered!`);\n    }\n    const tensorData = this.tensorMap.get(dataId);\n\n    const {values} = tensorData;\n\n    if (values != null) {\n      return values;\n    }\n\n    // Download the values from the GPU.\n    let vals: BackendValues;\n    if (tensorData.dtype === 'complex64') {\n      const ps = await Promise.all([\n        this.read(tensorData.complexTensorInfos.real.dataId),\n        this.read(tensorData.complexTensorInfos.imag.dataId)\n      ]);\n\n      const realValues = ps[0];\n      const imagValues = ps[1];\n      vals = backend_util.mergeRealAndImagArrays(\n          realValues as Float32Array, imagValues as Float32Array);\n    } else {\n      const data = await this.getBufferData(tensorData.resource as GPUBuffer);\n      vals = util.convertBackendValuesAndArrayBuffer(data, tensorData.dtype);\n    }\n    this.convertAndCacheOnCPU(dataId, vals);\n    return vals;\n  }\n\n  // The source GPUBuffer and destination GPUBuffer have the same size and\n  // usage.\n  private copyBuffer(srcBuffer: GPUBuffer) {\n    const size = srcBuffer.size;\n    const usage = srcBuffer.usage;\n    const dstBuffer = this.bufferManager.acquireBuffer(size, usage);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, size);\n    this.submitQueue();\n    return dstBuffer;\n  }\n\n  /**\n   * Create a TF.js tensor out of an existing WebGPU buffer.\n   */\n  override createTensorFromGPUData(\n      webGPUData: WebGPUData, shape: number[], dtype: DataType): Tensor {\n    let buffer = webGPUData.buffer;\n    if (dtype === 'complex64') {\n      throw new Error(`Cannot write to a complex64 dtype. `);\n    }\n    const dataId = {id: this.nextDataId()};\n    this.tensorMap.set(dataId, {\n      dtype,\n      shape,\n      values: null,\n      refCount: 1,\n      external: webGPUData.zeroCopy\n    });\n    const tensorData = this.tensorMap.get(dataId);\n    const size = webgpu_util.GPUBytesPerElement(tensorData.dtype) *\n        util.sizeFromShape(tensorData.shape);\n    if (webGPUData.buffer.size < size) {\n      throw new Error(`GPUBuffer size(${\n          webGPUData.buffer.size}) is smaller than tensor size(${size})!`);\n    } else if (\n        (webGPUData.buffer.usage &\n         (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) !==\n        (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) {\n      throw new Error(\n          'GPUBuffer.usage should include GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC!');\n    }\n\n    // Do buffer copy by default.\n    if (webGPUData.zeroCopy !== true) {\n      buffer = this.copyBuffer(buffer);\n    }\n    tensorData.resource = buffer;\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n  }\n\n  /**\n   * Read tensor to a new GPUBuffer.\n   * @param dataId The source tensor.\n   */\n  override readToGPU(dataId: DataId): GPUData {\n    const srcTensorData = this.tensorMap.get(dataId);\n    const {values, dtype, shape, resource} = srcTensorData;\n\n    if (dtype === 'complex64') {\n      throw new Error('Does not support reading buffer for complex64 dtype.');\n    }\n\n    if (resource == null) {\n      if (values != null) {\n        throw new Error('Data is not on GPU but on CPU.');\n      } else {\n        throw new Error('There is no data on GPU or CPU.');\n      }\n    }\n\n    const srcBuffer = resource as GPUBuffer;\n    const size = srcBuffer.size;\n    const usage = srcBuffer.usage;\n    const buffer = this.bufferManager.acquireBuffer(size, usage);\n    this.ensureCommandEncoderReady();\n    this.endComputePassEncoder();\n    this.commandEncoder.copyBufferToBuffer(\n        resource as GPUBuffer, 0, buffer, 0, size);\n    this.submitQueue();\n\n    const tensorInfo = this.makeTensorInfo(shape, dtype);\n    // Make engine track this tensor, so that we can dispose it later.\n    const tensorRef = engine().makeTensorFromTensorInfo(tensorInfo);\n\n    const tensorData = this.tensorMap.get(tensorInfo.dataId);\n    tensorData.resource = buffer;\n\n    return {tensorRef, buffer};\n  }\n\n  bufferSync<R extends Rank, D extends DataType>(t: TensorInfo):\n      TensorBuffer<R, D> {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = (data as Uint8Array[]).map(d => util.decodeString(d));\n        return buffer(t.shape as ShapeMap[R], t.dtype, strings) as\n            TensorBuffer<R, D>;\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, data as TypedArray) as\n        TensorBuffer<R, D>;\n  }\n\n  override async time(f: () => void): Promise<WebGPUTimingInfo> {\n    if (!this.supportTimestampQuery && !this.hasTimestampQueryWarned) {\n      console.warn(\n          `This device doesn't support timestamp-query extension. ` +\n          `Start Chrome browser with flag ` +\n          `--disable-dawn-features=disallow_unsafe_apis to try it again. ` +\n          `Otherwise, zero will be shown for the kernel time when profiling ` +\n          `mode is enabled.`);\n      this.hasTimestampQueryWarned = true;\n    }\n\n    const oldActiveTimers = this.activeTimers;\n    const newActiveTimers: TimerNode[] = [];\n\n    let outerMostTime = false;\n    if (this.programTimersStack == null) {\n      this.programTimersStack = newActiveTimers;\n      outerMostTime = true;\n    } else {\n      this.activeTimers.push(newActiveTimers);\n    }\n    this.activeTimers = newActiveTimers;\n\n    f();\n\n    const flattenedActiveTimerQueries =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.query))\n            .filter(d => d != null);\n    const flattenedActiveTimerNames =\n        util.flatten(this.activeTimers.map((d: WebGPUKernelInfo) => d.name))\n            .filter(d => d != null);\n\n    this.activeTimers = oldActiveTimers;\n\n    if (outerMostTime) {\n      this.programTimersStack = null;\n    }\n    const res: WebGPUTimingInfo = {\n      uploadWaitMs: this.uploadWaitMs,\n      downloadWaitMs: this.downloadWaitMs,\n      kernelMs: null,\n      wallMs: null\n    };\n\n    const kernelMs = await Promise.all(flattenedActiveTimerQueries);\n    res['kernelMs'] = util.sum(kernelMs);\n    res['getExtraProfileInfo'] = () =>\n        kernelMs.map((d, i) => ({name: flattenedActiveTimerNames[i], ms: d}))\n            .map(d => `${d.name}: ${d.ms}`)\n            .join(', ');\n    this.uploadWaitMs = 0;\n    this.downloadWaitMs = 0;\n    return res;\n  }\n\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: BackendValues|string[]): TensorInfo {\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      values = (values as unknown as string[]).map(d => util.encodeString(d));\n    }\n    const dataId = this.write(values as BackendValues, shape, dtype);\n    return {dataId, shape, dtype};\n  }\n\n  private tensorToBinding(tensor?: TensorInfo): GPUBindingResource {\n    if (!tensor) {\n      return null;\n    }\n\n    const tensorData = this.tensorMap.get(tensor.dataId);\n    const resource = tensorData.resource;\n\n    if (resource instanceof GPUBuffer) {\n      return {buffer: resource};\n    }\n    if (resource instanceof GPUTexture) {\n      return resource.createView();\n    }\n    // GPUExternalTexture\n    return resource;\n  }\n\n  uploadToGPU(dataId: DataId): void {\n    const tensorData = this.tensorMap.get(dataId);\n    // Already on the GPU.\n    if (tensorData.resource != null) {\n      return;\n    }\n\n    const size = webgpu_util.GPUBytesPerElement(tensorData.dtype) *\n        util.sizeFromShape(tensorData.shape);\n    let buffer;\n    const usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC |\n        GPUBufferUsage.COPY_DST;\n    if (tensorData.values) {\n      buffer = this.bufferManager.acquireBuffer(size, usage, true);\n      if (buffer.mapState === 'unmapped') {\n        const stagingBuffer = this.bufferManager.acquireBuffer(\n            size, GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC, true,\n            false);\n        const arrayBuffer = stagingBuffer.getMappedRange();\n        if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {\n          new Int32Array(arrayBuffer).set(tensorData.values as TypedArray);\n        } else {\n          new Float32Array(arrayBuffer).set(tensorData.values as Float32Array);\n        }\n        stagingBuffer.unmap();\n        this.ensureCommandEncoderReady();\n        this.endComputePassEncoder();\n        this.commandEncoder.copyBufferToBuffer(\n            stagingBuffer, 0, buffer, 0, size);\n\n        this.stagingPendingDisposal.push(stagingBuffer);\n      } else {\n        const arrayBuffer = buffer.getMappedRange();\n        if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {\n          new Int32Array(arrayBuffer).set(tensorData.values as TypedArray);\n        } else {\n          new Float32Array(arrayBuffer).set(tensorData.values as Float32Array);\n        }\n        buffer.unmap();\n      }\n\n      // Once uploaded, don't store the values on cpu.\n      tensorData.values = null;\n    } else {\n      buffer = this.bufferManager.acquireBuffer(size, usage);\n    }\n    tensorData.resource = buffer;\n  }\n\n  private makeUniforms(programUniform: ProgramUniform): GPUBindingResource {\n    let currentOffset = 0;\n    let preLength = 0;\n    const offsets: number[] = [];\n    let maxAlignmentOfField = 1;\n    programUniform.forEach((d) => {\n      if (d.data.length === 0) {\n        d.data = [1];\n      }\n      // https://www.w3.org/TR/WGSL/#alignof\n      let baseAlignment: number;\n      switch (d.data.length) {\n        case 1:\n          baseAlignment = 4;\n          break;\n        case 2:\n          baseAlignment = 8;\n          break;\n        case 3:\n          baseAlignment = 16;\n          break;\n        case 4:\n          baseAlignment = 16;\n          break;\n        case 5:\n          baseAlignment = 16;\n          break;\n        case 6:\n          baseAlignment = 16;\n          break;\n        default:\n          util.assert(false, () => `Unsupported ${d.data.length}D shape`);\n      }\n\n      if (preLength === 5 || preLength === 6) {\n        baseAlignment = 16;\n      }\n      if (baseAlignment > maxAlignmentOfField) {\n        maxAlignmentOfField = baseAlignment;\n      }\n      currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n      preLength = d.data.length;\n      offsets.push(currentOffset);\n      currentOffset += d.data.length * 4;\n    });\n\n    currentOffset =\n        Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n    const arrayBuffer = new ArrayBuffer(currentOffset);\n    programUniform.forEach((d, i) => {\n      const offset = offsets[i];\n      if (d.type === 'int32') {\n        new Int32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else if (d.type === 'uint32') {\n        new Uint32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      } else {\n        new Float32Array(arrayBuffer, offset, d.data.length).set(d.data);\n      }\n    });\n\n    const uniformBuffer = this.bufferManager.acquireBuffer(\n        currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n    this.queue.writeBuffer(uniformBuffer, 0, arrayBuffer, 0, currentOffset);\n    this.uniformPendingDisposal.push(uniformBuffer);\n\n    return {offset: 0, size: currentOffset, buffer: uniformBuffer};\n  }\n\n  public runWebGPUProgram(\n      program: webgpu_program.WebGPUProgram, inputs: TensorInfo[],\n      outputDtype: DataType, programDefinedUniform?: ProgramUniform,\n      output?: TensorInfo): TensorInfo {\n    if (!output) {\n      output = this.makeTensorInfo(program.outputShape, outputDtype);\n    }\n    if (util.sizeFromShape(output.shape) === 0) {\n      // Short-circuit the computation since the result is empty (has 0 in its\n      // shape).\n      this.tensorMap.get(output.dataId).values =\n          util.getTypedArrayFromDType(output.dtype as 'float32', 0);\n      return output;\n    }\n    this.uploadToGPU(output.dataId);\n    program.dispatch = reshapeDispatch(this.device, program);\n\n    const inputsData = inputs.map((input: TensorInfo, i: number) => {\n      if (input.dtype === 'complex64') {\n        throw new Error(\n            `GPGPUProgram does not support complex64 input. For complex64 ` +\n            `dtypes, please separate the program into real and imaginary ` +\n            `parts.`);\n      }\n      this.uploadToGPU(input.dataId);\n\n      return {\n        // Returning dtype from tensorMap because it reflects dtype\n        // of underlying buffer, rather than abstract dtype.\n        dtype: this.tensorMap.get(input.dataId).dtype,\n        shape: input.shape,\n        name: program.variableNames[i]\n      };\n    });\n\n    program.shaderKey =\n        webgpu_program.makeShaderKey(program, inputsData, output);\n\n    const parallelCompilation = env().getBool('WEBGPU_ENGINE_COMPILE_ONLY');\n    if (!(program.shaderKey in this.pipelineCache)) {\n      this.pipelineCache[program.shaderKey] = webgpu_program.compileProgram(\n          this.device, program, inputsData, output, parallelCompilation);\n    }\n    program.pipeline = this.pipelineCache[program.shaderKey];\n\n    if (!parallelCompilation) {\n      this.recordAndSubmit(program, output, inputs, programDefinedUniform);\n    }\n    return output;\n  }\n\n  private recordAndSubmit(\n      program: webgpu_program.WebGPUProgram, output: TensorInfo,\n      inputs: TensorInfo[], programDefinedUniform?: ProgramUniform) {\n    if (program.pipeline instanceof Promise<GPUComputePipeline>) {\n      throw new Error(\n          'Please call checkCompileCompletionAsync to ensure parallel compilation is done!');\n    }\n    // There are six kinds of uniforms: NAN, INFINITY, shapes, shape strides,\n    // program size, program defined uniforms.\n    let programUniform: ProgramUniform = [];\n    let bufferShapes: number[][] = [];\n    const uniformsType = 'int32';\n    if (program.pixelsOpType == null) {\n      programUniform.push(\n          {type: 'float32', data: [NaN]}, {type: 'float32', data: [Infinity]});\n      bufferShapes = inputs.concat(output).map(d => d.shape);\n      const uniformsType = 'int32';\n      bufferShapes.map(d => {\n        programUniform.push({type: uniformsType, data: d});\n        const strides = util.computeStrides(d);\n        programUniform.push({type: uniformsType, data: strides});\n      });\n    } else {\n      const strides = util.computeStrides(output.shape);\n      programUniform.push({type: uniformsType, data: strides});\n    }\n    if (program.size) {\n      const size = util.sizeFromShape(program.outputShape);\n      programUniform.push({\n        type: uniformsType,\n        data: [program.outputComponent ? size / program.outputComponent : size]\n      });\n    }\n\n    if (programDefinedUniform) {\n      programUniform = [...programUniform, ...programDefinedUniform];\n    }\n    const bindings = [\n      this.tensorToBinding(output), ...inputs.map(t => this.tensorToBinding(t)),\n      this.makeUniforms(programUniform)\n    ];\n\n    inputs.forEach(input => {\n      this.commandQueueOwnedIds.add(input.dataId);\n    });\n    this.commandQueueOwnedIds.add(output.dataId);\n\n    const bindGroup = this.device.createBindGroup({\n      layout: program.pipeline.getBindGroupLayout(0),\n      entries: bindings.map((b, i) => ({binding: i, resource: b})),\n    });\n\n    const shouldTimeProgram = this.activeTimers != null;\n    this.ensureCommandEncoderReady();\n\n    const computePassDescriptor: GPUComputePassDescriptor = {};\n    if (shouldTimeProgram && this.supportTimestampQuery) {\n      this.endComputePassEncoder();\n      if (this.querySet == null) {\n        this.querySet = this.device.createQuerySet({\n          type: 'timestamp',\n          count: this.querySetCount,\n        });\n      }\n      computePassDescriptor.timestampWrites = [\n        {\n          querySet: this.querySet,\n          queryIndex: 0,\n          location: 'beginning',\n        },\n        {\n          querySet: this.querySet,\n          queryIndex: 1,\n          location: 'end',\n        }\n      ];\n      this.computePassEncoder =\n          this.commandEncoder.beginComputePass(computePassDescriptor);\n    } else if (!this.computePassEncoder) {\n      this.computePassEncoder =\n          this.commandEncoder.beginComputePass(computePassDescriptor);\n    }\n\n    this.computePassEncoder.setPipeline(program.pipeline);\n    this.computePassEncoder.setBindGroup(0, bindGroup);\n    this.computePassEncoder.dispatchWorkgroups(\n        program.dispatch[0], program.dispatch[1], program.dispatch[2]);\n    this.dispatchCountInPass++;\n\n    if (shouldTimeProgram ||\n        env().get('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE') as\n            number <= this.dispatchCountInPass ||\n        program.pixelsOpType === webgpu_program.PixelsOpType.DRAW) {\n      this.endComputePassEncoder();\n      if (shouldTimeProgram) {\n        this.activeTimers.push(\n            {name: program.constructor.name, query: this.getQueryTime()});\n      } else {\n        this.submitQueue();\n      }\n    }\n  }\n\n  async getQueryTime(): Promise<number> {\n    if (!this.supportTimestampQuery) {\n      return 0;\n    }\n\n    if (this.queryResolveBuffer == null) {\n      this.queryResolveBuffer = this.bufferManager.acquireBuffer(\n          this.querySetCount * 8,\n          GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST |\n              GPUBufferUsage.QUERY_RESOLVE);\n    }\n    this.commandEncoder.resolveQuerySet(\n        this.querySet, 0, this.querySetCount, this.queryResolveBuffer, 0);\n\n    const queryStagingBuffer = this.bufferManager.acquireBuffer(\n        this.querySetCount * 8,\n        GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n    this.commandEncoder.copyBufferToBuffer(\n        this.queryResolveBuffer, 0, queryStagingBuffer, 0,\n        this.querySetCount * 8);\n\n    this.submitQueue();\n\n    await queryStagingBuffer.mapAsync(GPUMapMode.READ);\n    const arrayBuffer = new BigUint64Array(queryStagingBuffer.getMappedRange());\n    const time = Number(arrayBuffer[1] - arrayBuffer[0]) / 1000000;\n    queryStagingBuffer.unmap();\n    this.bufferManager.releaseBuffer(queryStagingBuffer);\n    return time;\n  }\n\n  shouldExecuteOnCPU(\n      inputs: TensorInfo[],\n      sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD): boolean {\n    return env().getBool('WEBGPU_CPU_FORWARD') &&\n        inputs.every(\n            input => this.tensorMap.get(input.dataId).resource == null &&\n                util.sizeFromShape(input.shape) < sizeThreshold);\n  }\n\n  override numDataIds() {\n    return this.tensorMap.numDataIds() - this.tensorDataPendingDisposal.length;\n  }\n\n  override dispose() {\n    if (this.disposed) {\n      return;\n    }\n    if (this.querySet != null) {\n      this.querySet.destroy();\n    }\n    this.bufferManager.dispose();\n    this.textureManager.dispose();\n    this.disposed = true;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport enum BinaryOpType {\n  ADD,\n  ATAN2,\n  COMPLEX_MULTIPLY_IMAG,\n  COMPLEX_MULTIPLY_REAL,\n  DIV,\n  ELU_DER,\n  EQUAL,\n  FLOOR_DIV,\n  GREATER,\n  GREATER_EQUAL,\n  LESS,\n  LESS_EQUAL,\n  LOGICAL_AND,\n  LOGICAL_OR,\n  MAX,\n  MIN,\n  MOD,\n  MUL,\n  NOT_EQUAL,\n  POW,\n  PRELU,\n  SQUARED_DIFFERENCE,\n  SUB\n}\n\nconst ADD = 'let resultTemp = a + b;';\nconst ATAN2 = 'let resultTemp = atan2(a, b);';\n// (Ar + Ai)(Br + Bi) =\n// ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr\n// Yr = ArBr - AB\n// Yi = ArBi + AiBr\nconst COMPLEX_MULTIPLY_REAL = 'let resultTemp = areal * breal - aimag * bimag;';\nconst COMPLEX_MULTIPLY_IMAG = 'let resultTemp = areal * bimag + aimag * breal;';\nconst DIV = 'let resultTemp = a / b;';\nconst ELU_DER = 'let resultTemp = select(a * (b + 1.0), a, b >= b - b);';\nconst EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a == b);\n`;\nconst FLOOR_DIV = `\n  let remainder =\n      select(a % b, round(a % b), (round(a) == a) & (round(b) == b));\n  let quotient = (a - remainder) / b;\n  let resultTemp =\n      round(select(quotient, quotient - 1, sign(remainder) == -sign(b)));\n`;\nconst GREATER = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a > b);\n`;\nconst GREATER_EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a >= b);\n`;\nconst LESS = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a < b);\n`;\nconst LESS_EQUAL = `\n  let zero = sign(a) * 0 + 0;\n  let one = sign(b) * 0 + 1;\n  let resultTemp = select(zero, one, a <= b);\n`;\nconst LOGICAL_AND = 'return f32(a >= 1.0 && b >= 1.0);';\nconst LOGICAL_AND_VEC4 = `return (vec4<f32>(a >= vec4<f32>(1.0)) *\n  vec4<f32>(b >= vec4<f32>(1.0)));`;\nconst LOGICAL_OR = 'return f32(a >= 1.0 || b >= 1.0);';\nconst LOGICAL_OR_VEC4 = `return min(vec4<f32>(a >= vec4<f32>(1.0)) +\n  vec4<f32>(b >= vec4<f32>(1.0)), vec4<f32>(1.0));`;\nconst MAX = 'let resultTemp = max(a, b);';\nconst MIN = 'let resultTemp = min(a, b);';\nconst MOD = `\n  let isNaN = b == 0.;\n  var resultTemp = a % b;\n  resultTemp = select((resultTemp + b) % b, resultTemp,\n      (a < 0. && b < 0.) || (a >= 0. && b > 0.));\n`;\nconst MOD_VEC4 = `\n  let isNaN = !vec4<bool>(b);\n  var resultTemp = vec4<f32>(a % b);\n  if (!((a[0] < 0. && b[0] < 0.) || (a[0] >= 0. && b[0] > 0.))) {\n    resultTemp[0] = (resultTemp[0] + b[0]) % b[0];\n  }\n  if (!((a[1] < 0. && b[1] < 0.) || (a[1] >= 0. && b[1] > 0.))) {\n    resultTemp[1] = (resultTemp[1] + b[1]) % b[1];\n  }\n  if (!((a[2] < 0. && b[2] < 0.) || (a[2] >= 0. && b[2] > 0.))) {\n    resultTemp[2] = (resultTemp[2] + b[2]) % b[2];\n  }\n  if (!((a[3] < 0. && b[3] < 0.) || (a[3] >= 0. && b[3] > 0.))) {\n    resultTemp[3] = (resultTemp[3] + b[3]) % b[3];\n  }\n`;\nconst MUL = 'let resultTemp = a * b;';\nconst NOT_EQUAL = `\n  var resultTemp = f32(a != b);\n  let valueForNaN = 1.0;\n`;\nconst NOT_EQUAL_VEC4 = `\n  var resultTemp = vec4<f32>(a != b);\n  let valueForNaN = 1.0;\n`;\n\nconst POW = `\n  let isNaN = a < 0.0 && floor(b) < b;\n  if (b == 0.0) {\n    return 1.0;\n  }\n  var resultTemp = select(sign(a) * pow(abs(a), b), pow(abs(a), b),\n      round(abs(b) % 2.0) != 1.0);\n`;\nconst POW_VEC4 = `\n  let isModRound1Bool = vec4<i32>(round(abs(b) % vec4<f32>(2.0))) == vec4<i32>(1);\n  let isModRound1 = vec4<f32>(isModRound1Bool);\n  let multiplier = sign(a) * isModRound1 + (vec4<f32>(1.0) - isModRound1);\n  var resultTemp = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  let isExpZero = b == vec4<f32>(0.0);\n  if (isExpZero.r) {\n    resultTemp.r = 1.0;\n  }\n  if (isExpZero.g) {\n    resultTemp.g = 1.0;\n  }\n  if (isExpZero.b) {\n    resultTemp.b = 1.0;\n  }\n  if (isExpZero.a) {\n    resultTemp.a = 1.0;\n  }\n  let isNaN = (a < vec4<f32>(0.0)) & (floor(b) < b);\n`;\n\nconst PRELU = `if (a < 0.0) { return b * a; }  return a;`;\nconst PRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (b * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n`;\nconst SQUARED_DIFFERENCE = 'let resultTemp = (a - b) * (a - b);';\nconst SUB = 'let resultTemp = a - b;';\n\nexport function getBinaryOpString(\n    type: BinaryOpType, useVec4?: boolean): string {\n  let doOpSnippet: string;\n\n  // Ops with NaN check\n  do {\n    switch (type) {\n      case BinaryOpType.ATAN2:\n        doOpSnippet = ATAN2;\n        break;\n      case BinaryOpType.MAX:\n        doOpSnippet = MAX;\n        break;\n      case BinaryOpType.MIN:\n        doOpSnippet = MIN;\n        break;\n      case BinaryOpType.MOD:\n        doOpSnippet = useVec4 ? MOD_VEC4 : MOD;\n        break;\n      case BinaryOpType.NOT_EQUAL:\n        doOpSnippet = useVec4 ? NOT_EQUAL_VEC4 : NOT_EQUAL;\n        break;\n      case BinaryOpType.POW:\n        doOpSnippet = useVec4 ? POW_VEC4 : POW;\n        break;\n      default:\n        continue;\n    }\n\n    let isNaN: string;\n    let dTypeN: string;\n    let boolN: string;\n    if (useVec4) {\n      isNaN = 'isnanVec4';\n      dTypeN = 'vec4<f32>';\n      boolN = 'vec4<bool>';\n    } else {\n      isNaN = 'isnan';\n      dTypeN = 'f32';\n      boolN = 'bool';\n    }\n\n    return `\n      let aIsNaN = ${isNaN}(a);\n      let aPostLegalization = select(a, ${dTypeN}(42), aIsNaN);\n      let bIsNaN = ${isNaN}(b);\n      let bPostLegalization = select(b, ${dTypeN}(42), bIsNaN);\n      let isNaN = false;\n      let valueForNaN = uniforms.NAN;\n      {\n        let a = aPostLegalization;\n        let b = bPostLegalization;\n        ${doOpSnippet}\n        return select(\n            resultTemp, ${dTypeN}(valueForNaN),\n            ${boolN}(isNaN) | aIsNaN | bIsNaN);\n      }\n    `;\n  } while (false);\n\n  // Ops without NaN check\n  switch (type) {\n    case BinaryOpType.ADD:\n      doOpSnippet = ADD;\n      break;\n    case BinaryOpType.COMPLEX_MULTIPLY_IMAG:\n      doOpSnippet = COMPLEX_MULTIPLY_IMAG;\n      break;\n    case BinaryOpType.COMPLEX_MULTIPLY_REAL:\n      doOpSnippet = COMPLEX_MULTIPLY_REAL;\n      break;\n    case BinaryOpType.DIV:\n      doOpSnippet = DIV;\n      break;\n    case BinaryOpType.ELU_DER:\n      doOpSnippet = ELU_DER;\n      break;\n    case BinaryOpType.EQUAL:\n      doOpSnippet = EQUAL;\n      break;\n    case BinaryOpType.FLOOR_DIV:\n      doOpSnippet = FLOOR_DIV;\n      break;\n    case BinaryOpType.GREATER:\n      doOpSnippet = GREATER;\n      break;\n    case BinaryOpType.GREATER_EQUAL:\n      doOpSnippet = GREATER_EQUAL;\n      break;\n    case BinaryOpType.LESS:\n      doOpSnippet = LESS;\n      break;\n    case BinaryOpType.LESS_EQUAL:\n      doOpSnippet = LESS_EQUAL;\n      break;\n    case BinaryOpType.LOGICAL_AND:\n      return useVec4 ? LOGICAL_AND_VEC4 : LOGICAL_AND;\n    case BinaryOpType.LOGICAL_OR:\n      return useVec4 ? LOGICAL_OR_VEC4 : LOGICAL_OR;\n    case BinaryOpType.MUL:\n      doOpSnippet = MUL;\n      break;\n    case BinaryOpType.PRELU:\n      return useVec4 ? PRELU_VEC4 : PRELU;\n    case BinaryOpType.SQUARED_DIFFERENCE:\n      doOpSnippet = SQUARED_DIFFERENCE;\n      break;\n    case BinaryOpType.SUB:\n      doOpSnippet = SUB;\n      break;\n    default:\n      // throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n  return `\n    ${doOpSnippet}\n    return resultTemp;\n  `;\n}\n","/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport './flags_webgpu';\n\nimport {env, registerBackend} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from './backend_webgpu';\nimport {isWebGPUSupported} from './webgpu_util';\n\nif (isWebGPUSupported()) {\n  registerBackend('webgpu', async () => {\n    const gpuDescriptor: GPURequestAdapterOptions = {\n      powerPreference: env().get('WEBGPU_USE_LOW_POWER_GPU') ?\n          'low-power' :\n          'high-performance'\n    };\n\n    const adapter = await navigator.gpu.requestAdapter(gpuDescriptor);\n    const deviceDescriptor: GPUDeviceDescriptor = {};\n\n    const requiredFeatures = [];\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('bgra8unorm-storage')) {\n      requiredFeatures.push(['bgra8unorm-storage']);\n    }\n    deviceDescriptor.requiredFeatures =\n        requiredFeatures as Iterable<GPUFeatureName>;\n\n    const adapterLimits = adapter.limits;\n    deviceDescriptor.requiredLimits = {\n      'maxComputeWorkgroupStorageSize':\n          adapterLimits.maxComputeWorkgroupStorageSize,\n      'maxComputeWorkgroupsPerDimension':\n          adapterLimits.maxComputeWorkgroupsPerDimension,\n      'maxStorageBufferBindingSize': adapterLimits.maxStorageBufferBindingSize,\n      'maxBufferSize': adapterLimits.maxBufferSize,\n      'maxComputeWorkgroupSizeX': adapterLimits.maxComputeWorkgroupSizeX,\n      'maxComputeInvocationsPerWorkgroup':\n          adapterLimits.maxComputeInvocationsPerWorkgroup,\n    };\n\n    const device: GPUDevice = await adapter.requestDevice(deviceDescriptor);\n    const adapterInfo = await adapter.requestAdapterInfo();\n    return new WebGPUBackend(device, adapterInfo);\n  }, 3 /*priority*/);\n}\n\n// Export webgpu utilities\nexport * from './webgpu';\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nexport enum UnaryOpType {\n  ABS,\n  ACOS,\n  ACOSH,\n  ASIN,\n  ASINH,\n  ATAN,\n  ATANH,\n  CEIL,\n  COS,\n  COSH,\n  ELU,\n  ERF,\n  EXP,\n  EXPM1,\n  FLOOR,\n  IS_FINITE,\n  IS_INF,\n  IS_NAN,\n  LINEAR,\n  LOG,\n  LOG1P,\n  LOGICAL_NOT,\n  NEG,\n  RELU,\n  RELU6,\n  LEAKYRELU,\n  RECIPROCAL,\n  ROUND,\n  RSQRT,\n  SELU,\n  SIGMOID,\n  SIGN,\n  SIN,\n  SINH,\n  SOFTPLUS,\n  SQRT,\n  SQUARE,\n  STEP,\n  TAN,\n  TANH,\n  TO_INT\n}\n\nconst ABS = `return abs(a);`;\nconst ACOS = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  return acos(a);\n`;\nconst ACOSH = `\n  if (a < 1.) {\n    return uniforms.NAN;\n  }\n  return acosh(a);\n`;\nconst ASIN = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  return asin(a);\n`;\nconst ASINH = `return asinh(a);`;\nconst ATAN = `\n  if (isnan(a)) {\n    return uniforms.NAN;\n  }\n  return atan(a);\n`;\nconst ATANH = `\n  if (abs(a) > 1.) {\n    return uniforms.NAN;\n  }\n  if (a == 1.) {\n    return uniforms.INFINITY;\n  }\n  if (a == -1.) {\n    return -uniforms.INFINITY;\n  }\n  return atanh(a);\n`;\nconst CEIL = `return ceil(a);`;\nconst COS = `return cos(a);`;\nconst COSH = `\n  let e2x = exp(-a);\n  return (e2x + 1.0 / e2x) / 2.0;\n`;\nconst EXPM1 = `return exp(a) - 1.0;`;\nconst ELU = `if (a >= 0.0) { return a; }  return (exp(a) - 1.0);`;\nconst ELU_VEC4 = `\n  var resFloat = exp(a) - vec4<f32>(1.0);\n  if (a.r >= 0.0) {\n    resFloat.r = a.r;\n  }\n  if (a.g >= 0.0) {\n    resFloat.g = a.g;\n  }\n  if (a.b >= 0.0) {\n    resFloat.b = a.b;\n  }\n  if (a.a >= 0.0) {\n    resFloat.a = a.a;\n  }\n  return resFloat;\n`;\nconst ERF = `\n  // Error function is calculated approximately with elementary function.\n  // See \"Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\n  let p = ${backend_util.ERF_P};\n  let a1 = ${backend_util.ERF_A1};\n  let a2 = ${backend_util.ERF_A2};\n  let a3 = ${backend_util.ERF_A3};\n  let a4 = ${backend_util.ERF_A4};\n  let a5 = ${backend_util.ERF_A5};\n\n  let sign = sign(a);\n  let absA = abs(a);\n  let t = 1.0 / (1.0 + p * absA);\n  return sign * (1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * exp(-absA * absA));\n`;\nconst EXP = `return exp(a);`;\nconst FLOOR = `return floor(a);`;\nconst IS_FINITE = `return f32(!isnan(a) && !isinf(a));`;\nconst IS_INF = `return f32(isinf(a));`;\nconst IS_NAN = `return f32(isnan(a));`;\nconst LINEAR = `return a;`;\nconst LOG = `if (a < 0.0) { return uniforms.NAN; }\n  return log(a);`;\nconst LOG1P = `\n  if (isnan(a)) { return a; }\n  return log(1.0 + a);\n`;\nconst LOGICAL_NOT = `return f32(!(a >= 1.0));`;\nconst NEG = `return -a;`;\nconst LEAKYRELU = `if (a < 0.0) { return uniforms.alpha * a; } return a;`;\nconst LEAKYRELU_VEC4 = `\n  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));\n  return (aLessThanZero * (uniforms.alpha * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);\n`;\nconst RECIPROCAL = `return 1.0 / a;`;\nconst RELU = `return select(a, 0.0, a < 0.0);`;\nconst RELU6 = 'return clamp(a, 0.0, 6.0);';\nconst RELU6_VEC4 =\n    'return clamp(a, vec4<f32>(0.0, 0.0, 0.0, 0.0), vec4<f32>(6.0, 6.0, 6.0, 6.0));';\nconst RELU_VEC4 = `\n  return select(a, vec4<f32>(0.0), a < vec4<f32>(0.0));\n`;\nconst ROUND = `return round(a);`;\nconst RSQRT = `return inverseSqrt(a);`;\n// Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n// See: https://arxiv.org/abs/1706.02515\nconst SELU = `\n  if (a >= 0.0) {\n    return ${backend_util.SELU_SCALE} * a;\n  } else {\n    return ${backend_util.SELU_SCALEALPHA} * (exp(a) - 1.0);\n  }\n`;\nconst SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * a));`;\nconst SIGN = `return sign(a);`;\nconst SIN = `return sin(a);`;\nconst SINH = `\n  let e2x = exp(a);\n  return (e2x - 1.0 / e2x) / 2.0;\n`;\nconst SOFTPLUS = `\n  let epsilon = 1.1920928955078125e-7;\n  let threshold = log(epsilon) + 2.0;\n\n  let too_large = a > -threshold;\n  let too_small = a < threshold;\n  let exp_a = exp(a);\n\n  if (too_large) {\n    return a;\n  } else if (too_small) {\n    return exp_a;\n  } else {\n    return log(exp_a + 1.0);\n  }\n`;\nconst SQRT = `return sqrt(a);`;\nconst SQUARE = `return a * a;`;\nconst STEP = `\n  if (isnan(a)) {\n    return a;\n  }\n\n  return select(uniforms.stepAlpha, 1.0, a > 0.0);\n`;\nconst TAN = `return tan(a);`;\nconst TANH = `\n  let e2x = exp(-2.0 * abs(a));\n  return sign(a) * (1.0 - e2x) / (1.0 + e2x);\n`;\nconst TO_INT = `return f32(i32((a)));`;\n\nexport function getUnaryOpString(type: UnaryOpType, useVec4?: boolean): string {\n  switch (type) {\n    case UnaryOpType.ABS:\n      return ABS;\n    case UnaryOpType.ACOS:\n      return ACOS;\n    case UnaryOpType.ACOSH:\n      return ACOSH;\n    case UnaryOpType.ASIN:\n      return ASIN;\n    case UnaryOpType.ASINH:\n      return ASINH;\n    case UnaryOpType.ATAN:\n      return ATAN;\n    case UnaryOpType.ATANH:\n      return ATANH;\n    case UnaryOpType.COS:\n      return COS;\n    case UnaryOpType.COSH:\n      return COSH;\n    case UnaryOpType.CEIL:\n      return CEIL;\n    case UnaryOpType.ELU:\n      return useVec4 ? ELU_VEC4 : ELU;\n    case UnaryOpType.ERF:\n      return ERF;\n    case UnaryOpType.EXP:\n      return EXP;\n    case UnaryOpType.EXPM1:\n      return EXPM1;\n    case UnaryOpType.FLOOR:\n      return FLOOR;\n    case UnaryOpType.IS_FINITE:\n      return IS_FINITE;\n    case UnaryOpType.IS_INF:\n      return IS_INF;\n    case UnaryOpType.IS_NAN:\n      return IS_NAN;\n    case UnaryOpType.LINEAR:\n      return LINEAR;\n    case UnaryOpType.LOG:\n      return LOG;\n    case UnaryOpType.LOG1P:\n      return LOG1P;\n    case UnaryOpType.LOGICAL_NOT:\n      return LOGICAL_NOT;\n    case UnaryOpType.NEG:\n      return NEG;\n    case UnaryOpType.LEAKYRELU:\n      return useVec4 ? LEAKYRELU_VEC4 : LEAKYRELU;\n    case UnaryOpType.RECIPROCAL:\n      return RECIPROCAL;\n    case UnaryOpType.RELU:\n      return useVec4 ? RELU_VEC4 : RELU;\n    case UnaryOpType.RELU6:\n      return useVec4 ? RELU6_VEC4 : RELU6;\n    case UnaryOpType.ROUND:\n      return ROUND;\n    case UnaryOpType.RSQRT:\n      return RSQRT;\n    case UnaryOpType.SELU:\n      return SELU;\n    case UnaryOpType.SIGMOID:\n      return SIGMOID;\n    case UnaryOpType.SIGN:\n      return SIGN;\n    case UnaryOpType.SIN:\n      return SIN;\n    case UnaryOpType.SINH:\n      return SINH;\n    case UnaryOpType.SOFTPLUS:\n      return SOFTPLUS;\n    case UnaryOpType.SQRT:\n      return SQRT;\n    case UnaryOpType.SQUARE:\n      return SQUARE;\n    case UnaryOpType.STEP:\n      return STEP;\n    case UnaryOpType.TAN:\n      return TAN;\n    case UnaryOpType.TANH:\n      return TANH;\n    case UnaryOpType.TO_INT:\n      return TO_INT;\n\n    default:\n      throw new Error(`BinaryType ${type} is not implemented!`);\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\nimport {typeSnippet} from './webgpu_program';\n\nexport function activationFnSnippet(\n    activation: backend_util.Activation, hasPreluActivationWeights = false,\n    packed = false, coordsLength = 3): string {\n  if (activation === null) {\n    return '';\n  }\n\n  let activationOpSnippet = '';\n  if (activation === 'linear') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LINEAR);\n  } else if (activation === 'relu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU, packed);\n  } else if (activation === 'elu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.ELU, packed);\n  } else if (activation === 'relu6') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.RELU6, packed);\n  } else if (activation === 'prelu') {\n    activationOpSnippet = getBinaryOpString(BinaryOpType.PRELU, packed);\n  } else if (activation === 'sigmoid') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.SIGMOID, packed);\n  } else if (activation === 'leakyrelu') {\n    activationOpSnippet = getUnaryOpString(UnaryOpType.LEAKYRELU, packed);\n  } else {\n    throw new Error(`Activation ${\n        activation} has not been implemented for the WebGPU backend.`);\n  }\n  const elementSize = packed ? 4 : 1;\n  const dataType = typeSnippet(elementSize);\n  let activationFnSnippet = '';\n  if (hasPreluActivationWeights) {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        let b = getPreluActivationWeightsByOutputCoords(coords);\n        ${activationOpSnippet}\n      }`;\n  } else {\n    activationFnSnippet = `\n      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${\n        dataType} {\n        ${activationOpSnippet}\n      }`;\n  }\n  return activationFnSnippet;\n}\n\nexport function biasActivationSnippet(\n    hasBias: boolean, activation: backend_util.Activation): string {\n  return `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      ${activation ? 'value = activation(value, coords);' : ''}\n      `;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupInfoForMatMul} from './webgpu_util';\n\nexport function matMulReadFnSource(\n    transposeA: boolean, transposeB: boolean, fitAOuter = false,\n    fitBOuter = false, fitInner = false, component = 1) {\n  util.assert(\n      transposeA && component === 1 || !transposeA,\n      () => `transposeA ${transposeA} is not compatible with component size ${\n          component}`);\n  const sampleA = `\n      ${\n      transposeA ? `value = getA(batch, col, row);` :\n                   `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` :\n                               `value = getB(batch, row, col);`;\n\n  return `\n  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${\n      fitAOuter && fitInner ?\n          sampleA :\n          `\n    ${\n              transposeA ?\n                  `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :\n                  `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\n\nexport function matMulReadWriteFnSource(\n    hasBias: boolean, activation: backend_util.Activation, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  return `\n  ${\n      matMulReadFnSource(\n          transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${\n      typeSnippet(component)}) {\n    ${\n      fitAOuter && fitBOuter ?\n          '' :\n          'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\n\nconst writeDataToSubAVec4Snippet =\n    (transpose: boolean, innerElementSize: number) => {\n      if (transpose) {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol * ${innerElementSize});\n        `;\n\n      } else {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRow + innerRow,\n          kStart + inputCol * ${innerElementSize});\n        `;\n      }\n    };\n\nconst calculateResultSnippet =\n    (transposeA: boolean, innerElementSize: number, rowPerThread: number,\n     tileInner: number) => {\n      if (transposeA) {\n        return `\n      for (var k = 0; k < ${tileInner}; k++) {\n        let BCached0 = mm_Bsub[k][tileCol];\n        let ACached0 = mm_Asub[k][localRow];\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\n        }\n      }`;\n      } else {\n        let bCachedStr = '';\n        let accStr = '';\n        for (let i = 0; i < innerElementSize; i++) {\n          bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${\n              i}][tileCol];`;\n          accStr +=\n              `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;\n        }\n        return `\n      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {\n        ${bCachedStr}\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          let ACached = mm_Asub[tileRow + i][k];\n          ${accStr}\n        }\n      }`;\n      }\n    };\n\nexport function makeMatMulPackedVec4Source(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    broadcastBatch = false): string {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n       (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4,\n      () => `If transposeA ${transposeA} is true, innerElementSize ${\n          innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}. tileInner ${\n          tileInner} must be divisible by workgroupSize[1] ${\n          workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${\n      tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${\n      tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  ${main()} {\n    let localRow = i32(localId.y);\n    let tileRow = localRow * ${rowPerThread};\n    let tileCol = i32(localId.x);\n\n    let globalRow = i32(globalId.y) * ${rowPerThread};\n    let globalCol = i32(globalId.x) * ${colPerThread};\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n    let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, ${rowPerThread}>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        ${\n      calculateResultSnippet(\n          transposeA, innerElementSize, rowPerThread, tileInner)}\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\n\nconst writeDataToSubASnippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :\n\n                      'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    sequentialAccessByThreads = false, broadcastBatch = false): string {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(\n      tileAHight % workgroupSize[1] === 0 &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0,\n      () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n          workgroupSize[1]}, tileAWidth ${\n          tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}, tileInner ${\n          tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ?\n      `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n          tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${\n          tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ${colPerThread}>;\n        for (var k = 0; k < ${tileInner}; k++) {\n          for (var inner = 0; inner < ${colPerThread}; inner++) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let ACached = ${\n          transposeA ?\n              `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n              `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n              acc[innerRow][innerCol] =\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` :\n      `\n  let tileRow = i32(localId.y) * ${rowPerThread};\n  let tileCol = i32(localId.x) * ${colPerThread};\n\n  let globalRow = i32(globalId.y) * ${rowPerThread};\n  let globalCol = i32(globalId.x) * ${colPerThread};\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t++) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + ${tileInner};\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ${colPerThread}>;\n    for (var k = 0; k < ${tileInner}; k++) {\n      for (var inner = 0; inner < ${colPerThread}; inner++) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] =\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n    ${main()} {\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n      let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n      let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\n\nconst readVectorASnippet = (transpose: boolean) => {\n  return transpose ? `\n      mm_readA(batchA, colA, globalRow),\n      mm_readA(batchA, colA + 1, globalRow),\n      mm_readA(batchA, colA + 2, globalRow),\n      mm_readA(batchA, colA + 3, globalRow)\n  ` :\n                     `\n      mm_readA(batchA, globalRow, colA),\n      mm_readA(batchA, globalRow, colA + 1),\n      mm_readA(batchA, globalRow, colA + 2),\n      mm_readA(batchA, globalRow, colA + 3)\n  `;\n};\n\nexport function makeVectorMatrixProductSource(\n    workgroupSize: [number, number, number], transposeA = false): string {\n  util.assert(\n      workgroupSize[1] === 1 && workgroupSize[2] === 1,\n      () => `A linear work group size is required. But got ${workgroupSize}.`);\n  const tileSize = workgroupSize[0] * 4;\n  return `\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;\n      let batch = i32(globalId.z);\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        let colA = t * ${tileSize} + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < ${tileSize / 4}; k++) {\n          let rowB = t * ${tileSize} + k * 4;\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\n                              mm_readB(batchB, rowB + 1, globalCol),\n                              mm_readB(batchB, rowB + 2, globalCol),\n                              mm_readB(batchB, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\n\nexport class MatMulPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileInner: number;\n  isVectorA: boolean;\n  isVec4: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      aShape: [number, number, number], outputShape: [number, number, number],\n      transposeA = false, transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null,\n      sequentialAccessByThreads = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||\n                   (outputShape[1] % 4 === 0 && transposeA)) &&\n        outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(\n          outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] =\n        this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${\n        transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${\n        this.fitInner}_${this.isVec4}_${this.isVectorA}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getShapeFit(dimAOuter: number, dimBOuter: number, dimInner: number):\n      boolean[] {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation,\n            false /* transposeA is implemented in makeMatMulPackedSource */,\n            this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.isVec4 ? 4 : 1)}\n      ${\n        this.isVec4 ?\n            makeMatMulPackedVec4Source(\n                this.elementsPerThread, this.workgroupSize, this.transposeA,\n                this.tileInner, false, null, true) :\n            (this.isVectorA ? makeVectorMatrixProductSource(\n                                  this.workgroupSize, this.transposeA) :\n                              makeMatMulPackedSource(\n                                  this.elementsPerThread, this.workgroupSize,\n                                  this.transposeA, this.tileInner, false, null,\n                                  this.sequentialAccessByThreads, true))}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport function makeMatMulReduceSource(workgroupSizeX: number): string {\n  return `\n    var<workgroup> sumValues : array<f32, ${workgroupSizeX}>;\n    ${main()} {\n      let coords = getOutputCoords();\n      let batch = coords[0];\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      let row = coords[1];\n      let col = coords[2];\n      var sum = 0.0;\n      let Length = uniforms.dimInner;\n      for (var k = i32(localId.x); k < Length; k = k + ${workgroupSizeX}) {\n        let dataA = mm_readA(batchA, row, k);\n        let dataB = mm_readB(batchB, k, col);\n        sum = sum + dataA * dataB;\n      }\n      sumValues[localId.x] = sum;\n      workgroupBarrier();\n\n      for(var currentSize = ${workgroupSizeX / 2}u; currentSize > 1u;\n          currentSize = currentSize / 2u) {\n        if (localId.x < currentSize)\n        {\n          sumValues[localId.x] = sumValues[localId.x] + sumValues[localId.x + currentSize];\n        }\n        workgroupBarrier();\n      }\n\n      if (localId.x == 0u) {\n        sum = sumValues[0] + sumValues[1];\n        mm_write(batch, row, col, sum);\n      }\n    }\n  `;\n}\n\nexport class MatMulReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n\n  constructor(\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [], y: [1, 2], z: [0]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey =\n        `matMulReduce_${this.activation}_${transposeA}_${transposeB}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulReduceSource(this.workgroupSize[0])}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\n\nexport function makeMatMulSmallOutputSizeSource(\n    workgroupSize: [number, number, number]): string {\n  const tileAOuter = workgroupSize[1];\n  const tileBOuter = workgroupSize[0];\n  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;\n  return `\n  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;\n  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n  // If the output size is small for matrix multiplication, avoid to use vec4\n  // and handle some elements per thread to optimally utilize the ALU.\n  // Read data from global memory to registers firstly, then store them into\n  // shared memory, so it is instruction-Level parallelism for arithmetic\n  // operations and others handle IO operations between barrier api, makes ALU\n  // and load/store units work simultaneously, could improves the performance.\n  ${main()} {\n    let tileRow = i32(localId.y);\n    let tileCol = i32(localId.x);\n    let globalRow = i32(globalId.y);\n    let globalCol = i32(globalId.x);\n    let batch = i32(globalId.z);\n    let batchA = batch % uniforms.aShape[0];\n    let batchB = batch % uniforms.bShape[0];\n\n    // uniforms.dimInner should be greater than 0.\n    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;\n    var acc = 0.0;\n\n    var globalColA = tileCol;\n    var globalRowB = 0;\n    var regA = mm_readA(batchA, globalRow, globalColA);\n    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n    globalColA = globalColA + ${tileInner};\n    globalRowB = globalRowB + ${tileInner};\n\n    for (var t = 0; t < numTiles; t = t + 1) {\n      mm_Asub[tileRow][tileCol] = regA;\n      mm_Bsub[2 * tileRow][tileCol] = regB0;\n      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;\n\n      workgroupBarrier();\n\n      regA = mm_readA(batchA, globalRow, globalColA);\n      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n      globalColA = globalColA + ${tileInner};\n      globalRowB = globalRowB + ${tileInner};\n\n      for (var k = 0; k < ${tileInner}; k = k + 1) {\n        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];\n      }\n      workgroupBarrier();\n    }\n\n    mm_write(batch, globalRow, globalCol, acc);\n  }\n  `;\n}\n\nexport class MatMulSmallOutputSizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [16, 8, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n\n  constructor(\n      aShape: [number, number, number], bShape: [number, number, number],\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    this.dispatch = [\n      Math.ceil(outputShape[2] / this.workgroupSize[0]),\n      Math.ceil(outputShape[1] / this.workgroupSize[1]), outputShape[0]\n    ];\n\n    const addBias = bias != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey =\n        `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source, matMulReadFnSource} from './matmul_packed_webgpu';\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MatMulSplitKProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [8, 8, 1];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  atomic = true;\n  outputComponent: number;\n  splitedDimInner = 128;\n\n  constructor(\n      outputShape: [number, number, number], dimInner: number,\n      transposeA = false, transposeB = false) {\n    util.assert(\n        outputShape[0] === 1,\n        () => 'MatMulSplitKProgram only supports batch = 1.');\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0, 3]};\n    const isVec4 = (transposeA && this.outputShape[1] % 4 === 0 ||\n                    !transposeA && dimInner % 4 === 0) &&\n        this.outputShape[2] % 4 === 0;\n    this.elementsPerThread = [4, 4, this.splitedDimInner];\n    this.outputComponent = isVec4 ? 4 : 1;\n    if (!isVec4) {\n      if (this.outputShape[1] < 16) {\n        this.elementsPerThread[1] = 1;\n      }\n      if (this.outputShape[2] < 16) {\n        this.elementsPerThread[0] = 1;\n      }\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout,\n        [\n          this.outputShape[0], this.outputShape[1], this.outputShape[2],\n          dimInner\n        ],\n        this.workgroupSize, this.elementsPerThread);\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.shaderKey = `matMulSplitK_${transposeA}_${transposeB}_${\n        this.elementsPerThread}_${this.outputComponent}`;\n  }\n\n  getUserCode(): string {\n    const component = this.outputComponent;\n    const userCode = `\n      ${\n        matMulReadFnSource(\n            false, this.transposeB, false, false, false, component)}\n      fn mm_write(batch: i32, row : i32, col : i32, value : ${\n        typeSnippet(component)}) {\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n          let coords = vec3<i32>(batch, row, col);\n          let flatIndex = getOutputIndexFromCoords(coords);\n          // The problem is that we should initialize output to zero before using.\n          // Otherwise, the original value will be added to the result.\n          for (var i = 0; i < ${component}; i = i + 1) {\n            ${\n        atomicAddSnippet(\n            '&result[flatIndex + i]', `${component > 1 ? 'value[i]' : 'value'}`,\n            'float32')}\n          }\n        }\n      }\n      ${\n        component === 4 ? makeMatMulPackedVec4Source(\n                              this.elementsPerThread, this.workgroupSize,\n                              this.transposeA, 32, true, this.splitedDimInner) :\n                          makeMatMulPackedSource(\n                              this.elementsPerThread, this.workgroupSize,\n                              this.transposeA, 32, true, this.splitedDimInner)}\n    `;\n    return userCode;\n  }\n}\n\nexport class BiasActivationProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  private addBias: boolean;\n  private activation: backend_util.Activation;\n  private hasPreluActivationWeights: boolean;\n\n  constructor(\n      outputShape: number[], bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.addBias = bias != null;\n    this.hasPreluActivationWeights = preluActivationWeights != null;\n    this.activation = activation;\n    if (this.addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (this.hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `biasActivation_${activation}`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        var value = getXByOutputIndex(index);\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        setOutputAtIndex(index, value);\n      }\n    }\n    `;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FillProgram implements WebGPUProgram {\n  variableNames: string[] = [];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'value : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'fill';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        setOutputAtIndex(index, uniforms.value);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FillProgram} from '../fill_webgpu';\n\nexport function fill(args: {backend: WebGPUBackend, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value} = attrs;\n  let {dtype} = attrs;\n\n  dtype = dtype || util.inferDtype(value);\n\n  if (dtype === 'string') {\n    // String type should be handled in CPU memory.\n    const values = util.getArrayFromDType(dtype, util.sizeFromShape(shape));\n    values.fill(value as string);\n    return backend.makeTensorInfo(shape, dtype, values);\n  } else {\n    const program = new FillProgram(shape);\n    const uniformData = [{type: 'float32', data: [value as number]}];\n    return backend.runWebGPUProgram(program, [], dtype, uniformData);\n  }\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'webgpu',\n  kernelFunc: fill as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function reshape(\n    args: {inputs: ReshapeInputs, backend: WebGPUBackend, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  // Backend needs to track refCount for the dataId for reshape op\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'webgpu',\n  kernelFunc: reshape as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcast_util, env, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MatMulPackedProgram} from '../matmul_packed_webgpu';\nimport {MatMulReduceProgram} from '../matmul_reduce_webgpu';\nimport {MatMulSmallOutputSizeProgram} from '../matmul_small_output_size_webgpu';\nimport {BiasActivationProgram, MatMulSplitKProgram} from '../matmul_splitK_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\nimport {MatMulProgramType} from '../webgpu_util';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\ntype BatchMatMulConfig = {\n  a: TensorInfo,\n  b: TensorInfo,\n  transposeA: boolean,\n  transposeB: boolean,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\nexport function batchMatMulImpl({\n  a,\n  b,\n  transposeA,\n  transposeB,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: BatchMatMulConfig): TensorInfo {\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape: [number, number, number] = transposeA ?\n      [batchDimA, innerShapeA, outerShapeA] :\n      [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape: [number, number, number] = transposeB ?\n      [batchDimB, outerShapeB, innerShapeB] :\n      [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n  const intermediates: TensorInfo[] = [a3d, b3d];\n\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const inputs: TensorInfo[] = [a3d, b3d];\n  const dimensions = [\n    {type: 'int32', data: [outerShapeA]}, {type: 'int32', data: [outerShapeB]},\n    {type: 'int32', data: [innerShapeA]}\n  ];\n\n  let program: WebGPUProgram;\n  let out: TensorInfo;\n  const outputShape: [number, number, number] =\n      [batchDim, outerShapeA, outerShapeB];\n  let matmulProgramType = env().get('WEBGPU_MATMUL_PROGRAM_TYPE') as number;\n  if (matmulProgramType < 0) {\n    // Usually increasing workgroups is a good way to gain more performance for\n    // few workgroups by tiling 32x32 (default matmul algorithm). Currently,\n    // there are three ways to increase workgroups. 1) MatMulReduceProgram,\n    // which is used only when the output size is very small (128 for now). 2)\n    // MatMulSplitKProgram, increasing workgroups by spliting K. 3)\n    // MatMulSmallOutputSizeProgram, increasing workgroups by small tile size.\n    // For different devices, the minimum optimal workgroups may be different.\n    // So here we set a |thresholdToIncreaseWorkgroups| to indicate whether we\n    // need to increase workgroups. And the literal number is an empirical\n    // value.\n    const thresholdFlagValue =\n        env().getNumber('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');\n    const thresholdToIncreaseWorkgroups = thresholdFlagValue > 0 ?\n        thresholdFlagValue :\n        backend.thresholdToIncreaseWorkgroups;\n    const workgroupsBy32x32 =\n        batchDim * Math.ceil(outerShapeA / 32) * Math.ceil(outerShapeB / 32);\n    const hasFewWorkgroups =\n        workgroupsBy32x32 <= thresholdToIncreaseWorkgroups ||\n        (outerShapeA <= 8 &&\n         workgroupsBy32x32 <= thresholdToIncreaseWorkgroups * 2);\n    if (hasFewWorkgroups) {\n      if (batchDim * outerShapeA * outerShapeB <= 128) {\n        matmulProgramType = MatMulProgramType.MatMulReduceProgram;\n      } else if (batchDim === 1 && innerShapeB >= 2000) {\n        matmulProgramType = MatMulProgramType.MatMulSplitKProgram;\n      } else {\n        matmulProgramType = MatMulProgramType.MatMulSmallOutputSizeProgram;\n      }\n    } else {\n      matmulProgramType = MatMulProgramType.MatMulPackedProgram;\n    }\n  }\n\n  switch (matmulProgramType) {\n    case MatMulProgramType.MatMulReduceProgram:\n      program = new MatMulReduceProgram(\n          outputShape, transposeA, transposeB, bias, activation,\n          preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulSplitKProgram: {\n      // The output buffer must be initailzed to zero before using since we\n      // use atomicAdd in MatMulSplitKProgram.\n      out = fill(\n          {backend, attrs: {shape: outputShape, value: 0, dtype: a.dtype}});\n      program = new MatMulSplitKProgram(\n          outputShape, innerShapeB, transposeA, transposeB);\n      if (bias || activation) {\n        out =\n            backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n        const biasActivationProgram = new BiasActivationProgram(\n            out.shape, bias, activation, preluActivationWeights);\n        let uniformData = null;\n        const activationInputs: TensorInfo[] = [out];\n        if (bias) {\n          activationInputs.push(bias);\n        }\n        if (preluActivationWeights) {\n          activationInputs.push(preluActivationWeights);\n        }\n        if (activation === 'leakyrelu') {\n          uniformData = [{type: 'float32', data: [leakyreluAlpha]}];\n          biasActivationProgram.uniforms += ' alpha : f32,';\n        }\n        const outActivated = backend.runWebGPUProgram(\n            biasActivationProgram, activationInputs, out.dtype, uniformData);\n        intermediates.push(out);\n        const outReshaped = reshape(\n            {inputs: {x: outActivated}, backend, attrs: {shape: outShape}});\n        intermediates.push(outActivated);\n        for (const i of intermediates) {\n          backend.disposeData(i.dataId);\n        }\n        return outReshaped;\n      }\n      break;\n    }\n    case MatMulProgramType.MatMulSmallOutputSizeProgram:\n      program = new MatMulSmallOutputSizeProgram(\n          a3dShape, b3dShape, outputShape, transposeA, transposeB, bias,\n          activation, preluActivationWeights);\n      break;\n    case MatMulProgramType.MatMulPackedProgram:\n      // Experiments show that sequential access is more friendly for Intel\n      // GPUs.\n      const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n      program = new MatMulPackedProgram(\n          a3dShape, outputShape, transposeA, transposeB, bias, activation,\n          preluActivationWeights, sequentialAccessByThreads);\n      break;\n    default:\n      throw new Error(`Unsupported MatMulProgramType ${matmulProgramType}.`);\n  }\n\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (preluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  out = backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);\n  const outReshaped =\n      reshape({inputs: {x: out}, backend, attrs: {shape: outShape}});\n  intermediates.push(out);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return outReshaped;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  return batchMatMulImpl({\n    a,\n    b,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'webgpu',\n  kernelFunc: _fusedMatMul as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpComplexProgram implements WebGPUProgram {\n  variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  op: BinaryOpType;\n  size = true;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `binaryOpComplex_${op}`;\n    this.op = op;\n  }\n\n  getUserCode(): string {\n    const opStr = getBinaryOpString(this.op, false);\n    const userCode = `\n      fn binaryOpComplex(\n          areal : f32, aimag : f32, breal : f32, bimag : f32) -> f32 {\n        ${opStr}\n      }\n\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let areal = getARealByOutputIndex(index);\n          let aimag = getAImagByOutputIndex(index);\n          let breal = getBRealByOutputIndex(index);\n          let bimag = getBImagByOutputIndex(index);\n          setOutputAtIndex(index, binaryOpComplex(areal, aimag, breal, bimag));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType, getBinaryOpString} from './binary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BinaryOpProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  outputComponent: number;\n  op: BinaryOpType;\n  outputShape: number[];\n  shaderKey: string;\n  size = true;\n  variableNames = ['A', 'B'];\n  workgroupSize: [number, number, number];\n  variableComponents: number[];\n\n  private lastDimensionSize: number;\n  private useSharedMemoryWithA: boolean;\n  private useSharedMemoryWithB: boolean;\n  private type: string;\n\n  constructor(op: BinaryOpType, aShape: number[], bShape: number[]) {\n    this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.op = op;\n\n    this.useSharedMemoryWithA =\n        aShape.length <= 1 && bShape.length > 1 && aShape[0] < 128;\n    this.useSharedMemoryWithB =\n        bShape.length <= 1 && aShape.length > 1 && bShape[0] < 128;\n\n    if (this.useSharedMemoryWithA || this.useSharedMemoryWithB) {\n      this.outputComponent = 1;\n      this.variableComponents = [1, 1];\n      // lastDimensionSize is used as sharedBuf array size, so can not be\n      // used as uniform.\n      this.lastDimensionSize =\n          this.useSharedMemoryWithB ? bShape[0] : aShape[0];\n      this.shaderKey = `binary_${op}_${this.lastDimensionSize}`;\n      this.type = 'shared';\n      // This is an experimental value when using shared memory.\n      // Note that the maximum of workgroup X dimension is 256.\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      const aDivisibleBy4 =\n          aShape.length > 0 && aShape[aShape.length - 1] % 4 === 0;\n      const bDivisibleBy4 =\n          bShape.length > 0 && bShape[bShape.length - 1] % 4 === 0;\n      if (aDivisibleBy4 && bDivisibleBy4) {\n        this.outputComponent = 4;\n        this.variableComponents = [4, 4];\n      } else if (\n          (aDivisibleBy4 &&\n           (util.isScalarShape(bShape) || bShape[bShape.length - 1] === 1)) ||\n          (bDivisibleBy4 &&\n           (util.isScalarShape(aShape) || aShape[aShape.length - 1] === 1))) {\n        this.outputComponent = 4;\n        this.variableComponents = aDivisibleBy4 ? [4, 1] : [1, 4];\n      } else {\n        this.outputComponent = 1;\n        this.variableComponents = [1, 1];\n      }\n      this.type = 'nonshared';\n      this.shaderKey = `binary_${op}_${this.variableComponents}`;\n      // TODO(jiajia.qin@intel.com): Heuristically select a good work group\n      // size.\n      this.workgroupSize = [128, 1, 1];\n    }\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.outputComponent, 1, 1]);\n  }\n\n  getUserCode(): string {\n    let userCode;\n    const dType = this.outputComponent === 4 ? 'vec4<f32>' : 'f32';\n    const opFnStr = `\n    fn binaryOperation(a : ${dType}, b : ${dType}) -> ${dType} {\n      ${getBinaryOpString(this.op, this.outputComponent === 4)}\n    };\n    `;\n\n    if (this.type === 'shared') {\n      const sharedIndexSnippet = this.lastDimensionSize > 1 ?\n          `coords[${this.outputShape.length - 1}]` :\n          '0';\n      const accessDataSnippet = this.useSharedMemoryWithB ?\n          `let a = getAByOutputIndex(index);\n          let b = sharedBuf[${sharedIndexSnippet}];` :\n          `let a = sharedBuf[${sharedIndexSnippet}];\n          let b = getBByOutputIndex(index);`;\n      userCode = `\n        ${opFnStr}\n        var<workgroup> sharedBuf : array<f32, ${this.lastDimensionSize}>;\n        ${main('index')} {\n          // Fill in the shared memory buffer.\n          let localIndex = i32(localId.x);\n          if(localIndex < ${this.lastDimensionSize}) {\n            sharedBuf[localIndex] = f32(${\n          this.useSharedMemoryWithB ? 'B' : 'A'}[localIndex]);\n          }\n          workgroupBarrier();\n\n          if(index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            ${accessDataSnippet}\n            setOutputAtIndex(index, binaryOperation(a, b));\n          }\n        }\n        `;\n    } else {\n      userCode = `\n       ${opFnStr}\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let coords = getCoordsFromIndex(index * ${this.outputComponent});\n           let a = ${dType}(getAByOutputCoords(coords));\n           let b = ${dType}(getBByOutputCoords(coords));\n           setOutputAtIndex(index, binaryOperation(a, b));\n         }\n       }\n       `;\n    }\n\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs} = args;\n  const {x} = inputs;\n\n  args.backend.incRef(x.dataId);\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'webgpu',\n  kernelFunc: identity as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\n/**\n * Complex tensors share data with their real and imaginary components. Complex\n * tensors' reference to the components is tracked by refCount on the individual\n * component. The refCounts are increased by the identity call.\n *\n * When a complex tensor is disposed, it will reduce the refCount on the\n * components by calling disposeData on each.\n */\nexport function complex(args: {inputs: ComplexInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n  const complex = backend.tensorMap.get(complexInfo.dataId);\n\n  const realTensorInfo = identity({inputs: {x: real}, backend});\n\n  const imagTensorInfo = identity({inputs: {x: imag}, backend});\n\n  complex.complexTensorInfos = {real: realTensorInfo, imag: imagTensorInfo};\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'webgpu',\n  kernelFunc: complex as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getUnaryOpString, UnaryOpType} from './unary_op_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class UnaryOpProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A'];\n  workgroupSize: [number, number, number];\n  op: UnaryOpType;\n  uniforms?: string;\n  size = true;\n\n  constructor(outputShape: number[], op: UnaryOpType, uniforms = '') {\n    // TODO(jiajia.qin@intel.com): Heuristically select a good work group size.\n    const workgroupSizeX = 128;\n    this.workgroupSize = [workgroupSizeX, 1, 1];\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.op = op;\n    if (uniforms !== '') {\n      this.uniforms = uniforms;\n    }\n    this.shaderKey = `unary_${op}`;\n  }\n\n  getUserCode(): string {\n    return `\n      fn unaryOperation(a : f32) -> f32 {\n        ${getUnaryOpString(this.op, false)}\n      }\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let a = getAByOutputIndex(index);\n          setOutputAtIndex(index, unaryOperation(a));\n        }\n      }\n      `;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TensorInfo, TypedArray, UnaryInputs, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BinaryOpComplexProgram} from '../binary_op_complex_webgpu';\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\nimport {complex} from '../kernels/Complex';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nimport {SimpleBinaryKernelImplCPU, SimpleUnaryKernelImplCPU} from './shared';\n\ntype UnaryKernelFuncConfig = {\n  opType: UnaryOpType,\n  cpuKernelImpl?: SimpleUnaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opType Op type to create `UnaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc(\n    {opType, cpuKernelImpl, dtype}: UnaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    const $dtype = dtype || x.dtype;\n    if (webgpuBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webgpuBackend.tensorMap.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values as TypedArray, $dtype);\n      return webgpuBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const program: UnaryOpProgram = new UnaryOpProgram(x.shape, opType);\n    return webgpuBackend.runWebGPUProgram(program, [x], $dtype);\n  };\n}\n\ntype BinaryKernelFuncConfig = {\n  opType: BinaryOpType,\n  cpuKernelImpl?: SimpleBinaryKernelImplCPU,\n  supportsComplex?: boolean,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opType Op type to create `BinaryOpProgram`.\n * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it\n *     will be involved when necessary.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    {opType, cpuKernelImpl, supportsComplex = false, dtype}:\n        BinaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const webgpuBackend = backend as WebGPUBackend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webgpuBackend.tensorMap.get(a.dataId);\n      const bData = webgpuBackend.tensorMap.get(b.dataId);\n      let real: TensorInfo, imag: TensorInfo;\n      if (opType !== BinaryOpType.MUL) {\n        [real, imag] = [\n          [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n          [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n        ].map(complexParts => {\n          const [aPart, bPart] = complexParts;\n\n          const aHandle = {\n            dataId: aPart.dataId,\n            dtype: aPart.dtype,\n            shape: a.shape\n          };\n          const bHandle = {\n            dataId: bPart.dataId,\n            dtype: bPart.dtype,\n            shape: b.shape\n          };\n\n          const program = new BinaryOpProgram(opType, a.shape, b.shape);\n          return webgpuBackend.runWebGPUProgram(\n              program, [aHandle, bHandle],\n              upcastType(aPart.dtype, bPart.dtype));\n        });\n      } else {\n        const realProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_REAL, a.shape, b.shape);\n        const imagProgram = new BinaryOpComplexProgram(\n            BinaryOpType.COMPLEX_MULTIPLY_IMAG, a.shape, b.shape);\n\n        const inputs = [\n          {\n            dataId: aData.complexTensorInfos.real.dataId,\n            dtype: aData.complexTensorInfos.real.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: aData.complexTensorInfos.imag.dataId,\n            dtype: aData.complexTensorInfos.imag.dtype,\n            shape: a.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.real.dataId,\n            dtype: bData.complexTensorInfos.real.dtype,\n            shape: b.shape\n          },\n          {\n            dataId: bData.complexTensorInfos.imag.dataId,\n            dtype: bData.complexTensorInfos.imag.dtype,\n            shape: b.shape\n          }\n        ];\n\n        real = webgpuBackend.runWebGPUProgram(realProgram, inputs, 'float32');\n        imag = webgpuBackend.runWebGPUProgram(imagProgram, inputs, 'float32');\n      }\n\n      const complexOutput =\n          complex({inputs: {real, imag}, backend: webgpuBackend});\n\n      webgpuBackend.disposeData(real.dataId);\n      webgpuBackend.disposeData(imag.dataId);\n\n      // TODO: Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' ||\n         webgpuBackend.shouldExecuteOnCPU([a, b])) &&\n        cpuKernelImpl != null) {\n      const aData = webgpuBackend.tensorMap.get(a.dataId).values as TypedArray;\n      const bData = webgpuBackend.tensorMap.get(b.dataId).values as TypedArray;\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aData as any as Uint8Array[]) :\n          aData;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bData as any as Uint8Array[]) :\n          bData;\n      const [outValues, outShape] =\n          cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      return webgpuBackend.makeTensorInfo(outShape, $dtype, outValues);\n    }\n    const program = new BinaryOpProgram(opType, a.shape, b.shape);\n    return webgpuBackend.runWebGPUProgram(program, [a, b], $dtype);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataValues, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: DataValues,\n          bVals: DataValues, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const addImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BitwiseAnd, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const bitwiseAndImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => a & b));\n\nexport const bitwiseAnd = binaryKernelFunc(BitwiseAnd, bitwiseAndImpl);\n\nexport const bitwiseAndConfig: KernelConfig = {\n  kernelName: BitwiseAnd,\n  backendName: 'cpu',\n  kernelFunc: bitwiseAnd\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl<I extends number | string = number,\n  O extends number | string = number>(op: SimpleUnaryOperation<I, O>):\n    SimpleUnaryImpl<I, O> {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getArrayFromDType(dtype, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const equalImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a === b) ? 1 : 0);\nexport const equal =\n    binaryKernelFunc(Equal, equalImpl, null /* complexImpl */, 'bool');\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'cpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl, 'float32');\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const floorDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.floor(a / b));\nexport const floorDiv =\n    binaryKernelFunc(FloorDiv, floorDivImpl, null /* complexImpl */, 'int32');\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'cpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a > b) ? 1 : 0);\nexport const greater =\n    binaryKernelFunc(Greater, greaterImpl, null /* complexImpl */, 'bool');\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'cpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a >= b) ? 1 : 0);\nexport const greaterEqual = binaryKernelFunc(\n    GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'cpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a < b) ? 1 : 0);\nexport const less =\n    binaryKernelFunc(Less, lessImpl, null /* complexImpl */, 'bool');\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'cpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a <= b) ? 1 : 0);\nexport const lessEqual =\n    binaryKernelFunc(LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'cpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const maximumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.max(aValue as number, bValue as number)));\nexport const maximum = binaryKernelFunc(Maximum, maximumImpl);\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'cpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const minimumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.min(aValue as number, bValue as number)));\nexport const minimum = binaryKernelFunc(Minimum, minimumImpl);\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'cpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const multiplyImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction validateIndices(\n    indices: TypedArray, indicesShape: number[], numParams: number) {\n  indices.forEach((index: number, i: number) => {\n    if (index < 0 || index >= numParams) {\n      const locString =\n          util.indexToLoc(\n                  i, indicesShape.length, util.computeStrides(indicesShape))\n              .join(',');\n      throw new Error(\n          `indices[${locString}] = ${index} is not in [0, ${numParams})`);\n    }\n  });\n}\n\nfunction validateSplits(\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  // Validate\n  for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n    const splits = paramsNestedSplits[dim];\n    const lastSplit = (dim === paramsNestedSplits.length - 1) ?\n        numParamsDenseValues :\n        paramsNestedSplits[dim + 1].length;\n    if (splits.length === 0) {\n      throw new Error('Ragged splits may not be empty');\n    }\n    if (splits[0] < 0) {\n      throw new Error('Ragged splits must be non-negative');\n    }\n    if (splits[splits.length - 1] > lastSplit) {\n      throw new Error('Ragged splits must not point past values');\n    }\n    for (let i = 1; i < splits.length; ++i) {\n      if (splits[i - 1] > splits[i]) {\n        throw new Error('Ragged splits must be sorted in ascending order');\n      }\n    }\n  }\n}\n\n// Construct the `splits` output tensors, encoded using a nested vector.\n// Also find the slices of values that need to be copied, and store them\n// in `valueSlices`.  The total number of values that will be copied (which\n// we need for allocating the output values tensor) is stored in `numValues`.\nfunction makeSplits(\n    indices: TypedArray, indicesShape: number[],\n    paramsNestedSplits: TypedArray[], numParamsDenseValues: number) {\n  const valueSlices: Array<[number, number]> = [];\n  let numValues = 0;\n\n  const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;\n  const outSplits = new Array(numSplits).fill(null).map(() => [0]);\n\n  validateSplits(paramsNestedSplits, numParamsDenseValues);\n\n  // Add `splits` that come from all but the last dimension of the dense\n  // Tensor `indices`.  In particular, for each dimension D, we add a\n  // splits tensor whose values are:\n  //   range(reduceProd(splits.shape[:D]) + 1) * splits.shape[D+1]\n  // E.g., if indices.shape=[2, 3, 4] then we will add splits tensors:\n  //   [0, 3, 6]                    # length=2+1, stride=3\n  //   [0, 4, 8, 12, 16, 20, 24]    # length=2*3+1, stride=4\n  let nrows = 1;\n  for (let dim = 0; dim < indicesShape.length - 1; ++dim) {\n    nrows *= indicesShape[dim];\n    const rowLength = indicesShape[dim + 1];\n    for (let i = 1; i < nrows + 1; ++i) {\n      outSplits[dim].push(i * rowLength);\n    }\n  }\n\n  // Add `splits` that come from `paramsNestedSplits`.  Starting with the\n  // outermost ragged dimension (i.e., the first `splits` tensor), we work\n  // our way in, finding the range of values that should be copied.  As we\n  // go, we update the output `splits` for each dimension with the appropriate\n  // values.  In particular, the *lengths* of the slices from `param_splits`\n  // should be copied to generate corresponding slice lengths in the output\n  // splits.  E.g., if we are copying a ragged row with length 4, then we\n  // should add a new split point to outSplits that is 4 greater than the\n  // previous split point in outSplits.\n  for (let i = 0; i < indices.length; ++i) {\n    let start = indices[i];\n    let limit = indices[i] + 1;\n\n    // Copy splits.\n    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {\n      const splits = paramsNestedSplits[dim];\n      const outDim = dim + indicesShape.length - 1;\n      if (outDim >= 0) {\n        const outSplitsOutDim = outSplits[outDim];\n        const delta =\n            outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];\n        for (let j = start; j < limit; ++j) {\n          outSplits[outDim].push(splits[j + 1] + delta);\n        }\n      }\n      start = splits[start];\n      limit = splits[limit];\n    }\n    if (limit !== start) {\n      valueSlices.push([start, limit]);\n      numValues += limit - start;\n    }\n  }\n\n  return {outSplits, valueSlices, numValues};\n}\n\nfunction getSplits(outSplits: number[][]) {\n  const splitsOut: TypedArray[] = [];\n  for (let i = 0; i < outSplits.length; ++i) {\n    const numSplits = outSplits[i].length;\n    const splits = util.getArrayFromDType('int32', numSplits) as TypedArray;\n    splitsOut.push(splits);\n\n    outSplits[i].forEach((value, j: number) => splits[j] = value);\n  }\n\n  return splitsOut;\n}\n\nfunction computeFlatOuterDims(orig: number[], numOutDims: number) {\n  const outDims = orig.slice(0, numOutDims);\n  while (outDims.length < numOutDims) {\n    outDims.push(1);\n  }\n\n  for (let inDim = numOutDims; inDim < orig.length; inDim++) {\n    outDims[numOutDims - 1] *= orig[inDim];\n  }\n\n  return outDims;\n}\n// For each slice in `(start, limit)` in `valueSlices`, append\n// `paramsDenseValues[start,...,limit] to `values`.  `valueSize` indicates\n// the number of scalars contained in each value paramsDenseValues[i].\nfunction writeValueSlices(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    valueSlices: Array<[number, number]>, valueSize: number, values: TypedArray,\n    valuesShape: number[]) {\n  const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];\n  const valuesM = computeFlatOuterDims(valuesShape, 2)[1];\n\n  let outPos = 0;\n  for (const slice of valueSlices) {\n    for (let i = slice[0]; i < slice[1]; ++i) {\n      for (let j = 0; j < valueSize; ++j) {\n        values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];\n      }\n      ++outPos;\n    }\n  }\n}\n\nfunction getValues(\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, valueSlices: Array<[number, number]>,\n    numValues: number): [TypedArray, number[]] {\n  const valuesShape = paramsDenseValuesShape.slice();\n  valuesShape[0] = numValues;\n\n  const valuesOut = util.getArrayFromDType(\n                        paramsDenseValuesDType,\n                        util.sizeFromShape(valuesShape)) as TypedArray;\n\n  const numElements = paramsDenseValues.length;\n  const valueSize =\n      numElements === 0 ? 0 : (numElements / paramsDenseValuesShape[0]);\n  writeValueSlices(\n      paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize,\n      valuesOut, valuesShape);\n\n  return [valuesOut, valuesShape];\n}\nexport function raggedGatherImpl(\n    paramsNestedSplits: TypedArray[], paramsNestedSplitsShapes: number[][],\n    paramsDenseValues: TypedArray, paramsDenseValuesShape: number[],\n    paramsDenseValuesDType: DataType, indices: TypedArray,\n    indicesShape: number[],\n    outputRaggedRank: number): [TypedArray[], TypedArray, number[]] {\n  if (paramsNestedSplits.length === 0) {\n    throw new Error('paramsNestedSplits must be non empty');\n  }\n\n  if (paramsNestedSplitsShapes[0].length === 0) {\n    throw new Error('Split tensors must not be scalars');\n  }\n  const numParams = paramsNestedSplitsShapes[0][0] - 1;\n  validateIndices(indices, indicesShape, numParams);\n\n  if (paramsDenseValuesShape.length === 0) {\n    throw new Error('params.rank must be nonzero');\n  }\n  const numParamsDenseValues = paramsDenseValuesShape[0];\n\n  // Calculate the `splits`, and store the value slices that we need to\n  // copy in `valueSlices`.\n  const {outSplits, valueSlices, numValues} = makeSplits(\n      indices, indicesShape, paramsNestedSplits, numParamsDenseValues);\n\n  // Write the output tensors.\n  const outputNestedSplits = getSplits(outSplits);\n  const outputDenseValues = getValues(\n      paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType,\n      valueSlices, numValues);\n\n  return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst INT32_MAX = 2147483647;\n\nexport function raggedRangeImpl(\n    starts: TypedArray, startsShape: number[], startsDType: DataType,\n    limits: TypedArray, limitsShape: number[], deltas: TypedArray,\n    deltasShape: number[]): [TypedArray, TypedArray] {\n  // Check input tensor shapes.\n  if (startsShape.length > 1) {\n    throw new Error('starts must be a scalar or vector');\n  }\n  if (limitsShape.length > 1) {\n    throw new Error('limits must be a scalar or vector');\n  }\n  if (deltasShape.length > 1) {\n    throw new Error('deltas must be a scalar or vector');\n  }\n\n  // Determine which tensors we need to broadcast.\n  const broadcastStarts = startsShape.length === 0;\n  const broadcastLimits = limitsShape.length === 0;\n  const broadcastDeltas = deltasShape.length === 0;\n\n  // nRows (number of output rows) is the size of the non-broadcast inputs,\n  // or 1 if all inputs are scalars.\n  const inSizes: number[] = [];\n  if (!broadcastStarts) {\n    inSizes.push(startsShape[0]);\n  }\n  if (!broadcastLimits) {\n    inSizes.push(limitsShape[0]);\n  }\n  if (!broadcastDeltas) {\n    inSizes.push(deltasShape[0]);\n  }\n\n  for (let i = 1; i < inSizes.length; ++i) {\n    if (inSizes[i] !== inSizes[i - 1]) {\n      throw new Error('starts, limits, and deltas must have the same shape');\n    }\n  }\n  const nRows = inSizes.length === 0 ? 1 : inSizes[0];\n\n  // Construct the rtNestedSplits tensor.\n  const rtNestedSplits =\n      util.getArrayFromDType('int32', nRows + 1) as TypedArray;\n  rtNestedSplits[0] = 0;\n  for (let row = 0; row < nRows; ++row) {\n    const start = broadcastStarts ? starts[0] : starts[row];\n    const limit = broadcastLimits ? limits[0] : limits[row];\n    const delta = broadcastDeltas ? deltas[0] : deltas[row];\n    if (delta === 0) {\n      throw new Error('Requires delta != 0');\n    }\n    let size: number;  // The number of elements in the specified range.\n    if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {\n      size = 0;\n    } else {\n      size = Math.ceil(Math.abs((limit - start) / delta));\n\n      if (size > INT32_MAX) {\n        throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX}`);\n      }\n    }\n    rtNestedSplits[row + 1] = rtNestedSplits[row] + size;\n  }\n\n  const nVals = rtNestedSplits[nRows];\n\n  // Construct the rtDenseValues tensor.\n  const rtDenseValues =\n      util.getArrayFromDType(startsDType, nVals) as TypedArray;\n\n  let valueIndex = 0;\n  for (let row = 0; row < nRows; ++row) {\n    const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];\n    let value = broadcastStarts ? starts[0] : starts[row];\n    const delta = broadcastDeltas ? deltas[0] : deltas[row];\n    for (let i = 0; i < rowSize; ++i) {\n      rtDenseValues[valueIndex++] = value;\n      value += delta;\n    }\n  }\n\n  return [rtNestedSplits, rtDenseValues];\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcastTo, DataType, reshape, tidy, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport RowPartitionType = backend_util.RowPartitionType;\n// Based on\n// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc\nclass RaggedTensorToTensorOp {\n  private readonly rowPartitionTypes: RowPartitionType[];\n  private readonly raggedRank: number;\n  constructor(\n      private shape: TypedArray, private shapeShape: number[],\n      private values: TypedArray, private valuesShape: number[],\n      private valuesDType: DataType, private defaultValue: TypedArray,\n      private defaultValueShape: number[],\n      private readonly rowPartitionValues: TypedArray[],\n      private readonly rowPartitionValuesShapes: number[][],\n      rowPartitionTypeStrings: string[]) {\n    this.rowPartitionTypes =\n        backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);\n    this.raggedRank = backend_util.getRaggedRank(this.rowPartitionTypes);\n  }\n\n  private getRowPartitionTypeByDimension(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionTypes[dimension + 1];\n    } else {\n      return this.rowPartitionTypes[dimension];\n    }\n  }\n\n  // Returns the relationship between dimension and dimension + 1.\n  private getRowPartitionTensor(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionValues[dimension + 1];\n    } else {\n      return this.rowPartitionValues[dimension];\n    }\n  }\n\n  private getMaxWidth(dimension: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);\n    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);\n      case RowPartitionType.ROW_SPLITS:\n        return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);\n      default:\n        throw new Error(`Cannot handle partition type ${\n            RowPartitionType[this.getRowPartitionTypeByDimension(\n                dimension - 1)]}`);\n    }\n  }\n\n  static getMaxWidthRowSplit(rowSplit: TypedArray) {\n    const tensorLength = rowSplit.length;\n    if (tensorLength === 0 || tensorLength === 1) {\n      return 0;\n    }\n    let maxWidth = 0;\n    for (let i = 0; i < tensorLength - 1; ++i) {\n      const currentWidth = rowSplit[i + 1] - rowSplit[i];\n      if (currentWidth > maxWidth) {\n        maxWidth = currentWidth;\n      }\n    }\n    return maxWidth;\n  }\n\n  static getMaxWidthValueRowID(valueRowIds: TypedArray) {\n    const indexLength = valueRowIds.length;\n    if (indexLength === 0) {\n      return 0;\n    }\n    let firstEqualIndex = 0;\n    let firstEqualIndexValue = valueRowIds[0];\n    let maxWidth = 0;\n    for (let i = 1; i < indexLength; ++i) {\n      const value = valueRowIds[i];\n      if (value !== firstEqualIndexValue) {\n        firstEqualIndexValue = value;\n        maxWidth = Math.max(i - firstEqualIndex, maxWidth);\n        firstEqualIndex = i;\n      }\n    }\n    return Math.max(indexLength - firstEqualIndex, maxWidth);\n  }\n\n  private tensorShapeFromTensor(\n      t: TypedArray, tShape: number[], isPartial = true) {\n    if (tShape.length === 0) {\n      if (t[0] === -1) {\n        return [];\n      }\n      throw new Error(\n          `The only valid scalar shape tensor is the fully unknown shape specified as -1.`);\n    }\n    // MakePartialShape/MakeShapeHelper.\n    return makeShape(t, isPartial);\n  }\n\n  private calculateOutputSize(firstDim: number) {\n    const valueShape = this.valuesShape;\n    const defaultValueShape = this.defaultValueShape;\n\n    backend_util.validateDefaultValueShape(defaultValueShape, valueShape);\n\n    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);\n    const outputShape = backend_util.combineRaggedTensorToTensorShapes(\n        this.raggedRank, shape, valueShape);\n\n    const result = outputShape;\n\n    if (result[0] < 0) {\n      result[0] = firstDim;\n    }\n    for (let i = 1; i <= this.raggedRank; ++i) {\n      if (result[i] < 0) {\n        result[i] = this.getMaxWidth(i);\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * The outputIndex represents the index in the output tensor\n   * where the first element of a particular dimension would be written.\n   * If it is -1, it indicates that the index is out of scope.\n   * Example, given firstDimension = 10, firstDimensionOutput = 6,\n   * and outputIndexMultiplier = 100:\n   * result = [0 100 200 300 400 500 -1 -1 -1 -1]\n   * If firstDimensionOutput = 11 instead, then:\n   * result = [0 100 200 300 400 500 600 700 800 900]\n   */\n  private calculateFirstParentOutputIndex(\n      firstDimension: number, outputIndexMultiplier: number,\n      firstDimensionOutput: number) {\n    const minDimension = Math.min(firstDimension, firstDimensionOutput);\n    const result: number[] = [];\n    let currentOutputIndex = 0;\n    for (let i = 0; i < minDimension;\n         ++i, currentOutputIndex += outputIndexMultiplier) {\n      result.push(currentOutputIndex);\n    }\n    for (let i = minDimension; i < firstDimension; ++i) {\n      result.push(-1);\n    }\n    util.assert(\n        result.length === firstDimension,\n        () => 'Final length of result must be equal to firstDimension.');\n\n    return result;\n  }\n\n  private calculateOutputIndexRowSplit(\n      rowSplit: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowSplitSize = rowSplit.length;\n    const result: number[] = [];\n    for (let i = 0; i < rowSplitSize - 1; ++i) {\n      const rowLength = rowSplit[i + 1] - rowSplit[i];\n      let realLength = Math.min(outputSize, rowLength);\n      let parentOutputIndexCurrent = parentOutputIndex[i];\n\n      if (parentOutputIndexCurrent === -1) {\n        realLength = 0;\n      }\n      for (let j = 0; j < realLength; ++j) {\n        result.push(parentOutputIndexCurrent);\n        parentOutputIndexCurrent += outputIndexMultiplier;\n      }\n      for (let j = 0; j < rowLength - realLength; ++j) {\n        result.push(-1);\n      }\n    }\n    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {\n      throw new Error('Invalid row split size.');\n    }\n\n    return result;\n  }\n\n  // Calculate the output index of the first element of a list.\n  // The parentOutputIndex is the same computation for the previous list.\n  // -1 indicates an element or list that is out of range.\n  // The outputIndexMultiplier is the number of output indices one moves\n  // forward for each column.\n  // E.g., given:\n  // valueRowIds:[0 1 2 2 2 3 5 5 6]\n  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]\n  // outputIndexMultiplier: 10\n  // outputSize: 2\n  // You get:\n  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]\n  // result[0] = parentOutputIndex[valueRowIds[0]]\n  // result[1] = parentOutputIndex[valueRowIds[1]]\n  // result[2] = parentOutputIndex[valueRowIds[2]]\n  // result[3] = parentOutputIndex[valueRowIds[2] + 10]\n  // result[4] = -1 because it is the third element the size is 2.\n  // result[5] = parentOutputIndex[valueRowIds[3]]\n  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[8] = parentOutputIndex[valueRowIds[7]]\n  private calculateOutputIndexValueRowID(\n      valueRowIds: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const indexSize = valueRowIds.length;\n    const result: number[] = [];\n    if (indexSize === 0) {\n      return [];\n    }\n\n    let currentOutputColumn = 0;\n    let currentValueRowId = valueRowIds[0];\n\n    if (currentValueRowId >= parentOutputIndex.length) {\n      throw new Error(\n          `Got currentValueRowId=${currentValueRowId}, which is not less than ${\n              parentOutputIndex.length}`);\n    }\n\n    let currentOutputIndex = parentOutputIndex[currentValueRowId];\n    result.push(currentOutputIndex);\n    for (let i = 1; i < indexSize; ++i) {\n      const nextValueRowId = valueRowIds[i];\n      if (nextValueRowId === currentValueRowId) {\n        if (currentOutputIndex >= 0) {\n          ++currentOutputColumn;\n          if (currentOutputColumn < outputSize) {\n            currentOutputIndex += outputIndexMultiplier;\n          } else {\n            currentOutputIndex = -1;\n          }\n        }\n      } else {\n        currentOutputColumn = 0;\n        currentValueRowId = nextValueRowId;\n\n        if (nextValueRowId >= parentOutputIndex.length) {\n          throw new Error(\n              `Got nextValueRowId=${nextValueRowId} which is not less than ${\n                  parentOutputIndex.length}`);\n        }\n\n        currentOutputIndex = parentOutputIndex[nextValueRowId];\n      }\n      result.push(currentOutputIndex);\n    }\n\n    if (result.length !== valueRowIds.length) {\n      throw new Error('Invalid row ids.');\n    }\n\n    return result;\n  }\n\n  private calculateOutputIndex(\n      dimension: number, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension);\n    const partitionType = this.getRowPartitionTypeByDimension(dimension);\n    switch (partitionType) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return this.calculateOutputIndexValueRowID(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      case RowPartitionType.ROW_SPLITS:\n        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {\n          throw new Error(`Row partition size is greater than output size: ${\n              rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);\n        }\n        return this.calculateOutputIndexRowSplit(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      default:\n        throw new Error(\n            `Unsupported partition type: ${RowPartitionType[partitionType]}`);\n    }\n  }\n\n  private getFirstDimensionSize() {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (this.rowPartitionTypes.length === 0) {\n      throw new Error('No row_partition_types given.');\n    }\n    const firstPartitionType = this.rowPartitionTypes[0];\n    switch (firstPartitionType) {\n      case RowPartitionType.FIRST_DIM_SIZE:\n        return firstPartitionTensor[0];\n      case RowPartitionType.VALUE_ROWIDS:\n        throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');\n      case RowPartitionType.ROW_SPLITS:\n        return this.rowPartitionValuesShapes[0][0] - 1;\n      default:\n        throw new Error(\n            `Cannot handle type ${RowPartitionType[firstPartitionType]}`);\n    }\n  }\n\n  compute(): [number[], TypedArray] {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (firstPartitionTensor.length <= 0) {\n      throw new Error(\n          'Invalid first partition input. ' +\n          'Tensor requires at least one element.');\n    }\n    const firstDimension = this.getFirstDimensionSize();\n    const outputSize = this.calculateOutputSize(firstDimension);\n    const multiplier: number[] = new Array(this.raggedRank + 1);\n\n    multiplier[multiplier.length - 1] = 1;\n    for (let i = multiplier.length - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];\n    }\n    // Full size of the tensor.\n    const outputShape: number[] = makeShape(outputSize, false);\n    const outputTensor =\n        util.getArrayFromDType(\n            this.valuesDType, util.sizeFromShape(outputShape)) as TypedArray;\n\n    const fullSize = multiplier[0] * outputSize[0];\n    if (fullSize > 0) {\n      let outputIndex = this.calculateFirstParentOutputIndex(\n          firstDimension, multiplier[0], outputSize[0]);\n      for (let i = 1; i <= this.raggedRank; ++i) {\n        const newOutputIndex = this.calculateOutputIndex(\n            i - 1, outputIndex, multiplier[i], outputSize[i]);\n        outputIndex = newOutputIndex;\n      }\n\n      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);\n    }\n\n    return [outputShape, outputTensor];\n  }\n  setOutput(\n      raggedRank: number, outputIndex: number[], outputTensor: TypedArray,\n      outputShape: number[]) {\n    if (outputTensor.length === 0) {\n      return;\n    }\n\n    const valuesBase = this.values;\n    const outputBase = outputTensor;\n\n    let elementShape = outputShape.slice();\n    elementShape = elementShape.slice(raggedRank + 1);\n    const valueElementSize = util.sizeFromShape(elementShape);\n    const outputIndexSize = outputIndex.length;\n\n    // Broadcast the default value to value_element_size.  (We can skip this\n    // if defaultValueTensor.size == 1, since we use fill when that's true.)\n    let defaultValue = this.defaultValue;\n    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {\n      const srcShape = this.defaultValueShape;\n      tidy(() => {\n        const defaultValueTensor = reshape(defaultValue, srcShape);\n        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);\n        defaultValue = bCastDefault.dataSync();\n      });\n    }\n\n    // Loop through the outputIndex array, finding contiguous regions that\n    // should be copied.  Once we find the end of a contiguous region, copy it\n    // and add any necessary padding (with defaultValue).\n    let srcStart = 0;  // Start of contiguous region (in values)\n    let dstStart = 0;  // Destination for contiguous region (in output)\n    let dstEnd = 0;    // Destination for contiguous region (in output)\n    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {\n      // dstI is the destination where the value at srcI should be copied.\n      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;\n\n      // If we're still in a contiguous region, then update dstEnd go to the\n      // next srcI.\n      if (dstI === dstEnd) {\n        ++dstEnd;\n        continue;\n      }\n\n      // We found the end of contiguous region.  This can be because we found\n      // a gap (dstI > dstEnd), or a source value that shouldn't be copied\n      // because it's out-of-bounds (dstI == -1), or the end of the tensor\n      // (dstI === -1).\n      if (dstStart < dstEnd) {\n        // Copy the contiguous region.\n        const src = valuesBase.subarray(srcStart * valueElementSize);\n        const dst = outputBase.subarray(dstStart * valueElementSize);\n        const nVals = (dstEnd - dstStart) * valueElementSize;\n        copyArray(dst, src, nVals);\n      }\n\n      // Add any necessary padding (w/ defaultValue).\n      if (srcI >= outputIndexSize) {\n        // We reached the end of values: pad to the end of output.\n        const outputSize = outputTensor.length;\n        dstI = Math.floor(outputSize / valueElementSize);\n      }\n      if (dstI > dstEnd) {\n        if (this.defaultValue.length === 1) {\n          outputBase\n              .subarray(dstEnd * valueElementSize, dstI * valueElementSize)\n              .fill(this.defaultValue[0]);\n          dstEnd = dstI;\n        } else {\n          while (dstI > dstEnd) {\n            const dst = outputBase.slice(dstEnd * valueElementSize);\n            copyArray(dst, defaultValue, valueElementSize);\n            ++dstEnd;\n          }\n        }\n      }\n\n      // Update indices.\n      if (dstI < 0) {\n        // srcI should be skipped -- leave it out of the contiguous region.\n        srcStart = srcI + 1;\n        dstStart = dstEnd;\n      } else {\n        // srcI should be copied -- include it in the contiguous region.\n        srcStart = srcI;\n        dstStart = dstEnd;\n        dstEnd = dstStart + 1;\n      }\n    }\n  }\n}\n\nfunction copyArray(dst: TypedArray, src: TypedArray, size: number) {\n  for (let i = 0; i < size; i++) {\n    dst[i] = src[i];\n  }\n}\n\nfunction makeShape(shape: number[]|TypedArray, isPartial: boolean) {\n  const out: number[] = [];\n  for (let dim of shape) {\n    if (dim < 0) {\n      if (!isPartial) {\n        throw new Error(`Dimension ${dim} must be >= 0`);\n      }\n      if (dim < -1) {\n        throw new Error(`Dimension ${dim} must be >= -1`);\n      }\n      dim = -1;\n    }\n    out.push(dim);\n  }\n\n  return out;\n}\n\nexport function raggedTensorToTensorImpl(\n    shape: TypedArray, shapesShape: number[], values: TypedArray,\n    valuesShape: number[], valuesDType: DataType, defaultValue: TypedArray,\n    defaultValueShape: number[], rowPartitionValues: TypedArray[],\n    rowPartitionValuesShapes: number[][],\n    rowPartitionTypes: string[]): [number[], TypedArray] {\n  return new RaggedTensorToTensorOp(\n             shape, shapesShape, values, valuesShape, valuesDType, defaultValue,\n             defaultValueShape, rowPartitionValues, rowPartitionValuesShapes,\n             rowPartitionTypes)\n      .compute();\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidImpl =\n    createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const squaredDifferenceImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => {\n      const diff = a - b;\n      return diff * diff;\n    }));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, StaticRegexReplace, StaticRegexReplaceAttrs} from '@tensorflow/tfjs-core';\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const staticRegexReplaceImpl = createSimpleUnaryImpl<string,\n  string>((x: string, attrs) => {\n    const {pattern, replaceGlobal, rewrite} =\n      attrs as unknown as StaticRegexReplaceAttrs;\n    // TODO(mattSoulanille): Don't create a regex each time.\n    return x.replace(new RegExp(pattern, replaceGlobal ? 'g' : ''), rewrite);\n});\n\nconst staticRegexReplace =\n  unaryKernelFuncFromImpl(StaticRegexReplace, staticRegexReplaceImpl);\n\nexport const staticRegexReplaceConfig: KernelConfig = {\n  kernelName: StaticRegexReplace,\n  backendName: 'cpu',\n  kernelFunc: staticRegexReplace,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nclass StringNGramsOp {\n  private separator: Uint8Array;\n  private nGramWidths: number[];\n  private padWidth: number;\n  private leftPad: Uint8Array;\n  private rightPad: Uint8Array;\n  private preserveShort: boolean;\n\n  constructor(\n      separator: string, nGramWidths: number[], leftPad: string,\n      rightPad: string, padWidth: number, preserveShortSequences: boolean) {\n    this.separator = util.encodeString(separator);\n    this.nGramWidths = nGramWidths;\n    this.leftPad = util.encodeString(leftPad);\n    this.rightPad = util.encodeString(rightPad);\n    this.padWidth = padWidth;\n    this.preserveShort = preserveShortSequences;\n  }\n\n  private getPadWidth(nGramWidth: number) {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'padWidth' arg, but in no case should the padding\n    // ever be wider than 'nGramWidth' - 1.\n    return Math.min(\n        this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n  }\n\n  private getNumNGrams(length: number, nGramWidth: number) {\n    const padWidth = this.getPadWidth(nGramWidth);\n    return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n  }\n\n  private createNGrams(\n      data: Uint8Array[], splitIndex: number, output: Uint8Array[],\n      outputStartIndex: number, numNGrams: number, nGramWidth: number) {\n    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n      const padWidth = this.getPadWidth(nGramWidth);\n      const leftPadding = Math.max(0, padWidth - nGramIndex);\n      const rightPadding =\n          Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n      const numTokens = nGramWidth - (leftPadding + rightPadding);\n      const dataStartIndex =\n          splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n\n      // Calculate the total expected size of the nGram so we can reserve the\n      // correct amount of space in the string.\n      let nGramSize = 0;\n      // Size of the left padding.\n      nGramSize += leftPadding * this.leftPad.length;\n      // Size of the tokens.\n      for (let n = 0; n < numTokens; ++n) {\n        nGramSize += data[dataStartIndex + n].length;\n      }\n      // Size of the right padding.\n      nGramSize += rightPadding * this.rightPad.length;\n      // Size of the separators.\n      const numSeparators = leftPadding + rightPadding + numTokens - 1;\n      nGramSize += numSeparators * this.separator.length;\n\n      // Build the nGram.\n      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n      const nGram = output[outputStartIndex + nGramIndex];\n\n      let nextNGramIndex = 0;\n      const appendToNGram = (str: Uint8Array) =>\n          str.forEach((value) => nGram[nextNGramIndex++] = value);\n\n      for (let n = 0; n < leftPadding; ++n) {\n        appendToNGram(this.leftPad);\n        appendToNGram(this.separator);\n      }\n      // Only output first numTokens - 1 pairs of data and separator\n      for (let n = 0; n < numTokens - 1; ++n) {\n        appendToNGram(data[dataStartIndex + n]);\n        appendToNGram(this.separator);\n      }\n      // Handle case when there are no tokens or no right padding as these\n      // can result in consecutive separators.\n      if (numTokens > 0) {\n        // If we have tokens, then output last and then pair each separator\n        // with the right padding that follows, to ensure nGram ends either with\n        // the token or with the right pad.\n        appendToNGram(data[dataStartIndex + numTokens - 1]);\n        for (let n = 0; n < rightPadding; ++n) {\n          appendToNGram(this.separator);\n          appendToNGram(this.rightPad);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the nGram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (let n = 0; n < rightPadding - 1; ++n) {\n          appendToNGram(this.rightPad);\n          appendToNGram(this.separator);\n        }\n        appendToNGram(this.rightPad);\n      }\n    }\n  }\n\n  // Data and splits together form the definition of the ragged tensor,\n  // where data is 1 dimensional and contains the values of the tensor\n  // and splits denotes the indices at which each row starts.\n  public compute(data: Uint8Array[], splits: Int32Array):\n      [Uint8Array[], Int32Array] {\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const inputDataSize = data.length;\n    const splitsSize = splits.length;\n    if (splitsSize > 0) {\n      let prevSplit = splits[0];\n      if (prevSplit !== 0) {\n        throw new Error(`First split value must be 0, got ${prevSplit}`);\n      }\n      for (let i = 1; i < splitsSize; ++i) {\n        let validSplits = splits[i] >= prevSplit;\n        validSplits = validSplits && (splits[i] <= inputDataSize);\n        if (!validSplits) {\n          throw new Error(`Invalid split value ${splits[i]}, must be in [${\n              prevSplit}, ${inputDataSize}]`);\n        }\n        prevSplit = splits[i];\n      }\n      if (prevSplit !== inputDataSize) {\n        throw new Error(`Last split value must be data size. Expected ${\n            inputDataSize}, got ${prevSplit}`);\n      }\n    }\n\n    const numBatchItems = splitsSize - 1;\n    const nGramsSplits = util.getArrayFromDType('int32', splitsSize);\n    // If there is no data or size, return an empty ragged tensor.\n    if (inputDataSize === 0 || splitsSize === 0) {\n      const empty: Uint8Array[] = new Array(inputDataSize);\n      for (let i = 0; i <= numBatchItems; ++i) {\n        nGramsSplits[i] = 0;\n      }\n      return [empty, nGramsSplits];\n    }\n\n    nGramsSplits[0] = 0;\n    for (let i = 1; i <= numBatchItems; ++i) {\n      const length = splits[i] - splits[i - 1];\n      let numNGrams = 0;\n      this.nGramWidths.forEach((nGramWidth) => {\n        numNGrams += this.getNumNGrams(length, nGramWidth);\n      });\n      if (this.preserveShort && length > 0 && numNGrams === 0) {\n        numNGrams = 1;\n      }\n      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n    }\n\n    const nGrams: Uint8Array[] = new Array(nGramsSplits[numBatchItems]);\n\n    for (let i = 0; i < numBatchItems; ++i) {\n      const splitIndex = splits[i];\n      let outputStartIdx = nGramsSplits[i];\n      this.nGramWidths.forEach((nGramWidth) => {\n        const length = splits[i + 1] - splits[i];\n        const numNGrams = this.getNumNGrams(length, nGramWidth);\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n        outputStartIdx += numNGrams;\n      });\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (nGramSplitsdata). If no ngrams were generated, then they will\n      // be equal (since we increment outputStartIdx by numNGrams every\n      // time we create a set of ngrams.)\n      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {\n        const dataLength = splits[i + 1] - splits[i];\n        // One legitimate reason to not have any ngrams when this.preserveShort\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (dataLength === 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one nGram.\n        const nGramWidth = dataLength + 2 * this.padWidth;\n        const numNGrams = 1;\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n      }\n    }\n    return [nGrams, nGramsSplits];\n  }\n}\n\nexport function stringNGramsImpl(\n    data: Uint8Array[], dataSplits: Int32Array, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): [Uint8Array[], Int32Array] {\n  return new StringNGramsOp(\n             separator, nGramWidths, leftPad, rightPad, padWidth,\n             preserveShortSequences)\n      .compute(data, dataSplits);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction split(\n    str: Uint8Array, delimiters: Uint8Array, skipEmpty: boolean,\n    result: Uint8Array[]): void {\n  if (!str.length) {\n    return;\n  }\n  // When the delimiter is empty, the input is split into individual characters.\n  if (delimiters.length === 0) {\n    for (let i = 0; i < str.length; ++i) {\n      result.push(str.subarray(i, i + 1));\n    }\n    return;\n  }\n  // When there is one delimiter, the input is split only at that delimiter.\n  if (delimiters.length === 1) {\n    const delimiter = delimiters[0];\n    let f = str.indexOf(delimiter);\n    while (f !== -1) {\n      const token = str.subarray(0, f);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      str = str.subarray(f + 1);\n      f = str.indexOf(delimiter);\n    }\n    if (!skipEmpty || str.length !== 0) {\n      result.push(str);\n    }\n    return;\n  }\n  // When there are multiple delimiters, the input is split at every instance\n  // one of the delimiters appears.\n  let tokenStart = 0;\n  for (let i = 0; i < str.length + 1; i++) {\n    if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n      const token = str.subarray(tokenStart, i);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      tokenStart = i + 1;\n    }\n  }\n}\n\nexport function stringSplitImpl(\n    input: Uint8Array[], delimiter: Uint8Array,\n    skipEmpty: boolean): [TypedArray, Uint8Array[], [number, number]] {\n  const batchSize = input.length;\n\n  // Empty delimiter means split the input character by character.\n  const tokens: Uint8Array[] = [];\n\n  let outputSize = 0;\n  let maxNumEntries = 0;\n  const numIndices: number[] = new Array(batchSize);\n  for (let i = 0; i < batchSize; ++i) {\n    const prevTokensLength = tokens.length;\n    split(input[i], delimiter, skipEmpty, tokens);\n    const nEntries = tokens.length - prevTokensLength;\n    numIndices[i] = nEntries;\n    outputSize += nEntries;\n    maxNumEntries = Math.max(maxNumEntries, nEntries);\n  }\n\n  const indices = util.getArrayFromDType('int32', outputSize * 2) as TypedArray;\n  const values: Uint8Array[] = new Array(outputSize);\n  const shape: [number, number] = [batchSize, maxNumEntries];\n\n  let c = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    for (let j = 0; j < numIndices[i]; ++j) {\n      // indices is a 2d tensor with shape of [outputSize, 2]\n      indices[c * 2] = i;\n      indices[c * 2 + 1] = j;\n      values[c] = tokens[c];\n      ++c;\n    }\n  }\n\n  return [indices, values, shape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const subImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the TopK kernel shared between webgl and cpu. */\n\nimport {buffer, NumericDataType, Rank, ShapeMap, Tensor, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\ntype Pair = {\n  value: number,\n  index: number\n};\n\nconst comparePair = (a: Pair, b: Pair) => {\n  const valueDiff = b.value - a.value;\n  return valueDiff === 0 ? a.index - b.index : valueDiff;\n};\n\n/**\n * Partitions array where all elements smaller than the (k+1) smallest element\n * are found to the left of it, and all larger to the right of it.\n * Based on the Floyd-Rivest Algorithm, ref:\n * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm\n * @param array: Array to partition\n * @param left: Left index for the interval\n * @param right: Right index for the interval\n * @param k: Desired index value, where array[k] is the (k+1)th smallest element\n *           when left = 0\n */\nfunction select(array: Pair[], k: number, left = 0, right = array.length - 1) {\n  while (right > left) {\n    // Use select recursively to sample a smaller set of size s\n    // the arbitrary constants 600 and 0.5 are used in the original\n    // version to minimize execution time.\n    if (right - left > 600) {\n      const n = right - left + 1;\n      const i = k - left + 1;\n      const z = Math.log(n);\n      const s = 0.5 * Math.exp(2 * z / 3);\n      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i - n / 2);\n      const newLeft = Math.max(left, Math.floor(k - i * s / n + sd));\n      const newRight = Math.min(right, Math.floor(k + (n - i) * s / n + sd));\n      select(array, k, newLeft, newRight);\n    }\n    // partition the elements between left and right around t\n    const t = array[k];\n    let i = left;\n    let j = right;\n\n    util.swap(array, left, k);\n\n    if (comparePair(array[right], t) > 0) {\n      util.swap(array, left, right);\n    }\n    while (i < j) {\n      util.swap(array, i, j);\n      i++;\n      j--;\n      while (comparePair(array[i], t) < 0) {\n        i = i + 1;\n      }\n      while (comparePair(array[j], t) > 0) {\n        j = j - 1;\n      }\n    }\n    if (comparePair(array[left], t) === 0) {\n      util.swap(array, left, j);\n    } else {\n      j = j + 1;\n      util.swap(array, j, right);\n    }\n    // Adjust left and right towards the boundaries of the subset\n    // containing the (k - left + 1)th smallest element.\n    if (j <= k) {\n      left = j + 1;\n    }\n    if (k <= j) {\n      right = j - 1;\n    }\n  }\n}\n\nexport function topKImpl<T extends Tensor, R extends Rank>(\n    x: TypedArray, xShape: number[], xDtype: NumericDataType, k: number,\n    sorted: boolean):\n    [TensorBuffer<R, NumericDataType>, TensorBuffer<R, 'int32'>] {\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const lastDim = xShape[xShape.length - 1];\n  const [batch, size] = [x.length / lastDim, lastDim];\n  const allTopKVals = util.getTypedArrayFromDType(xDtype, batch * k);\n  const allTopKIndices = util.getTypedArrayFromDType('int32', batch * k);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = x.subarray(offset, offset + size);\n\n    let valAndInd: Pair[] = new Array(vals.length);\n    vals.forEach(\n        (value: number, index: number) => valAndInd[index] = {value, index});\n\n    if (k < valAndInd.length) {\n      select(valAndInd, k);\n      valAndInd = valAndInd.slice(0, k);\n    }\n\n    if (sorted) {\n      valAndInd.sort(comparePair);\n    }\n    \n    const outOffset = b * k;\n    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n    for (let i = 0; i < k; i++) {\n      topKVals[i] = valAndInd[i].value;\n      topKIndices[i] = valAndInd[i].index;\n    }\n  }\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const outputShape = xShape.slice();\n  outputShape[outputShape.length - 1] = k;\n\n  return [\n    buffer(outputShape as ShapeMap[R], xDtype, allTopKVals),\n    buffer(outputShape as ShapeMap[R], 'int32', allTopKIndices)\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function bincountImpl(\n    xVals: TypedArray, weightsVals: TypedArray, weightsDtype: DataType,\n    weightsShape: number[], size: number): TypedArray {\n  const weightsSize = util.sizeFromShape(weightsShape);\n  const outVals = util.makeZerosTypedArray(size, weightsDtype) as TypedArray;\n\n  for (let i = 0; i < xVals.length; i++) {\n    const value = xVals[i];\n    if (value < 0) {\n      throw new Error('Input x must be non-negative!');\n    }\n\n    if (value >= size) {\n      continue;\n    }\n\n    if (weightsSize > 0) {\n      outVals[value] += weightsVals[i];\n    } else {\n      outVals[value] += 1;\n    }\n  }\n\n  return outVals;\n}\n\nexport function bincountReduceImpl<R extends Rank>(\n    xBuf: TensorBuffer<R>, weightsBuf: TensorBuffer<R>, size: number,\n    binaryOutput = false): TensorBuffer<R> {\n  const numRows = xBuf.shape[0];\n  const numCols = xBuf.shape[1];\n\n  const outBuf = buffer([numRows, size], weightsBuf.dtype);\n\n  for (let i = 0; i < numRows; i++) {\n    for (let j = 0; j < numCols; j++) {\n      const value = xBuf.get(i, j);\n      if (value < 0) {\n        throw new Error('Input x must be non-negative!');\n      }\n\n      if (value >= size) {\n        continue;\n      }\n\n      if (binaryOutput) {\n        outBuf.set(1, i, value);\n      } else {\n        if (weightsBuf.size > 0) {\n          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n        } else {\n          outBuf.set(outBuf.get(i, value) + 1, i, value);\n        }\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, DataType, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function castImpl(\n    values: TypedArray, shape: number[], inputType: DataType,\n    dtype: DataType): [number[], DataType, TypedArray] {\n  if (dtype === 'int32') {\n    const resultValues = Int32Array.from(values);\n    return [shape, 'int32', resultValues];\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const zero = util.toTypedArray([0], inputType);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(shape, [], values, zero, 'bool');\n\n    return [resultShape, 'bool', resultData];\n  }\n  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);\n}\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const [resultShape, resultType, resultData] =\n      castImpl(values, x.shape, x.dtype, dtype);\n  return backend.makeTensorInfo(resultShape, resultType, resultData);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function gatherNdImpl<R extends Rank>(\n    indicesData: TypedArray, paramsBuf: TensorBuffer<R>, dtype: DataType,\n    numSlices: number, sliceRank: number, sliceSize: number, strides: number[],\n    paramsShape: number[], paramsSize: number): TensorBuffer<R> {\n  const outBuf = buffer([numSlices, sliceSize], dtype);\n\n  for (let i = 0; i < numSlices; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      flattenIndex += dim * strides[j];\n      index.push(dim);\n    }\n    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n      throw new Error(\n          `Invalid indices: ${index} does not index into ${paramsShape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      outBuf.values[i * sliceSize + k] =\n          paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function gatherV2Impl<R extends Rank, D extends DataType>(\n    xBuf: TensorBuffer<R, D>, indicesBuf: TensorBuffer<R, D>,\n    flattenOutputShape: number[]): TensorBuffer<R, D> {\n  const outBuf = buffer(flattenOutputShape, xBuf.dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const newLoc = outBuf.indexToLoc(i);\n\n    const originalLoc: number[] = newLoc.slice();\n    const batchIdx = originalLoc[0];\n    const indicesIdx = originalLoc[2];\n    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n    originalLoc[2] = indicesBuf.values[indicesIndex] as number;\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    if (0 <= originalIndex && originalIndex < xBuf.values.length) {\n      outBuf.values[i] = xBuf.values[originalIndex];\n    } // Else, index is out of bounds, so leave the default zero val in outBuf.\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function linSpaceImpl(\n    start: number, stop: number, num: number): TypedArray {\n  const step = (stop - start) / (num - 1);\n\n  const values = util.makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value > max) {  // comparison with NaN always return false\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, Neg, TensorInfo, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {multiplyImpl} from './Multiply';\n\nexport function negImpl(xVals: TypedArray, xShape: number[], xDtype: DataType):\n    [TypedArray, number[]] {\n  const minusOne =\n      util.createScalarValue(-1 as unknown as 'float32', xDtype) as TypedArray;\n  return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\n\nexport function neg(args: {inputs: UnaryInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  assertNotComplex(x, 'neg');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);\n\n  return backend.makeTensorInfo(newShape, x.dtype, res);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'cpu',\n  kernelFunc: neg as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function prodImpl(\n    xShape: number[], xDtype: DataType, xVals: TypedArray,\n    reductionAxes: number[]):\n    {outVals: TypedArray, outShape: number[], outDtype: DataType} {\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, reductionAxes);\n  const outDtype = upcastType(xDtype, 'int32');\n  const outVals = util.makeZerosTypedArray(\n                      util.sizeFromShape(outShape), outDtype) as TypedArray;\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  for (let i = 0; i < outVals.length; ++i) {\n    const offset = i * reduceSize;\n    let prod = 1;\n    for (let j = 0; j < reduceSize; ++j) {\n      prod *= xVals[offset + j];\n    }\n    outVals[i] = prod;\n  }\n\n  return {outVals, outShape, outDtype};\n}\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: MathBackendCPU, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'prod');\n\n  const xRank = x.shape.length;\n  const axes = util.parseAxisParam(axis, x.shape);\n\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n  let reductionAxes = axes;\n  let permutedX = x;\n  const intermediateTensorInfos = [];\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    intermediateTensorInfos.push(permutedX);\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  const xVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  const {outVals, outShape, outDtype} =\n      prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);\n\n  let resultShape = outShape;\n  if (keepDims) {\n    resultShape = backend_util.expandShapeToKeepDim(outShape, axes);\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'cpu',\n  kernelFunc: prod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {buffer, Rank, ShapeMap, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\ninterface DefaultValueTypeMap {\n  bool: boolean;\n  int32: number;\n  float32: number;\n  string: string;\n}\n\nexport function\nscatterImpl<R extends Rank, D extends 'float32'|'int32'|'bool'|'string'>(\n    indices: TensorBuffer<R, 'int32'>, updates: TensorBuffer<R, D>,\n    shape: number[], outputSize: number, sliceSize: number, numUpdates: number,\n    sliceRank: number, strides: number[],\n    defaultValue: TensorBuffer<R, D>|DefaultValueTypeMap[D],\n    sumDupeIndices: boolean): TensorBuffer<R, D> {\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const indicesData = indices.values as TypedArray;\n  const updatesData = updates.values;\n\n  if (outputSize === 0) {\n    return buffer(shape as ShapeMap[R], updates.dtype);\n  }\n\n  const outBuf = (defaultValue instanceof TensorBuffer) ?\n      defaultValue :\n      buffer(flattenShape, updates.dtype);\n  if (typeof defaultValue === 'string') {\n    (outBuf.values as string[]).fill(defaultValue);\n  } else if (typeof defaultValue === 'number') {\n    (outBuf.values as TypedArray).fill(defaultValue);\n  } else if (typeof defaultValue === 'boolean') {\n    (outBuf.values as TypedArray).fill(+defaultValue);\n  }\n\n  for (let i = 0; i < numUpdates; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      index.push(dim);\n      flattenIndex += dim * strides[j];\n    }\n\n    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      if (sumDupeIndices) {\n        (outBuf.values as TypedArray)[flattenIndex * sliceSize + k] +=\n            (updatesData as TypedArray)[i * sliceSize + k];\n      } else {\n        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n            updatesData[0] :\n            updatesData[i * sliceSize + k];\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n\n  assertNotComplex(x, 'abs');\n\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n  resultValues = simpleAbsImpl(values);\n\n  return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseFillEmptyRowsImpl(\n    indices: TypedArray, indicesShape: number[], indicesDType: DataType,\n    values: TypedArray, valuesDType: DataType, denseShape: TypedArray,\n    defaultValue: number):\n    [TypedArray, number[], TypedArray, boolean[], number[]] {\n  const indicesCount = indicesShape[0];\n  const denseRows = denseShape[0];\n\n  const emptyRowIndicator: boolean[] = new Array(denseRows);\n  const reverseIndexMap: number[] = new Array(indicesCount);\n\n  const rank = indicesShape[1];\n\n  if (denseRows === 0) {\n    if (indicesCount !== 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n              indicesCount));\n    }\n    const outputIndices = util.getArrayFromDType(indicesDType, 0) as TypedArray;\n    const outputValues = util.getArrayFromDType(valuesDType, 0) as TypedArray;\n    return [\n      outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n    ];\n  }\n\n  let rowsAreOrdered = true;\n  let lastIndicesRow = 0;\n  const csrOffset: number[] = new Array(denseRows).fill(0);\n\n  for (let i = 0; i < indicesCount; ++i) {\n    // indices is a 2d tensor with shape of [N, rank]\n    const row = indices[i * rank];\n    if (row < 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));\n    }\n    if (row >= denseRows) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n              i, row, denseRows));\n    }\n    ++csrOffset[row];\n    rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n    lastIndicesRow = row;\n  }\n\n  let allRowsFull = true;\n  for (let row = 0; row < denseRows; ++row) {\n    // csrOffset here describes the number of elements in this dense row\n    const rowEmpty = (csrOffset[row] === 0);\n    emptyRowIndicator[row] = rowEmpty;\n    allRowsFull = allRowsFull && !rowEmpty;\n    // In filled version, each row has at least one element.\n    csrOffset[row] = Math.max(csrOffset[row], 1);\n    // Update csrOffset to represent the number of elements up to and\n    // including denseRows + 1:\n    //  csrOffset[0] == #{elements of row 0}\n    //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n    //  ..\n    //  csrOffset[i] == starting index for elements in row i + 1.\n    if (row > 0) {\n      csrOffset[row] += csrOffset[row - 1];\n    }\n  }\n\n  if (allRowsFull && rowsAreOrdered) {\n    const outputIndices: TypedArray = indices;\n    const outputValues: TypedArray = values;\n    for (let i = 0; i < indicesCount; ++i) {\n      reverseIndexMap[i] = i;\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  } else {\n    const fullIndicesCount = csrOffset[denseRows - 1];\n    const outputIndices =\n        util.getArrayFromDType(indicesDType, fullIndicesCount * rank) as\n        TypedArray;\n    const outputValues =\n        util.getArrayFromDType(valuesDType, fullIndicesCount) as TypedArray;\n    const filledCount: number[] = new Array(denseRows).fill(0);\n\n    // Fill in values for rows that are not missing\n    for (let i = 0; i < indicesCount; ++i) {\n      // indices is a 2d tensor with shape of [N, rank]\n      const row = indices[i * rank];\n      const offset = filledCount[row];\n      const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n      filledCount[row]++;  // Increment the filled count for this row.\n      for (let j = 0; j < rank; ++j) {\n        // indices and outputIndices are 2d tensors with shape of [N, rank]\n        outputIndices[outputI * rank + j] = indices[i * rank + j];\n      }\n      outputValues[outputI] = values[i];\n      // We'll need this reverse index map to backprop correctly.\n      reverseIndexMap[i] = outputI;\n    }\n\n    // Fill in values for rows that are missing\n    for (let row = 0; row < denseRows; ++row) {\n      const rowCount = filledCount[row];\n      if (rowCount === 0) {  // We haven't filled this row\n        const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n        // Remaining index values were set to zero already.\n        // Just need to set the row index in the right location.\n        // outputIndices is a 2d tensor with shape of [N, rank]\n        outputIndices[startingIndex * rank + 0] = row;\n        for (let col = 1; col < rank; ++col) {\n          outputIndices[startingIndex * rank + col] = 0;\n        }\n        outputValues[startingIndex] = defaultValue;\n      }\n    }\n    return [\n      outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseReshapeImpl(\n    inputIndices: TypedArray, inputIndicesShape: number[], inputDType: DataType,\n    inputShape: number[],\n    targetShape: number[]): [TypedArray, number[], number[]] {\n  const denseSize = util.sizeFromShape(inputShape);\n  const nnz = inputIndicesShape[0];\n  const outputRank = targetShape.length;\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  const outputShape: number[] = [];\n  let product = 1;\n  let unknownIndex = -1;\n  for (let d = 0; d < outputRank; ++d) {\n    const size = targetShape[d];\n    if (size === -1) {\n      if (unknownIndex !== -1) {\n        throw new Error(\n            backend_util\n                .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n                    unknownIndex, d));\n      }\n      unknownIndex = d;\n      outputShape.push(1);\n    } else {\n      if (size < 0) {\n        throw new Error(\n            backend_util.getSparseReshapeNegativeOutputDimErrorMessage(\n                d, size));\n      }\n      product *= size;\n      outputShape.push(size);\n    }\n  }\n  if (unknownIndex !== -1) {\n    if (product <= 0) {\n      throw new Error(\n          backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());\n    }\n    const missing = Math.trunc(denseSize / product);\n    if (product * missing !== denseSize) {\n      throw new Error(\n          backend_util.getSparseReshapeInputOutputMultipleErrorMessage(\n              inputShape, outputShape));\n    }\n\n    outputShape[unknownIndex] = missing;\n  }\n  const outputSize = util.sizeFromShape(outputShape);\n  if (outputSize !== denseSize) {\n    throw new Error(\n        backend_util.getSparseReshapeInputOutputMismatchErrorMessage(\n            inputShape, outputShape));\n  }\n\n  const inputRank = inputShape.length;\n  const inputStrides: number[] = [];\n  if (inputRank > 0) {\n    inputStrides[inputRank - 1] = 1;\n    for (let d = inputRank - 2; d >= 0; --d) {\n      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n    }\n  }\n\n  const outputStrides: number[] = [];\n  if (outputRank > 0) {\n    outputStrides[outputRank - 1] = 1;\n    for (let d = outputRank - 2; d >= 0; --d) {\n      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n    }\n  }\n\n  const newIndices =\n      util.getArrayFromDType(inputDType, nnz * outputRank) as TypedArray;\n  for (let i = 0; i < nnz; ++i) {\n    let id = 0;\n    for (let j = 0; j < inputRank; ++j) {\n      // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n      id += inputIndices[i * inputRank + j] * inputStrides[j];\n    }\n    for (let j = 0; j < outputRank; ++j) {\n      // newIndices is a 2d tensor with shape of [nnz, outputRank]\n      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n      id %= outputStrides[j];\n    }\n  }\n  return [newIndices, [nnz, outputRank], outputShape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseSegmentReductionImpl(\n    input: TypedArray, inputShape: number[], inputDType: DataType,\n    indices: TypedArray, segmentIds: TypedArray, isMean = false,\n    defaultValue = 0): [TypedArray, number[]] {\n  const numIndices = indices.length;\n\n  // Flatten the array to two dimensions\n  const inputFlat: number[] = [inputShape[0], input.length / inputShape[0]];\n  const numCol = inputFlat[1];\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  if (outputRows < 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  const outputShape = inputShape.slice();\n  outputShape[0] = outputRows;\n\n  const outputLength =\n      outputShape.reduce((product, value) => product * value, 1);\n  // Output array is initialized with the value 0 by default.\n  const output = util.getArrayFromDType(inputDType, outputLength) as TypedArray;\n\n  // Note that we do not initialize the output buffer with a default value, so\n  // we need to explicitly set missing indices to the default value.\n  if (numIndices === 0) {\n    if (outputRows > 0) {\n      output.fill(defaultValue);\n    }\n    return [output, outputShape];\n  }\n\n  if (outputRows <= 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  let start = 0, end = 1;\n  // Index from which the output is not initialized.\n  let uninitializedIndex = 0;\n  let outIndex = segmentIds[start];\n\n  while (true) {\n    // We initialize nextIndex to 0 to avoid may be uninitialized warning\n    let nextIndex = 0;\n    if (end < numIndices) {\n      nextIndex = segmentIds[end];\n      if (outIndex === nextIndex) {\n        ++end;\n        continue;\n      }\n      // We have a new segment here.  Verify that the segment ids are growing.\n      if (outIndex >= nextIndex) {\n        throw new Error(backend_util\n            .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());\n      }\n    }\n\n    if (outIndex < 0 || outIndex >= outputRows) {\n      throw new Error(\n          backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n              outIndex, outputRows));\n    }\n\n    // If there is a gap between two indices, we need to set that gap to the\n    // default value.\n    if (outIndex > uninitializedIndex) {\n      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);\n    }\n\n    for (let i = start; i < end; ++i) {\n      const index = indices[i];\n      if (index < 0 || index >= inputFlat[0]) {\n        throw new Error(\n            backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n                i, indices[i], inputFlat[0]));\n      }\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] += input[index * numCol + j];\n      }\n    }\n\n    if (isMean) {\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] /= end - start;\n      }\n    }\n\n    start = end;\n    ++end;\n    uninitializedIndex = outIndex + 1;\n    outIndex = nextIndex;\n    if (end > numIndices) {\n      break;\n    }\n  }\n\n  // Fill the gap at the end with the default value.\n  if (uninitializedIndex < outputRows) {\n    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);\n  }\n\n  return [output, outputShape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function stridedSliceImpl<R extends Rank>(\n    outShape: number[], xBuf: TensorBuffer<R>, strides: number[],\n    begin: number[]): TensorBuffer<R> {\n  const outBuf = buffer(outShape, xBuf.dtype);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const loc = outBuf.indexToLoc(i);\n\n    const newLoc: number[] = new Array(loc.length);\n    for (let j = 0; j < newLoc.length; j++) {\n      newLoc[j] = loc[j] * strides[j] + begin[j];\n    }\n    outBuf.set(xBuf.get(...newLoc), ...loc);\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function stringToHashBucketFastImpl(\n    input: Uint8Array[], numBuckets: number): TypedArray {\n  const output = util.getArrayFromDType('int32', input.length) as TypedArray;\n\n  for (let i = 0; i < input.length; ++i) {\n    output[i] =\n        util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\n\nexport function tileImpl<R extends Rank>(\n    xBuf: TensorBuffer<R, DataType>,\n    reps: number[]): TensorBuffer<R, DataType> {\n  const newShape: number[] = new Array(xBuf.rank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = xBuf.shape[i] * reps[i];\n  }\n  const result = buffer(newShape, xBuf.dtype);\n  for (let i = 0; i < result.values.length; ++i) {\n    const newLoc = result.indexToLoc(i);\n\n    const originalLoc: number[] = new Array(xBuf.rank);\n    for (let j = 0; j < originalLoc.length; j++) {\n      originalLoc[j] = newLoc[j] % xBuf.shape[j];\n    }\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    result.values[i] = xBuf.values[originalIndex];\n  }\n  return result as TensorBuffer<R, DataType>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements = new Map<string, number>();\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    const existingIndex = uniqueElements.get(element);\n    if (existingIndex != null) {\n      indices[i] = existingIndex;\n    } else {\n      const uniqueIndex = uniqueElements.size;\n      uniqueElements.set(element, uniqueIndex);\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = uniqueElements.size;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Import shared functionality from tfjs-backend-cpu without triggering\n// side effects.\n// tslint:disable-next-line: no-imports-from-dist\nimport * as shared from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleBinaryKernelImpl} from '@tensorflow/tfjs-backend-cpu/dist/shared';\n// tslint:disable-next-line: no-imports-from-dist\nimport {SimpleUnaryImpl} from '@tensorflow/tfjs-backend-cpu/dist/utils/unary_types';\n\nexport type SimpleBinaryKernelImplCPU = SimpleBinaryKernelImpl;\nexport type SimpleUnaryKernelImplCPU = SimpleUnaryImpl;\nconst {\n  addImpl: addImplCPU,\n  castImpl: castImplCPU,\n  ceilImpl: ceilImplCPU,\n  concatImpl: concatImplCPU,\n  equalImpl: equalImplCPU,\n  expImpl: expImplCPU,\n  expm1Impl: expm1ImplCPU,\n  floorImpl: floorImplCPU,\n  floorDivImpl: floorDivImplCPU,\n  gatherNdImpl: gatherNdImplCPU,\n  gatherV2Impl: gatherV2ImplCPU,\n  greaterEqualImpl: greaterEqualImplCPU,\n  greaterImpl: greaterImplCPU,\n  lessEqualImpl: lessEqualImplCPU,\n  lessImpl: lessImplCPU,\n  logImpl: logImplCPU,\n  maxImpl: maxImplCPU,\n  maximumImpl: maximumImplCPU,\n  minimumImpl: minimumImplCPU,\n  multiplyImpl: multiplyImplCPU,\n  negImpl: negImplCPU,\n  notEqualImpl: notEqualImplCPU,\n  prodImpl: prodImplCPU,\n  rangeImpl: rangeImplCPU,\n  rsqrtImpl: rsqrtImplCPU,\n  scatterImpl: scatterImplCPU,\n  simpleAbsImpl: simpleAbsImplCPU,\n  sliceImpl: sliceImplCPU,\n  stridedSliceImpl: stridedSliceImplCPU,\n  stringNGramsImpl: stringNGramsImplCPU,\n  subImpl: subImplCPU,\n  tileImpl: tileImplCPU,\n  topKImpl: topKImplCPU,\n  transposeImpl: transposeImplCPU,\n  uniqueImpl: uniqueImplCPU,\n} = shared;\n\nexport {\n  addImplCPU,\n  castImplCPU,\n  ceilImplCPU,\n  concatImplCPU,\n  equalImplCPU,\n  expImplCPU,\n  expm1ImplCPU,\n  floorImplCPU,\n  floorDivImplCPU,\n  gatherNdImplCPU,\n  gatherV2ImplCPU,\n  greaterEqualImplCPU,\n  greaterImplCPU,\n  lessEqualImplCPU,\n  lessImplCPU,\n  logImplCPU,\n  maxImplCPU,\n  maximumImplCPU,\n  minimumImplCPU,\n  multiplyImplCPU,\n  prodImplCPU,\n  negImplCPU,\n  notEqualImplCPU,\n  scatterImplCPU,\n  simpleAbsImplCPU,\n  sliceImplCPU,\n  stridedSliceImplCPU,\n  stringNGramsImplCPU,\n  subImplCPU,\n  rangeImplCPU,\n  rsqrtImplCPU,\n  tileImplCPU,\n  topKImplCPU,\n  transposeImplCPU,\n  uniqueImplCPU,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {simpleAbsImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const abs =\n    unaryKernelFunc({opType: UnaryOpType.ABS, cpuKernelImpl: simpleAbsImplCPU});\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'webgpu',\n  kernelFunc: abs\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const acos = unaryKernelFunc({opType: UnaryOpType.ACOS});\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'webgpu',\n  kernelFunc: acos\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const acosh = unaryKernelFunc({opType: UnaryOpType.ACOSH});\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'webgpu',\n  kernelFunc: acosh\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {addImplCPU as cpuAdd} from '../kernel_utils/shared';\n\nexport const addKernelFunc = binaryKernelFunc(\n    {opType: BinaryOpType.ADD, cpuKernelImpl: cpuAdd, supportsComplex: true});\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'webgpu',\n  kernelFunc: addKernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class AddNPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shapes: number[][]) {\n    this.outputShape = shapes[0];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'addN';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    // Get target elements from every input tensor.\n    this.variableNames.forEach(variable => {\n      snippets.push(`let v${variable} = get${variable}ByOutputCoords(coords);`);\n    });\n    // Calculate the sum of all elements.\n    const operation = this.variableNames\n                          .map(variable => {\n                            return `v${variable}`;\n                          })\n                          .join(' + ');\n\n    const userCode = `\n      ${main('index')} {\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if (flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            ${snippets.join('\\n        ')}\n            setOutputAtIndex(flatIndex, ${operation});\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, KernelConfig, KernelFunc, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {AddNPackedProgram} from '../addn_packed_webgpu';\nimport {identity} from './Identity';\n\nexport function addN(args: {inputs: AddNInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n\n  const tensors = inputs;\n  if (tensors.length === 1) {\n    return identity({inputs: {x: tensors[0]}, backend});\n  }\n\n  const dtype =\n      tensors.map(t => t.dtype).reduce((d1, d2) => upcastType(d1, d2));\n  const shapes = tensors.map(t => t.shape);\n  const program = new AddNPackedProgram(shapes);\n  return backend.runWebGPUProgram(program, tensors, dtype);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'webgpu',\n  kernelFunc: addN as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class TransposeSharedProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[]};\n  dispatch: [number, number, number];\n  // Note that the maximum number of workgroup invocations by webgpu is 256.\n  workgroupSize: [number, number, number] = [16, 16, 1];\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [0], y: [1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize, [1, 1, 1]);\n\n    this.shaderKey = 'transposeShared';\n  }\n\n  getUserCode(): string {\n    util.assert(\n        this.workgroupSize[0] === this.workgroupSize[1],\n        () => `Must be a square tile, current tile shape is ${\n            this.workgroupSize[0]} x ${this.workgroupSize[1]}`);\n    const tileSize = this.workgroupSize[0];\n    const userCode = `\n      var<workgroup> tile : array<array<f32, ${this.workgroupSize[0] + 1}>, ${\n        this.workgroupSize[0]}>;\n      ${main()} {\n        var x = i32(workgroupId.x) * ${tileSize} + i32(localId.x);\n        var y = i32(workgroupId.y) * ${tileSize} + i32(localId.y);\n        let width = uniforms.outShape[0];\n        let height = uniforms.outShape[1];\n        if (x < width && y < height) {\n          tile[localId.y][localId.x] = f32(A[y * width + x]);\n        }\n        workgroupBarrier();\n\n        x = i32(workgroupId.y) * ${tileSize} + i32(localId.x);\n        y = i32(workgroupId.x) * ${tileSize} + i32(localId.y);\n        if (x < height && y < width) {\n          setOutputAtIndex((y * height + x), tile[localId.x]\n            [localId.y]);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransposeProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  shaderKey: string;\n  outputShape: number[];\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  newDim: number[];\n  size = true;\n\n  constructor(aShape: number[], newDim: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.newDim = newDim;\n    this.shaderKey = `transpose_${newDim}`;\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.outputShape.length);\n    const switched = getSwitchedCoords(this.newDim);\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            setOutputAtIndex(flatIndex, A[getIndexFromCoords${\n        this.outputShape.length}D(\n              ${dtype}(${switched}), uniforms.aShape)]);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nexport function getSwitchedCoords(newDim: number[]): string {\n  const rank = newDim.length;\n  if (rank > 6) {\n    throw Error(`Transpose for rank ${rank} is not yet supported`);\n  }\n  const switchedCoords = new Array(rank);\n  for (let i = 0; i < newDim.length; i++) {\n    switchedCoords[newDim[i]] = `coords.${getCoordsXYZ(i)}`;\n  }\n\n  return switchedCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Transpose, TransposeAttrs, TransposeInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {transposeImplCPU as cpuTranspose} from '../kernel_utils/shared';\n\nimport {TransposeSharedProgram} from '../transpose_shared_webgpu';\nimport {TransposeProgram} from '../transpose_webgpu';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n  const webgpuBackend = backend;\n\n  const xRank = x.shape.length;\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = webgpuBackend.tensorMap.get(x.dataId);\n    const values = xData.values as TypedArray;\n    const outValues = cpuTranspose(values, x.shape, x.dtype, perm, newShape);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n  if (x.shape.length === 2 && util.arraysEqual(perm, [1, 0])) {\n    const program = new TransposeSharedProgram(x.shape, perm);\n    return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n  const program = new TransposeProgram(x.shape, perm);\n  return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'webgpu',\n  kernelFunc: transpose as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'reduceSize : i32,';\n  reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\n  inputShape: number[];\n  size = true;\n\n  constructor(\n      reduceInfo: backend_util.ReduceInfo,\n      reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum',\n      maxComputeWorkgroupSizeX: number) {\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape, ] =\n        backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n\n  getUserCode(): string {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${\n          this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n\n    const outputSnippet = this.reduceType === 'mean' ?\n        // tslint:disable-next-line:max-line-length\n        `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :\n        `setOutputAtIndex(outputIndex, bestValue);`;\n\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n       `;\n\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${\n        this.outputShape.length === 1 ?\n            'outputCoords' :\n            'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / ${workgroupSizeX};\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + ${workgroupSizeX}) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), ${workgroupSizeX}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, sumOutType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reshape} from '../kernels/Reshape';\nimport {transpose} from '../kernels/Transpose';\nimport {ReduceProgram} from '../reduce_webgpu';\n\nimport {maxImplCPU} from './shared';\nimport {prodImplCPU} from './shared';\n\ntype ReduceTypes = 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\n\nexport function reduce(\n    x: TensorInfo, axis: number|number[], keepDims: boolean,\n    reduceType: ReduceTypes, backend: WebGPUBackend): TensorInfo {\n  const xRank = x.shape.length;\n  const toDispose = [];\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n\n  let input = x;\n  if (permutedAxes != null) {\n    input = transpose({inputs: {x}, attrs: {perm: permutedAxes}, backend});\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    toDispose.push(input);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(reduceType, axes, xRank);\n\n  const [reduceOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  let resOutShape = reduceOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    resOutShape = backend_util.expandShapeToKeepDim(reduceOutShape, origAxes);\n  }\n\n  let res;\n  if ((reduceType === 'max' || reduceType === 'prod') &&\n      backend.shouldExecuteOnCPU([input])) {\n    const xVals = backend.tensorMap.get(input.dataId).values as TypedArray;\n    switch (reduceType) {\n      case 'max':\n        const outValues = maxImplCPU(\n            xVals, util.sizeFromShape(reduceShape), resOutShape, x.dtype);\n        res = backend.makeTensorInfo(resOutShape, x.dtype, outValues);\n        break;\n      case 'prod':\n        const {outVals, outShape, outDtype} =\n            prodImplCPU(input.shape, input.dtype, xVals, axes);\n        res = backend.makeTensorInfo(outShape, outDtype, outVals);\n        break;\n      default:\n        throw new Error(\n            `${reduceType} CPU implementation is not yet supported.`);\n    }\n  } else {\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(input.shape);\n    const batchSize = xSize / inSize;\n\n    const reduceInfo = {windowSize: inSize, inSize, batchSize, outSize: 1};\n    const dtype = reduceType === 'mean' ? 'float32' : sumOutType(x.dtype);\n    const uniformData = [\n      {type: 'int32', data: [inSize]},\n    ];\n    const program = new ReduceProgram(\n        reduceInfo, reduceType, backend.device.limits.maxComputeWorkgroupSizeX);\n    const reduced =\n        backend.runWebGPUProgram(program, [input], dtype, uniformData);\n    toDispose.push(reduced);\n\n    res = reshape({inputs: {x: reduced}, attrs: {shape: resOutShape}, backend});\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return res;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function all(\n    args: {inputs: AllInputs, attrs: AllAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'all', backend);\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'webgpu',\n  kernelFunc: all as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function any(\n    args: {inputs: AnyInputs, attrs: AnyAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'any', backend);\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'webgpu',\n  kernelFunc: any as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ArgMinMaxProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  variableNames = ['x'];\n  uniforms = 'infinityValue : f32,';\n  inputShape: number[];\n  reductionFactor: number;\n  op: string;\n  size = true;\n  private type: string;\n\n  constructor(inputShape: number[], axis: number, reduceType: 'min'|'max') {\n    const axes = [axis];\n\n    this.op = reduceType === 'min' ? '<' : '>';\n\n    // |outShape| is the shape with the removed axis\n    const [outputShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(inputShape, axes);\n\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // The shared algorithm is mainly used for large reduce size. It fully\n    // utilizes the threads in one workgroup to do the reduction. However,\n    // when the reduce size is very small, it's better to use the plain\n    // algorithm to reduce the number of workgroups to speedup. The threthold\n    // can be further tuned.\n    if (util.sizeFromShape(reduceShape) < 32) {\n      this.type = 'plain';\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize);\n    } else {\n      this.type = 'shared';\n      // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n      // dispatch size.\n      this.dispatch =\n          computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n    }\n\n    this.inputShape = inputShape;\n    this.shaderKey = `argMinMax_${this.op}_${this.type}`;\n  }\n\n  getUserCode(): string {\n    const workgroupSizeX = this.workgroupSize[0];\n    const getInputShapeLastDim = () => {\n      if (this.inputShape.length === 1) {\n        return 'uniforms.xShape';\n      } else {\n        return `uniforms.xShape.${getCoordsXYZ(this.inputShape.length - 1)}`;\n      }\n    };\n\n    const splitOutputCoords = () => {\n      let snippet = '';\n      if (this.outputShape.length === 1) {\n        if (this.inputShape.length !== 1) {\n          snippet += 'outputCoords,';\n        }\n      } else {\n        for (let i = 0; i < this.outputShape.length; i++) {\n          snippet += `outputCoords.${getCoordsXYZ(i)},`;\n        }\n      }\n      return snippet;\n    };\n\n    if (this.type === 'shared') {\n      const sharedMemorySnippet = `\n      var<workgroup> xBestIndices : array<i32, ${workgroupSizeX}>;\n      var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n    `;\n      const userCode = `\n      fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n      }\n\n      ${sharedMemorySnippet}\n\n      ${main('index')} {\n        let outputIndex = index / ${workgroupSizeX};\n        let reduceLength = ${getInputShapeLastDim()};\n\n        var bestIndex = i32(localId.x);\n        var bestValue = uniforms.infinityValue;\n        let outputCoords = getCoordsFromIndex(outputIndex);\n        for (var k = i32(localId.x); k < reduceLength && outputIndex < uniforms.size;\n            k = k + ${workgroupSizeX}) {\n          let candidate = getX(${splitOutputCoords()} k);\n          if (!isnan(candidate) && candidate ${this.op} bestValue) {\n            bestValue = candidate;\n            bestIndex = k;\n          }\n        }\n        xBestValues[localId.x] = bestValue;\n        xBestIndices[localId.x] = bestIndex;\n        workgroupBarrier();\n\n        var reduceSize = min(u32(reduceLength), ${workgroupSizeX}u);\n        for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n            currentSize = reduceSize / 2u) {\n          let interval = DIV_CEIL(reduceSize, 2u);\n          if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              xBestValues[localId.x] = bestValue;\n              xBestIndices[localId.x] = xBestIndices[localId.x + interval];\n            }\n          }\n          reduceSize = interval;\n          workgroupBarrier();\n        }\n\n        if (localId.x == 0u && outputIndex < uniforms.size) {\n          setOutputAtIndexI32(outputIndex, xBestIndices[localId.x]);\n        }\n      }\n    `;\n      return userCode;\n    } else {\n      const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let outputCoords = getCoordsFromIndex(index);\n          var bestIndex = 0;\n          var bestValue = getX(${splitOutputCoords()} 0);\n          let reduceLength = ${getInputShapeLastDim()};\n          for (var i = 1; i < reduceLength; i++) {\n            let candidate = getX(${splitOutputCoords()} i);\n            if (candidate ${this.op} bestValue) {\n              bestValue = candidate;\n              bestIndex = i;\n            }\n          }\n          setOutputAtIndexI32(index, bestIndex);\n        }\n      }\n      `;\n      return userCode;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: WebGPUBackend, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMax', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'max');\n  const uniformData = [{type: 'float32', data: [Number.NEGATIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'webgpu',\n  kernelFunc: argMax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {ArgMinMaxProgram} from '../argminmax_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: WebGPUBackend, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('argMin', [axes[0]], $x.shape.length);\n  const program = new ArgMinMaxProgram($x.shape, axes[0], 'min');\n  const uniformData = [{type: 'float32', data: [Number.POSITIVE_INFINITY]}];\n  const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n  return out;\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'webgpu',\n  kernelFunc: argMin as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const asin = unaryKernelFunc({opType: UnaryOpType.ASIN});\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'webgpu',\n  kernelFunc: asin\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const asinh = unaryKernelFunc({opType: UnaryOpType.ASINH});\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'webgpu',\n  kernelFunc: asinh\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const atan = unaryKernelFunc({opType: UnaryOpType.ATAN});\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'webgpu',\n  kernelFunc: atan\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const atan2 = binaryKernelFunc({opType: BinaryOpType.ATAN2});\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'webgpu',\n  kernelFunc: atan2\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const atanh = unaryKernelFunc({opType: UnaryOpType.ATANH});\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'webgpu',\n  kernelFunc: atanh\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class PoolWithFilterSizeEqualsOneProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = `strides : vec2<i32>,`;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'poolWithFilterSizeEqualsOne';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let d = coords[3];\n\n          let xRCCorner = coords.yz * uniforms.strides;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          let value = getX(batch, xRCorner, xCCorner, d);\n          setOutputAtIndex(index, value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Pool2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, convDims : vec2<i32>, filterDims : vec2<i32>,`;\n  // TODO(jiajia.qin@intel.com): Dynamically choose different workgroupSize for\n  // different output shapes.\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  poolType: 'max'|'avg';\n  size = true;\n  computePositions: boolean;\n  flattenPositions: boolean;\n  includeBatchIndex: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, poolType: 'max'|'avg',\n      computePositions = false, flattenPositions = false,\n      includeBatchIndex = false) {\n    if (poolType === 'avg' && computePositions) {\n      throw new Error('Cannot compute positions for average pool.');\n    }\n\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.poolType = poolType;\n    this.computePositions = computePositions;\n    this.flattenPositions = flattenPositions;\n    this.includeBatchIndex = includeBatchIndex;\n    this.shaderKey = `pool2D_${poolType}_${computePositions}_${\n        flattenPositions}_${includeBatchIndex}`;\n  }\n\n  getUserCode(): string {\n    let updateSnippet: string;\n    if (this.poolType === 'avg') {\n      updateSnippet = `resultValue = resultValue + value; count = count + 1.0;`;\n    } else if (this.computePositions) {\n      const positionStr = this.flattenPositions ?\n          (this.includeBatchIndex ?\n               `((batch * uniforms.xShape[1] + xR) * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d` :\n               `(xR * uniforms.xShape[2] + xC) * uniforms.xShape[3] + d`) :\n          `wR * uniforms.filterDims.y + wC`;\n      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);\n      if (value >= currMaxValue) {\n        maxValue = value;\n        maxValueFound = 1.0;\n        maxPosition = ${positionStr};\n      }`;\n    } else {\n      updateSnippet = `resultValue = max(value, resultValue);`;\n    }\n\n    let returnValue = `resultValue`;\n    if (this.poolType === 'avg') {\n      returnValue = `resultValue / max(count, 1.0)`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let batch = coords[0];\n          let d = coords[3];\n          let xRCCorner = vec2<i32>(coords.yz) * uniforms.strides - uniforms.pads;\n          let xRCorner = xRCCorner.x;\n          let xCCorner = xRCCorner.y;\n\n          ${\n        this.computePositions ?\n            `var maxValue = 0.0;\n            var maxValueFound = 0.0;\n            var maxPosition = 0;` :\n            `var resultValue = ${\n                this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};`}\n\n          var count = 0.0;\n          for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + uniforms.dilations.x) {\n            let xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= uniforms.convDims.x) {\n              continue;\n            }\n\n            for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + uniforms.dilations.y) {\n              let xC = xCCorner + wC;\n              if (xC < 0 || xC >= uniforms.convDims.y) {\n                continue;\n              }\n\n              let value = getX(batch, xR, xC, d);\n              ${updateSnippet}\n            }\n          }\n\n          ${\n        this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` :\n                                `setOutputAtIndex(index, ${returnValue});`}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nexport class Pool3DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms =\n      `strides : vec3<i32>, pads : vec3<i32>, convDims : vec3<i32>, filterDims : vec3<i32>,`;\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  poolType: 'max'|'avg';\n  size = true;\n  computePositions: boolean;\n  flattenPositions: boolean;\n  includeBatchIndex: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv3DInfo, poolType: 'max'|'avg',\n      computePositions = false, flattenPositions = false,\n      includeBatchIndex = false) {\n    if (poolType === 'avg' && computePositions) {\n      throw new Error('Cannot compute positions for average pool.');\n    }\n\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.poolType = poolType;\n    this.computePositions = computePositions;\n    this.flattenPositions = flattenPositions;\n    this.includeBatchIndex = includeBatchIndex;\n    this.shaderKey = `pool3D_${poolType}_${computePositions}_${\n        flattenPositions}_${includeBatchIndex}`;\n  }\n\n  getUserCode(): string {\n    let updateSnippet: string;\n    if (this.poolType === 'avg') {\n      updateSnippet = `resultValue += value; count += 1.0;`;\n    } else if (this.computePositions) {\n      const positionStr = this.flattenPositions ?\n          (this.includeBatchIndex ?\n               `(((batch * uniforms.xShape.y + xD) * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch` :\n               `((xD * uniforms.xShape.z + xR) * uniforms.xShape.w + xC) * uniforms.xShape.u + ch`) :\n          `wD * uniforms.filterDims.y * uniforms.filterDims.y + wR * uniforms.filterDims.z + wC`;\n      updateSnippet = `let currMaxValue = mix(value, maxValue, maxValueFound);\n      if (value >= currMaxValue) {\n        maxValue = value;\n        maxValueFound = 1.0;\n        maxPosition = ${positionStr};\n      }`;\n    } else {\n      updateSnippet = `resultValue = max(value, resultValue);`;\n    }\n\n    let returnValue = `resultValue`;\n    if (this.poolType === 'avg') {\n      returnValue = `resultValue / max(count, 1.0)`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let batch = coords.x;\n          let ch = coords.u;\n\n          let xCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;\n          let xDCorner = xCorner.x;\n          let xRCorner = xCorner.y;\n          let xCCorner = xCorner.z;\n\n          ${\n        this.computePositions ?\n            `var maxValue = 0.0;\n            var maxValueFound = 0.0;\n            var maxPosition = 0;` :\n            `var resultValue = ${\n                this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};`}\n\n          var count = 0.0;\n          for (var wD = 0; wD < uniforms.filterDims.x; wD++) {\n            let xD = xDCorner + wD;\n            if (xD < 0 || xD >= uniforms.convDims.x) {\n              continue;\n            }\n\n            for (var wR = 0; wR < uniforms.filterDims.y; wR++) {\n              let xR = xRCorner + wR;\n              if (xR < 0 || xR >= uniforms.convDims.y) {\n                continue;\n              }\n\n              for (var wC = 0; wC < uniforms.filterDims.z; wC++) {\n                let xC = xCCorner + wC;\n                if (xC < 0 || xC >= uniforms.convDims.z) {\n                  continue;\n                }\n\n                let value = getX(batch, xD, xR, xC, ch);\n                ${updateSnippet}\n              }\n            }\n          }\n\n          ${\n        this.computePositions ? `setOutputAtIndexI32(index, maxPosition);` :\n                                `setOutputAtIndex(index, ${returnValue});`}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: WebGPUBackend, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  return reduce(x, reductionIndices, keepDims, 'max', backend);\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgpu',\n  kernelFunc: max as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function mean(\n    args: {inputs: MeanInputs, attrs: MeanAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {keepDims, axis} = attrs;\n\n  return reduce(x, axis, keepDims, 'mean', backend);\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'webgpu',\n  kernelFunc: mean as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {PoolWithFilterSizeEqualsOneProgram} from '../pool_filtersizeone_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\n\nimport {identity} from './Identity';\nimport {max} from './Max';\nimport {mean} from './Mean';\nimport {reshape} from './Reshape';\n\ntype PoolType = 'max'|'avg';\nexport function poolImpl(\n    x: TensorInfo, convInfo: backend_util.Conv2DInfo, poolType: PoolType,\n    backend: WebGPUBackend): TensorInfo {\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    return identity({inputs: {x}, backend});\n  }\n\n  if (convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.filterHeight === convInfo.inHeight && convInfo.batchSize === 1 &&\n      convInfo.padInfo.type === 'VALID') {\n    const length = x.shape.length;\n    const reshapeX = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: [\n          x.shape[length - 3] * x.shape[length - 2] /* height * width */,\n          x.shape[length - 1] /* channel */\n        ]\n      }\n    });\n    let reduceX;\n    if (poolType === 'avg') {\n      reduceX = mean(\n          {inputs: {x: reshapeX}, backend, attrs: {axis: 0, keepDims: false}});\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      reduceX = max({\n        inputs: {x: reshapeX},\n        backend,\n        attrs: {reductionIndices: 0, keepDims: false}\n      });\n    }\n\n    const result = reshape(\n        {inputs: {x: reduceX}, backend, attrs: {shape: convInfo.outShape}});\n    backend.disposeData(reshapeX.dataId);\n    backend.disposeData(reduceX.dataId);\n    return result;\n  }\n\n  let program: Pool2DProgram|PoolWithFilterSizeEqualsOneProgram;\n  const dimensions =\n      [{type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}];\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1) {\n    program = new PoolWithFilterSizeEqualsOneProgram(convInfo);\n  } else {\n    if (poolType === 'avg') {\n      program = new Pool2DProgram(convInfo, 'avg');\n    } else {\n      util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);\n      program = new Pool2DProgram(convInfo, 'max');\n    }\n\n    dimensions.push(\n        {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        },\n        {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n          type: 'int32',\n          data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x], x.dtype, dimensions);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function avgPool(\n    args: {inputs: AvgPoolInputs, backend: WebGPUBackend, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'avg', backend);\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'webgpu',\n  kernelFunc: avgPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dataFormat, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode, dataFormat);\n  const avgPoolProgram = new Pool3DProgram(convInfo, 'avg');\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  return backend.runWebGPUProgram(avgPoolProgram, [x], x.dtype, dimensions);\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'webgpu',\n  kernelFunc: avgPool3D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class AvgPool2DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32, avgMultiplier : f32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `avgPool2DBackprop`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d = coords[3];\n\n        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;\n        let dyRCorner = dyRCCorner.x;\n        let dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR = wR + uniforms.dilations[0]) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC = wC + uniforms.dilations[1]) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            let dyValue = getDy(batch, idyR, idyC, d);\n\n            dotProd = dotProd + dyValue * uniforms.avgMultiplier;\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class AvgPool3DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,\n       outDepth : i32, outHeight : i32, outWidth : i32, avgMultiplier : f32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `avgPool3DBackprop`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let ch = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyDCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {\n          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);\n\n          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {\n            continue;\n          }\n          let idyD = i32(dyD);\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              dotProd += dyValue * uniforms.avgMultiplier;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {AvgPool3DBackpropProgram} from '../avg_pool_backprop_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const program = new AvgPool3DBackpropProgram(convInfo);\n  const avgMultiplier =\n      1 / (convInfo.filterDepth * convInfo.filterHeight * convInfo.filterWidth);\n  const uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'float32', data: [avgMultiplier]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], x.dtype, uniformData);\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'webgpu',\n  kernelFunc: avgPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {AvgPool2DBackpropProgram} from '../avg_pool_backprop_webgpu';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {assertNotComplex} from '../webgpu_util';\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  backend: WebGPUBackend,\n  attrs: AvgPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolGrad');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const program = new AvgPool2DBackpropProgram(convInfo);\n  const avgMultiplier = 1 / (convInfo.filterHeight * convInfo.filterWidth);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    },\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'float32', data: [avgMultiplier]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], x.dtype, uniformData);\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'webgpu',\n  kernelFunc: avgPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {batchMatMulImpl} from './BatchMatMul_impl';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  return batchMatMulImpl({a, b, transposeA, transposeB, backend});\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'webgpu',\n  kernelFunc: batchMatMul as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getCoordsXYZ, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SliceProgram implements WebGPUProgram {\n  variableNames = ['source'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  rank: number;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  start: number[];\n  size = true;\n\n  constructor(start: number[], destSize: number[]) {\n    this.outputShape = destSize;\n    this.rank = destSize.length;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.start = start;\n    this.uniforms = `start : ${getCoordsDataType(start.length)}, `;\n    this.shaderKey = 'slice';\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.rank);\n    const sourceCoords = getCoords(this.rank);\n    let coordSum;\n    if (this.start.length === 1) {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc = uniforms.start + coords;`;\n      });\n    } else {\n      coordSum = this.outputShape.map((_, i) => {\n        return `sourceLoc.${coords[i]} = uniforms.start.${\n            getCoordsXYZ(i)} + coords.${coords[i]};`;\n      });\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          var sourceLoc : ${dtype};\n          let coords = getCoordsFromIndex(index);\n          ${coordSum.join('\\n')}\n          setOutputAtIndex(index, getSource(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nconst coords = ['x', 'y', 'z', 'w', 'u', 'v'];\n\nfunction getCoords(rank: number): string {\n  if (rank === 1) {\n    return 'sourceLoc';\n  } else if (rank <= 6) {\n    return coords.slice(0, rank).map(coord => `sourceLoc.${coord}`).join(',');\n  } else {\n    throw Error(`Slicing for rank ${rank} is not yet supported`);\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_webgpu';\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: WebGPUBackend, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTensorData = backend.tensorMap.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTensorData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // TODO(xing.xu): Add shadow slice support.\n  const program = new SliceProgram($begin, $size);\n  const uniformData = [{type: 'int32', data: $begin}];\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgpu',\n  kernelFunc: slice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport const batchToSpaceND = (args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: WebGPUBackend,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'batchToSpaceND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const toDispose = [];\n\n  const reshapedIntermediate =\n      reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const transposedIntermediate = transpose(\n      {inputs: {x: reshapedIntermediate}, backend, attrs: {perm: permuted}});\n  const reshapedIntermediate2 = reshape({\n    inputs: {x: transposedIntermediate},\n    backend,\n    attrs: {shape: reshapedPermuted}\n  });\n  const sliced = slice({\n    inputs: {x: reshapedIntermediate2},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  toDispose.push(reshapedIntermediate);\n  toDispose.push(transposedIntermediate);\n  toDispose.push(reshapedIntermediate2);\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return sliced;\n};\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'webgpu',\n  kernelFunc: batchToSpaceND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nconst writeSnippet = `\n  fn bincount_write(index: i32, value: f32) {\n    ${atomicAddSnippet('&result[index]', 'value', 'float32')}\n  }\n`;\n\nconst binaryWriteSnippet = `\n  fn bincount_write(index: i32, value: f32) {\n    atomicStore(&result[index], bitcast<i32>(value));\n  }\n`;\n\nexport class BincountProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'binCountSize : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  hasWeights = true;\n  binaryOutput = false;\n  rank: number;\n\n  constructor(\n      shape: [number]|[number, number], hasWeights: boolean,\n      binaryOutput = false) {\n    this.outputShape = shape;\n    this.rank = shape.length;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.binaryOutput = binaryOutput;\n    if (binaryOutput) {\n      this.atomic = false;\n    }\n    this.hasWeights = hasWeights;\n    if (this.hasWeights) {\n      this.variableNames.push('w');\n    }\n    this.shaderKey =\n        `bincount_${this.hasWeights}_${this.binaryOutput}_${this.rank}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${this.binaryOutput ? binaryWriteSnippet : writeSnippet}\n  ${main('index')} {\n    ${\n        this.rank === 1 ?\n            `if (index < uniforms.xShape) {\n      let indexVal = i32(getX(index));\n      if (indexVal < uniforms.binCountSize) {\n        let value = ${\n                this.binaryOutput ? 1. :\n                                    (this.hasWeights ? 'getW(index)' : '1.')};\n        bincount_write(indexVal, value);\n      }\n    }` :\n            `let coord = getCoordsFromIndex(index);\n    if (coordsInBounds2D(coord, uniforms.xShape)) {\n      let indexVal = i32(getX(coord[0], coord[1]));\n      if (indexVal < uniforms.binCountSize) {\n        let value = ${\n                this.binaryOutput ?\n                    1. :\n                    (this.hasWeights ? 'getW(coord[0], coord[1])' : '1.')};\n        bincount_write(coord.x * uniforms.binCountSize + indexVal, value);\n      }\n    }`}\n  }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BincountProgram} from '../bincount_webgpu';\n\nimport {fill} from './Fill';\n\nexport function bincount(\n    args:\n        {inputs: BincountInputs, backend: WebGPUBackend, attrs: BincountAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const weightsSize = util.sizeFromShape(weights.shape);\n  const hasWeights = weightsSize > 0;\n  const outputSize: [number] = [size];\n  const dtype = weights.dtype;\n\n  const output = fill({backend, attrs: {shape: outputSize, value: 0, dtype}});\n  const program = new BincountProgram([xSize], hasWeights);\n  const uniformData = [{type: 'int32', data: [size]}];\n  const bincountInputs: TensorInfo[] = hasWeights ? [x, weights] : [x];\n  const res = backend.runWebGPUProgram(\n      program, bincountInputs, dtype, uniformData, output);\n\n  return res;\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'webgpu',\n  kernelFunc: bincount as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BroadcastArgsProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['s0', 's1'];\n  uniforms = 's0Size : i32, s1Size : i32, ';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number) {\n    this.outputShape = [shape];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'broadcastArgs';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n  ${main('index')} {\n    if (index < uniforms.size) {\n      var s0 = 1.0;\n      var s1 = 1.0;\n      let indexS0 = index - uniforms.size + uniforms.s0Size;\n      let indexS1 = index - uniforms.size + uniforms.s1Size;\n      if (indexS0 >= 0) {\n        s0 = getS0(indexS0);\n      }\n      if (indexS1 >= 0) {\n        s1 = getS1(indexS1);\n      }\n\n      if (s0 == 1.0) {\n        setOutputAtIndex(index, s1);\n      } else if (s1 == 1.0) {\n        setOutputAtIndex(index, s0);\n      } else if (s0 != s1) {\n        setOutputAtIndex(index, uniforms.NAN);\n      } else {\n        setOutputAtIndex(index, s0);\n      }\n    }\n  }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BroadcastArgs, BroadcastArgsInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BroadcastArgsProgram} from '../broadcast_args_webgpu';\n\nexport function broadcastArgs(args: {\n  inputs: BroadcastArgsInputs,\n  backend: WebGPUBackend,\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {s0, s1} = inputs;\n\n  if (backend.shouldExecuteOnCPU([s0, s1])) {\n    const s0TensorInfo = backend.tensorMap.get(s0.dataId);\n    const s1TensorInfo = backend.tensorMap.get(s1.dataId);\n    const s0Vals = s0TensorInfo.values as TypedArray;\n    const s1Vals = s1TensorInfo.values as TypedArray;\n    const broadcastShape = backend_util.assertAndGetBroadcastShape(\n        Array.from(s0Vals), Array.from(s1Vals));\n    return backend.makeTensorInfo(\n        [broadcastShape.length], 'int32', Int32Array.from(broadcastShape));\n  }\n\n  const s0Size = util.sizeFromShape(s0.shape);\n  const s1Size = util.sizeFromShape(s1.shape);\n  const outputSize = Math.max(s0Size, s1Size);\n\n  const program = new BroadcastArgsProgram(outputSize);\n  const uniformData =\n      [{type: 'int32', data: [s0Size]}, {type: 'int32', data: [s1Size]}];\n  return backend.runWebGPUProgram(program, [s0, s1], 'int32', uniformData);\n}\n\nexport const broadcastArgsConfig: KernelConfig = {\n  kernelName: BroadcastArgs,\n  backendName: 'webgpu',\n  kernelFunc: broadcastArgs as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {notEqualImplCPU as cpuNotEqual} from '../kernel_utils/shared';\n\nexport const notEqual = binaryKernelFunc({\n  opType: BinaryOpType.NOT_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuNotEqual\n});\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'webgpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function real(args: {inputs: RealInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.real}, backend});\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'webgpu',\n  kernelFunc: real as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BinaryInputs, Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {castImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {notEqual} from './NotEqual';\nimport {real} from './Real';\n\nimport {int} from '../kernel_utils/int';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: WebGPUBackend, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO: Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeData(floatX.dataId);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n    backend.disposeData(realPart.dataId);\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const values = backend.tensorMap.get(x.dataId).values as TypedArray;\n    const [resultShape, resultType, resultData] =\n        castImplCPU(values, x.shape, x.dtype, dtype);\n    return backend.makeTensorInfo(resultShape, resultType, resultData);\n  }\n\n  if (dtype === 'int32') {\n    return int(x, backend);\n  }\n\n  if (dtype === 'bool') {\n    const zerosTensorInfo = backend.makeTensorInfo(\n        [], 'bool', util.getTypedArrayFromDType('bool', 1));\n\n    const binaryInputs: BinaryInputs = {a: x, b: zerosTensorInfo};\n\n    const result = notEqual({inputs: binaryInputs, backend}) as TensorInfo;\n    backend.disposeData(zerosTensorInfo.dataId);\n    return result;\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'webgpu',\n  kernelFunc: cast as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function int(input: TensorInfo, backend: WebGPUBackend): TensorInfo {\n  const program = new UnaryOpProgram(input.shape, UnaryOpType.TO_INT);\n  const output = backend.runWebGPUProgram(program, [input], 'int32');\n  return {dataId: output.dataId, shape: output.shape, dtype: output.dtype};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {ceilImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const ceil =\n    unaryKernelFunc({opType: UnaryOpType.CEIL, cpuKernelImpl: ceilImplCPU});\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'webgpu',\n  kernelFunc: ceil\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workPerThread = 4;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  outputComponent = 4;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n    this.shaderKey = 'clipVec4';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          var clampedValue = clamp(\n              value, vec4<f32>(uniforms.minVal), vec4<f32>(uniforms.maxVal));\n          clampedValue = select(clampedValue, value, isnanVec4(value));\n          setOutputAtIndex(index, clampedValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ClipProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  variableNames = ['A'];\n  uniforms = 'minVal : f32, maxVal : f32,';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  minVal: number;\n  maxVal: number;\n  size = true;\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'clip';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let value = getAByOutputIndex(index);\n          if (isnan(value)) {\n            setOutputAtIndex(index, value);\n            return;\n          }\n          setOutputAtIndex(index, clamp(value, uniforms.minVal, uniforms.maxVal));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, ClipByValueInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {ClipVec4Program} from '../clip_vec4_webgpu';\nimport {ClipProgram} from '../clip_webgpu';\n\nexport function clipByValue(args: {\n  inputs: ClipByValueInputs,\n  backend: WebGPUBackend,\n  attrs: ClipByValueAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {clipValueMin, clipValueMax} = attrs;\n\n  let program: ClipProgram|ClipVec4Program;\n  const uniformData = [\n    {type: 'float32', data: [clipValueMin]},\n    {type: 'float32', data: [clipValueMax]}\n  ];\n  if (util.sizeFromShape(x.shape) % 4 === 0) {\n    program = new ClipVec4Program(x.shape);\n  } else {\n    program = new ClipProgram(x.shape);\n  }\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'webgpu',\n  kernelFunc: clipByValue as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ComplexAbsProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['real', 'imag'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'complexAbs';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let re = abs(getRealByOutputIndex(index));\n        let im = abs(getImagByOutputIndex(index));\n        let mx = max(re, im);\n\n        // The length function in wgsl may be not underflow-safe on some GPUs.\n        // So the safe solution is to ensure underflow-safety in all cases.\n        setOutputAtIndex(index, select(mx * length(vec2<f32>(1, min(re, im)/mx)), 0.0, mx == 0.0));\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ComplexAbs, ComplexAbsInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ComplexAbsProgram} from '../complex_abs_webgpu';\n\n// Returns a TensorInfo with the complex shape and the dataId of the\n// underlying part. We need to do this because a reshaped complex tensor is\n// not reflected in its parts.\nfunction makeComplexComponentTensorInfo(\n    complexTensor: TensorInfo, complexPart: TensorInfo): TensorInfo {\n  return {\n    dataId: complexPart.dataId,\n    dtype: complexPart.dtype,\n    shape: complexTensor.shape\n  };\n}\n\nexport function complexAbs(\n    args: {inputs: ComplexAbsInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xData = backend.tensorMap.get(x.dataId);\n\n  const program = new ComplexAbsProgram(x.shape);\n  const programInputs = [\n    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),\n    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag),\n  ];\n\n  return backend.runWebGPUProgram(\n      program, programInputs, programInputs[0].dtype);\n}\n\nexport const complexAbsConfig: KernelConfig = {\n  kernelName: ComplexAbs,\n  backendName: 'webgpu',\n  kernelFunc: complexAbs as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ConcatProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = '';\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  offsetLength: number;\n\n  constructor(shapes: Array<[number, number]>) {\n    this.outputShape =\n        backend_util.computeOutShape(shapes, 1 /* axis */) as [number, number];\n    this.variableNames = shapes.map((_, i) => `T${i}`);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    this.offsetLength = shapes.length - 1;\n    for (let i = 0; i < this.offsetLength; i++) {\n      this.uniforms += `offset${i} : i32,`;\n    }\n    this.shaderKey = 'concat';\n  }\n\n  getUserCode(): string {\n    const snippets: string[] = [];\n    if (this.offsetLength > 0) {\n      snippets.push(\n          `if (yC < uniforms.offset0){ setOutputAtCoords(coords.x, coords.y, getT0(yR, yC)); }`);\n      for (let i = 1; i < this.offsetLength; i++) {\n        snippets.push(\n            `else if (yC < uniforms.offset${[i]}){ ` +\n            `setOutputAtCoords(coords.x, coords.y, getT${\n                i}(yR, yC - uniforms.offset${i - 1})); }`);\n      }\n      const lastIndex = this.offsetLength;\n      const lastShiftIndex = this.offsetLength - 1;\n      snippets.push(`else { setOutputAtCoords(coords.x, coords.y, getT${\n          lastIndex}(yR, yC - uniforms.offset${lastShiftIndex})); }`);\n    } else {\n      snippets.push(`setOutputAtCoords(coords.x, coords.y, getT0(yR, yC));`);\n    }\n\n    const userCode = `\n      ${main('index')} {\n        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let flatIndex = index * ${this.workPerThread} + i;\n          if(flatIndex < uniforms.size) {\n            let coords = getCoordsFromIndex(flatIndex);\n            let yR = coords.x;\n            let yC = coords.y;\n\n            ${snippets.join('\\n        ')}\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\n\nexport function imag(args: {inputs: ImagInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n  const inputData = backend.tensorMap.get(input.dataId);\n\n  return identity({inputs: {x: inputData.complexTensorInfos.imag}, backend});\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'webgpu',\n  kernelFunc: imag as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, ConcatInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ConcatProgram} from '../concat_webgpu';\nimport {concatImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concatImpl(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend): TensorInfo {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeData(r.dataId));\n    imags.forEach(i => backend.disposeData(i.dataId));\n    backend.disposeData(realConcated.dataId);\n    backend.disposeData(imagConcated.dataId);\n\n    return result;\n  }\n\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgpu doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = tensors2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    const outShape =\n        backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals =\n        concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n\n    const finalOutShape =\n        backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n\n    tensors2D.forEach(t => backend.disposeData(t.dataId));\n\n    return outInfo;\n  }\n\n  // There is a storage buffer limitation in compute stage, one for output so\n  // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1\n  const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;\n  if (inputs.length > maxInputNum) {\n    const reducedInputs = [];\n    for (let i = 0; i < inputs.length; i += maxInputNum) {\n      const subArray = inputs.slice(i, i + maxInputNum);\n      reducedInputs.push(concatImpl(subArray, axis, backend));\n    }\n    const result = concatImpl(reducedInputs, axis, backend);\n\n    for (const i of reducedInputs) {\n      backend.disposeData(i.dataId);\n    }\n\n    return result;\n  }\n\n  const {tensors2D, outShape} = computeTensors2D(inputs, axis, backend);\n  const shapes = (tensors2D).map(t => t.shape as [number, number]);\n  const program = new ConcatProgram(shapes);\n\n  const uniformData: Array<{type: string; data: number[]}> = [];\n  const offsets: number[] = new Array(shapes.length - 1);\n  if (offsets.length > 0) {\n    offsets[0] = shapes[0][1];\n    uniformData.push({type: 'int32', data: [offsets[0]]});\n    for (let i = 1; i < offsets.length; i++) {\n      offsets[i] = offsets[i - 1] + shapes[i][1];\n      uniformData.push({type: 'int32', data: [offsets[i]]});\n    }\n  }\n\n  const res = backend.runWebGPUProgram(\n      program, tensors2D, tensors2D[0].dtype, uniformData);\n  tensors2D.forEach(r => backend.disposeData(r.dataId));\n\n  const reshapedResult =\n      reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n  backend.disposeData(res.dataId);\n  return reshapedResult;\n}\n\nfunction computeTensors2D(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend) {\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(t => reshape({\n                                 inputs: {x: t},\n                                 backend,\n                                 attrs: {\n                                   shape: [\n                                     util.sizeFromShape(t.shape.slice(0, axis)),\n                                     util.sizeFromShape(t.shape.slice(axis))\n                                   ]\n                                 }\n                               }));\n\n  return {tensors2D, outShape};\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\n\nexport function concat(\n    args: {inputs: ConcatInputs, attrs: ConcatAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n\n  const shapes = inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  const outShape =\n      backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  return concatImpl($inputs, $axis, backend);\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'webgpu',\n  kernelFunc: concat as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dCommonSnippet(\n    isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean,\n    fitInner: boolean, addBias = false,\n    activation: backend_util.Activation = null,\n    hasPreluActivationWeights = false, innerElementSizeX = 4,\n    innerElementSizeW = 4, innerElementSize = 4) {\n  const getXSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'resData = x[xIndex];';\n      case 3:\n        return 'resData = vec3<f32>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);';\n      case 4:\n        return 'resData = x[xIndex / 4];';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return W[row * uniforms.wShape[3] + col];';\n      case 4:\n        return 'return W[(row * uniforms.wShape[3] + col) / 4];';\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, xRow, xCol, xCh);\n      ` :\n                                         `\n      let coord = vec4<i32>(batch, xCh, xRow, xCol);\n      `;\n\n  const coordResSnippet = isChannelsLast ? `\n      let coords = vec4<i32>(\n        batch,\n        row / outWidth,\n        row % outWidth,\n        col);\n      ` :\n                                           `\n      let coords = vec4<i32>(\n        batch,\n        row,\n        col / outWidth,\n        col % outWidth);\n      `;\n\n  const xHight = isChannelsLast ? 'uniforms.xShape[1]' : 'uniforms.xShape[2]';\n  const xWidth = isChannelsLast ? 'uniforms.xShape[2]' : 'uniforms.xShape[3]';\n  const row = isChannelsLast ? 'row' : 'col';\n  const col = isChannelsLast ? 'col' : 'row';\n  const readXSnippet = `\n      let inChannels = uniforms.wShape[2];\n      let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (uniforms.filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % uniforms.filterDims[1];\n      let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * WRow - uniforms.pads[0];\n      let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * WCol - uniforms.pads[1];\n      let xCh = ${col} % inChannels;\n      var resData = ${typeSnippet(innerElementSizeX)}(0.0);\n      // The bounds checking is always needed since we use it to pad zero for\n      // the 'same' padding type.\n      if (xRow >= 0 && xRow < ${xHight} && xCol >= 0 && xCol < ${xWidth}) {\n        ${coordASnippet}\n        let xIndex = getIndexFromCoords4D(coord, uniforms.xShape);\n        ${getXSnippet(innerElementSizeX)}\n      }\n      return resData;`;\n\n  const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n      ${readXSnippet}` :\n                                                            `\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`) :\n                                   (fitInner && fitBOuter ? `\n      ${readXSnippet}` :\n                                                            `\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${readXSnippet}\n      }\n      return ${typeSnippet(innerElementSizeX)}(0.0);`);\n\n  const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n  const resType = typeSnippet(innerElementSize);\n  const aType = isChannelsLast ? typeSnippet(innerElementSizeX) :\n                                 typeSnippet(innerElementSizeW);\n  const bType = isChannelsLast ? typeSnippet(innerElementSizeW) :\n                                 typeSnippet(innerElementSizeX);\n  const userCode = `\n      ${\n      activationFnSnippet(\n          activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n      fn mm_readA(batch: i32, row : i32, col : i32) -> ${aType} {\n        ${isChannelsLast ? sampleX : sampleW}\n      }\n\n      fn mm_readB(batch: i32, row : i32, col : i32) -> ${bType} {\n        ${isChannelsLast ? sampleW : sampleX}\n      }\n\n      fn mm_write(batch: i32, row : i32, col : i32, valueIn : ${resType}) {\n        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n        {\n        var value = valueIn;\n        let outWidth = ${\n      isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};\n        ${coordResSnippet}\n        ${biasActivationSnippet(addBias, activation)}\n        setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }`;\n  return userCode;\n}\n\nexport class Conv2DMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableComponents: number[];\n  uniforms =\n      `filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileAOuter: number;\n  tileBOuter: number;\n  tileInner: number;\n  innerElementSize: number;\n  isVec4?: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, dimAOuter: number, dimBOuter: number,\n      dimInner: number, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false, sequentialAccessByThreads = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.isVec4 =\n        (((convInfo.inChannels % 4 === 0 || convInfo.inChannels % 3 === 0) &&\n          this.isChannelsLast) ||\n         (convInfo.outWidth % 4 === 0 && !this.isChannelsLast)) &&\n        convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = this.isChannelsLast ? {x: [3], y: [1, 2], z: [0]} :\n                                                {x: [2, 3], y: [1], z: [0]};\n    this.workgroupSize = computeWorkgroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      this.outputComponent = 4;\n      if (this.isChannelsLast && convInfo.inChannels % 4 !== 0) {\n        this.innerElementSize = 3;\n        this.variableComponents = [1, 4];\n      } else {\n        this.innerElementSize = 4;\n        this.variableComponents = [4, 4];\n      }\n\n      if (addBias) {\n        this.variableNames.push('bias');\n        this.variableComponents.push(4);\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n        this.variableComponents.push(4);\n      }\n    } else {\n      this.innerElementSize = this.elementsPerThread[0];\n      if (addBias) {\n        this.variableNames.push('bias');\n      }\n\n      if (hasPreluActivationWeights) {\n        this.variableNames.push('preluActivationWeights');\n      }\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    this.tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    this.tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n    this.tileInner = Math.max(\n        this.workgroupSize[0] * this.innerElementSize, this.workgroupSize[1]);\n\n    this.fitAOuter = dimAOuter % this.tileAOuter === 0;\n    this.fitBOuter = dimBOuter % this.tileBOuter === 0;\n    this.fitInner = dimInner % this.tileInner === 0;\n\n    this.shaderKey = `conv2DMM_${this.elementsPerThread}_${this.activation}}_${\n        this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${\n        this.innerElementSize}_${this.isChannelsLast}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(\n            this.elementsPerThread, this.workgroupSize, !this.isChannelsLast,\n            this.tileInner) :\n        makeMatMulPackedSource(\n            this.elementsPerThread, this.workgroupSize, !this.isChannelsLast,\n            this.tileInner, false, null, this.sequentialAccessByThreads);\n    const elementsSize =\n        this.isVec4 ? [this.innerElementSize, 4, 4] : [1, 1, 1];\n    const userCode = `\n    ${\n        conv2dCommonSnippet(\n            this.isChannelsLast, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.addBias, this.activation, this.hasPreluActivationWeights,\n            elementsSize[0], elementsSize[1], elementsSize[2])}\n    ${matMulSource}\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class Conv2DNaiveProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>,';\n  workgroupSize: [number, number, number] = [4, 4, 8];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  isChannelsLast: boolean;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null,\n      hasPreluActivationWeights = false) {\n    this.outputShape = convInfo.outShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.dispatchLayout = this.isChannelsLast ? {x: [2], y: [1], z: [0, 3]} :\n                                                {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.shaderKey = `conv2dnaive_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n       ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, false, 4)}\n       fn readInp(batch : i32, row : i32, col : i32, chan : i32) -> f32{\n         let coords = vec4<i32>(batch, row, col, chan);\n         if (coordsInBounds4D(coords, uniforms.xShape)) {\n           return  getX(batch, row, col, chan);\n         } else {\n          return 0.0;\n         }\n       }\n       fn readFilt(row : i32, col : i32, xChannel : i32, outChannel : i32) -> f32{\n         let coords = vec4<i32>(row, col, xChannel, outChannel);\n         if(coordsInBounds4D(coords, uniforms.wShape)) {\n           return getW(row, col, xChannel, outChannel);\n          } else {\n            return 0.0;\n          }\n       }\n       fn writeResult(batch : i32, row : i32, col : i32, chan : i32, valueIn : f32) {\n         let coords = ${\n        this.isChannelsLast ? `vec4<i32>(batch, row, col, chan);` :\n                              `vec4<i32>(batch, chan, row, col);`}\n         if (coordsInBounds4D(coords, uniforms.outShape)) {\n           var value = valueIn;\n           ${biasActivationSnippet(this.addBias, this.activation)}\n           setOutputAtCoords(coords.x, coords.y, coords.z, coords.w, value);\n         }\n       }\n       ${main('index')} {\n         let coords = getOutputCoords();\n         let batch = coords[0];\n         let outChannel = ${this.isChannelsLast ? `coords[3];` : `coords[1];`}\n         let outRow = ${this.isChannelsLast ? `coords[1];` : `coords[2];`}\n         let outCol = ${this.isChannelsLast ? `coords[2];` : `coords[3];`}\n         var acc : f32 = 0.0;\n         for (var row = 0; row < uniforms.filterDims[0]; row = row + 1) {\n           for (var col = 0; col < uniforms.filterDims[1]; col = col + 1) {\n             let xRow = outRow * uniforms.strides[0] + uniforms.dilations[0] * row - uniforms.pads[0];\n             let xCol = outCol * uniforms.strides[1] + uniforms.dilations[1] * col - uniforms.pads[1];\n             for (var xChannel = 0; xChannel < ${\n        this.isChannelsLast ? `uniforms.xShape[3];` :\n                              `uniforms.xShape[1];`} xChannel = xChannel + 1) {\n               ${\n        this.isChannelsLast ? `let v = readInp(batch, xRow, xCol, xChannel);` :\n                              `let v = readInp(batch, xChannel, xRow, xCol);`}\n               let f = readFilt(row, col, xChannel, outChannel);\n               acc = acc + v * f;\n             }\n           }\n         }\n         writeResult(batch, outRow, outCol, outChannel, acc);\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Im2ColProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  uniforms =\n      `pads : vec2<i32>, strides : vec2<i32>, dilations : vec2<i32>, outWidth : i32, itemsPerBlockRow : i32,\n       inChannels : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(outputShape: number[], isChannelsLast: boolean) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = isChannelsLast;\n    this.shaderKey = `im2col_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const rowDim = this.isChannelsLast ? 1 : 2;\n    const colDim = this.isChannelsLast ? 2 : 3;\n\n    const row = this.isChannelsLast ? 'coords[1]' : 'coords[2]';\n    const col = this.isChannelsLast ? 'coords[2]' : 'coords[1]';\n    const getXSnippet = this.isChannelsLast ? 'getX(batch, xRow, xCol, ch)' :\n                                              'getX(batch, ch, xRow, xCol)';\n\n    const userCode = `\n    ${main('index')} {\n      let coords = getCoordsFromIndex(index);\n      if(index < uniforms.size) {\n        let batch = coords[0];\n        let row = ${row};\n        let col = ${col};\n        let offsetY = (row / uniforms.outWidth) * uniforms.strides[0] - uniforms.pads[0];\n        let xRow = offsetY + uniforms.dilations[0] * (col / uniforms.itemsPerBlockRow);\n        var value = 0.0;\n        if(xRow < uniforms.xShape[${rowDim}] && xRow >= 0) {\n          let offsetX = (row % uniforms.outWidth) * uniforms.strides[1] -\n              uniforms.pads[1];\n          let xCol = offsetX + uniforms.dilations[1] * ((col %\n              uniforms.itemsPerBlockRow) / uniforms.inChannels);\n          let ch = col % uniforms.inChannels;\n          if(xCol < uniforms.xShape[${colDim}] && xCol >= 0) {\n            value = ${getXSnippet};\n          }\n        }\n        setOutputAtIndex(index, value);\n      }\n    }\n   `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DMMProgram} from '../conv2d_mm_webgpu';\nimport {Conv2DNaiveProgram} from '../conv2d_naive_webgpu';\nimport {Im2ColProgram} from '../im2col_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\n\nimport {batchMatMulImpl} from './BatchMatMul_impl';\nimport {reshape} from './Reshape';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: WebGPUBackend,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// conv2dByMatMul fuses height and width into one dimension to compute\n// batchMatMul, so bias and activation weights are also supposed to fuse the two\n// dimensions into one.\n//\n// This function computes the target shape for fusing height and width\n// dimensions. Returning null means the shape is already compatible.\nfunction getShapeForBatchMatMul(\n    shape: number[], isChannelsLast: boolean): number[] {\n  const length = shape.length;\n  if (length >= 3) {\n    return isChannelsLast ?\n        [\n          ...shape.slice(0, -3) /* batch */,\n          shape[length - 3] * shape[length - 2] /* height * width */,\n          shape[length - 1] /* channel */\n        ] :\n        [\n          ...shape.slice(0, -3) /* batch */, shape[length - 3] /* channel */,\n          shape[length - 2] * shape[length - 1] /* height * width */\n        ];\n  } else if (!isChannelsLast && length === 1 && shape[0] > 1) {\n    return [shape[0], 1];\n  } else {\n    return null;\n  }\n}\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nfunction conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = isChannelsLast ? false : true;\n  const transposeB = false;\n\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const intermediates: TensorInfo[] = [];\n  let xReshaped;\n  let filterReshaped;\n\n  if (sameSize) {\n    const sharedDim =\n        convInfo.inHeight * convInfo.inWidth * convInfo.inChannels;\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {shape: [1, convInfo.batchSize, sharedDim]}\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, sharedDim, convInfo.outChannels]}\n    });\n  } else {\n    xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {\n        shape: isChannelsLast ?\n            [\n              convInfo.batchSize, convInfo.inHeight * convInfo.inWidth,\n              convInfo.inChannels\n            ] :\n            [\n              convInfo.batchSize, convInfo.inChannels,\n              convInfo.inHeight * convInfo.inWidth\n            ]\n      }\n    });\n    filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n  }\n  intermediates.push(xReshaped);\n  intermediates.push(filterReshaped);\n\n  if (preluActivationWeights != null) {\n    const targetShape =\n        getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);\n    if (targetShape != null) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: targetShape}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n  }\n\n  if (bias != null) {\n    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);\n    if (targetShape != null) {\n      bias = reshape({inputs: {x: bias}, backend, attrs: {shape: targetShape}});\n      intermediates.push(bias);\n    }\n  }\n\n  const result = batchMatMulImpl({\n    a: isChannelsLast ? xReshaped : filterReshaped,\n    b: isChannelsLast ? filterReshaped : xReshaped,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    activation,\n    preluActivationWeights,\n    leakyreluAlpha\n  });\n  const out = reshape(\n      {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n  intermediates.push(result);\n\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n\n  return out;\n}\n\n// Implements the im2col algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nfunction conv2dWithIm2Col({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // row of a new matrix with shape [outHeight * outWidth,\n  // filterWidth * filterHeight * inChannels]. The filter is also rearranged so\n  // each output channel forms a col of a new matrix with shape [\n  // filterWidth * filterHeight * inChannels, outChannels]. The convolution is\n  // then computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    strideWidth,\n    strideHeight,\n    padInfo,\n    outWidth,\n    outHeight,\n    dilationWidth,\n    dilationHeight,\n    dataFormat\n  } = convInfo;\n\n  const isChannelsLast = dataFormat === 'channelsLast';\n\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = isChannelsLast ? [convInfo.batchSize, numCols, sharedDim] :\n                                      [convInfo.batchSize, sharedDim, numCols];\n\n  const im2ColProgram = new Im2ColProgram(x2ColShape, isChannelsLast);\n  const dimensions = [\n    {type: 'int32', data: [padInfo.top, padInfo.left]},      // Padding.\n    {type: 'int32', data: [strideHeight, strideWidth]},      // Stride.\n    {type: 'int32', data: [dilationHeight, dilationWidth]},  // Dilation.\n    {type: 'int32', data: [outWidth]},\n    {type: 'int32', data: [inChannels * filterWidth]},  // itemsPerBlockRow.\n    {type: 'int32', data: [inChannels]}\n  ];\n  const x2Col =\n      backend.runWebGPUProgram(im2ColProgram, [x], x.dtype, dimensions);\n\n  const intermediates: TensorInfo[] = [];\n  intermediates.push(x2Col);\n\n  const filterReshaped = reshape(\n      {inputs: {x: filter}, backend, attrs: {shape: [1, sharedDim, -1]}});\n  intermediates.push(filterReshaped);\n\n  if (preluActivationWeights != null) {\n    const targetShape =\n        getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);\n    if (targetShape != null) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: targetShape}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n  }\n\n  if (bias != null) {\n    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);\n    if (targetShape != null) {\n      bias = reshape({inputs: {x: bias}, backend, attrs: {shape: targetShape}});\n      intermediates.push(bias);\n    }\n  }\n\n  const transposeA = isChannelsLast ? false : true;\n  const transposeB = false;\n  const result = batchMatMulImpl({\n    a: isChannelsLast ? x2Col : filterReshaped,\n    b: isChannelsLast ? filterReshaped : x2Col,\n    transposeA,\n    transposeB,\n    backend,\n    bias,\n    activation,\n    preluActivationWeights,\n    leakyreluAlpha\n  });\n  const out = reshape(\n      {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n  intermediates.push(result);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n\n  return out;\n}\n\nexport function conv2DImpl({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const sameSize = isChannelsLast &&\n      convInfo.filterHeight === convInfo.inHeight &&\n      convInfo.filterWidth === convInfo.inWidth &&\n      convInfo.padInfo.type === 'VALID';\n  const useNaiveConv2d = env().getBool('WEBGPU_USE_NAIVE_CONV2D_DEBUG');\n\n  if (!useNaiveConv2d &&\n      (sameSize ||\n       (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n        convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n        convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n        (convInfo.padInfo.type === 'SAME' ||\n         convInfo.padInfo.type === 'VALID')))) {\n    return conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  }\n\n  const thresholdFlagValue = env().getNumber(\n    'WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');\n  const thresholdToIncreaseWorkgroups =  thresholdFlagValue > 0 ?\n      thresholdFlagValue : backend.thresholdToIncreaseWorkgroups;\n  const workgroupsBy32x32 = convInfo.batchSize *\n      Math.ceil((convInfo.outHeight * convInfo.outWidth) / 32) *\n      Math.ceil(convInfo.outChannels / 32);\n  if (env().getBool('WEBGPU_CONV_SEPARATE_IM2COL_SHADER') ||\n      workgroupsBy32x32 <= thresholdToIncreaseWorkgroups) {\n    return conv2dWithIm2Col({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      preluActivationWeights,\n      leakyreluAlpha,\n      activation\n    });\n  }\n\n  let program: WebGPUProgram;\n  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [...padInfo]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}\n  ];\n  if (useNaiveConv2d) {\n    program = new Conv2DNaiveProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n  } else {\n    const dimAOuter = isChannelsLast ? convInfo.outHeight * convInfo.outWidth :\n                                       convInfo.outChannels;\n    const dimBOuter = isChannelsLast ? convInfo.outChannels :\n                                       convInfo.outHeight * convInfo.outWidth;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.inChannels;\n    dimensions.push(\n        {type: 'int32', data: [dimAOuter]}, {type: 'int32', data: [dimBOuter]},\n        {type: 'int32', data: [dimInner]});\n\n    // Experiments show that sequential access is more friendly for Intel GPUs.\n    const sequentialAccessByThreads = backend.adapterInfo.isIntel();\n    program = new Conv2DMMProgram(\n        convInfo, dimAOuter, dimBOuter, dimInner, hasBias, activation,\n        hasPreluActivationWeights, sequentialAccessByThreads);\n  }\n\n  const intermediates: TensorInfo[] = [];\n  const inputVar: TensorInfo[] = [x, filter];\n  if (hasBias) {\n    if (!isChannelsLast && bias.shape.length === 1) {\n      bias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      intermediates.push(bias);\n    }\n    inputVar.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    if (!isChannelsLast && preluActivationWeights.shape.length === 1) {\n      preluActivationWeights = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      intermediates.push(preluActivationWeights);\n    }\n    inputVar.push(preluActivationWeights);\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const out = backend.runWebGPUProgram(program, inputVar, x.dtype, dimensions);\n  for (const i of intermediates) {\n    backend.disposeData(i.dataId);\n  }\n  return out;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function conv2d(\n    args: {inputs: Conv2DInputs, attrs: Conv2DAttrs, backend: WebGPUBackend}) {\n  const {inputs, attrs, backend} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n  return conv2DImpl({x, filter, convInfo, backend});\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'webgpu',\n  kernelFunc: conv2d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Conv2DDerInputProgram implements WebGPUProgram {\n  variableNames = ['dy', 'W'];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = false;\n  isVec4 = false;\n  workPerThread = 1;\n  outputComponent: number;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.isVec4 = this.isChannelsLast && convInfo.outChannels % 4 === 0 &&\n        convInfo.inChannels % 4 === 0;\n    if (this.isVec4) {\n      // TODO: Expand to any value.\n      this.workPerThread = 2;\n      this.outputComponent = 4;\n      this.workgroupSize = [4, 4, 4];\n      this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize,\n          [4, this.workPerThread, 1]);\n    } else {\n      this.size = true;\n      this.workPerThread = 1;\n      this.workgroupSize = [64, 1, 1];\n      this.dispatchLayout = flatDispatchLayout(this.outputShape);\n      this.dispatch = computeDispatch(\n          this.dispatchLayout, this.outputShape, this.workgroupSize);\n    }\n    this.shaderKey = `conv2DDerInput_${this.isChannelsLast}_${this.isVec4}_${\n        this.workPerThread}`;\n  }\n\n  getUserCode(): string {\n    const rowDim = this.isChannelsLast ? 1 : 2;\n    const colDim = this.isChannelsLast ? 2 : 3;\n    const channelDim = this.isChannelsLast ? 3 : 1;\n\n    const vec4Snippet = `\n    ${main()} {\n      let batch = i32(globalId.z) / uniforms.outShape[1];\n      let r = i32(globalId.z) % uniforms.outShape[1];\n      let c = i32(globalId.y) * ${this.workPerThread};\n      let d1 = i32(globalId.x) * 4;\n\n      let dyCorner = vec2<i32>(r, c) - uniforms.pads;\n\n      // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n      // ? = to be determined. : = across all values in that axis.\n      var dotProd: array<vec4<f32>, ${this.workPerThread}>;\n      for (var i = 0; i < ${this.workPerThread}; i++) {\n        dotProd[i] = vec4<f32>(0.0);\n      }\n      for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {\n        let dyR = f32(dyCorner.x + wR) / f32(uniforms.strides.x);\n        let wRPerm = uniforms.filterDims.x - 1 - wR;\n        if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) ||\n            fract(dyR) > 0.0) {\n          continue;\n        }\n        let idyR = i32(dyR);\n\n        for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {\n          let dyC = f32(dyCorner.y + wC) / f32(uniforms.strides.y);\n          let dyC2 = f32(dyCorner.y + 1 + wC) / f32(uniforms.strides.y);\n          let wCPerm = uniforms.filterDims.y - 1 - wC;\n          var bDyCVal = true;\n          var bDyCVal2 = true;\n          if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||\n              fract(dyC) > 0.0) {\n            bDyCVal = false;\n          }\n          if (dyC2 < 0.0 || dyC2 >= f32(uniforms.outBackprop[2]) ||\n              fract(dyC2) > 0.0) {\n            bDyCVal2 = false;\n          }\n\n          let idyC = i32(dyC);\n          let idyC2 = i32(dyC2);\n          if (bDyCVal && bDyCVal2) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[0] = dotProd[0] + tmpval;\n              xValue = getDy(batch, idyR, idyC2, d2);\n              dotProd[1] = dotProd[1] + vec4<f32>(dot(xValue, wValue0),\n                                                  dot(xValue, wValue1),\n                                                  dot(xValue, wValue2),\n                                                  dot(xValue, wValue3));\n            }\n          } else if (bDyCVal) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[0] = dotProd[0] + tmpval;\n            }\n          } else if (bDyCVal2) {\n            let d2Length = uniforms.outBackprop[3];\n            for (var d2 = 0; d2 < d2Length; d2 = d2 + 4) {\n              let wValue0 = getW(wRPerm, wCPerm, d1, d2);\n              let wValue1 = getW(wRPerm, wCPerm, d1 + 1, d2);\n              let wValue2 = getW(wRPerm, wCPerm, d1 + 2, d2);\n              let wValue3 = getW(wRPerm, wCPerm, d1 + 3, d2);\n              var xValue =  getDy(batch, idyR, idyC2, d2);\n              let tmpval = vec4<f32>(dot(xValue, wValue0),\n                                     dot(xValue, wValue1),\n                                     dot(xValue, wValue2),\n                                     dot(xValue, wValue3));\n              dotProd[1] = dotProd[1] + tmpval;\n            }\n          }\n        }\n      }\n\n      for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n        let coords = vec4<i32>(batch, r, c + i, d1);\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], dotProd[i]);\n        }\n      }\n    }\n    `;\n    return this.isVec4 ?\n        `\n    ${vec4Snippet}\n    ` :\n        `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d1 = coords[${channelDim}];\n\n        let dyCorner = vec2<i32>(coords[${rowDim}], coords[${\n            colDim}]) - uniforms.pads;\n        let dyRCorner = dyCorner.x;\n        let dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {\n          let dyR = (f32(dyRCorner) + f32(wR)) / f32(uniforms.strides.x);\n          let wRPerm = uniforms.filterDims.x - 1 - wR;\n          if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) || fract(dyR) > 0.0 ||\n              wRPerm < 0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {\n            let dyC = (f32(dyCCorner) + f32(wC)) / f32(uniforms.strides.y);\n            let wCPerm = uniforms.filterDims.y - 1 - wC;\n            if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||\n                fract(dyC) > 0.0 || wCPerm < 0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            for (var d2 = 0; d2 < uniforms.outBackprop[3]; d2 = d2 + 1) {\n              let xValue = ${\n            this.isChannelsLast ? 'getDy(batch, idyR, idyC, d2)' :\n                                  'getDy(batch, d2, idyR, idyC)'};\n              let wValue = getW(wRPerm, wCPerm, d1, d2);\n              dotProd = dotProd + xValue * wValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv2DDerFilterProgram implements WebGPUProgram {\n  variableNames = ['x', 'dy'];\n  uniforms =\n      'pads : vec2<i32>, strides : vec2<i32>, batchSize : i32, outHeight : i32, outWidth : i32, inHeight : i32, inWidth : i32,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    this.shaderKey = `conv2DDerFilter_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wR = coords[0];\n        let wC = coords[1];\n        let d1 = coords[2];\n        let d2 = coords[3];\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b = b + 1) {\n          for (var yR = 0; yR < uniforms.outHeight; yR = yR + 1) {\n            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];\n            if (xR < 0 || xR >= uniforms.inHeight) {\n              continue;\n            }\n\n            for (var yC = 0; yC < uniforms.outWidth; yC = yC + 1) {\n              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];\n\n              if (xC < 0 || xC >= uniforms.inWidth) {\n                continue;\n              }\n\n              if (${this.isChannelsLast}) {\n                let dyValue = getDy(b, yR, yC, d2);\n                let xValue = getX(b, xR, xC, d1);\n                dotProd = dotProd + xValue * dyValue;\n              } else {\n                let dyValue = getDy(b, d2, yR, yC);\n                let xValue = getX(b, d1, xR, xC);\n                dotProd = dotProd + xValue * dyValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv3DDerFilterProgram implements WebGPUProgram {\n  variableNames = ['x', 'dy'];\n  uniforms =\n      `pads : vec3<i32>, strides : vec3<i32>, batchSize : i32, outDepth : i32,\n       outHeight : i32, outWidth : i32, inDepth : i32, inHeight : i32, inWidth : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `conv3DDerFilter`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wF = coords.x;\n        let wR = coords.y;\n        let wC = coords.z;\n        let d1 = coords.w;\n        let d2 = coords.u;\n\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b++) {\n          for (var yF = 0; yF < uniforms.outDepth; yF++) {\n            let xF = wF + yF * uniforms.strides[0] - uniforms.pads[0];\n            if (xF < 0 || xF >= uniforms.inDepth) {\n              continue;\n            }\n\n            for (var yR = 0; yR < uniforms.outHeight; yR++) {\n              let xR = wR + yR * uniforms.strides[1] - uniforms.pads[1];\n              if (xR < 0 || xR >= uniforms.inHeight) {\n                continue;\n              }\n\n              for (var yC = 0; yC < uniforms.outWidth; yC++) {\n                let xC = wC + yC * uniforms.strides[2] - uniforms.pads[2];\n                if (xC < 0 || xC >= uniforms.inWidth) {\n                  continue;\n                }\n\n                let dyValue = getDy(b, yF, yR, yC, d2);\n                let xValue = getX(b, xF, xR, xC, d1);\n                dotProd += xValue * dyValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n\nexport class Conv3DDerInputProgram implements WebGPUProgram {\n  variableNames = ['dy', 'W'];\n  uniforms = `filterDims : vec3<i32>, pads : vec3<i32>, strides : vec3<i32>,\n      outDepth : i32, outHeight : i32, outWidth : i32, outChannels : i32,`;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `conv3DDerInput`;\n  }\n\n  getUserCode(): string {\n    return `\n    ${main('index')} {\n      if(index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let d1 = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyFCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        var dotProd = 0.0;\n        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {\n          let dyF = f32(dyFCorner + wF) / f32(uniforms.strides[0]);\n          if (dyF < 0.0 || dyF >= f32(uniforms.outDepth) || fract(dyF) > 0.0) {\n            continue;\n          }\n          let idyF = i32(dyF);\n\n          let wFPerm = uniforms.filterDims[0] - 1 - wF;\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            let wRPerm = uniforms.filterDims[1] - 1 - wR;\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let wCPerm = uniforms.filterDims[2] - 1 - wC;\n\n              for (var d2 = 0; d2 < uniforms.outChannels; d2++) {\n                let xValue = getDy(batch, idyF, idyR, idyC, d2);\n                let wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n  `;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DDerFilterProgram} from '../conv_backprop_webgpu';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: WebGPUBackend,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const program = new Conv2DDerFilterProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], x.dtype, uniformData);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: conv2DBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\n\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\nimport {typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupSizeForConv2d, computeWorkPerThreadForConv2d} from './webgpu_util';\n\nfunction conv2dTransposeCommonSnippet(innerElementSize = 4) {\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return W[getIndexFromCoords4D(coord, uniforms.wShape)];';\n      case 4:\n        return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, uniforms.wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, uniforms.wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, uniforms.wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, uniforms.wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n      default:\n        throw new Error(\n            `innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n\n  const readASnippet = `\n      let outRow = row / uniforms.outShape[2];\n      let outCol = row % uniforms.outShape[2];\n\n      let WRow = col / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n      let WCol = col / uniforms.outBackprop[3] % uniforms.filterDims[1];\n      let xR = f32(outRow - uniforms.pads[0] + WRow) / f32(uniforms.strides[0]);\n      let xC = f32(outCol - uniforms.pads[1] + WCol) / f32(uniforms.strides[1]);\n      if (xR < 0.0 || xR >= f32(uniforms.outBackprop[1]) || fract(xR) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(uniforms.outBackprop[2]) || fract(xC) > 0.0) {\n        return ${typeSnippet(innerElementSize)}(0.0);\n      }\n      let coord = vec4<i32>(\n          batch,\n          i32(xR),\n          i32(xC),\n          col % uniforms.outBackprop[3]);\n      return x[getIndexFromCoords4D(coord, uniforms.xShape)/${\n      innerElementSize}];`;\n\n  const sampleA = `if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readASnippet}\n      }\n      return ${typeSnippet(innerElementSize)}(0.0);`;\n\n  const userCode = `\n  fn mm_readA(batch: i32, row : i32, col : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    ${sampleA}\n  }\n\n  fn mm_readB(batch: i32, row : i32, col : i32) -> ${\n      typeSnippet(innerElementSize)} {\n    let coordX = uniforms.filterDims.x - 1 -\n        row / (uniforms.filterDims[1] * uniforms.outBackprop[3]);\n    let coordY = uniforms.filterDims.y - 1 -\n        (row / uniforms.outBackprop[3]) % uniforms.filterDims[1];\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter &&\n        coordX >= 0 && coordY >= 0) {\n      let rowInner = row % uniforms.outBackprop[3];\n      let coord = vec4<i32>(coordX, coordY, col, rowInner);\n      ${getWSnippet(innerElementSize)}\n    }\n    return ${typeSnippet(innerElementSize)}(0.0);\n  }\n\n  fn mm_write(batch: i32, row : i32, col : i32, valueInput : ${\n      typeSnippet(innerElementSize)}) {\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outCoord = vec4<i32>(\n          batch,\n          row / uniforms.outShape[2],\n          row % uniforms.outShape[2],\n          col);\n      result[getIndexFromCoords4D(outCoord, uniforms.outShape)/${\n      innerElementSize}] = value;\n    }\n  }`;\n  return userCode;\n}\n\nexport class Conv2DDerInputMMProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  variableComponents: number[];\n  uniforms =\n      'filterDims : vec2<i32>, pads : vec2<i32>, strides : vec2<i32>, outBackprop : vec4<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,';\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  isVec4?: boolean;\n  outputComponent: number;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n    this.isVec4 =\n        convInfo.inChannels % 4 === 0 && convInfo.outChannels % 4 === 0;\n    this.dispatchLayout = {x: [3], y: [1, 2], z: [0]};\n    this.workgroupSize = computeWorkgroupSizeForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n    this.elementsPerThread = computeWorkPerThreadForConv2d(\n        this.dispatchLayout, this.outputShape, this.isVec4);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    if (this.isVec4) {\n      this.outputComponent = 4;\n      this.variableComponents = [4, 1];\n    }\n\n    this.shaderKey =\n        `conv2DDerInputMM_${this.isVec4}_${this.elementsPerThread}`;\n  }\n\n  getUserCode(): string {\n    const matMulSource = this.isVec4 ?\n        makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize) :\n        makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize);\n    const userCode = `\n    ${conv2dTransposeCommonSnippet(this.isVec4 ? 4 : 1)}\n    ${matMulSource}\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv2DDerInputMMProgram} from '../conv_backprop_mm_webgpu';\nimport {Conv2DDerInputProgram} from '../conv_backprop_webgpu';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  attrs: Conv2DBackpropInputAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {\n      type: 'int32',\n      data: [\n        convInfo.batchSize, convInfo.outHeight, convInfo.outWidth,\n        convInfo.outChannels\n      ]\n    },\n  ];\n  let program: Conv2DDerInputProgram|Conv2DDerInputMMProgram;\n  // TODO: Experiment when to use Conv2DDerInputMMProgram algorithm.\n  if (env().getBool('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE') ||\n      convInfo.dataFormat !== 'channelsLast') {\n    program = new Conv2DDerInputProgram(convInfo);\n  } else {\n    program = new Conv2DDerInputMMProgram(convInfo);\n    const dimAOuter = convInfo.inHeight * convInfo.inWidth;\n    const dimBOuter = convInfo.inChannels;\n    const dimInner =\n        convInfo.filterHeight * convInfo.filterWidth * convInfo.outChannels;\n    dimensions.push(\n        {type: 'uint32', data: [dimAOuter]},\n        {type: 'uint32', data: [dimBOuter]},\n        {type: 'uint32', data: [dimInner]});\n  }\n  return backend.runWebGPUProgram(program, [dy, filter], 'float32', dimensions);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: conv2DBackpropInput as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Conv3DNaiveProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms =\n      'filterDims: vec3<i32>, pads: vec3<i32>, strides: vec3<i32>, dilations: vec3<i32>,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `conv3dnaive`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let batch = coords.x;\n        let d2 = coords.u;\n\n        let xFRCCorner = vec3<i32>(coords.y, coords.z, coords.w) * uniforms.strides - uniforms.pads;\n        let xFCorner = xFRCCorner.x;\n        let xRCorner = xFRCCorner.y;\n        let xCCorner = xFRCCorner.z;\n\n        let inputDepthNearestVec4 = (uniforms.xShape.u / 4) * 4;\n        let inputDepthVec4Remainder = uniforms.xShape.u % 4;\n\n        var dotProd = 0.0;\n        for (var wF = 0; wF < uniforms.filterDims[0]; wF++) {\n          let xF = xFCorner + wF * uniforms.dilations[0];\n          if (xF < 0 || xF >= uniforms.xShape.y) {\n            continue;\n          }\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let xR = xRCorner + wR * uniforms.dilations[1];\n            if (xR < 0 || xR >= uniforms.xShape.z) {\n              continue;\n            }\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let xC = xCCorner + wC * uniforms.dilations[2];\n              if (xC < 0 || xC >= uniforms.xShape.w) {\n                continue;\n              }\n\n              for (var d1 = 0; d1 < inputDepthNearestVec4; d1 += 4) {\n                let xValues = vec4<f32>(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                let wValues = vec4<f32>(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (inputDepthVec4Remainder == 1) {\n                dotProd += getX(batch, xF, xR, xC, inputDepthNearestVec4) *\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2);\n              } else if (inputDepthVec4Remainder == 2) {\n                let xValues = vec2<f32>(\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1)\n                );\n                let wValues = vec2<f32>(\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (inputDepthVec4Remainder == 3) {\n                let xValues = vec3<f32>(\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),\n                  getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2)\n                );\n                let wValues = vec3<f32>(\n                  getW(wF, wR, wC, inputDepthNearestVec4, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 1, d2),\n                  getW(wF, wR, wC, inputDepthNearestVec4 + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }`;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DNaiveProgram} from '../conv3d_naive_webgpu';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, attrs: Conv3DAttrs, backend: WebGPUBackend}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const padInfo =\n      [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left];\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]\n    },\n    {type: 'int32', data: [...padInfo]}, {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.dilationDepth, convInfo.dilationHeight, convInfo.dilationWidth\n      ]\n    }\n  ];\n  const program = new Conv3DNaiveProgram(convInfo);\n  const dtype = upcastType(x.dtype, filter.dtype);\n  return backend.runWebGPUProgram(program, [x, filter], dtype, dimensions);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'webgpu',\n  kernelFunc: conv3D as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DDerFilterProgram} from '../conv_backprop_webgpu';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  attrs: Conv3DBackpropFilterV2Attrs,\n  backend: WebGPUBackend,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const program = new Conv3DDerFilterProgram(convInfo);\n  const uniformData = [\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inDepth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], dy.dtype, uniformData);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'webgpu',\n  kernelFunc: conv3DBackpropFilterV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Conv3DDerInputProgram} from '../conv_backprop_webgpu';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  attrs: Conv3DBackpropInputV2Attrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, pad, inputShape} = attrs;\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const program = new Conv3DDerInputProgram(convInfo);\n  const uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.filterDepth - 1 - convInfo.padInfo.front,\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.outChannels]}\n  ];\n\n  return backend.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'webgpu',\n  kernelFunc: conv3DBackpropInputV2 as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cos = unaryKernelFunc({opType: UnaryOpType.COS});\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'webgpu',\n  kernelFunc: cos\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const cosh = unaryKernelFunc({opType: UnaryOpType.COSH});\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'webgpu',\n  kernelFunc: cosh\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class CropAndResizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['Image', 'Boxes', 'BoxInd'];\n  uniforms = 'extrapolationValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  methodId: number;\n  cropHeightBiggerThan1: boolean;\n  cropWidthBiggerThan1: boolean;\n  size = true;\n\n  constructor(\n      channnel: number, boxShape: [number, number], cropSize: [number, number],\n      method: 'bilinear'|'nearest') {\n    const [numBoxes, ] = boxShape;\n    this.outputShape = [numBoxes, cropSize[0], cropSize[1], channnel];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.methodId = method === 'bilinear' ? 1 : 0;\n    this.cropHeightBiggerThan1 = this.outputShape[1] > 1;\n    this.cropWidthBiggerThan1 = this.outputShape[2] > 1;\n    this.shaderKey = `cropAndResize_${this.methodId}_${\n        this.cropHeightBiggerThan1}_${this.cropWidthBiggerThan1}`;\n  }\n\n  getUserCode(): string {\n    const [inputHeightFloat, inputWidthFloat] =\n        [`f32(uniforms.imageShape[1] - 1)`, `f32(uniforms.imageShape[2] - 1)`];\n\n    const [heightRatio, heightScale, inY] = this.cropHeightBiggerThan1 ?\n        [\n          `(${inputHeightFloat} / f32(uniforms.outShape[1] - 1))`,\n          '(y2-y1) * height_ratio',\n          `y1*${inputHeightFloat} + f32(y)*(height_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (y1+y2) * ${inputHeightFloat}`,\n        ];\n    const [widthRatio, widthScale, inX] = this.cropWidthBiggerThan1 ?\n        [\n          `(${inputWidthFloat} / f32(uniforms.outShape[2] - 1))`,\n          '(x2-x1) * width_ratio',\n          `x1*${inputWidthFloat} + f32(x)*(width_scale)`,\n        ] :\n        [\n          '0.0',\n          '0.0',\n          `0.5 * (x1+x2) * ${inputWidthFloat}`,\n        ];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let height_ratio = f32(${heightRatio});\n        let width_ratio = f32(${widthRatio});\n        let b = coords[0];\n        let y = coords[1];\n        let x = coords[2];\n        let d = coords[3];\n        // get box vals\n        let y1 = getBoxes(b, 0);\n        let x1 = getBoxes(b, 1);\n        let y2 = getBoxes(b, 2);\n        let x2 = getBoxes(b, 3);\n        // get image in batch index\n        let bInd = i32(round(getBoxInd(b)));\n        if(bInd < 0 || bInd >= uniforms.outShape[0]) {\n          return;\n        }\n        let height_scale = ${heightScale};\n        let width_scale = ${widthScale};\n        let in_y = ${inY};\n        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let in_x = ${inX};\n        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {\n          setOutputAtIndex(index, uniforms.extrapolationValue);\n          return;\n        }\n        let sourceFracIndexCR = vec2<f32>(in_x,in_y);\n        if(${this.methodId} == 1) {\n          // Compute the four integer indices.\n          let sourceFloorCR = vec2<i32>(sourceFracIndexCR);\n          let sourceCeilCR = vec2<i32>(ceil(sourceFracIndexCR));\n          let topLeft = getImage(bInd, sourceFloorCR.y, sourceFloorCR.x, d);\n          let bottomLeft = getImage(bInd, sourceCeilCR.y, sourceFloorCR.x, d);\n          let topRight = getImage(bInd, sourceFloorCR.y, sourceCeilCR.x, d);\n          let bottomRight = getImage(bInd, sourceCeilCR.y, sourceCeilCR.x, d);\n          let fracCR = sourceFracIndexCR - vec2<f32>(sourceFloorCR);\n          let top = topLeft + (topRight - topLeft) * fracCR.x;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          let newValue = top + (bottom - top) * fracCR.y;\n          setOutputAtIndex(index, newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          let sourceNearestCR = vec2<i32>(floor(\n            sourceFracIndexCR + vec2<f32>(0.5,0.5)));\n          let newValue = getImage(\n            bInd, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CropAndResizeProgram} from '../crop_and_resize_webgpu';\n\nexport const cropAndResize = (args: {\n  inputs: CropAndResizeInputs,\n  backend: WebGPUBackend,\n  attrs: CropAndResizeAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const program = new CropAndResizeProgram(\n      image.shape[3], boxes.shape as [number, number], cropSize, method);\n  const uniformData = [{type: 'float32', data: [extrapolationValue]}];\n  return backend.runWebGPUProgram(\n      program, [image, boxes, boxInd], 'float32', uniformData);\n};\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'webgpu',\n  kernelFunc: cropAndResize as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport enum CumOpType {\n  Prod = '*',\n  Sum = '+',\n}\n\nexport class CumProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number];\n  // pow(i32, i32) is not supported, use pow(f32, f32) instead.\n  uniforms = 'index : f32,';\n  size = true;\n  exclusive: boolean;\n  reverse: boolean;\n  op: CumOpType;\n\n  constructor(\n      op: CumOpType, shape: number[], exclusive: boolean, reverse: boolean) {\n    this.workgroupSize = [128, 1, 1];\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.exclusive = exclusive;\n    this.reverse = reverse;\n    this.op = op;\n    this.shaderKey = `cum_${this.op}_${this.exclusive}_${this.reverse}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    const initVal = this.op === CumOpType.Prod ? '1.0' : '0.0';\n    const val = this.exclusive ? initVal :\n                                 `getX(${getCoords(rank, 'coords', this.op)})`;\n    const length = this.outputShape[this.outputShape.length - 1];\n    let condition = '';\n    let idxString = '';\n    // When exclusive is set, the cum op becomes roll op that copies the\n    // value from the previous index based on the direction specified by the\n    // reverse flag.\n    if (this.exclusive) {\n      condition = this.reverse ? `end != ${length - 1}` : 'end != 0';\n      idxString = this.reverse ? 'end + 1' : 'end - 1';\n    } else {\n      condition = this.reverse ? `end + pow2 < ${length}` : 'end >= pow2';\n      idxString = (this.reverse ? 'end + pow2' : 'end - pow2');\n    }\n    return `\n      ${main('index')} {\n       if (index < uniforms.size) {\n         var coords = getCoordsFromIndex(index);\n\n         let end = ${getFinalCoord(rank, 'coords', this.op)};\n         var val = ${val};\n         let pow2 = i32(pow(2.0, uniforms.index));\n         if (${condition}) {\n           let idx = ${idxString};\n           ${getFinalCoord(rank, 'coords', this.op)} = idx;\n           val ${this.op}= getX(${getCoords(rank, 'coords', this.op)});\n         }\n         setOutputAtIndex(index, val);\n       }\n      }\n    `;\n  }\n}\n\nfunction getCoords(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.x, ${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.x, ${name}.y, ${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n\nfunction getFinalCoord(rank: number, name: string, op: CumOpType): string {\n  if (rank === 1) {\n    return `${name}`;\n  } else if (rank === 2) {\n    return `${name}.y`;\n  } else if (rank === 3) {\n    return `${name}.z`;\n  } else if (rank === 4) {\n    return `${name}.w`;\n  } else {\n    throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType, CumProgram} from '../cum_webgpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: WebGPUBackend, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGPU cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [i]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [0]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeData(result.dataId);\n    backend.disposeData(permutedX.dataId);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumprod, CumprodAttrs, CumprodInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumprod(\n    args: {inputs: CumprodInputs, backend: WebGPUBackend, attrs: CumprodAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Prod, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'webgpu',\n  kernelFunc: cumprod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType} from '../cum_webgpu';\nimport {cumImpl} from './Cum_impl';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: WebGPUBackend, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n  return cumImpl(CumOpType.Sum, x, backend, axis, exclusive, reverse);\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'webgpu',\n  kernelFunc: cumsum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BincountProgram} from '../bincount_webgpu';\n\nimport {fill} from './Fill';\n\nexport function denseBincount(args: {\n  inputs: DenseBincountInputs,\n  backend: WebGPUBackend,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  const xRankOne = x.shape.length === 1;\n  const weightsSize = util.sizeFromShape(weights.shape);\n  const hasWeights = weightsSize > 0;\n  const dtype = weights.dtype;\n  const xSize: [number]|[number, number] =\n      xRankOne ? [x.shape[0]] : [x.shape[0], x.shape[1]];\n  const outputSize: [number]|[number, number] =\n      xRankOne ? [size] : [x.shape[0], size];\n\n  const output = fill({backend, attrs: {shape: outputSize, value: 0, dtype}});\n  const program = new BincountProgram(xSize, hasWeights, binaryOutput);\n  const uniformData = [{type: 'int32', data: [size]}];\n  const bincountInputs: TensorInfo[] = hasWeights ? [x, weights] : [x];\n  const res = backend.runWebGPUProgram(\n      program, bincountInputs, dtype, uniformData, output);\n\n  return res;\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'webgpu',\n  kernelFunc: denseBincount as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthToSpaceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  outputShape: number[];\n  dataFormat: string;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  uniforms = 'blockSize : i32,';\n\n  constructor(outputShape: number[], dataFormat: 'NHWC'|'NCHW') {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `depthToSpace_${dataFormat}`;\n    this.dataFormat = dataFormat;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let h = ${this.getHeightCoordString()};\n          let w = ${this.getWidthCoordString()};\n          let d = ${this.getDepthCoordString()};\n\n          let in_h = h / uniforms.blockSize;\n          let offset_h = h % uniforms.blockSize;\n          let in_w = w / uniforms.blockSize;\n          let offset_w = w % uniforms.blockSize;\n          let offset_d = (offset_h * uniforms.blockSize + offset_w) *\n            ${this.getOutputDepthSize()};\n          let in_d = d + offset_d;\n\n          let rlt = ${this.getInputSamplingString()};\n          setOutputAtIndex(index, rlt);\n        }\n      }`;\n    return userCode;\n  }\n\n  private getHeightCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[1]`;\n    } else {\n      return `coords[2]`;\n    }\n  }\n\n  private getWidthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[2]`;\n    } else {\n      return `coords[3]`;\n    }\n  }\n\n  private getDepthCoordString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `coords[3]`;\n    } else {\n      return `coords[1]`;\n    }\n  }\n\n  private getOutputDepthSize(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `uniforms.outShape[3]`;\n    } else {\n      return `uniforms.outShape[1]`;\n    }\n  }\n\n  private getInputSamplingString(): string {\n    if (this.dataFormat === 'NHWC') {\n      return `getX(b, in_h, in_w, in_d)`;\n    } else {\n      return `getX(b, in_d, in_h, in_w)`;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthToSpaceProgram} from '../depth_to_space_webgpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: WebGPUBackend,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  const batchSize = x.shape[0];\n  const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n  const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n  const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const outputShape = (dataFormat === 'NHWC') ?\n      [batchSize, outputHeight, outputWidth, outputDepth] :\n      [batchSize, outputDepth, outputHeight, outputWidth];\n\n  const uniformData = [\n    {type: 'int32', data: [blockSize]},\n  ];\n\n  const program = new DepthToSpaceProgram(outputShape, dataFormat);\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'webgpu',\n  kernelFunc: depthToSpace as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch} from './webgpu_util';\n\nexport class DepthwiseConv2DNCHWSharedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pads : vec2<i32>, inDims : vec2<i32>,`;\n  workgroupSize: [number, number, number] = [16, 16, 1];\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  filterHeight: number;\n  filterWidth: number;\n\n  constructor(\n      outputShape: number[], filterHeight: number, filterWidth: number,\n      addBias = false, activation: backend_util.Activation = null,\n      hasPreluActivation = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.filterHeight = filterHeight;\n    this.filterWidth = filterWidth;\n    this.shaderKey = `depthwiseNCHW_${this.activation}_${this.filterHeight}_${\n        this.filterWidth}`;\n  }\n\n  getUserCode(): string {\n    const filterSize = this.filterWidth * this.filterHeight;\n    const flatWorkgroupSize =\n        this.workgroupSize[0] * this.workgroupSize[1] * this.workgroupSize[2];\n    const tileAHeight = this.workgroupSize[1] + this.filterHeight - 1;\n    const tileAWidth = this.workgroupSize[0] + this.filterWidth - 1;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHeight}>;\n      var<workgroup> mm_Bsub : array<array<f32, ${this.filterWidth}>, ${\n        this.filterHeight}>;\n      fn readX(batch : i32, channel : i32, row : i32, col : i32) -> f32 {\n        var value = 0.0;\n        if (row >=0 && row < uniforms.inDims[0] && col >=0 && col < uniforms.inDims[1])\n        {\n          value = getX(batch, channel, row, col);\n        }\n        return value;\n      }\n\n      ${main()} {\n        let coords = getOutputCoords();\n        let batch = coords[0];\n        let xRCCorner = vec2<i32>(coords.zw) - uniforms.pads;\n        let channelMul = uniforms.wShape[3];\n        let d1 = coords[1] / channelMul;\n        let q = coords[1] % channelMul;\n\n        let inputRowStart = xRCCorner.x;\n        let inputColStart = xRCCorner.y;\n\n        let localRow = i32(localId.y);\n        let localCol = i32(localId.x);\n\n        // Load one tile of X into local memory.\n        for (var inputRow = localRow; inputRow < ${\n        tileAHeight}; inputRow = inputRow + ${this.workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n        tileAWidth}; inputCol = inputCol + ${this.workgroupSize[0]}) {\n            let rowOffset = inputRow - localRow;\n            let colOffset = inputCol - localCol;\n            mm_Asub[inputRow][inputCol] = readX(batch, d1, inputRowStart + rowOffset, inputColStart + colOffset);\n          }\n        }\n\n        // Load one tile of W into local memory.\n        var wIndex = i32(localIndex);\n        ${\n        filterSize < flatWorkgroupSize ?\n            `if (wIndex < ${filterSize})` :\n            `for(; wIndex < ${filterSize}; wIndex = wIndex + ${\n                flatWorkgroupSize})`}\n\n        {\n          let wRow = wIndex / ${this.filterWidth};\n          let wCol = wIndex % ${this.filterWidth};\n          mm_Bsub[wRow][wCol] = getW(wRow, wCol, d1, q);\n        }\n\n        workgroupBarrier();\n\n        var value = 0.0;\n        for (var wR = 0; wR < ${this.filterHeight}; wR = wR + 1) {\n          for (var wC = 0; wC < ${this.filterWidth}; wC = wC + 1) {\n            let xVal = mm_Asub[localRow + wR][localCol + wC];\n            let wVal = mm_Bsub[wR][wC];\n            value = fma(xVal, wVal, value);\n          }\n        }\n        ${biasActivationSnippet(this.addBias, this.activation)}\n        if (coordsInBounds4D(coords, uniforms.outShape)) {\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, util} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DVec4Program implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = 'pads : vec2<i32>, inDims : vec2<i32>, virtualWidth : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  workPerThread = 4;\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  outputComponent = 4;\n  virtualWidth: number;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.virtualWidth = Math.ceil(this.outputShape[2] / this.workPerThread) *\n        this.workPerThread;\n    const virtualOutputShape = [\n      this.outputShape[0], this.outputShape[1], this.virtualWidth,\n      this.outputShape[3]\n    ];\n    this.dispatchLayout = flatDispatchLayout(virtualOutputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, virtualOutputShape, this.workgroupSize,\n        [this.outputComponent * this.workPerThread, 1, 1]);\n\n    util.assert(\n        convInfo.dataFormat === 'channelsLast',\n        () => 'TODO: NCHW is unimplemented');\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n\n    this.shaderKey =\n        `depthwiseVec4_${activation}_${this.convInfo.filterHeight}_${\n            this.convInfo.filterWidth}_${this.convInfo.strideHeight}_${\n            this.convInfo.strideWidth}_${this.workPerThread}`;\n  }\n\n  getUserCode(): string {\n    const xNumber = (this.workPerThread - 1) * this.convInfo.strideWidth +\n        this.convInfo.filterWidth;\n    const strideHeight = this.convInfo.strideHeight;\n    const strideWidth = this.convInfo.strideWidth;\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, true, 4)}\n      fn readX(batch : i32, row : i32, col : i32, channel : i32) -> vec4<f32> {\n        var value = vec4<f32>(0.0);\n        if (col >=0 && col < uniforms.inDims[1]) {\n          value = getX(batch, row, col, channel);\n        }\n        return value;\n      }\n\n      ${main('index')} {\n        let width0 = uniforms.outShape[3] / ${this.outputComponent};\n        let d1 = (index % width0) * ${this.outputComponent};\n        var index1 = index / width0;\n        let width1 = uniforms.virtualWidth / ${this.workPerThread};\n        let c = (index1 % width1) * ${this.workPerThread};\n        index1 = index1 / width1;\n        let r = index1 % uniforms.outShape[1];\n        let batch = index1 / uniforms.outShape[1];\n\n        let xRCCorner = vec2<i32>(r, c) * vec2<i32>(${strideHeight}, ${\n        strideWidth}) - uniforms.pads;\n\n        let xRCorner = xRCCorner.x;\n        let xCCorner = xRCCorner.y;\n        var xVals : array<vec4<f32>, ${xNumber}>;\n        var dotProd : array<vec4<f32>, ${this.workPerThread}>;\n        for (var i = 0; i < ${this.workPerThread}; i++) {\n          dotProd[i] = vec4<f32>(0.0);\n        }\n\n        // Use constant instead of uniform can give better performance.\n        for (var wR = 0; wR < ${this.convInfo.filterHeight}; wR = wR + 1) {\n          let xR = xRCorner + wR;\n          if (xR >=0 && xR < uniforms.inDims[0]) {\n            for (var i = 0; i < ${xNumber}; i++) {\n              xVals[i] = readX(batch, xR, xCCorner + i, d1);\n            }\n            for (var wC = 0; wC < ${this.convInfo.filterWidth}; wC = wC + 1) {\n              let wValue = getW(wR, wC, d1, 0);\n              for (var i = 0; i < ${this.workPerThread}; i++) {\n                dotProd[i] = fma(xVals[i * ${\n        strideWidth} + wC], wValue, dotProd[i]);\n              }\n            }\n          }\n        }\n\n        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {\n          let coords = vec4<i32>(batch, r, c + i, d1);\n          if (coordsInBounds4D(coords, uniforms.outShape)) {\n            var value = dotProd[i];\n            ${biasActivationSnippet(this.addBias, this.activation)}\n            setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'W'];\n  uniforms = `pads : vec2<i32>, inDims : vec2<i32>, filterHeight : i32,\n      filterWidth : i32, strides : vec2<i32>, dilations : vec2<i32>,`;\n  // This is an experimental value.\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  convInfo: backend_util.Conv2DInfo;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivation: boolean;\n  isChannelsLast: boolean;\n  size = true;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, addBias = false,\n      activation: backend_util.Activation = null, hasPreluActivation = false) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivation) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.convInfo = convInfo;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivation = hasPreluActivation;\n    this.shaderKey = `depthwise_${this.activation}_${this.isChannelsLast}`;\n  }\n\n  getUserCode(): string {\n    const getXSnippet = this.isChannelsLast ? 'getX(batch, xR, xC, d1);' :\n                                              'getX(batch, d1, xR, xC);';\n\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}\n\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let batch = coords[0];\n          let xRCCorner = vec2<i32>(coords.${\n        this.isChannelsLast ? 'yz' : 'zw'}) * uniforms.strides - uniforms.pads;\n          let d2 = coords[${this.isChannelsLast ? 3 : 1}];\n          let channelMul = uniforms.wShape[3];\n          let d1 = d2 / channelMul;\n          let q = d2 % channelMul;\n\n          let inputRowStart = xRCCorner.x;\n          let inputColStart = xRCCorner.y;\n          let inputRowEnd = inputRowStart + uniforms.filterHeight *\n              uniforms.dilations[0];\n          let inputColEnd = inputColStart + uniforms.filterWidth *\n              uniforms.dilations[1];\n\n          // Convolve x(?, ?, d1)|x(d1, ?, ?) with w(:, :, d1, q) to get\n          // y(yR, yC, d2)|y(d2, yR, yC). ? = to be determined. : = across all\n          // values in that axis. x(?, ?, d1) and y(yR, yC, d2) is for NHWC.\n          // x(d1, ?, ?) and y(d2, yR, yC) is for NCHW.\n          var value = 0.0;\n\n          // Extract if checking out of for loop for performance.\n          if (inputRowStart >= 0 && inputColStart >= 0 &&\n            inputRowEnd < uniforms.inDims[0] &&\n                inputColEnd < uniforms.inDims[1]) {\n              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n                let xR = inputRowStart + wR * uniforms.dilations[0];\n\n                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                  let xC = inputColStart + wC * uniforms.dilations[1];\n\n                  let xVal = ${getXSnippet};\n                  let wVal = getW(wR, wC, d1, q);\n                  value = value + xVal * wVal;\n                }\n              }\n            } else {\n              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {\n                let xR = inputRowStart + wR * uniforms.dilations[0];\n\n                if (xR < 0 || xR >= uniforms.inDims[0]) {\n                  continue;\n                }\n\n                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {\n                  let xC = inputColStart + wC * uniforms.dilations[1];\n\n                  if (xC < 0 || xC >= uniforms.inDims[1]) {\n                    continue;\n                  }\n\n                  let xVal = ${getXSnippet};\n                  let wVal = getW(wR, wC, d1, q);\n                  value = value + xVal * wVal;\n                }\n              }\n            }\n            ${biasActivationSnippet(this.addBias, this.activation)}\n          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DNCHWSharedProgram} from '../depthwise_conv2d_nchw_shared_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  attrs: DepthwiseConv2dNativeAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */, $dataFormat);\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program|\n      DepthwiseConv2DNCHWSharedProgram;\n  if (!isChannelsLast && convInfo.inHeight > 16 && convInfo.inWidth > 16 &&\n      convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n      convInfo.dilationWidth === 1 && convInfo.dilationHeight === 1 &&\n      convInfo.inChannels === convInfo.outChannels) {\n    program = new DepthwiseConv2DNCHWSharedProgram(\n        convInfo.outShape, convInfo.filterHeight, convInfo.filterWidth);\n  } else if (\n      isChannelsLast && convInfo.outHeight > 4 && convInfo.outWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(convInfo);\n    dimensions.push({type: 'int32', data: [program.virtualWidth]});\n  } else {\n    program = new DepthwiseConv2DProgram(convInfo);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n\n  return backend.runWebGPUProgram(program, [x, filter], x.dtype, dimensions);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNative as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DepthwiseConv2DDerFilterProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'dy'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>, outHeight : i32,\n      outWidth : i32, inHeight : i32, inWidth : i32, batchSize : i32, channelMul : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.filterShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `depthwise_conv2d_backprop_filter`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let wR = coords[0];\n        let wC = coords[1];\n        let d1 = coords[2];\n        let dm = coords[3];\n        let d2 = d1 * uniforms.channelMul + dm;\n\n        var dotProd = 0.0;\n        for (var b = 0; b < uniforms.batchSize; b++) {\n          for (var yR = 0; yR < uniforms.outHeight; yR++) {\n            let xR = wR + yR * uniforms.strides[0] - uniforms.pads[0];\n\n            if (xR < 0 || xR >= uniforms.inHeight) {\n              continue;\n            }\n\n            for (var yC = 0; yC < uniforms.outWidth; yC++) {\n              let xC = wC + yC * uniforms.strides[1] - uniforms.pads[1];\n\n              if (xC < 0 || xC >= uniforms.inWidth) {\n                continue;\n              }\n\n              let dyValue = getDy(b, yR, yC, d2);\n              let xValue = getX(b, xR, xC, d1);\n              dotProd += xValue * dyValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class DepthwiseConv2DDerInputProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'W'];\n  uniforms = `strides : vec2<i32>, pads : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32, channelMul : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `depthwise_conv2d_backprop_input`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d1 = coords[3];\n        let dyCorner = coords.yz - uniforms.pads;\n        let dyRCorner = dyCorner.x;\n        let dyCCorner = dyCorner.y;\n\n        var dotProd = 0.0;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n\n          let idyR = i32(dyR);\n          let wRPerm = uniforms.filterDims[0] - 1 - wR;\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n\n            let idyC = i32(dyC);\n            let wCPerm = uniforms.filterDims[1] - 1 - wC;\n\n            for (var dm = 0; dm < uniforms.channelMul; dm++) {\n              let d2 = d1 * uniforms.channelMul + dm;\n              let xValue = getDy(batch, idyR, idyC, d2);\n              let wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DDerFilterProgram} from '../conv_backprop_depthwise_webgpu';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const program = new DepthwiseConv2DDerFilterProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.inHeight]},\n    {type: 'int32', data: [convInfo.inWidth]},\n    {type: 'int32', data: [convInfo.batchSize]},\n    {type: 'int32', data: [convInfo.outChannels / convInfo.inChannels]}\n  ];\n  return backend.runWebGPUProgram(program, [x, dy], 'float32', uniformData);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DDerInputProgram} from '../conv_backprop_depthwise_webgpu';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const program = new DepthwiseConv2DDerInputProgram(convInfo);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.filterHeight - 1 - convInfo.padInfo.top,\n        convInfo.filterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]},\n    {type: 'int32', data: [convInfo.outChannels / convInfo.inChannels]}\n  ];\n  return backend.runWebGPUProgram(program, [dy, filter], dy.dtype, uniformData);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DiagProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(size: number) {\n    this.outputShape = [size, size];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'diag';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let value = select(0.0, getX(coords[0]), coords[0] == coords[1]);\n          setOutputAtIndex(index, value);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DiagProgram} from '../diag_webgpu';\nimport {reshape} from './Reshape';\n\nexport function diag(args: {inputs: DiagInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const outShape = [...x.shape, ...x.shape];\n  const xSize = util.sizeFromShape(x.shape);\n\n  const flat = reshape({inputs: {x}, backend, attrs: {shape: [xSize]}});\n\n  const program = new DiagProgram(xSize);\n  const res = backend.runWebGPUProgram(program, [flat], flat.dtype);\n\n  const out = reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n\n  backend.disposeData(flat.dataId);\n  backend.disposeData(res.dataId);\n\n  return out;\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'webgpu',\n  kernelFunc: diag as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Dilation2DProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'dilation2d';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let neg_infinity = -3.4e38;\n           let coords = getOutputCoords();\n           let batch = coords.x;\n           let d1 = coords.w;\n           let outTopLeftCorner = coords.yz * uniforms.strides - uniforms.pads;\n           let hBeg = outTopLeftCorner.x;\n           let wBeg = outTopLeftCorner.y;\n\n           var curVal = neg_infinity;\n           for (var h = 0; h < uniforms.filterDims[0]; h = h + 1) {\n             let hIn = hBeg + h * uniforms.dilations[0];\n\n             if (hIn >= 0 && hIn < uniforms.xShape[1]) {\n               for (var w = 0; w < uniforms.filterDims[1]; w = w + 1) {\n                 let wIn = wBeg + w * uniforms.dilations[1];\n\n                 if (wIn >= 0 && wIn < uniforms.xShape[2]) {\n                   let val = getX(batch, hIn, wIn, d1) + getW(h, w, d1);\n                   if (val > curVal) {\n                     curVal = val;\n                   }\n                 }\n               }\n             }\n           }\n\n           setOutputAtIndex(index, curVal);\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DProgram} from '../dilation_webgpu';\n\nexport function dilation2D(args: {\n  inputs: Dilation2DInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n  const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [...padInfo]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}\n  ];\n\n  const program = new Dilation2DProgram(convInfo);\n  const out =\n      backend.runWebGPUProgram(program, [x, filter], x.dtype, uniformData);\n\n  return out;\n}\n\nexport const dilation2DConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'webgpu',\n  kernelFunc: dilation2D as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class Dilation2DBackpropInputProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(convInfo: backend_util.Conv2DInfo, outputDtype: DataType) {\n    this.outputShape = convInfo.inShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropInput only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropInput';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var xRMax = 0;\n           var xCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     xRMax = xR;\n                     xCMax = xC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.xShape[3] *\n               (xCMax + uniforms.xShape[2] * (xRMax + uniforms.xShape[1] * b));\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n\nexport class Dilation2DBackpropFilterProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'w', 'dy'];\n  uniforms =\n      'filterDims: vec2<i32>, pads: vec2<i32>, strides: vec2<i32>, dilations: vec2<i32>, dySize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      convInfo: backend_util.Conv2DInfo, shape: number[],\n      outputDtype: DataType) {\n    this.outputShape = convInfo.filterShape;\n    this.dispatchLayout = flatDispatchLayout(convInfo.outShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, convInfo.outShape, this.workgroupSize);\n\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`Dilation2DBackpropFilter only supports float32 and int32\n          types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'dilation2DBackpropFilter';\n  }\n\n  getUserCode(): string {\n    // This implementation follows the TF c++ cuda implementation:\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dilation_ops_gpu.cu.cc\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.dySize) {\n           let coords = getDyCoordsFromIndex(index);\n           let b = coords[0];\n           let r = coords[1];\n           let c = coords[2];\n           let d = coords[3];\n\n           let dyCorner = vec2<i32>(r, c) * uniforms.strides - uniforms.pads;\n           var curVal = -3.4e38;  // neg_infinity\n           var wRMax = 0;\n           var wCMax = 0;\n\n           // In the case of multiple argmax branches, we only back-propagate\n           // along the last branch, i.e., the one with largest value of\n           // 'wR * uniforms.filterDims[1] + wC', similarly to the max-pooling\n           // backward routines.\n           for (var wR = 0; wR < uniforms.filterDims[0]; wR++) {\n             let xR = dyCorner.x + wR * uniforms.dilations[0];\n\n             if (xR >= 0 && xR < uniforms.xShape[1]) {\n               for (var wC = 0; wC < uniforms.filterDims[1]; wC++) {\n                 let xC = dyCorner.y + wC * uniforms.dilations[1];\n\n                 if (xC >= 0 && xC < uniforms.xShape[2]) {\n                   let val = getX(b, xR, xC, d) + getW(wR, wC, d);\n                   if (val > curVal) {\n                     curVal = val;\n                     wRMax = wR;\n                     wCMax = wC;\n                   }\n                 }\n               }\n             }\n           }\n\n           let flatIndexIn = d + uniforms.wShape[2] * (wCMax + wRMax * uniforms.wShape[1]);\n           let value = getDy(b, r, c, d);\n           ${\n        atomicAddSnippet(\n            '&result[flatIndexIn]', 'value', this.type as 'float32' | 'int32')}\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Dilation2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DBackpropFilterProgram} from '../dilation_backprop_webgpu';\nimport {fill} from './Fill';\n\nexport function dilation2DBackpropFilter(args: {\n  inputs: Dilation2DBackpropFilterInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n\n  const dtype = filter.dtype;\n  const program =\n      new Dilation2DBackpropFilterProgram(convInfo, filter.shape, dtype);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [util.sizeFromShape(convInfo.outShape)]}\n  ];\n  const output = fill({backend, attrs: {shape: filter.shape, value: 0, dtype}});\n  return backend.runWebGPUProgram(\n      program, [x, filter, dy], dtype, uniformData, output);\n}\n\nexport const dilation2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'webgpu',\n  kernelFunc: dilation2DBackpropFilter as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Dilation2DBackpropInputInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Dilation2DBackpropInputProgram} from '../dilation_backprop_webgpu';\nimport {fill} from './Fill';\n\nexport function dilation2DBackpropInput(args: {\n  inputs: Dilation2DBackpropInputInputs,\n  attrs: Dilation2DAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, dy} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  const convInfo = backend_util.computeDilation2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number], strides, pad,\n      'NHWC' /* dataFormat */, dilations);\n\n  const dtype = x.dtype;\n  const program = new Dilation2DBackpropInputProgram(convInfo, dtype);\n  const uniformData = [\n    {type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [util.sizeFromShape(convInfo.outShape)]}\n  ];\n  const output =\n      fill({backend, attrs: {shape: convInfo.inShape, value: 0, dtype}});\n  return backend.runWebGPUProgram(\n      program, [x, filter, dy], dtype, uniformData, output);\n}\n\nexport const dilation2DBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'webgpu',\n  kernelFunc: dilation2DBackpropInput as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {getMainHeaderString as main, PixelsOpType, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class DrawProgram implements WebGPUProgram {\n  variableNames = ['Image'];\n  uniforms = 'alpha: f32,';\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  type: DataType;\n  textureFormat: GPUTextureFormat;\n  pixelsOpType = PixelsOpType.DRAW;\n  size = true;\n\n  constructor(\n      outShape: number[], type: DataType, textureFormat: GPUTextureFormat) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.type = type;\n    this.textureFormat = textureFormat;\n    this.shaderKey = `draw_${type}_${textureFormat}`;\n  }\n\n  getUserCode(): string {\n    let calculateResult;\n    const value = this.type === 'float32' ? 'value' : 'value / 255.0';\n    calculateResult = `\n      if (uniforms.numChannels == 1) {\n        rgba[0] = ${value};\n        rgba[1] = ${value};\n        rgba[2] = ${value};\n      } else {\n        rgba[d] = ${value};\n      }`;\n\n    const userCode = `\n       @group(0) @binding(0) var outImage : texture_storage_2d<${\n        this.textureFormat}, write>;\n       ${main('index')} {\n         if (index < uniforms.size) {\n           var rgba = vec4<f32>(0.0, 0.0, 0.0, uniforms.alpha);\n           for (var d = 0; d < uniforms.numChannels; d = d + 1) {\n             let value = f32(inBuf[index * uniforms.numChannels + d]);\n             ${calculateResult}\n           }\n           rgba.x = rgba.x * rgba.w;\n           rgba.y = rgba.y * rgba.w;\n           rgba.z = rgba.z * rgba.w;\n           let coords = getCoordsFromIndex(index);\n           textureStore(outImage, vec2<i32>(coords.yx), rgba);\n         }\n       }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use backend file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\nimport {Draw, DrawAttrs, DrawInputs,} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DrawProgram} from '../draw_webgpu';\n\nexport function draw(\n    args: {inputs: DrawInputs, backend: WebGPUBackend, attrs: DrawAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image} = inputs;\n  const {canvas, options} = attrs;\n  const [height, width] = image.shape.slice(0, 2);\n  const {imageOptions} = options || {};\n  const alpha = imageOptions ?.alpha || 1;\n\n  //  'rgba8unorm' should work on macOS according to\n  //  https://bugs.chromium.org/p/chromium/issues/detail?id=1298618. But\n  //  failed on macOS/M2. So use 'bgra8unorm' first when available.\n  const format = backend.device.features.has('bgra8unorm-storage') ?\n      'bgra8unorm' :\n      'rgba8unorm';\n  const outShape = [height, width];\n  const program = new DrawProgram(outShape, image.dtype, format);\n  canvas.width = width;\n  canvas.height = height;\n  const backendName = 'webgpu';\n  let gpuContext = canvas.getContext(backendName);\n  let canvasWebGPU;\n  if (!gpuContext) {\n    canvasWebGPU = new OffscreenCanvas(width, height);\n    gpuContext = canvasWebGPU.getContext(backendName);\n  }\n  const numChannels = image.shape.length === 3 ? image.shape[2] : 1;\n  gpuContext.configure({\n    device: backend.device,\n    format,\n    usage: GPUTextureUsage.STORAGE_BINDING,\n    alphaMode: 'premultiplied'\n  });\n\n  const outputDtype = 'int32';\n  const output = backend.makeTensorInfo(outShape, outputDtype);\n  const info = backend.tensorMap.get(output.dataId);\n  info.resource = gpuContext.getCurrentTexture();\n  info.external = true;\n\n  const uniformData =\n      [{type: 'uint32', data: [numChannels]}, {type: 'float32', data: [alpha]}];\n  backend.runWebGPUProgram(program, [image], outputDtype, uniformData, output);\n\n  if (canvasWebGPU) {\n    const canvas2dContext = canvas.getContext('2d');\n    if (!canvas2dContext) {\n      throw new Error(\n          `Please make sure this canvas has only been used for 2d or webgpu context!`);\n    }\n    canvas2dContext.drawImage(canvasWebGPU, 0, 0);\n  }\n  backend.disposeData(output.dataId);\n  return image;\n}\n\nexport const drawConfig: KernelConfig = {\n  kernelName: Draw,\n  backendName: 'webgpu',\n  kernelFunc: draw as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {multiplyImplCPU as cpuMultiply} from '../kernel_utils/shared';\n\nexport const multiplyKernelFunc = binaryKernelFunc({\n  opType: BinaryOpType.MUL,\n  cpuKernelImpl: cpuMultiply,\n  supportsComplex: true\n});\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'webgpu',\n  kernelFunc: multiplyKernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: WebGPUBackend, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'sum', backend);\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'webgpu',\n  kernelFunc: sum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {multiplyKernelFunc} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: WebGPUBackend, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out =\n            multiplyKernelFunc({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeData(tensorInfo.dataId);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'webgpu',\n  kernelFunc: einsum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const elu = unaryKernelFunc({opType: UnaryOpType.ELU});\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'webgpu',\n  kernelFunc: elu\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\n\nexport const eluGrad =\n    (args: {inputs: EluGradInputs, backend: WebGPUBackend}): TensorInfo => {\n      const {inputs, backend} = args;\n      const {dy, y} = inputs;\n\n      const program =\n          new BinaryOpProgram(BinaryOpType.ELU_DER, dy.shape, y.shape);\n      return backend.runWebGPUProgram(program, [dy, y], dy.dtype);\n    };\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'webgpu',\n  kernelFunc: eluGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {equalImplCPU as cpuEqual} from '../kernel_utils/shared';\n\nexport const equal = binaryKernelFunc(\n    {opType: BinaryOpType.EQUAL, dtype: 'bool', cpuKernelImpl: cpuEqual});\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'webgpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const erf = unaryKernelFunc({opType: UnaryOpType.ERF});\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'webgpu',\n  kernelFunc: erf\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const exp = unaryKernelFunc({\n  opType: UnaryOpType.EXP,\n  cpuKernelImpl: expImplCPU,\n  dtype: 'float32',\n});\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'webgpu',\n  kernelFunc: exp\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  attrs: ExpandDimsAttrs,\n  backend: WebGPUBackend\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {dim} = attrs;\n  const {input} = inputs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'webgpu',\n  kernelFunc: expandDims as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {expm1ImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const expm1 =\n    unaryKernelFunc({opType: UnaryOpType.EXPM1, cpuKernelImpl: expm1ImplCPU});\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'webgpu',\n  kernelFunc: expm1\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FFTProgram implements WebGPUProgram {\n  variableNames: string[] = ['real', 'imag'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'exponentMultiplier : f32, denominator: f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  component: string;\n\n  constructor(component: 'real'|'imag', shape: [number, number]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.component = component;\n    this.shaderKey = `fft_${component}`;\n  }\n\n  getUserCode(): string {\n    const opString = this.component === 'real' ?\n        'return real * expR - imag * expI;' :\n        'return real * expI + imag * expR;';\n    const userCode = `\n    fn unaryOpComplex(real: f32, expR: f32, imag: f32, expI: f32) -> f32 {\n      ${opString}\n    }\n\n    fn mulMatDFT(batch: i32, index: i32) -> f32 {\n      let indexRatio = f32(index) / f32(uniforms.realShape[1]);\n      let exponentMultiplierTimesIndexRatio =\n          uniforms.exponentMultiplier * indexRatio;\n\n      var result = 0.0;\n\n      for (var i = 0; i < uniforms.realShape[1]; i = i + 1) {\n        // x = (-2|2 * PI / N) * index * i;\n        let x = exponentMultiplierTimesIndexRatio * f32(i);\n        let expR = cos(x);\n        let expI = sin(x);\n        let real = getReal(batch, i);\n        let imag = getImag(batch, i);\n\n        result = result +\n            unaryOpComplex(real, expR, imag, expI) / uniforms.denominator;\n      }\n\n      return result;\n    }\n\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        setOutputAtIndex(index, mulMatDFT(coords[0], coords[1]));\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FFTProgram} from '../fft_webgpu';\n\nimport {complex} from './Complex';\nimport {reshape} from './Reshape';\n\nexport function fftImpl(\n    x: TensorInfo, inverse: boolean, backend: WebGPUBackend): TensorInfo {\n  const xData = backend.tensorMap.get(x.dataId);\n\n  const inputSize = util.sizeFromShape(x.shape);\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = x.shape[x.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const toDispose = [];\n  const input2D = reshape(\n      {inputs: {x}, backend, attrs: {shape: [batch, innerDimensionSize]}});\n  toDispose.push(input2D);\n\n  const xShape = input2D.shape as [number, number];\n  const realProgram = new FFTProgram('real', xShape);\n  const imagProgram = new FFTProgram('imag', xShape);\n\n  const inputs = [\n    {\n      dataId: xData.complexTensorInfos.real.dataId,\n      dtype: xData.complexTensorInfos.real.dtype,\n      shape: xShape\n    },\n    {\n      dataId: xData.complexTensorInfos.imag.dataId,\n      dtype: xData.complexTensorInfos.imag.dtype,\n      shape: xShape\n    }\n  ];\n\n  const exponentMultiplier = inverse ? 2.0 * Math.PI : -2.0 * Math.PI;\n  const denominator = inverse ? xShape[1] : 1.0;\n  const uniformData = [\n    {type: 'float32', data: [exponentMultiplier]},\n    {type: 'float32', data: [denominator]}\n  ];\n\n  const realPart =\n      backend.runWebGPUProgram(realProgram, inputs, 'float32', uniformData);\n  toDispose.push(realPart);\n  const imagPart =\n      backend.runWebGPUProgram(imagProgram, inputs, 'float32', uniformData);\n  toDispose.push(imagPart);\n\n  const complexOutput =\n      complex({inputs: {real: realPart, imag: imagPart}, backend});\n  toDispose.push(complexOutput);\n\n  const complexOutputReshaped =\n      reshape({inputs: {x: complexOutput}, backend, attrs: {shape: x.shape}});\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return complexOutputReshaped;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {fftImpl} from './FFT_impl';\n\nexport function fft(args: {inputs: FFTInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  return fftImpl(input, false /* inverse */, backend);\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'webgpu',\n  kernelFunc: fft\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FlipLeftRightProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(imageShape: [number, number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'flipLeftRight';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let coordX = uniforms.xShape[2] - coords[2] - 1;\n          let outputValue = getX(coords[0], coords[1], coordX, coords[3]);\n          setOutputAtIndex(index, outputValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FlipLeftRightProgram} from '../flip_left_right_webgpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n    kernelName: FlipLeftRight,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, backend}) => {\n      const {image} = inputs as FlipLeftRightInputs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new FlipLeftRightProgram((image as Tensor4D).shape);\n      const output =\n          webgpuBackend.runWebGPUProgram(program, [image], image.dtype);\n      return output;\n  }\n};\n","\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {floorImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const floor =\n    unaryKernelFunc({opType: UnaryOpType.FLOOR, cpuKernelImpl: floorImplCPU});\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'webgpu',\n  kernelFunc: floor\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {floorDivImplCPU} from '../kernel_utils/shared';\n\nexport const floorDiv = binaryKernelFunc({\n  opType: BinaryOpType.FLOOR_DIV,\n  cpuKernelImpl: floorDivImplCPU,\n  dtype: 'int32'\n});\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'webgpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, PixelsOpType, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class FromPixelsProgram implements WebGPUProgram {\n  dispatch: [number, number, number];\n  dispatchLayout: {x: number[]};\n  pixelsOpType = PixelsOpType.FROM_PIXELS;\n  outputShape: number[] = [0];\n  shaderKey: string;\n  importVideo: boolean;\n  variableNames: string[] = [];\n  workgroupSize: [number, number, number] =\n      [256, 1, 1];  // The empirical value.\n\n  constructor(outputShape: number[], numChannels: number, importVideo = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [numChannels, 1, 1]);\n\n    this.importVideo = importVideo;\n    this.shaderKey = `fromPixels_${this.importVideo}`;\n  }\n\n  getUserCode(): string {\n    const textureLoad = this.importVideo ?\n        'textureLoad(src, vec2<i32>(coords.yx));' :\n        'textureLoad(src, vec2<i32>(coords.yx), 0)';\n    const textureType =\n        this.importVideo ? 'texture_external' : 'texture_2d<f32>';\n    return `\n      @binding(1) @group(0) var src: ${textureType};\n      ${main('index')} {\n        let flatIndex = index * uniforms.numChannels;\n        if (flatIndex < uniforms.size) {\n          let coords = getCoordsFromIndex(flatIndex);\n          let values = ${textureLoad};\n          for (var i = 0; i < uniforms.numChannels; i = i + 1) {\n            result[flatIndex + i] = i32(floor(255.0 * values[i]));\n          }\n        }\n      }\n  `;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use backend file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\nimport {FromPixels, FromPixelsAttrs, FromPixelsInputs, util} from '@tensorflow/tfjs-core';\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {FromPixelsProgram} from '../from_pixels_webgpu';\n\nexport const fromPixelsConfig: KernelConfig = {\n  kernelName: FromPixels,\n  backendName: 'webgpu',\n  kernelFunc: fromPixels as unknown as KernelFunc,\n};\n\nlet fromPixels2DContext: CanvasRenderingContext2D;\nlet willReadFrequently = env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\n\nexport function fromPixels(args: {\n  inputs: FromPixelsInputs,\n  backend: WebGPUBackend,\n  attrs: FromPixelsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  let {pixels} = inputs;\n  const {numChannels} = attrs;\n\n  if (pixels == null) {\n    throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n  }\n\n  const isVideo = typeof (HTMLVideoElement) !== 'undefined' &&\n      pixels instanceof HTMLVideoElement;\n  const isImage = typeof (HTMLImageElement) !== 'undefined' &&\n      pixels instanceof HTMLImageElement;\n  const isCanvas = (typeof (HTMLCanvasElement) !== 'undefined' &&\n                    pixels instanceof HTMLCanvasElement) ||\n      (typeof (OffscreenCanvas) !== 'undefined' &&\n       pixels instanceof OffscreenCanvas);\n  const isImageBitmap =\n      typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap;\n\n  const [width, height] = isVideo ?\n      [\n        (pixels as HTMLVideoElement).videoWidth,\n        (pixels as HTMLVideoElement).videoHeight\n      ] :\n      [pixels.width, pixels.height];\n  const outputShape = [height, width, numChannels];\n\n  // Disable importExternalTexture temporarily as it has problem in spec and\n  // browser impl\n  const importVideo =\n      false && env().getBool('WEBGPU_IMPORT_EXTERNAL_TEXTURE') && isVideo;\n  const isVideoOrImage = isVideo || isImage;\n  if (isImageBitmap || isCanvas || isVideoOrImage) {\n    let resource;\n    if (importVideo) {\n      resource = backend.device.importExternalTexture(\n          {source: pixels as HTMLVideoElement});\n    } else {\n      if (isVideoOrImage) {\n        const newWillReadFrequently =\n            env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');\n        if (fromPixels2DContext == null ||\n            newWillReadFrequently !== willReadFrequently) {\n          willReadFrequently = newWillReadFrequently;\n          fromPixels2DContext = document.createElement('canvas').getContext(\n              '2d', {willReadFrequently});\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(\n            pixels as HTMLVideoElement | HTMLImageElement, 0, 0, width, height);\n        pixels = fromPixels2DContext.canvas;\n      }\n\n      const usage = GPUTextureUsage.COPY_DST |\n          GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING;\n      const format = 'rgba8unorm' as GPUTextureFormat;\n      const texture = backend.textureManager.acquireTexture(\n          outputShape[1], outputShape[0], format, usage);\n      backend.queue.copyExternalImageToTexture(\n          {source: pixels as HTMLCanvasElement | ImageBitmap}, {texture},\n          [outputShape[1], outputShape[0]]);\n      resource = texture;\n    }\n\n    const size = util.sizeFromShape(outputShape);\n    const strides = util.computeStrides(outputShape);\n    const program =\n        new FromPixelsProgram(outputShape, numChannels, importVideo);\n\n    const uniformData = [\n      {type: 'uint32', data: [size]}, {type: 'uint32', data: [numChannels]},\n      {type: 'uint32', data: [...strides]}\n    ];\n    const input = backend.makeTensorInfo([height, width], 'int32');\n    const info = backend.tensorMap.get(input.dataId);\n    info.resource = resource;\n\n    const result =\n        backend.runWebGPUProgram(program, [input], 'int32', uniformData);\n    backend.disposeData(input.dataId);\n    return result;\n  }\n\n  // TODO: Encoding should happen on GPU once we no longer have to download\n  // image data to the CPU.\n  const imageData = (pixels as ImageData | backend_util.PixelData).data;\n  let pixelArray = imageData;\n  if (numChannels != null && numChannels !== 4) {\n    pixelArray = new Uint8Array(pixels.width * pixels.height * numChannels);\n\n    const dataLength = imageData.length;\n    let j = 0;\n    for (let i = 0; i < dataLength; i++) {\n      if (i % 4 < numChannels) {\n        pixelArray[j++] = imageData[i];\n      }\n    }\n  }\n\n  const output =\n      backend.makeTensorInfo(outputShape, 'int32', new Int32Array(pixelArray));\n  backend.uploadToGPU(output.dataId);\n  return output;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class BatchNormProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y?: number[], z?: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[];\n  uniforms = 'varianceEpsilon : f32,';\n  // This is an experimental value.\n  workgroupSize: [number, number, number] = [128, 1, 1];\n  offsetShape: number[]|null;\n  scaleShape: number[]|null;\n  varianceEpsilon: number;\n  size = true;\n\n  constructor(\n      xShape: number[], meanShape: number[], varianceShape: number[],\n      offsetShape: number[]|null, scaleShape: number[]|null) {\n    this.variableNames = ['x', 'mean', 'variance'];\n    backend_util.assertAndGetBroadcastShape(xShape, meanShape);\n    backend_util.assertAndGetBroadcastShape(xShape, varianceShape);\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    if (offsetShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, offsetShape);\n      this.variableNames.push('offset');\n    }\n    if (scaleShape != null) {\n      backend_util.assertAndGetBroadcastShape(xShape, scaleShape);\n      this.variableNames.push('scale');\n    }\n    this.offsetShape = offsetShape;\n    this.scaleShape = scaleShape;\n    this.shaderKey = 'batchNorm';\n  }\n\n  getUserCode(): string {\n    let offsetSnippet = '0.0';\n    if (this.offsetShape != null) {\n      offsetSnippet = 'getOffsetByOutputIndex(index)';\n    }\n\n    let scaleSnippet = '1.0';\n    if (this.scaleShape != null) {\n      scaleSnippet = 'getScaleByOutputIndex(index)';\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size)\n        {\n          let xValue = getXByOutputIndex(index);\n          let meanValue = getMeanByOutputIndex(index);\n          let varianValue = getVarianceByOutputIndex(index);\n          let offsetValue = ${offsetSnippet};\n          let scaleValue = ${scaleSnippet};\n          let inv = scaleValue * inverseSqrt(varianValue + f32(uniforms.varianceEpsilon));\n          setOutputAtIndex(index,dot(vec3<f32>(xValue, -meanValue, offsetValue), vec3<f32>(inv, inv, 1.0)));\n        }\n      }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, Tensor} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BatchNormProgram} from '../batchnorm_webgpu';\n\nexport const fusedBatchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x, scale, offset, mean, variance} = inputs as FusedBatchNormInputs;\n    const {varianceEpsilon} = attrs as unknown as FusedBatchNormAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const batchNormInputs = [x as Tensor, mean as Tensor, variance as Tensor];\n    let offsetShape = null;\n    if (offset != null) {\n      offsetShape = offset.shape;\n      batchNormInputs.push(offset as Tensor);\n    }\n    let scaleShape = null;\n    if (scale != null) {\n      scaleShape = scale.shape;\n      batchNormInputs.push(scale as Tensor);\n    }\n    const program = new BatchNormProgram(\n        x.shape, mean.shape, variance.shape, offsetShape, scaleShape);\n    const uniformData = [{type: 'float32', data: [varianceEpsilon]}];\n    return webGPUBackend.runWebGPUProgram(\n        program, batchNormInputs, x.dtype, uniformData);\n  }\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {conv2DImpl} from './Conv2D_impl';\n\nexport function fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  attrs: FusedConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  return conv2DImpl({\n    x,\n    filter,\n    convInfo,\n    backend,\n    bias,\n    preluActivationWeights,\n    leakyreluAlpha,\n    activation\n  });\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedConv2d as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {DepthwiseConv2DVec4Program} from '../depthwise_conv2d_vec4_webgpu';\nimport {DepthwiseConv2DProgram} from '../depthwise_conv2d_webgpu';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  attrs: FusedDepthwiseConv2DAttrs,\n  backend: WebGPUBackend\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {strides, pad, dilations, dimRoundingMode, activation, leakyreluAlpha} =\n      attrs;\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const programInputs: TensorInfo[] = [x, filter];\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n\n  if (hasBias) {\n    programInputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    programInputs.push(preluActivationWeights);\n  }\n\n  const dimensions = [\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]},\n  ];\n\n  let program: DepthwiseConv2DProgram|DepthwiseConv2DVec4Program;\n  if (convInfo.outHeight > 4 && convInfo.outWidth > 4 &&\n      convInfo.strideWidth <= 2 &&\n      convInfo.inChannels === convInfo.outChannels &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.inChannels % 4 === 0) {\n    program = new DepthwiseConv2DVec4Program(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n    dimensions.push({type: 'int32', data: [program.virtualWidth]});\n  } else {\n    program = new DepthwiseConv2DProgram(\n        convInfo, hasBias, activation, hasPreluActivationWeights);\n    dimensions.push(\n        {type: 'int32', data: [convInfo.filterHeight]},\n        {type: 'int32', data: [convInfo.filterWidth]},\n        {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n          type: 'int32',\n          data: [convInfo.dilationHeight, convInfo.dilationWidth]\n        });\n  }\n  if (activation === 'leakyrelu') {\n    dimensions.push({type: 'float32', data: [leakyreluAlpha]});\n    program.uniforms += ' alpha : f32,';\n  }\n  const result =\n      backend.runWebGPUProgram(program, programInputs, 'float32', dimensions);\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'webgpu',\n  kernelFunc: fusedDepthwiseConv2D as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherNDProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  sliceDim: number;\n  constructor(sliceDim: number, shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `gathernd_${sliceDim}`;\n    this.sliceDim = sliceDim;\n    this.uniforms = `sliceDim : i32, strides : ${getCoordsDataType(sliceDim)},`;\n  }\n\n  getUserCode(): string {\n    let strideString;\n    if (this.sliceDim > 1) {\n      strideString = 'uniforms.strides[j]';\n    } else {\n      strideString = 'uniforms.strides';\n    }\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          var flattenIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexTemp = i32(round(getIndices(coords[0], j)));\n            let strideNum = ${strideString};\n            flattenIndex = flattenIndex + indexTemp * strideNum;\n          }\n\n          setOutputAtIndex(index, getA(flattenIndex, coords[1]));\n        }\n      }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {GatherNDProgram} from '../gather_nd_webgpu';\nimport {gatherNdImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numSlices, sliceRank]}});\n  const flattenX = reshape({\n    inputs: {x: params},\n    backend,\n    attrs: {shape: [(util.sizeFromShape(params.shape) / sliceSize), sliceSize]}\n  });\n  if (backend.shouldExecuteOnCPU([params, indices]) ||\n      params.dtype === 'string') {\n    const indicesData = backend.readSync(indices.dataId) as TypedArray;\n    const paramsBuf = backend.bufferSync<Rank, 'float32'>(params);\n    const outValue = gatherNdImplCPU(\n        indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize,\n        strides, params.shape, paramsSize);\n\n    return backend.makeTensorInfo(resultShape, params.dtype, outValue.values);\n  }\n  const program = new GatherNDProgram(sliceRank, [numSlices, sliceSize]);\n  const uniformData =\n      [{type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides}];\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], flattenX.dtype, uniformData);\n\n  const reshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: resultShape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'webgpu',\n  kernelFunc: gatherNd as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class GatherProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames: string[] = ['A', 'indices'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  aShape: number[];\n  size = true;\n\n  constructor(aShape: number[], outputShape: number[]) {\n    this.outputShape = aShape.slice();\n    this.aShape = aShape;\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = `gather`;\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.aShape);\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let indexZ = i32(getIndices(resRC.x, resRC.z));\n          let inBounds = select(0.0, 1.0, indexZ >= 0 && indexZ < uniforms.aShape[2]);\n          setOutputAtIndex(index, inBounds * getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\n// The input and output are always flattened into rank 4 tensors.\nfunction getSourceCoords(aShape: number[]): string {\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < aShape.length; i++) {\n    if (i === 2) {\n      sourceCoords.push('indexZ');\n    } else {\n      sourceCoords.push(`${currentCoords[i]}`);\n    }\n  }\n  return sourceCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, Rank, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {GatherProgram} from '../gather_webgpu';\nimport {gatherV2ImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\n\nexport function gatherV2(\n    args:\n        {inputs: GatherV2Inputs, backend: WebGPUBackend, attrs: GatherV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  // Unlike WebGL, WebGPU won't check if index is out of bound by calling\n  // backend.readSync() function in debug mode.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, batchDims);\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const toDispose = [];\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  toDispose.push(flattenX);\n  toDispose.push(flattenIndex);\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  if (backend.shouldExecuteOnCPU([x, indices])) {\n    const indicesTensorData = backend.tensorMap.get(flattenIndex.dataId);\n    const indicesValues = indicesTensorData.values as TypedArray;\n    const indicesBuffer =\n        buffer(flattenIndex.shape, flattenIndex.dtype, indicesValues) as\n        TensorBuffer<Rank>;\n    const flattenXTensorData = backend.tensorMap.get(flattenX.dataId);\n    const xValues = flattenXTensorData.values as TypedArray;\n    const xBuffer =\n        buffer(flattenX.shape, flattenX.dtype, xValues) as TensorBuffer<Rank>;\n    const outBuf = gatherV2ImplCPU(xBuffer, indicesBuffer, flattenOutputShape);\n\n    toDispose.forEach(t => backend.disposeData(t.dataId));\n\n    return backend.makeTensorInfo(\n        shapeInfo.outputShape, outBuf.dtype, outBuf.values as TypedArray);\n  }\n\n  const program = new GatherProgram(flattenX.shape, flattenOutputShape);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndex], flattenX.dtype);\n  toDispose.push(res);\n\n  const reshaped = reshape(\n      {inputs: {x: res}, backend, attrs: {shape: shapeInfo.outputShape}});\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return reshaped;\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'webgpu',\n  kernelFunc: gatherV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterImplCPU as cpuGreater} from '../kernel_utils/shared';\n\nexport const greater = binaryKernelFunc({\n  opType: BinaryOpType.GREATER,\n  cpuKernelImpl: cpuGreater,\n  dtype: 'bool',\n});\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'webgpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {greaterEqualImplCPU as cpuGreaterEqual} from '../kernel_utils/shared';\n\nexport const greaterEqual = binaryKernelFunc({\n  opType: BinaryOpType.GREATER_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuGreaterEqual\n});\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'webgpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {fftImpl} from './FFT_impl';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  return fftImpl(input, true /* inverse */, backend);\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'webgpu',\n  kernelFunc: ifft\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isFinite =\n    unaryKernelFunc({opType: UnaryOpType.IS_FINITE, dtype: 'bool'});\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'webgpu',\n  kernelFunc: isFinite\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isInf =\n    unaryKernelFunc({opType: UnaryOpType.IS_INF, dtype: 'bool'});\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'webgpu',\n  kernelFunc: isInf\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const isNaN =\n    unaryKernelFunc({opType: UnaryOpType.IS_NAN, dtype: 'bool'});\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'webgpu',\n  kernelFunc: isNaN\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: WebGPUBackend,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n  const uniformData = [{type: 'float32', data: [alpha]}];\n  const program =\n      new UnaryOpProgram(x.shape, UnaryOpType.LEAKYRELU, 'alpha : f32,');\n  return backend.runWebGPUProgram(program, [x], 'float32', uniformData);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'webgpu',\n  kernelFunc: leakyRelu as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessImplCPU as cpuLess} from '../kernel_utils/shared';\n\nexport const less = binaryKernelFunc(\n    {opType: BinaryOpType.LESS, dtype: 'bool', cpuKernelImpl: cpuLess});\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'webgpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {lessEqualImplCPU as cpuLessEqual} from '../kernel_utils/shared';\n\nexport const lessEqual = binaryKernelFunc({\n  opType: BinaryOpType.LESS_EQUAL,\n  dtype: 'bool',\n  cpuKernelImpl: cpuLessEqual\n});\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'webgpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class LinSpaceProgram implements WebGPUProgram {\n  variableNames: string[] = [];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'start : f32, step : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(shape: number) {\n    this.outputShape = [shape];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'linSpace';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          setOutputAtIndex(index, uniforms.start + f32(index) * uniforms.step);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LinSpaceProgram} from '../lin_space_webgpu';\n\nexport function linSpace(args: {backend: WebGPUBackend, attrs: LinSpaceAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, num} = attrs;\n  const step = (stop - start) / (num - 1);\n\n  const program = new LinSpaceProgram(num);\n  const uniformData =\n      [{type: 'float32', data: [start]}, {type: 'float32', data: [step]}];\n  return backend.runWebGPUProgram(program, [], 'float32', uniformData);\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'webgpu',\n  kernelFunc: linSpace as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {logImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const log =\n    unaryKernelFunc({opType: UnaryOpType.LOG, cpuKernelImpl: logImplCPU});\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'webgpu',\n  kernelFunc: log\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const log1p = unaryKernelFunc({opType: UnaryOpType.LOG1P});\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'webgpu',\n  kernelFunc: log1p\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const logicalAnd =\n    binaryKernelFunc({opType: BinaryOpType.LOGICAL_AND, dtype: 'bool'});\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'webgpu',\n  kernelFunc: logicalAnd\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const logicalNot = unaryKernelFunc({opType: UnaryOpType.LOGICAL_NOT});\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'webgpu',\n  kernelFunc: logicalNot\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const logicalOr = binaryKernelFunc({opType: BinaryOpType.LOGICAL_OR});\n\nexport const logicalOrConfig: KernelConfig = {\n  kernelName: LogicalOr,\n  backendName: 'webgpu',\n  kernelFunc: logicalOr\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nconst powOperatorSnippet = `\n  var powValue = 0.0;\n  let basis = uniforms.bias + uniforms.alpha * sum;\n  if (uniforms.beta == 0.5) {\n    powValue = inverseSqrt(basis);\n  } else if (uniforms.beta == 1.0) {\n    powValue = 1.0 / basis;\n  } else {\n    powValue = exp(log(basis) * (-uniforms.beta));\n  }\n`;\n\nexport class LRNProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(xShape: number[]) {\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'lrn';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let b = coords[0];\n        let r = coords[1];\n        let c = coords[2];\n        let d = coords[3];\n\n        let x = getX(b, r, c, d);\n        var sum = 0.0;\n        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {\n          let idx = d + i;\n          if (idx >= 0 && idx < uniforms.xShape[3]) {\n            let z = getX(b, r, c, idx);\n            sum = sum + z * z;\n          }\n        }\n        ${powOperatorSnippet}\n\n        setOutputAtIndex(index, x * powValue);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class LRNSharedProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  maxAllowRadius = 16;\n  elementsPerWorkgroup: number;\n\n  constructor(xShape: number[], radius: number) {\n    util.assert(\n        radius <= this.maxAllowRadius,\n        () => `Radius must be less than or equal to ${\n            this.maxAllowRadius}, current radius is ${radius}`);\n\n    this.outputShape = xShape;\n    // The reason why not using this.workgroupSize[0] + 2 * maxAllowRadius here\n    // is to make sure that there is only one time global memory load access for\n    // each thread.\n    this.elementsPerWorkgroup = this.workgroupSize[0] - 2 * this.maxAllowRadius;\n    this.dispatchLayout = {x: [3], y: [2], z: [0, 1]};\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [\n      this.elementsPerWorkgroup, this.workgroupSize[1], this.workgroupSize[2]\n    ]);\n    this.shaderKey = 'lrn_shared';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    var <workgroup>lrnSub: array<f32, ${this.workgroupSize[0]}>;\n    const elementsPerWorkgroup = ${this.elementsPerWorkgroup};\n    const maxAllowRadius = ${this.maxAllowRadius};\n\n    ${main()} {\n      let localDepth = i32(localId.x);\n      let workgroupDepth = i32(workgroupId.x) * elementsPerWorkgroup;\n      let xDepth = workgroupDepth + localDepth - maxAllowRadius;\n      let b = i32(globalId.z) / uniforms.xShape[1];\n      let r = i32(globalId.z) - b * uniforms.xShape[1];\n      let c = i32(globalId.y);\n      let d = workgroupDepth + localDepth;\n\n      var x = 0.0;\n      if (xDepth >= 0 && xDepth < uniforms.xShape[3]) {\n        x = getX(b, r, c, xDepth);\n      }\n      lrnSub[localDepth] = x;\n      workgroupBarrier();\n\n      if (localDepth < elementsPerWorkgroup && d < uniforms.outShape[3]) {\n        var sum = 0.0;\n        let index = localDepth + maxAllowRadius;\n        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {\n          let z = lrnSub[index + i];\n          sum = sum + z * z;\n        }\n        ${powOperatorSnippet}\n\n        setOutputAtCoords(b, r, c, d, lrnSub[index] * powValue);\n      }\n    } `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LRNProgram, LRNSharedProgram} from '../lrn_webgpu';\n\nexport function lrn(\n    args: {inputs: LRNInputs, backend: WebGPUBackend, attrs: LRNAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  // When the adjacent channels is less than or equal to 16, which could cover\n  // most cases, we use shared memory version to get better performance.\n  // The theoretical adjacent channels may be very large, but the shared memory\n  // size of hardware is limited, so we use the naive version when the adjacent\n  // channels is large.\n  let program: LRNProgram|LRNSharedProgram;\n  if (depthRadius > 16) {\n    program = new LRNProgram(x.shape);\n  } else {\n    program = new LRNSharedProgram(x.shape, depthRadius);\n  }\n  const uniformData = [\n    {type: 'int32', data: [depthRadius]}, {type: 'float32', data: [bias]},\n    {type: 'float32', data: [alpha]}, {type: 'float32', data: [beta]}\n  ];\n  const res = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n  return res;\n}\n\nexport const lrnConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'webgpu',\n  kernelFunc: lrn as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class LRNGradProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['inputImage', 'outputImage', 'dy'];\n  uniforms = 'depthRadius : i32, bias : f32, alpha : f32, beta : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(inputShape: number[]) {\n    this.outputShape = inputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'lrn_grad';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let b = coords[0];\n        let r = coords[1];\n        let c = coords[2];\n\n        let MIN_DEPTH_BEGIN = 0;\n        let MAX_DEPTH_END = uniforms.outShape[3];\n        var result = 0.0;\n        for (var d = MIN_DEPTH_BEGIN; d < MAX_DEPTH_END; d++) {\n          let depthBegin = max(MIN_DEPTH_BEGIN, d - uniforms.depthRadius);\n          let depthEnd = min(MAX_DEPTH_END, d + uniforms.depthRadius + 1);\n\n          var norm = 0.0;\n          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {\n            if (k < depthBegin) {\n              continue;\n            } else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            } else {\n              break;\n            }\n          }\n\n          norm = uniforms.alpha * norm + uniforms.bias;\n\n          for (var k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; k++) {\n            if (k < depthBegin) {\n              continue;\n            } else if (k >= depthBegin && k < depthEnd) {\n              var dyi = -2.0 * uniforms.alpha * uniforms.beta\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d) / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * uniforms.beta);\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            } else {\n              break;\n            }\n          }\n        }\n\n        setOutputAtIndex(index, result);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {LRNGradProgram} from '../lrn_grad_webgpu';\n\nexport function lrnGrad(\n    args: {inputs: LRNGradInputs, backend: WebGPUBackend, attrs: LRNGradAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  const program = new LRNGradProgram(x.shape);\n  const uniformData = [\n    {type: 'int32', data: [depthRadius]}, {type: 'float32', data: [bias]},\n    {type: 'float32', data: [alpha]}, {type: 'float32', data: [beta]}\n  ];\n  const res =\n      backend.runWebGPUProgram(program, [x, y, dy], x.dtype, uniformData);\n\n  return res;\n}\n\nexport const lrnGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'webgpu',\n  kernelFunc: lrnGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {maximumImplCPU as cpuMaximum} from '../kernel_utils/shared';\n\nexport const maximum = binaryKernelFunc({\n  opType: BinaryOpType.MAX,\n  cpuKernelImpl: cpuMaximum,\n});\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'webgpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {poolImpl} from './Pool_impl';\n\nexport function maxPool(\n    args: {inputs: MaxPoolInputs, backend: WebGPUBackend, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  return poolImpl(x, convInfo, 'max', backend);\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'webgpu',\n  kernelFunc: maxPool as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function maxPool3d(args: {\n  inputs: MaxPool3DInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dataFormat, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode, dataFormat);\n  const maxPoolProgram = new Pool3DProgram(convInfo, 'max');\n  const dimensions = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  return backend.runWebGPUProgram(maxPoolProgram, [x], x.dtype, dimensions);\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'webgpu',\n  kernelFunc: maxPool3d as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MaxPool2DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'maxPos'];\n  uniforms =\n      `strides : vec2<i32>, pads : vec2<i32>, dilations : vec2<i32>, filterDims : vec2<i32>,\n       outHeight : i32, outWidth : i32`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv2DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'maxPool2DBackprop';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords[0];\n        let d = coords[3];\n\n        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;\n        let dyRCorner = dyRCCorner.x;\n        let dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] - 1;\n        for (var wR = 0; wR < uniforms.filterDims[0]; wR += uniforms.dilations[0]) {\n          let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[0]);\n\n          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n            continue;\n          }\n          let idyR = i32(dyR);\n\n          for (var wC = 0; wC < uniforms.filterDims[1]; wC += uniforms.dilations[1]) {\n            let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[1]);\n\n            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n              continue;\n            }\n            let idyC = i32(dyC);\n\n            let dyValue = getDy(batch, idyR, idyC, d);\n            let maxPosValue = lastIndex - i32(getMaxPos(batch, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            let curPosValue = wR * uniforms.filterDims[1] + wC;\n            let mask = select(0.0, 1.0, maxPosValue == curPosValue);\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n\nexport class MaxPool3DBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy', 'maxPos'];\n  uniforms = `strides : vec3<i32>, pads : vec3<i32>, filterDims : vec3<i32>,\n      outDepth : i32, outHeight : i32, outWidth : i32`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(convInfo: backend_util.Conv3DInfo) {\n    this.outputShape = convInfo.inShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'maxPool3DBackprop';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n        let batch = coords.x;\n        let ch = coords.u;\n\n        let dyCorner = vec3<i32>(coords.y, coords.z, coords.w) - uniforms.pads;\n        let dyDCorner = dyCorner.x;\n        let dyRCorner = dyCorner.y;\n        let dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd = 0.0;\n        let lastIndex = uniforms.filterDims[0] * uniforms.filterDims[1] * uniforms.filterDims[2] - 1;\n\n        for (var wD = 0; wD < uniforms.filterDims[0]; wD++) {\n          let dyD = f32(dyDCorner + wD) / f32(uniforms.strides[0]);\n\n          if (dyD < 0.0 || dyD >= f32(uniforms.outDepth) || fract(dyD) > 0.0) {\n            continue;\n          }\n          let idyD = i32(dyD);\n\n          for (var wR = 0; wR < uniforms.filterDims[1]; wR++) {\n            let dyR = f32(dyRCorner + wR) / f32(uniforms.strides[1]);\n\n            if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {\n              continue;\n            }\n            let idyR = i32(dyR);\n\n            for (var wC = 0; wC < uniforms.filterDims[2]; wC++) {\n              let dyC = f32(dyCCorner + wC) / f32(uniforms.strides[2]);\n\n              if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {\n                continue;\n              }\n              let idyC = i32(dyC);\n\n              let dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              let maxPosValue = lastIndex - i32(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              let curPosValue = wD * uniforms.filterDims[1] * uniforms.filterDims[2] + wR * uniforms.filterDims[2] + wC;\n              let mask = select(0.0, 1.0, maxPosValue == curPosValue);\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n\n        setOutputAtIndex(index, dotProd);\n      }\n    }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MaxPool3DBackpropProgram} from '../max_pool_backprop_webgpu';\nimport {Pool3DProgram} from '../pool_webgpu';\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations: [number, number, number] = [1, 1, 1];\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n\n  const maxPool3dPositionsProgram =\n      new Pool3DProgram(convInfo, 'max', true /* get positions */);\n  let uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data:\n          [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left]\n    },\n    {\n      type: 'int32',\n      data: [convInfo.inDepth, convInfo.inHeight, convInfo.inWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    }\n  ];\n  const maxPool3dPositions = backend.runWebGPUProgram(\n      maxPool3dPositionsProgram, [x], 'int32', uniformData);\n\n  const maxPool3dBackpropProgram = new MaxPool3DBackpropProgram(convInfo);\n  uniformData = [\n    {\n      type: 'int32',\n      data: [convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth - 1 - convInfo.padInfo.front,\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterDepth, convInfo.effectiveFilterHeight,\n        convInfo.effectiveFilterWidth\n      ]\n    },\n    {type: 'int32', data: [convInfo.outDepth]},\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]}\n  ];\n  const result = backend.runWebGPUProgram(\n      maxPool3dBackpropProgram, [dy, maxPool3dPositions], x.dtype, uniformData);\n  backend.disposeData(maxPool3dPositions.dataId);\n\n  return result;\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'webgpu',\n  kernelFunc: maxPool3DGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MaxPool2DBackpropProgram} from '../max_pool_backprop_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\nimport {assertNotComplex} from '../webgpu_util';\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  backend: WebGPUBackend,\n  attrs: MaxPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolGrad');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n\n  const maxPoolPositionsProgram = new Pool2DProgram(convInfo, 'max', true);\n  let uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    }\n  ];\n  const maxPoolPositions = backend.runWebGPUProgram(\n      maxPoolPositionsProgram, [x], 'int32', uniformData);\n\n  const maxPoolBackpropProgram = new MaxPool2DBackpropProgram(convInfo);\n  uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]}, {\n      type: 'int32',\n      data: [\n        convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,\n        convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left\n      ]\n    },\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    },\n    {type: 'int32', data: [convInfo.outHeight]},\n    {type: 'int32', data: [convInfo.outWidth]}\n  ];\n  const result = backend.runWebGPUProgram(\n      maxPoolBackpropProgram, [dy, maxPoolPositions], x.dtype, uniformData);\n  backend.disposeData(maxPoolPositions.dataId);\n\n  return result;\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'webgpu',\n  kernelFunc: maxPoolGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {Pool2DProgram} from '../pool_webgpu';\n\nexport function maxPoolWithArgmax(args: {\n  inputs: MaxPoolWithArgmaxInputs,\n  attrs: MaxPoolWithArgmaxAttrs,\n  backend: WebGPUBackend\n}): TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {filterSize, strides, pad, includeBatchInIndex} = attrs;\n  const {x} = inputs;\n\n  util.assert(\n      x.shape.length === 4,\n      () => `Error in maxPool: input must be rank 4 but got rank ${\n          x.shape.length}.`);\n  const dilations: [number, number] = [1, 1];\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad);\n\n  const uniformData = [\n    {type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth]},\n    {type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left]},\n    {type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth]},\n    {type: 'int32', data: [convInfo.inHeight, convInfo.inWidth]}, {\n      type: 'int32',\n      data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]\n    }\n  ];\n  let program = new Pool2DProgram(convInfo, 'max', false);\n  const poolOutput =\n      backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n  program = new Pool2DProgram(convInfo, 'max', true, true, includeBatchInIndex);\n  const indexOutput =\n      backend.runWebGPUProgram(program, [x], 'int32', uniformData);\n  return [poolOutput, indexOutput];\n}\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'webgpu',\n  kernelFunc: maxPoolWithArgmax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function min(\n    args: {inputs: MinInputs, backend: WebGPUBackend, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'min', backend);\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'webgpu',\n  kernelFunc: min as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {minimumImplCPU as cpuMinimum} from '../kernel_utils/shared';\n\nexport const minimum = binaryKernelFunc({\n  opType: BinaryOpType.MIN,\n  cpuKernelImpl: cpuMinimum,\n});\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'webgpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MirrorPadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  uniforms = '';\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  offset: number;\n  size = true;\n\n  constructor(\n      xShape: number[], paddings: Array<[number, number]>,\n      mode: 'reflect'|'symmetric') {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.xShape = xShape;\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.offset = mode === 'reflect' ? 0 : 1;\n    this.shaderKey = `mirrorPad_${mode}`;\n  }\n\n  getUserCode(): string {\n    const rank = this.xShape.length;\n    // The length of paddings are same with the rank of the input tensor.\n    const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n    const end = this.xShape\n                    .map(\n                        (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                            rank > 1 ? `[${i}]` : ''}`)\n                    .join(',');\n\n    const shaderStart = rank === 1 ? 'start' : 'start[i]';\n    const shaderEnd = rank === 1 ? 'end' : 'end[i]';\n    const shaderOutC = rank === 1 ? 'outC' : 'outC[i]';\n    const dtype = getCoordsDataType(rank);\n    const unpackedCoords = rank > 1 ?\n        ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n        'coords';\n\n    return `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let start = ${dtype}(${start});\n          let end = ${dtype}(${end});\n          var outC = getCoordsFromIndex(index);\n          for (var i = 0; i < ${rank}; i = i + 1) {\n            if (${shaderOutC} < ${shaderStart}) {\n              ${shaderOutC} = ${shaderStart} * 2 - ${shaderOutC} - ${\n        this.offset};\n            } else if(${shaderOutC} >= ${shaderEnd}) {\n              ${shaderOutC} = (${shaderEnd} - 1) * 2 - ${shaderOutC} + ${\n        this.offset};\n            }\n          }\n          let coords = outC - start;\n          setOutputAtIndex(index, getX(${unpackedCoords}));\n        }\n      }\n    `;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, MirrorPad, MirrorPadAttrs, MirrorPadInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {MirrorPadProgram} from '../mirror_pad_webgpu';\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MirrorPadInputs;\n    const {paddings, mode} = attrs as unknown as MirrorPadAttrs;\n    const webGPUBackend = backend as WebGPUBackend;\n\n    const uniformData = paddings.map(p => {\n      return {type: 'int32', data: [p[0], p[1]]};\n    });\n    const program = new MirrorPadProgram(x.shape, paddings, mode);\n    const output =\n        webGPUBackend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n\n    return output;\n  }\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const mod = binaryKernelFunc({opType: BinaryOpType.MOD});\n\nexport const modConfig: KernelConfig = {\n  kernelName: Mod,\n  backendName: 'webgpu',\n  kernelFunc: mod\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class MultinomialProgram implements WebGPUProgram {\n  variableNames: string[] = ['probs'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'seed : f32, numOutcomes: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(batchSize: number, numSamples: number) {\n    this.outputShape = [batchSize, numSamples];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = 'multinomial';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    fn random (seed : f32, resultUV : vec2<f32>) -> f32 {\n      let HASHSCALE1 = 443.8975;\n      let p = resultUV * seed;\n      var p3  = fract(vec3<f32>(p.xyx) * HASHSCALE1);\n      p3 = p3 + dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let coords = getOutputCoords();\n        let batch = coords[0];\n\n        let resUV = vec2<f32>(f32(coords[1]) / f32(uniforms.outShape[1]),\n            f32(coords[0]) / f32(uniforms.outShape[0]));\n        let r = random(uniforms.seed, resUV);\n        var cdf = 0.0;\n        for (var i = 0; i < uniforms.numOutcomes - 1; i = i + 1) {\n          cdf = cdf + getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutputAtIndexI32(index, i);\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutputAtIndexI32(index, uniforms.numOutcomes - 1);\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {flatDispatchLayout} from './webgpu_util';\n\nexport class SoftmaxProgram implements WebGPUProgram {\n  variableNames = ['logits'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n\n  constructor(outputShape: number[]) {\n    this.outputShape = outputShape;  // [rows, cols]\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = [this.outputShape[0], 1, 1];\n    if (this.outputShape[1] >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.shaderKey = 'softmax';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    var<workgroup> buf : array<f32, ${this.workgroupSize[0]}>;\n    var<workgroup> rowMaxShared : f32;\n    var<workgroup> rowSumShared : f32;\n    const blockSize = ${this.workgroupSize[0]};\n    ${main('index')} {\n      let row = index / blockSize;\n      let tid = i32(localId.x);\n      let cols = uniforms.outShape[1];\n\n      var threadMax = -3.402823e+38f;\n      for (var col = tid; col < cols; col += blockSize) {\n        let value = getLogits(row, col);\n        threadMax = max(threadMax, value);\n      }\n      if (tid < cols) {\n        buf[tid] = threadMax;\n      }\n      workgroupBarrier();\n\n      var reduceSize = min(cols, blockSize);\n      for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n        reduceSize = currSize + (reduceSize & 1);\n        if (tid < currSize) {\n          buf[tid] = max(buf[tid], buf[tid + reduceSize]);\n        }\n        workgroupBarrier();\n      }\n\n      if (tid == 0) {\n        rowMaxShared = buf[0];\n      }\n      workgroupBarrier();\n\n      var threadSum = 0.0;\n      for (var col = tid; col < cols; col += blockSize) {\n        let subExp = exp(getLogits(row, col) - rowMaxShared);\n        threadSum += subExp;\n      }\n      buf[tid] = threadSum;\n      workgroupBarrier();\n\n      for (var currSize = blockSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n        if (tid < currSize) {\n          buf[tid] = buf[tid] + buf[tid + currSize];\n        }\n        workgroupBarrier();\n      }\n\n      if (tid == 0) {\n        rowSumShared = buf[0];\n      }\n      workgroupBarrier();\n\n      for (var col = tid; col < cols; col += blockSize) {\n        let value = exp(getLogits(row, col) - rowMaxShared) / rowSumShared;\n        setOutputAtCoords(row, col, value);\n      }\n  }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SoftmaxProgram} from '../softmax_webgpu';\n\nimport {reshape} from './Reshape';\n\nexport function softmax(\n    args: {inputs: SoftmaxInputs, backend: WebGPUBackend, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const logitsReshaped = reshape({\n    inputs: {x: logits},\n    backend,\n    attrs: {\n      shape: [\n        util.sizeFromShape(logits.shape) / logits.shape[dim], logits.shape[dim]\n      ]\n    }\n  });\n  const program = new SoftmaxProgram(logitsReshaped.shape);\n  const res = backend.runWebGPUProgram(program, [logitsReshaped], logits.dtype);\n  const resReshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: logits.shape}});\n  backend.disposeData(logitsReshaped.dataId);\n  backend.disposeData(res.dataId);\n  return resReshaped;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'webgpu',\n  kernelFunc: softmax as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {MultinomialProgram} from '../multinomial_webgpu';\n\nimport {softmax} from './Softmax';\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  backend: WebGPUBackend,\n  attrs: MultinomialAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  const probs = normalized ?\n      logits :\n      softmax(\n          {inputs: {logits}, backend, attrs: {dim: logits.shape.length - 1}});\n  const batchSize = probs.shape[0];\n  const numOutcomes = probs.shape[1];\n  const program = new MultinomialProgram(batchSize, numSamples);\n  const uniformData =\n      [{type: 'float32', data: [seed]}, {type: 'int32', data: [numOutcomes]}];\n  const res = backend.runWebGPUProgram(program, [probs], 'int32', uniformData);\n  if (!normalized) {\n    backend.disposeData(probs.dataId);\n  }\n  return res;\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'webgpu',\n  kernelFunc: multinomial as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Neg, NegInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {negImplCPU} from '../kernel_utils/shared';\n\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\n// This doesn't use unaryKernelFunc because negImplCPU is not of type\n// SimpleUnaryKernelImplCPU.\nexport function neg(args: {inputs: NegInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xData = backend.tensorMap.get(x.dataId);\n    const [outValues, newShape] =\n        negImplCPU(xData.values as TypedArray, x.shape, x.dtype);\n    return backend.makeTensorInfo(newShape, x.dtype, outValues);\n  }\n\n  const program = new UnaryOpProgram(x.shape, UnaryOpType.NEG);\n\n  return backend.runWebGPUProgram(program, [x], x.dtype);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'webgpu',\n  kernelFunc: neg as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TypedArray} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV3Attrs\n}) {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const {selectedIndices} = kernel_impls.nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV3 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nexport type TypedArray = Float32Array|Int32Array|Uint8Array;\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: WebGPUBackend,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  console.warn(\n      'tf.nonMaxSuppression() in webgpu locks the UI thread. ' +\n      'Call tf.nonMaxSuppressionAsync() instead');\n\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  const boxesVals = backend.readSync(boxes.dataId) as TypedArray;\n  const scoresVals = backend.readSync(scores.dataId) as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} =\n      kernel_impls.nonMaxSuppressionV5Impl(\n          boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n          scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'webgpu',\n  kernelFunc: nonMaxSuppressionV5 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class OneHotProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'onValue : f32, offValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(numIndices: number, depth: number) {\n    this.outputShape = [numIndices, depth];\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'onehot';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          setOutputAtIndex(index, mix(uniforms.offValue, uniforms.onValue,\n                                      f32(i32(round(getX(coords.x))) == coords.y)));\n        }\n      }\n    `;\n\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {OneHotProgram} from '../onehot_webgpu';\nimport {reshape} from './Reshape';\n\nexport function oneHot(\n    args: {inputs: OneHotInputs, backend: WebGPUBackend, attrs: OneHotAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {dtype, depth, onValue, offValue} = attrs;\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n  const program = new OneHotProgram(indicesSize, depth);\n  const reshaped =\n      reshape({inputs: {x: indices}, backend, attrs: {shape: [indicesSize]}});\n\n  const uniformData =\n      [{type: 'float32', data: [onValue]}, {type: 'float32', data: [offValue]}];\n  const result =\n      backend.runWebGPUProgram(program, [reshaped], dtype, uniformData);\n  backend.disposeData(reshaped.dataId);\n\n  const outShape = [...indices.shape, depth];\n  const out = reshape({inputs: {x: result}, backend, attrs: {shape: outShape}});\n  backend.disposeData(result.dataId);\n\n  return out;\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'webgpu',\n  kernelFunc: oneHot as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({\n      attrs: {\n        shape: x.shape,\n        dtype: x.dtype,\n        value: x.dtype === 'string' ? '' : 0\n      },\n      backend\n    });\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'webgpu',\n  kernelFunc: zerosLike as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: WebGPUBackend}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported under string dtype');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeData(realPart.dataId);\n    backend.disposeData(r.dataId);\n    backend.disposeData(imagPart.dataId);\n    backend.disposeData(i.dataId);\n\n    return result;\n  } else {\n    return fill({attrs: {shape: x.shape, dtype: x.dtype, value: 1}, backend});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'webgpu',\n  kernelFunc: onesLike as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: WebGPUBackend, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'webgpu',\n  kernelFunc: pack as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport function padCommon(shape: number[], fillZero = false): string {\n  const rank = shape.length;\n  const type = getCoordsDataType(rank);\n  const start = shape.map((_, i) => `uniforms.pad${i}[0]`).join(',');\n  const end = shape\n                  .map(\n                      (_, i) => `uniforms.pad${i}[0] + uniforms.xShape${\n                          rank > 1 ? `[${i}]` : ''}`)\n                  .join(',');\n  const startValue = rank > 1 ? `${type}(${start})` : `${start}`;\n  const endValue = rank > 1 ? `${type}(${end})` : `${end}`;\n\n  const leftPadCondition =\n      rank > 1 ? `any(paddedCoords < start)` : `paddedCoords < start`;\n  const rightPadCondition =\n      rank > 1 ? `any(paddedCoords >= end)` : `paddedCoords >= end`;\n\n  const unpackedCoords = rank > 1 ?\n      ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :\n      'coords';\n  return `\n        let start = ${startValue};\n        let end = ${endValue};\n        if (${leftPadCondition} || ${rightPadCondition}) {\n          setOutputAtIndex(index, ${fillZero ? 0.0 : 'uniforms.constantValue'});\n        } else {\n          let coords = paddedCoords - start;\n          setOutputAtIndex(index, getX(${unpackedCoords}));\n        }\n  `;\n}\n\nexport class PadProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'constantValue : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  xShape: number[];\n  size = true;\n\n  constructor(xShape: number[], paddings: Array<[number, number]>) {\n    this.outputShape = paddings.map(\n        (p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.xShape = xShape;\n    this.shaderKey = 'pad';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let paddedCoords = getCoordsFromIndex(index);\n          ${padCommon(this.xShape)}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {identity} from './Identity';\nimport {PadProgram} from '../pad_webgpu';\nimport {fill} from './Fill';\n\nexport const padV2 =\n    (args: {inputs: PadV2Inputs,\n            backend: WebGPUBackend,\n            attrs: PadV2Attrs}): TensorInfo => {\n      const {inputs, backend, attrs} = args;\n      const {x} = inputs;\n      const {paddings, constantValue} = attrs;\n      if (paddings.every(p => util.arraysEqual(p, [0, 0]))) {\n        return identity({inputs: {x}, backend});\n      }\n      if (util.sizeFromShape(x.shape) === 0) {\n        // Short-circuit the computation, since x doesn't have value, only\n        // the shape is used to compute output shape to pad.\n        const outputShape = paddings.map(\n            (p, i) =>\n                p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n        return fill({\n          backend,\n          attrs: {shape: outputShape, value: constantValue, dtype: x.dtype}\n        });\n      }\n      const uniformData = [{type: 'float32', data: [constantValue]}];\n      paddings.map(p => uniformData.push({type: 'int32', data: [p[0], p[1]]}));\n      const program = new PadProgram(x.shape, paddings);\n      return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n    };\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'webgpu',\n  kernelFunc: padV2 as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const pow = binaryKernelFunc({\n  opType: BinaryOpType.POW,\n});\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'webgpu',\n  kernelFunc: pow\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prelu, PreluInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {BinaryOpProgram} from '../binary_op_webgpu';\n\nexport function prelu(args: {inputs: PreluInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  const program = new BinaryOpProgram(BinaryOpType.PRELU, x.shape, alpha.shape);\n  return backend.runWebGPUProgram(program, [x, alpha], 'float32');\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'webgpu',\n  kernelFunc: prelu as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {reduce} from '../kernel_utils/reduce';\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: WebGPUBackend, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  return reduce(x, axis, keepDims, 'prod', backend);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'webgpu',\n  kernelFunc: prod as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {rangeImplCPU} from '../kernel_utils/shared';\n\nexport const range =\n    (args: {backend: WebGPUBackend, attrs: RangeAttrs}): TensorInfo => {\n      const {backend, attrs} = args;\n      const {start, stop, step, dtype} = attrs;\n      const values = rangeImplCPU(start, stop, step, dtype);\n      return backend.makeTensorInfo([values.length], dtype, values);\n    };\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'webgpu',\n  kernelFunc: range as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const realDiv = binaryKernelFunc({opType: BinaryOpType.DIV});\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'webgpu',\n  kernelFunc: realDiv as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const reciprocal = unaryKernelFunc({opType: UnaryOpType.RECIPROCAL});\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'webgpu',\n  kernelFunc: reciprocal\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu = unaryKernelFunc({opType: UnaryOpType.RELU});\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'webgpu',\n  kernelFunc: relu\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const relu6 = unaryKernelFunc({opType: UnaryOpType.RELU6});\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'webgpu',\n  kernelFunc: relu6\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeBilinearProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, halfPixelCenters : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.shaderKey = `resizeBilinear`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n        let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC =\n            (vec2<f32>(rc) + vec2<f32>(uniforms.halfPixelCenters)) *\n            effectiveInputOverOutputRatioRC - vec2<f32>(uniforms.halfPixelCenters);\n\n          // Compute the four integer indices.\n          let sourceFloorRC = vec2<i32>(sourceFracIndexRC);\n          let sourceCeilRC = vec2<i32>(\n            min(vec2<f32>(uniforms.xShape.yz) - vec2<f32>(1.0), ceil(sourceFracIndexRC)));\n\n          let topLeft = getX(b, sourceFloorRC.x, sourceFloorRC.y, d);\n          let bottomLeft = getX(b, sourceCeilRC.x, sourceFloorRC.y, d);\n          let topRight = getX(b, sourceFloorRC.x, sourceCeilRC.y, d);\n          let bottomRight = getX(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n          let fracRC = sourceFracIndexRC - vec2<f32>(sourceFloorRC);\n\n          let top = topLeft + (topRight - topLeft) * fracRC.y;\n          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n          let newValue = top + (bottom - top) * fracRC.x;\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeBilinearProgram} from '../resize_bilinear_webgpu';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, size, halfPixelCenters} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  const halfPixelCentersValue = halfPixelCenters ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [halfPixelCentersValue]}\n  ];\n\n  const program = new ResizeBilinearProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth);\n\n  return backend.runWebGPUProgram(program, [images], 'float32', uniformData);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'webgpu',\n  kernelFunc: resizeBilinear as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeBilinearBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, heightScale : f32, widthScale : f32,\n       invHeightScale : f32, invWidthScale : f32, winHeight : i32, winWidth : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  alignCorners: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], alignCorners: boolean) {\n    this.outputShape = inputShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.alignCorners = alignCorners;\n    this.shaderKey = `resizeBilinearBackprop_${alignCorners}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let b = coords[0];\n          let d = coords[3];\n          let r = coords[1];\n          let c = coords[2];\n\n          var accumulator = 0.0;\n\n          // Compute bounds for where in dy we will look\n          let startRLerp = floor(f32(r) * uniforms.invHeightScale);\n          let startDyR = i32(startRLerp - f32(uniforms.winHeight / 2));\n\n          let startCLerp = floor(f32(c) * uniforms.invWidthScale);\n          let startDyC = i32(startCLerp - f32(uniforms.winWidth / 2));\n\n          // Loop over dy\n          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {\n            let dyR = startDyR + dyROffset;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {\n              continue;\n            }\n\n            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {\n              let dyC = startDyC + dyCOffset;\n\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {\n                continue;\n              }\n\n              let dxR = f32(dyR) * uniforms.heightScale;\n              let topDxRIndex = i32(floor(dxR));\n              let bottomDxRIndex = i32(min(ceil(dxR), f32(uniforms.outShape[1] - 1)));\n              let dxRLerp = dxR - f32(topDxRIndex);\n              let inverseDxRLerp = 1.0 - dxRLerp;\n\n              let dxC = f32(dyC) * uniforms.widthScale;\n              let leftDxCIndex = i32(floor(dxC));\n              let rightDxCIndex = i32(min(ceil(dxC), f32(uniforms.outShape[2] - 1)));\n              let dxCLerp = dxC - f32(leftDxCIndex);\n              let inverseDxCLerp = 1.0 - dxCLerp;\n\n              if (r == topDxRIndex && c == leftDxCIndex) {\n                // topLeft\n                accumulator +=\n                  getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n              }\n\n              if (r == topDxRIndex && c == rightDxCIndex) {\n                // topRight\n                accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n              }\n\n              if (r == bottomDxRIndex && c == leftDxCIndex) {\n                // bottomLeft\n                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n              }\n\n              if (r == bottomDxRIndex && c == rightDxCIndex) {\n                // bottomRight\n                accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n              }\n            }\n          }\n          // End loop over dy\n\n          setOutputAtIndex(index, accumulator);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeBilinearBackpropProgram} from '../resize_bilinear_backprop_webgpu';\n\nexport function resizeBilinearGrad(args: {\n  inputs: ResizeBilinearGradInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeBilinearGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const [, xHeight, xWidth, ] =\n      images.shape as [number, number, number, number];\n  const [, yHeight, yWidth] = dy.shape as [number, number, number, number];\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  const program = new ResizeBilinearBackpropProgram(\n      images.shape as [number, number, number, number], alignCorners);\n  const uniformData = [\n    {type: 'int32', data: effectiveXSize},\n    {type: 'int32', data: effectiveYSize},\n    {type: 'float32', data: [heightScale]},\n    {type: 'float32', data: [widthScale]},\n    {type: 'float32', data: [invHeightScale]},\n    {type: 'float32', data: [invWidthScale]},\n    {type: 'int32', data: [winHeight]}, {type: 'int32', data: [winWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], dy.dtype, uniformData);\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'webgpu',\n  kernelFunc: resizeBilinearGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeNearestNeighborProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'adjustHeightWidth : vec2<f32>, roundBase : f32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  halfPixelCenters: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], newHeight: number,\n      newWidth: number, halfPixelCenters: boolean) {\n    this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.halfPixelCenters = halfPixelCenters;\n    this.shaderKey = `resizeNearest_${halfPixelCenters}`;\n  }\n\n  getUserCode(): string {\n    let sourceFracIndexRC: string;\n    if (this.halfPixelCenters) {\n      sourceFracIndexRC =\n          `max((vec2<f32>(rc) + vec2<f32>(0.5)) * effectiveInputOverOutputRatioRC` +\n          `, vec2<f32>(0.0))`;\n    } else {\n      sourceFracIndexRC = `vec2<f32>(rc) * effectiveInputOverOutputRatioRC`;\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let b = coords[0];\n          let d = coords[3];\n          let rc = coords.yz;\n\n          let effectiveInSize = vec2<f32>(\n            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveOutSize = vec2<f32>(\n            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],\n            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);\n\n          let effectiveInputOverOutputRatioRC =\n              effectiveInSize / effectiveOutSize;\n\n          // Fractional source index\n          let sourceFracIndexRC = ${sourceFracIndexRC};\n\n          // Compute the coordinators of nearest neighbor point.\n          let inputShapeRC = vec2<f32>(f32(uniforms.xShape.y), f32(uniforms.xShape.z));\n          let sourceNearestRC = vec2<i32>(\n            min(inputShapeRC - 1.0, floor(sourceFracIndexRC + uniforms.roundBase)));\n          let newValue = getX(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n          setOutputAtIndex(index, newValue);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeNearestNeighborProgram} from '../resize_nearest_neighbor_webgpu';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  const [newHeight, newWidth] = size;\n  const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;\n  const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;\n  // When align corners is false, we rounds the value with floor.\n  const roundBase = alignCorners ? 0.5 : 0.0;\n  const uniformData = [\n    {type: 'float32', data: [adjustHeight, adjustWidth]},\n    {type: 'float32', data: [roundBase]}\n  ];\n\n  const program = new ResizeNearestNeighborProgram(\n      images.shape as [number, number, number, number], newHeight, newWidth,\n      halfPixelCenters);\n  return backend.runWebGPUProgram(program, [images], images.dtype, uniformData);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'webgpu',\n  kernelFunc: resizeNearestNeighbor as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ResizeNearestNeigborBackpropProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['dy'];\n  uniforms =\n      `effectiveXSize : vec2<i32>, effectiveYSize : vec2<i32>, invHeightScale : f32, invWidthScale : f32,\n       winHeight : i32, winWidth : i32,`;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  alignCorners: boolean;\n  size = true;\n\n  constructor(\n      inputShape: [number, number, number, number], alignCorners: boolean) {\n    this.outputShape = inputShape;\n\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.alignCorners = alignCorners;\n    this.shaderKey = `resizeNearestNeigborBackprop_${alignCorners}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getOutputCoords();\n          let b = coords[0];\n          let d = coords[3];\n          let r = coords[1];\n          let c = coords[2];\n\n          var accumulator = 0.0;\n\n          // Compute bounds for where in dy we will look\n          let startRLerp = floor(f32(r) * uniforms.invHeightScale);\n          let startDyR = i32(floor(startRLerp - f32(uniforms.winHeight / 2)));\n\n          let startCLerp = floor(f32(c) * uniforms.invWidthScale);\n          let startDyC = i32(floor(startCLerp - f32(uniforms.winWidth / 2)));\n\n          // Loop over dy\n          for (var dyROffset = 0; dyROffset < uniforms.winHeight; dyROffset++) {\n            let dyR = startDyR + dyROffset;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= uniforms.dyShape[1]) {\n              continue;\n            }\n\n            for (var dyCOffset = 0; dyCOffset < uniforms.winWidth; dyCOffset++) {\n              let dyC = startDyC + dyCOffset;\n\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= uniforms.dyShape[2]) {\n                continue;\n              }\n\n              let sourceFracRow = f32(uniforms.effectiveXSize[0]) *\n                  (f32(dyR) / f32(uniforms.effectiveYSize[0]));\n\n              let sourceFracCol = f32(uniforms.effectiveXSize[1]) *\n                  (f32(dyC) / f32(uniforms.effectiveYSize[1]));\n\n              let sourceNearestRow =\n                  i32(min(f32(uniforms.outShape[1] - 1),\n                  ${\n        this.alignCorners ? 'floor(sourceFracRow + 0.5)' :\n                            'floor(sourceFracRow)'}));\n\n              let sourceNearestCol =\n                  i32(min(f32(uniforms.outShape[2] - 1),\n                  ${\n        this.alignCorners ? 'floor(sourceFracCol + 0.5)' :\n                            'floor(sourceFracCol)'}));\n\n              if (r == sourceNearestRow && c == sourceNearestCol) {\n                accumulator += getDy(b, dyR, dyC, d);\n              }\n            }\n          }\n          // End loop over dy\n\n          setOutputAtIndex(index, accumulator);\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ResizeNearestNeigborBackpropProgram} from '../resize_nearest_neighbor_backprop_webgpu';\n\nexport function resizeNearestNeighborGrad(args: {\n  inputs: ResizeNearestNeighborGradInputs,\n  backend: WebGPUBackend,\n  attrs: ResizeNearestNeighborGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  const [, xHeight, xWidth] = images.shape as [number, number, number, number];\n  const [, yHeight, yWidth] = dy.shape as [number, number, number, number];\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  const program = new ResizeNearestNeigborBackpropProgram(\n      images.shape as [number, number, number, number], alignCorners);\n  const uniformData = [\n    {type: 'int32', data: effectiveXSize},\n    {type: 'int32', data: effectiveYSize},\n    {type: 'float32', data: [invHeightScale]},\n    {type: 'float32', data: [invWidthScale]},\n    {type: 'int32', data: [winHeight]}, {type: 'int32', data: [winWidth]}\n  ];\n  return backend.runWebGPUProgram(program, [dy], dy.dtype, uniformData);\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'webgpu',\n  kernelFunc: resizeNearestNeighborGrad as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReverseProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(xShape: [number, number, number, number]) {\n    this.outputShape = xShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = ` axis : vec4<i32>,`;\n    this.shaderKey = 'reverse';\n  }\n\n  getUserCode(): string {\n    const reverseCoordsSnippet = `\n      // Using uniform variables as judging conditions, so the function has\n      // coherent execution within all threads.\n      fn getReverseCoords(coords : vec4<i32>) -> vec4<i32> {\n        var reverseCoords = coords;\n        if (uniforms.axis[0] == 1) {\n          reverseCoords[0] = uniforms.xShape[0] - coords[0] - 1;\n        }\n        if (uniforms.axis[1] == 1) {\n          reverseCoords[1] = uniforms.xShape[1] - coords[1] - 1;\n        }\n        if (uniforms.axis[2] == 1) {\n          reverseCoords[2] = uniforms.xShape[2] - coords[2] - 1;\n        }\n        if (uniforms.axis[3] == 1) {\n          reverseCoords[3] = uniforms.xShape[3] - coords[3] - 1;\n        }\n\n        return reverseCoords;\n      }\n    `;\n    const userCode = `\n      ${reverseCoordsSnippet}\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let reverseCoords = getReverseCoords(coords);\n          setOutputAtIndex(index, getX(reverseCoords[0],\n              reverseCoords[1], reverseCoords[2], reverseCoords[3]));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ReverseProgram} from '../reverse_webgpu';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\nexport function reverse(\n    args: {inputs: ReverseInputs, backend: WebGPUBackend, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  const xRank = x.shape.length;\n  if (xRank === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const xShape = x.shape;\n  const xShape4D: [number, number, number, number] = [1, 1, 1, 1];\n  xShape.forEach((d, i) => {\n    const index = i + 4 - xRank;\n    xShape4D[index] = d;\n  });\n\n  const axes = util.parseAxisParam(dims, x.shape);\n  const dims4D: [number, number, number, number] = [0, 0, 0, 0];\n  axes.forEach(ax => {\n    const index = ax + 4 - xRank;\n    dims4D[index] = 1;\n  });\n  const uniformData = [{type: 'int32', data: dims4D}];\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: xShape4D}});\n\n  const program = new ReverseProgram(xShape4D);\n  const values = backend.runWebGPUProgram(\n      program, [xReshaped], xReshaped.dtype, uniformData);\n  backend.disposeData(xReshaped.dataId);\n\n  const result =\n      reshape({inputs: {x: values}, backend, attrs: {shape: xShape}});\n  backend.disposeData(values.dataId);\n\n  return result;\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'webgpu',\n  kernelFunc: reverse as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class RotateProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  fillSnippet: string;\n  size = true;\n\n  constructor(\n      imageShape: [number, number, number, number],\n      fillValue: number|[number, number, number]) {\n    this.outputShape = imageShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = `centerX : f32, centerY : f32, sinRadians : f32,\n          cosRadians : f32,`;\n    this.shaderKey = 'rotate';\n    this.outputShape = imageShape;\n\n    if (typeof fillValue === 'number') {\n      this.uniforms += ` fillValue : f32,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue;`;\n      this.shaderKey += '_float';\n    } else {\n      this.uniforms += ` fillValue : vec3<f32>,`;\n      this.fillSnippet = `var outputValue = uniforms.fillValue[coords[3]];`;\n      this.shaderKey += '_vec3';\n    }\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let coords = getCoordsFromIndex(index);\n            let coordXFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.cosRadians - (f32(coords[1]) - uniforms.centerY) *\n                uniforms.sinRadians;\n            let coordYFloat = (f32(coords[2]) - uniforms.centerX) *\n                uniforms.sinRadians + (f32(coords[1]) - uniforms.centerY) *\n                uniforms.cosRadians;\n            let coordX = i32(round(coordXFloat + uniforms.centerX));\n            let coordY = i32(round(coordYFloat + uniforms.centerY));\n            ${this.fillSnippet}\n            if(coordX >= 0 && coordX < uniforms.xShape[2] && coordY >= 0 &&\n                coordY < uniforms.xShape[1]) {\n              outputValue = getX(coords[0], coordY, coordX, coords[3]);\n            }\n            setOutputAtIndex(index, outputValue);\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Tensor4D} from '@tensorflow/tfjs-core';\nimport {RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {RotateProgram} from '../rotate_webgpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n    kernelName: RotateWithOffset,\n    backendName: 'webgpu',\n    kernelFunc: ({inputs, attrs, backend}) => {\n      const {image} = inputs as RotateWithOffsetInputs;\n      const {radians, fillValue, center} =\n          attrs as unknown as RotateWithOffsetAttrs;\n      const webgpuBackend = backend as WebGPUBackend;\n\n      const program = new RotateProgram((image as Tensor4D).shape, fillValue);\n      const [centerX, centerY] =\n          backend_util.getImageCenter(center, image.shape[1], image.shape[2]);\n      const uniformData = [\n            {type: 'float32', data: [centerX]},\n            {type: 'float32', data: [centerY]},\n            {type: 'float32', data: [Math.sin(radians)]},\n            {type: 'float32', data: [Math.cos(radians)]}\n          ];\n\n      if (typeof fillValue === 'number') {\n        uniformData.push(\n            {type: 'float32', data: [Number.parseFloat(fillValue.toFixed(2))]});\n      } else {\n        uniformData.push({type: 'float32', data: fillValue});\n      }\n\n      const output = webgpuBackend.runWebGPUProgram(\n          program, [image], image.dtype, uniformData);\n      return output;\n   }\n };\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const round = unaryKernelFunc({opType: UnaryOpType.ROUND});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'webgpu',\n  kernelFunc: round\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {rsqrtImplCPU} from '../kernel_utils/shared';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const rsqrt =\n    unaryKernelFunc({opType: UnaryOpType.RSQRT, cpuKernelImpl: rsqrtImplCPU});\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'webgpu',\n  kernelFunc: rsqrt\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {dataTypeToGPUType, getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ScatterProgram implements WebGPUProgram {\n  variableNames = ['updates', 'indices'];\n  uniforms: string;\n  outputShape: number[];\n  sumDupeIndices: boolean;\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  updatesRank: number;\n  indicesRank: number;\n  sliceDimGreaterThanOne: boolean;\n  atomic = true;\n  type: DataType;\n\n  constructor(\n      flattenXShape: number[], sliceDim: number, indicesRank: number,\n      updatesRank: number, strides: number[], shape: number[],\n      outputDtype: DataType, sumDupeIndices = true) {\n    this.outputShape = shape;\n    this.type = outputDtype;\n    this.sumDupeIndices = sumDupeIndices;\n    this.dispatchLayout = flatDispatchLayout(flattenXShape);\n    // Dispatching based on |updates| shape instead of output shape.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, flattenXShape, this.workgroupSize);\n    this.sliceDimGreaterThanOne = sliceDim > 1;\n    this.shaderKey = `scatter_${indicesRank}_${updatesRank}_${\n        this.sliceDimGreaterThanOne}_${outputDtype}_${sumDupeIndices}`;\n    const stridesType = getCoordsDataType(strides.length);\n    this.uniforms =\n        `sliceDim : i32, strides: ${stridesType}, updatesSize: i32,`;\n    this.updatesRank = updatesRank;\n    this.indicesRank = indicesRank;\n  }\n\n  getUserCode(): string {\n    let indicesString = '';\n    if (this.indicesRank === 1) {\n      indicesString = 'coords[0]';\n    } else if (this.indicesRank === 2) {\n      indicesString = 'coords[0], j';\n    }\n    const indicesSnippet = `getIndices(${indicesString})`;\n\n    const strideString = this.sliceDimGreaterThanOne ? 'uniforms.strides[j]' :\n                                                       'uniforms.strides';\n\n    let outCoordsString = '';\n    let getUpdatesCoordsFromFlatIndex = '';\n    if (this.dispatchLayout.x.length === 1) {\n      outCoordsString = 'flattenedIndex';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> i32 {\n        return index;\n      }\n      `;\n    } else if (this.dispatchLayout.x.length === 2) {\n      outCoordsString = 'vec2<i32>(flattenedIndex, coords[1])';\n      getUpdatesCoordsFromFlatIndex = `\n      fn getUpdatesCoordsFromFlatIndex(index : i32) -> vec2<i32> {\n        // N.B. |updates| could be a scalar tensor, conceptually representing a\n        // 2D tensor with all values equal to that. By design, its size must be\n        // the same as |outShape[1]| in one dimension, and |indicesShape[0]|\n        // gives the other.\n        let sliceSize = uniforms.outShape[1];\n        let d0 = index / sliceSize;\n        let d1 = index - d0 * sliceSize;\n        return vec2<i32>(d0, d1);\n      }\n      `;\n    }\n    const updatesString =\n        Array.from({length: this.updatesRank}, (_, idx) => `coords[${idx}]`);\n    const updatesSnippet = `getUpdates(${updatesString.join(', ')})`;\n\n    const userCode = `\n    ${getUpdatesCoordsFromFlatIndex}\n      ${main('index')} {\n        if (index < uniforms.updatesSize) {\n          let coords = getUpdatesCoordsFromFlatIndex(index);\n          var flattenedIndex = 0;\n          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {\n            let indexInside = i32(round(${indicesSnippet}));\n            flattenedIndex = flattenedIndex + indexInside * ${strideString};\n          }\n          let updateValue =\n              ${dataTypeToGPUType(this.type)}(${updatesSnippet});\n          let flatIndex = getOutputIndexFromCoords(${outCoordsString});\n\n          ${\n        this.sumDupeIndices ?\n            atomicAddSnippet(\n                '&result[flatIndex]', 'updateValue',\n                this.type as 'float32' | 'int32') :\n            `atomicStore(&result[flatIndex], bitcast<i32>(updateValue));`}\n        }\n      }`;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: WebGPUBackend,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  if (outputSize === 0) {\n    return backend.makeTensorInfo(shape, indices.dtype);\n  }\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numUpdates, sliceRank]}});\n  const flattenX = reshape(\n      {inputs: {x: updates}, backend, attrs: {shape: [numUpdates, sliceSize]}});\n\n  const type = flattenX.dtype;\n  const output =\n      fill({backend, attrs: {shape: flattenShape, value: 0, dtype: type}});\n  const size = util.sizeFromShape(flattenX.shape);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]}, {type: 'int32', data: strides},\n    {type: 'int32', data: [size]}\n  ];\n  const program = new ScatterProgram(\n      flattenX.shape, sliceRank, flattenIndices.shape.length,\n      flattenX.shape.length, strides, flattenShape, type);\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], type, uniformData, output);\n\n  const reshaped = reshape({inputs: {x: res}, backend, attrs: {shape}});\n\n  backend.disposeData(flattenIndices.dataId);\n  backend.disposeData(flattenX.dataId);\n  backend.disposeData(res.dataId);\n\n  return reshaped;\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'webgpu',\n  kernelFunc: scatterNd as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SearchSortedProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['sortedSequence', 'values'];\n  uniforms = 'numInputs : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  side: string;\n\n  constructor(outputShape: [number, number], side: 'left'|'right') {\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.side = side;\n    this.shaderKey = `search_sorted_${side}`;\n  }\n\n  getUserCode(): string {\n    const boundComparator = this.side === 'left' ? '<' : '<=';\n    const userCode = `\n      fn findBound(batch: i32, value: f32) -> i32 {\n        var left = i32(0);\n        var right = uniforms.numInputs;\n        while (left < right) {\n          var mid = (left + right) / 2;\n          if (getSortedSequence(batch, mid) ${boundComparator} value) {\n            left = mid + 1;\n          } else {\n            right = mid;\n          }\n        }\n        return right;\n      }\n\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let value = getValuesByOutputIndex(index);\n          setOutputAtIndexI32(index, findBound(coords[0], value));\n        }\n      }\n    `;\n\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SearchSorted, SearchSortedAttrs, SearchSortedInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SearchSortedProgram} from '../search_sorted_webgpu';\n\nexport function searchSorted(args: {\n  inputs: SearchSortedInputs,\n  backend: WebGPUBackend,\n  attrs: SearchSortedAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sortedSequence, values} = inputs;\n  const {side} = attrs;\n\n  const program =\n      new SearchSortedProgram([values.shape[0], values.shape[1]], side);\n  const uniformData = [{type: 'int32', data: [sortedSequence.shape[1]]}];\n  return backend.runWebGPUProgram(\n      program, [sortedSequence, values], 'int32', uniformData);\n}\n\nexport const searchSortedConfig: KernelConfig = {\n  kernelName: SearchSorted,\n  backendName: 'webgpu',\n  kernelFunc: searchSorted as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SelectProgram implements WebGPUProgram {\n  variableNames = ['c', 'a', 'b'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  cRank: number;\n  rank: number;\n  size = true;\n\n  constructor(cRank: number, shape: number[], rank: number) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n\n    this.cRank = cRank;\n    this.rank = rank;\n    this.shaderKey = 'select';\n  }\n\n  getUserCode(): string {\n    // TODO(WGSL): below code can be merged with getUserCode.\n    let cCoords;\n    let abCoords;\n    if (this.rank > 4) {\n      throw Error(`Where for rank ${this.rank} is not yet supported`);\n    }\n\n    if (this.rank === 1) {\n      abCoords = `resRC`;\n      cCoords = `resRC`;\n    } else {\n      const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n      const cCoordVars = [];\n      const abCoordVars = [];\n      for (let i = 0; i < this.outputShape.length; i++) {\n        abCoordVars.push(`${currentCoords[i]}`);\n        if (i < this.cRank) {\n          cCoordVars.push(`${currentCoords[i]}`);\n        }\n      }\n      cCoords = cCoordVars.join();\n      abCoords = abCoordVars.join();\n    }\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          let cVal = getC(${cCoords});\n          if (cVal >= 1.0) {\n            setOutputAtIndex(index, getA(${abCoords}));\n          } else {\n            setOutputAtIndex(index, getB(${abCoords}));\n          }\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, upcastType} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SelectProgram} from '../select_webgpu';\n\nexport function select(args: {inputs: SelectInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  const program =\n      new SelectProgram(condition.shape.length, t.shape, t.shape.length);\n  return backend.runWebGPUProgram(\n      program, [condition, t, e], upcastType(t.dtype, e.dtype));\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'webgpu',\n  kernelFunc: select as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const selu = unaryKernelFunc({opType: UnaryOpType.SELU});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'webgpu',\n  kernelFunc: selu\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sigmoid = unaryKernelFunc({opType: UnaryOpType.SIGMOID});\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'webgpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sign = unaryKernelFunc({opType: UnaryOpType.SIGN});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'webgpu',\n  kernelFunc: sign\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sin = unaryKernelFunc({opType: UnaryOpType.SIN});\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'webgpu',\n  kernelFunc: sin\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sinh = unaryKernelFunc({opType: UnaryOpType.SINH});\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'webgpu',\n  kernelFunc: sinh\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const softplus = unaryKernelFunc({opType: UnaryOpType.SOFTPLUS});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'webgpu',\n  kernelFunc: softplus\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {padCommon} from './pad_webgpu';\nimport {getSwitchedCoords} from './transpose_webgpu';\nimport {getCoordsDataType, getCoordsFromIndexSnippet, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SpaceToBatchNDProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = '';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  newDim: number[];\n  xShape: number[];\n  paddedXShape: number[];\n  size = true;\n\n  constructor(\n      xShape: number[], paddedXShape: number[],\n      paddings: Array<[number, number]>, reshapedPaddedXShape: number[],\n      newDim: number[], paddedXShapeStridesShapeLength: number) {\n    const outputShape: number[] = new Array(reshapedPaddedXShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = reshapedPaddedXShape[newDim[i]];\n    }\n    this.outputShape = outputShape;\n    this.newDim = newDim;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.xShape = xShape;\n    this.paddedXShape = paddedXShape;\n    this.uniforms += `reshapedPaddedXShape : ${\n        getCoordsDataType(\n            reshapedPaddedXShape.length)}, paddedXShapeStrides : ${\n        getCoordsDataType(paddedXShapeStridesShapeLength)}, `;\n    paddings.map((_, i) => {\n      this.uniforms += ` pad${i} : vec2<i32>,`;\n    });\n    this.shaderKey = `spaceToBatchND_${newDim}`;\n  }\n\n  getUserCode(): string {\n    const dtype = getCoordsDataType(this.outputShape.length);\n    const switched = getSwitchedCoords(this.newDim);\n\n    const userCode = `\n      ${getCoordsFromIndexSnippet(this.paddedXShape, 'PaddedX')}\n      ${main('index')} {\n        if(index < uniforms.size) {\n          let coords = getCoordsFromIndex(index);\n          let switchedIndex = getIndexFromCoords${this.outputShape.length}D(${\n        dtype}(${switched}), uniforms.reshapedPaddedXShape);\n          let paddedCoords = getPaddedXCoordsFromIndex(switchedIndex);\n          ${padCommon(this.xShape, true)}\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {SpaceToBatchNDProgram} from '../space_to_batchND_webgpu';\n\nimport {reshape} from './Reshape';\n\nexport const spaceToBatchND = (args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: WebGPUBackend,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo => {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  util.assert(\n      x.shape.length <= 4,\n      () => 'spaceToBatchND for rank > 4 with a WebGPU backend not ' +\n          'implemented yet');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...paddings as Array<[number, number]>);\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedXShape = completePaddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedXShape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedXShape, blockShape, prod, false);\n\n  const paddedXShapeStrides = util.computeStrides(paddedXShape);\n  const program = new SpaceToBatchNDProgram(\n      x.shape, paddedXShape, completePaddings, reshapedPaddedShape,\n      permutedReshapedPaddedPermutation, paddedXShapeStrides.length);\n  const uniformData = [\n    {type: 'int32', data: reshapedPaddedShape},\n    {type: 'int32', data: paddedXShapeStrides}\n  ];\n  completePaddings.map(\n      p => uniformData.push({type: 'int32', data: [p[0], p[1]]}));\n  const paddedXT = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n  const result =\n      reshape({inputs: {x: paddedXT}, backend, attrs: {shape: flattenShape}});\n  backend.disposeData(paddedXT.dataId);\n  return result;\n};\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'webgpu',\n  kernelFunc: spaceToBatchND as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class SparseSegmentSumProgram implements WebGPUProgram {\n  variableNames = ['input', 'indices', 'segmentIds'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'segmentSize : i32, sparseSize : i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(outShape: number[], sparseSize: number, outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.type = outputDtype;\n    this.dispatchLayout = flatDispatchLayout([sparseSize]);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, [sparseSize], this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentSum';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.sparseSize) {\n        let indexInSegmentIds = index / uniforms.segmentSize;\n        let indexInSegment = index % uniforms.segmentSize;\n        let indexInInput = indices[indexInSegmentIds];\n        let segmentId = segmentIds[indexInSegmentIds];\n\n        let value = input[indexInInput * uniforms.segmentSize + indexInSegment];\n        let outIndex = segmentId * uniforms.segmentSize + indexInSegment;\n        ${\n        atomicAddSnippet(\n            '&result[outIndex]', 'value', this.type as 'float32' | 'int32')}\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class SparseSegmentIdCountProgram implements WebGPUProgram {\n  variableNames = ['segmentIds'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n\n  constructor(outShape: number, segmentIdsShape: number[]) {\n    this.outputShape = [outShape];\n    this.dispatchLayout = flatDispatchLayout(segmentIdsShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, segmentIdsShape, this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentIdCountProgram';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.segmentIdsShape) {\n        let segmentId = segmentIds[index];\n        ${atomicAddSnippet('&result[segmentId]', '1', 'int32')}\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n\nexport class SparseSegmentMeanProgram implements WebGPUProgram {\n  variableNames = ['segmentSum', 'sameSegmentIdCount'];\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  uniforms = 'segmentSize : i32';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  type: DataType;\n\n  constructor(outShape: number[], outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.type = outputDtype;\n    this.dispatchLayout = flatDispatchLayout(outShape);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, outShape, this.workgroupSize);\n\n    this.shaderKey = 'sparseSegmentMean';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.size) {\n        let segmentId = index / uniforms.segmentSize;\n        let count = sameSegmentIdCount[segmentId];\n        if (count != 0) {\n          ${\n        this.type === 'float32' ?\n            'setOutputAtIndex(index, segmentSum[index] / f32(count));' :\n            'setOutputAtIndexI32(index, segmentSum[index] / count);'}\n        }\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {fill} from '../kernels/Fill';\nimport {SparseSegmentIdCountProgram, SparseSegmentMeanProgram, SparseSegmentSumProgram} from '../sparse_segment_reduce_webgpu';\nimport {WebGPUProgram} from '../webgpu_program';\n\nexport function sparseSegmentReduce(\n    input: TensorInfo, indices: TensorInfo, segmentIds: TensorInfo,\n    isSum = false, backend: WebGPUBackend): TensorInfo {\n  const inputSize = util.sizeFromShape(input.shape);\n  const segmentSize = inputSize / input.shape[0];\n  const dtype = input.dtype;\n\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const numIndices = util.sizeFromShape(indices.shape);\n  const $segmentIds = backend.readSync(segmentIds.dataId) as TypedArray;\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? $segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  let program: WebGPUProgram;\n  const outputShape = input.shape.slice();\n  outputShape[0] = outputRows;\n\n  const sparseSize = numIndices * segmentSize;\n  const sparseSegmentSum =\n      fill({backend, attrs: {shape: outputShape, value: 0, dtype}});\n  program = new SparseSegmentSumProgram(outputShape, sparseSize, dtype);\n  let uniformData = [\n    {type: 'int32', data: [segmentSize]}, {type: 'int32', data: [sparseSize]}\n  ];\n  const $sparseSegmentSum = backend.runWebGPUProgram(\n      program, [input, indices, segmentIds], dtype, uniformData,\n      sparseSegmentSum);\n\n  if (isSum) {\n    return $sparseSegmentSum;\n  }\n\n  const sparseSegmentIdCount =\n      fill({backend, attrs: {shape: [outputRows], value: 0, dtype: 'int32'}});\n  program = new SparseSegmentIdCountProgram(outputRows, segmentIds.shape);\n  const $sparseSegmentIdCount = backend.runWebGPUProgram(\n      program, [segmentIds], 'int32', null, sparseSegmentIdCount);\n\n  const sparseSegmentMean =\n      fill({backend, attrs: {shape: outputShape, value: 0, dtype}});\n  program = new SparseSegmentMeanProgram(outputShape, dtype);\n  uniformData = [{type: 'int32', data: [segmentSize]}];\n  const $sparseSegmentMean = backend.runWebGPUProgram(\n      program, [$sparseSegmentSum, $sparseSegmentIdCount], dtype, uniformData,\n      sparseSegmentMean);\n\n  backend.disposeData($sparseSegmentSum.dataId);\n  backend.disposeData($sparseSegmentIdCount.dataId);\n  return $sparseSegmentMean;\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentMean, SparseSegmentMeanInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sparseSegmentReduce} from '../kernel_utils/sparse_segment_reduce';\n\nexport function sparseSegmentMean(\n    args: {inputs: SparseSegmentMeanInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n\n  return sparseSegmentReduce(data, indices, segmentIds, false, backend);\n}\n\nexport const sparseSegmentMeanConfig: KernelConfig = {\n  kernelName: SparseSegmentMean,\n  backendName: 'webgpu',\n  kernelFunc: sparseSegmentMean as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseSegmentSum, SparseSegmentSumInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {sparseSegmentReduce} from '../kernel_utils/sparse_segment_reduce';\n\nexport function sparseSegmentSum(\n    args: {inputs: SparseSegmentSumInputs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n\n  return sparseSegmentReduce(data, indices, segmentIds, true, backend);\n}\n\nexport const sparseSegmentSumConfig: KernelConfig = {\n  kernelName: SparseSegmentSum,\n  backendName: 'webgpu',\n  kernelFunc: sparseSegmentSum as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TileProgram implements WebGPUProgram {\n  variableNames = ['A'];\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n  rank: number;\n\n  constructor(aShape: number[], reps: number[]) {\n    const outputShape: number[] = new Array(aShape.length);\n    for (let i = 0; i < outputShape.length; i++) {\n      outputShape[i] = aShape[i] * reps[i];\n    }\n    this.outputShape = outputShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.rank = this.outputShape.length;\n    this.shaderKey = 'tile';\n  }\n\n  getUserCode(): string {\n    const sourceCoords = getSourceCoords(this.rank, 'uniforms.');\n\n    const userCode = `\n      ${main('index')} {\n        if (index < uniforms.size) {\n          let resRC = getCoordsFromIndex(index);\n          setOutputAtIndex(index, getA(${sourceCoords}));\n        }\n      }\n    `;\n    return userCode;\n  }\n}\n\nfunction getSourceCoords(rank: number, uniformPrefix = ''): string {\n  if (rank >= 5) {\n    throw Error(`Tile for rank ${rank} is not yet supported`);\n  }\n  if (rank === 1) {\n    return `(resRC % ${uniformPrefix}aShape)`;\n  }\n\n  const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n  const sourceCoords = [];\n  for (let i = 0; i < rank; i++) {\n    sourceCoords.push(`(${currentCoords[i]} % ${uniformPrefix}aShape[${i}])`);\n  }\n  return sourceCoords.join();\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {tileImplCPU} from '../kernel_utils/shared';\nimport {TileProgram} from '../tile_webgpu';\n\nexport function tile(\n    params: {inputs: TileInputs, backend: WebGPUBackend, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = params;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  // tile gpu program cannot handle rank >= 5 case.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string' ||\n      x.shape.length >= 5) {\n    // Even thought string tensor is always on CPU, just to be consistent on how\n    // to access tensor data.\n    const data = backend.readSync(x.dataId);\n    const value = x.dtype === 'string' ?\n        (data as Uint8Array[]).map(d => util.decodeString(d)) :\n        data as TypedArray;\n    const buf = buffer(x.shape, x.dtype, value);\n    const outBuf = tileImplCPU(buf, reps);\n    return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n  }\n\n  const program = new TileProgram(x.shape, reps);\n  const output = backend.runWebGPUProgram(program, [x], x.dtype);\n\n  return output;\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'webgpu',\n  kernelFunc: tile as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {scatterImplCPU} from '../kernel_utils/shared';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {tile} from './Tile';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: WebGPUBackend,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n\n  const sumDupeIndices = false;\n  if (sparseValues.dtype === 'string') {\n    const indicesBuf = backend.bufferSync<Rank, 'int32'>(sparseIndices);\n    const updatesBuf = backend.bufferSync<Rank, 'string'>(sparseValues);\n    const $defaultValue = util.decodeString(\n        backend.readSync(defaultValue.dataId)[0] as Uint8Array);\n    const outBuf = scatterImplCPU(\n        indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates,\n        sliceRank, strides, $defaultValue, sumDupeIndices);\n    return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n  }\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const $sparseIndices = reshape({\n    inputs: {x: sparseIndices},\n    backend,\n    attrs: {shape: [numUpdates, sliceRank]}\n  });\n  const $sparseValues = sparseValues.shape.length ?\n      reshape({\n        inputs: {x: sparseValues},\n        backend,\n        attrs: {shape: [numUpdates, sliceSize]}\n      }) :\n      identity({inputs: {x: sparseValues}, backend});\n\n  const type = $sparseValues.dtype;\n  const zero =\n      backend.makeTensorInfo([], type, util.makeZerosTypedArray(1, type));\n\n  // Fill output tensor with the default value.\n  const $defaultValue = reshape({\n    inputs: {x: defaultValue},\n    backend,\n    attrs: {shape: Array(flattenShape.length).fill(1)}\n  });\n  const $denseValues =\n      tile({inputs: {x: $defaultValue}, backend, attrs: {reps: flattenShape}});\n\n  const size = util.sizeFromShape([numUpdates, sliceSize]);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]},\n    {type: 'int32', data: strides},\n    {type: 'int32', data: [size]},\n  ];\n\n  switch (numUpdates) {\n    case 0:\n      break;\n    case 1:\n      if (true) {\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type,\n            sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n      break;\n    default:\n      if (true) {\n        // First replace the default value with 0 at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            zero.shape.length, strides, flattenShape, type, sumDupeIndices);\n        backend.runWebGPUProgram(\n            program, [zero, $sparseIndices], type, uniformData, $denseValues);\n      }\n      {\n        // Then replace 0 with the (sum of) sparse value(s) at indices.\n        const program = new ScatterProgram(\n            [numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length,\n            $sparseValues.shape.length, strides, flattenShape, type);\n        backend.runWebGPUProgram(\n            program, [$sparseValues, $sparseIndices], type, uniformData,\n            $denseValues);\n      }\n  }\n\n  const denseValues = reshape(\n      {inputs: {x: $denseValues}, backend, attrs: {shape: outputShape}});\n\n  backend.disposeData($sparseIndices.dataId);\n  backend.disposeData($sparseValues.dataId);\n  backend.disposeData($defaultValue.dataId);\n  backend.disposeData(zero.dataId);\n  backend.disposeData($denseValues.dataId);\n  return denseValues;\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'webgpu',\n  kernelFunc: sparseToDense as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SplitV, SplitVAttrs, SplitVInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: WebGPUBackend, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const xRank = x.shape.length;\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'webgpu',\n  kernelFunc: splitV as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const sqrt = unaryKernelFunc({opType: UnaryOpType.SQRT});\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'webgpu',\n  kernelFunc: sqrt\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'webgpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const webGPUBackend = backend as WebGPUBackend;\n    const program = new UnaryOpProgram(x.shape, UnaryOpType.SQUARE);\n    return webGPUBackend.runWebGPUProgram(program, [x], x.dtype);\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\n\nexport const squaredDifference = binaryKernelFunc({\n  opType: BinaryOpType.SQUARED_DIFFERENCE,\n});\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'webgpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Step, StepAttrs, TensorInfo, UnaryInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnaryOpType} from '../unary_op_util';\nimport {UnaryOpProgram} from '../unary_op_webgpu';\n\nexport function step(\n    {inputs, attrs, backend}:\n        {inputs: UnaryInputs, attrs: StepAttrs, backend: WebGPUBackend}):\n    TensorInfo {\n  const {x} = inputs;\n  const program =\n      new UnaryOpProgram(x.shape, UnaryOpType.STEP, 'stepAlpha : f32,');\n  const uniformData = [{type: 'float32', data: [attrs.alpha]}];\n  return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n}\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'webgpu',\n  kernelFunc: step as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getCoordsDataType, getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class StridedSliceProgram implements WebGPUProgram {\n  variableNames = ['x'];\n  uniforms: string;\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  // TODO(xing.xu): Increase the workPerThread.\n  workPerThread = 1;\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(destSize: number[]) {\n    this.outputShape = destSize;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        [this.workPerThread, 1, 1]);\n\n    const dtype = getCoordsDataType(this.outputShape.length);\n    this.uniforms = `begin : ${dtype},  strides : ${dtype}, `;\n    this.shaderKey = 'stridedSlice';\n  }\n\n  getUserCode(): string {\n    const rank = this.outputShape.length;\n    let newCoords = '';\n    if (rank === 1) {\n      newCoords = 'coords * uniforms.strides + uniforms.begin';\n    } else {\n      let outputAxis = 0;\n      newCoords =\n          this.outputShape\n              .map((_, i) => {\n                outputAxis++;\n                return this.outputShape.length === 1 ?\n                    `coords * uniforms.strides[${i}] + uniforms.begin[${i}]` :\n                    `coords[${outputAxis - 1}] * uniforms.strides[${\n                        i}] + uniforms.begin[${i}]`;\n              })\n              .join(',');\n    }\n\n    const userCode = `\n       ${main('index')} {\n         if (index < uniforms.size) {\n           let coords = getCoordsFromIndex(index);\n           setOutputAtIndex(index, getX(${newCoords}));\n         }\n       }\n     `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, KernelConfig, KernelFunc, Rank, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stridedSliceImplCPU} from '../kernel_utils/shared';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {StridedSliceProgram} from '../strided_slice_webgpu';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: WebGPUBackend,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeData(sliced.dataId);\n  } else {\n    const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n    if (shouldExecuteOnCPU) {\n      const values = backend.readSync(x.dataId) as TypedArray;\n      const xBuf = buffer(x.shape, x.dtype, values) as TensorBuffer<Rank>;\n      const resultValues =\n          stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);\n      result = backend.makeTensorInfo(finalShape, x.dtype, resultValues.values);\n    } else {\n      const program = new StridedSliceProgram(finalShapeSparse);\n      const uniformData =\n          [{type: 'int32', data: $begin}, {type: 'int32', data: $strides}];\n      const resultValues =\n          backend.runWebGPUProgram(program, [x], x.dtype, uniformData);\n      result = reshape(\n          {inputs: {x: resultValues}, backend, attrs: {shape: finalShape}});\n      backend.disposeData(resultValues.dataId);\n    }\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'webgpu',\n  kernelFunc: stridedSlice as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {stringNGramsImplCPU} from '../kernel_utils/shared';\n\nexport function stringNGrams(args: {\n  inputs: StringNGramsInputs,\n  backend: WebGPUBackend,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  } = attrs;\n  const {data, dataSplits} = inputs;\n  const $data = backend.readSync(data.dataId) as Uint8Array[];\n  const $dataSplits = backend.readSync(dataSplits.dataId) as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImplCPU(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n  return [\n    backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n    backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n  ];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'webgpu',\n  kernelFunc: stringNGrams as unknown as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {BinaryOpType} from '../binary_op_util';\nimport {binaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {subImplCPU as cpuSub} from '../kernel_utils/shared';\n\nexport const sub = binaryKernelFunc(\n    {opType: BinaryOpType.SUB, cpuKernelImpl: cpuSub, supportsComplex: true});\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'webgpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2022 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const tan = unaryKernelFunc({opType: UnaryOpType.TAN});\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'webgpu',\n  kernelFunc: tan\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\nimport {unaryKernelFunc} from '../kernel_utils/kernel_funcs_utils';\nimport {UnaryOpType} from '../unary_op_util';\n\nexport const tanh = unaryKernelFunc({opType: UnaryOpType.TANH});\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'webgpu',\n  kernelFunc: tanh\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, TensorScatterUpdate, TensorScatterUpdateAttrs, TensorScatterUpdateInputs, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ScatterProgram} from '../scatter_webgpu';\n\nimport {reshape} from './Reshape';\nimport {tile} from './Tile';\n\nexport function tensorScatterUpdate(args: {\n  inputs: TensorScatterUpdateInputs,\n  backend: WebGPUBackend,\n  attrs: TensorScatterUpdateAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {tensor, indices, updates} = inputs;\n  const {} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, tensor.shape);\n\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  if (outputSize === 0) {\n    return backend.makeTensorInfo(tensor.shape, indices.dtype);\n  }\n\n  const toDispose = [];\n\n  const flattenIndices = reshape(\n      {inputs: {x: indices}, backend, attrs: {shape: [numUpdates, sliceRank]}});\n  toDispose.push(flattenIndices);\n  const flattenX = reshape(\n      {inputs: {x: updates}, backend, attrs: {shape: [numUpdates, sliceSize]}});\n  toDispose.push(flattenX);\n  const flattenTensor =\n      reshape({inputs: {x: tensor}, backend, attrs: {shape: flattenShape}});\n  toDispose.push(flattenTensor);\n  const output = tile({\n    inputs: {x: flattenTensor},\n    backend,\n    attrs: {reps: Array(flattenShape.length).fill(1)}\n  });\n  const program = new ScatterProgram(\n      [numUpdates, sliceSize], sliceRank, flattenIndices.shape.length,\n      flattenX.shape.length, strides, flattenShape, tensor.dtype, false);\n  const size = util.sizeFromShape([numUpdates, sliceSize]);\n  const uniformData = [\n    {type: 'int32', data: [sliceRank]},\n    {type: 'int32', data: strides},\n    {type: 'int32', data: [size]},\n  ];\n  const res = backend.runWebGPUProgram(\n      program, [flattenX, flattenIndices], flattenTensor.dtype, uniformData,\n      output);\n  toDispose.push(res);\n\n  const reshaped =\n      reshape({inputs: {x: res}, backend, attrs: {shape: tensor.shape}});\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n\n  return reshaped;\n}\n\nexport const tensorScatterUpdateConfig: KernelConfig = {\n  kernelName: TensorScatterUpdate,\n  backendName: 'webgpu',\n  kernelFunc: tensorScatterUpdate as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\n// The original algorithm is based on computing the top K only, however\n// since for TFJS we require the indices of the top K values as well then the\n// algorithm found here is a bit modified. Rather than producing the values\n// at each step, the indices containing the top K are generated instead.\n// The output values are not generated to reduce the number of outputs in the\n// GPU, the values can easily be retrieved from the indices using a gather\n// op.\n\nexport class SwapProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.uniforms = `inputSize : i32, firstPass : i32, negativeInf : f32,\n        dir : i32, inc : i32,`;\n    this.shaderKey = 'swap';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // We compare elements pair-wise within a group of size 2 * inc.\n            // The comparing rule for each group alternates between ascending\n            // and descending. Within each group, we compare each pair at\n            // positions i and i+inc. To decide whether an element at position i\n            // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n            // inc, it is in the first half of the group, we denote it as x0,\n            // otherwise we denote it as x1.\n            // For example, as shown in the Bitonic top K paper referenced\n            // above, Figure5(a) shows that element[1] is in the second half of\n            // the group when group size is 2, but it is in the first half of\n            // the group when group size is 4.\n            let isFirstInPair = elemIdx % (2 * uniforms.inc) < uniforms.inc;\n            var i = 0;\n            if (isFirstInPair) {\n              i = elemIdx;\n            } else {\n              i = elemIdx - uniforms.inc;\n            }\n\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.inc;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.inc));\n            }\n\n            var x0 = f32(0.0);\n            var x1 = f32(0.0);\n            if (i0 < uniforms.inputSize) {\n              x0 = getX(batch, i0);\n            } else {\n              x0 = uniforms.negativeInf;\n            }\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = uniforms.negativeInf;\n            }\n\n            let reverse = elemIdx % (2 * uniforms.dir) >= uniforms.dir;\n            let isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n            if (reverse == isGreater) {\n              // Elements in opposite order of direction\n              let iTemp = i0;\n              i0 = i1;\n              i1 = iTemp;\n            }\n            if (isFirstInPair) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n\nexport class MergeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'indices'];\n  uniforms: string;\n  workgroupSize: [number, number, number] = [256, 1, 1];\n  size = true;\n\n  constructor(shape: number[]) {\n    this.outputShape = shape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    // |n| Size of the original input of TopK\n    // |firstPass| indicates if this is the first time swap is being used which\n    // means no indices input containing the top K is present yet.\n    // |k| Top k elements desired\n    this.uniforms = `inputSize : i32, firstPass : i32, k : i32,`;\n    this.shaderKey = 'merge';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n        ${main('index')} {\n          if (index < uniforms.size) {\n            let outC = getCoordsFromIndex(index);\n            let batch = outC[0];\n            let elemIdx = outC[1];\n            // The output size is half of the previous size.\n            // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _\n            // (k=4), we only need to output the indices at positions |, the\n            // indices at positions _ can be thrown away, see Figure5(b) After\n            // Phase 2 (Merge phase) in the Bitonic Top K paper referenced\n            // above.\n            // For example, the paper shows we only need to output the orange\n            // bars. The output sequence should look like this | | | | | | | |.\n            // Because the sequence is halved, to map the output index back to\n            // the previous sequence to find the corresponding value, we need\n            // to double the index. When we double the index, we basically\n            // interpolate a position, so 2i looks like\n            // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k\n            // position of each 2k positions by - elemIdx % k. E.g. for output\n            // at index 4,5,6,7, we want to get the corresponding element at\n            // original index 8,9,10,11, for output at index 8,9,10,11,\n            // we want to get the corresponding element at original index\n            // 16,17,18,19, so on and so forth.\n\n            var i = 0;\n            if (elemIdx < uniforms.k) {\n              i = elemIdx;\n            } else {\n              i = elemIdx * 2 - elemIdx % uniforms.k;\n            }\n            var i0 = 0;\n            if (uniforms.firstPass == 1) {\n              i0 = i;\n            } else {\n              i0 = i32(getIndices(batch, i));\n            }\n            var i1 = 0;\n            if (uniforms.firstPass == 1) {\n              i1 = i + uniforms.k;\n            } else {\n              i1 = i32(getIndices(batch, i + uniforms.k));\n            }\n\n            let x0 = getX(batch, i0);\n            var x1 = f32(0.0);\n            if (i1 < uniforms.inputSize) {\n              x1 = getX(batch, i1);\n            } else {\n              x1 = x0;\n            }\n\n            if (x0 >= x1) {\n              setOutputAtIndex(index, f32(i0));\n            } else {\n              setOutputAtIndex(index, f32(i1));\n            }\n          }\n        }\n      `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {topKImplCPU} from '../kernel_utils/shared';\nimport {MergeProgram, SwapProgram} from '../top_k_webgpu';\nimport {fill} from './Fill';\nimport {gatherV2} from './GatherV2';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nfunction disposeIntermediateTensorInfoOrNull(\n    backend: WebGPUBackend, tensorInfo: TensorInfo) {\n  if (tensorInfo !== null) {\n    backend.disposeData(tensorInfo.dataId);\n  }\n}\n\nfunction roundUpToPow2(num: number) {\n  let pow2 = 1;\n  while (pow2 < num) {\n    pow2 *= 2;\n  }\n  return pow2;\n}\n\n// Based on Algorithm 2 of Bitonic Top K, ref:\n// https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf\nexport function topK(\n    args: {inputs: TopKInputs, backend: WebGPUBackend, attrs: TopKAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted}= attrs;\n\n  const xShape = x.shape;\n  const lastDim = xShape[xShape.length - 1];\n\n  if (backend.shouldExecuteOnCPU([x])) {\n    const xVals = backend.readSync(x.dataId) as TypedArray;\n    const [allTopKVals, allTopKIndices] =\n        topKImplCPU(xVals, xShape, x.dtype as NumericDataType, k, sorted);\n\n    return [\n      backend.makeTensorInfo(\n          allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n      backend.makeTensorInfo(\n          allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n    ];\n  }\n\n  if (k === 0) {\n    xShape[xShape.length - 1] = 0;\n    return [\n      backend.makeTensorInfo(xShape, x.dtype, []),\n      backend.makeTensorInfo(xShape, 'int32', [])\n    ];\n  }\n\n  if (lastDim === 1 /* firstPass */) {\n    return [\n      x, fill({attrs: {shape: xShape, dtype: 'int32', value: 0}, backend})\n    ];\n  }\n\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const xSize = util.sizeFromShape(xShape);\n  const batch = xSize / lastDim;\n  const x2D = reshape({inputs: {x}, attrs: {shape: [batch, lastDim]}, backend});\n\n  const kPow2 = roundUpToPow2(k);\n  const lastDimPow2 = roundUpToPow2(lastDim);\n\n  // Only the indices containing the top K are kept at every step to reduce\n  // number of outputs in the GPU algorithms, so once the final set of indices\n  // is computed then gather is used to grab the corresponding values\n  // from the original input.\n  let indices: TensorInfo = null;\n\n  // GPU algorithm always takes in an indices input but this input is not used\n  // on the first run of a GPU algorithm, therefore if indices is null we simply\n  // pass in x2D instead of it but the value will not actually be used\n  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];\n\n  const runSwap = (dir: number, inc: number, shape: number[]) => {\n    const inputs = getInputs();\n    const program = new SwapProgram(shape);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataSwap = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'float32', data: [Number.NEGATIVE_INFINITY]},\n        {type: 'int32', data: [dir]},\n        {type: 'int32', data: [inc]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        program, inputs, 'int32', uniformDataSwap);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n  };\n\n  // Step 1: local sort\n  for (let len = 1; len < kPow2; len *= 2) {\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, [batch, lastDimPow2]);\n    }\n  }\n\n  // Step 2: merge\n  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {\n    const inputs = getInputs();\n    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);\n    const firstPass = indices === null ? 1 : 0;\n    const uniformDataMerge = [\n        {type: 'int32', data: [lastDim]},\n        {type: 'int32', data: [firstPass]},\n        {type: 'int32', data: [kPow2]}\n    ];\n    const prevIndices = indices;\n    indices = backend.runWebGPUProgram(\n        mergeProgram, inputs, 'int32', uniformDataMerge);\n    disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n    // Step 3: rebuild\n    const len = kPow2 / 2;\n    const dir = len * 2;\n    for (let inc = len; inc >= 1; inc /= 2) {\n      runSwap(dir, inc, indices.shape);\n    }\n  }\n\n  // Keep only the requested top K results instead of kPow2\n  let prevIndices = indices;\n  indices = slice(\n      {inputs: {x: indices}, backend, attrs: {begin: 0, size: [batch, k]}});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  // Gather values on last dimension\n  let values = gatherV2(\n      {inputs: {x: x2D, indices}, backend, attrs: {axis: 1, batchDims: 1}});\n  disposeIntermediateTensorInfoOrNull(backend, x2D);\n\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const newShape = xShape.slice(0, -1);\n  newShape.push(k);\n\n  prevIndices = indices;\n  indices = reshape({inputs: {x: indices}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevIndices);\n\n  const prevValues = values;\n  values = reshape({inputs: {x: values}, attrs: {shape: newShape}, backend});\n  disposeIntermediateTensorInfoOrNull(backend, prevValues);\n\n  return [values, indices];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'webgpu',\n  kernelFunc: topK as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class TransformProgram implements WebGPUProgram {\n  variableNames = ['Image', 'Transforms'];\n  outputShape: number[];\n  uniforms = 'interpolationModeId : i32, fillModeId : i32, fillValue : f32,';\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  size = true;\n\n  constructor(outShape: [number, number, number, number]) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize);\n    this.shaderKey = 'transform';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n          fn mapCoord(outCoord : f32, len : f32) -> f32{\n            var inCoord = outCoord;\n            if(uniforms.fillModeId == 2) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  if (inCoord < sz2) {\n                    inCoord = sz2 * f32(i32(f32(-inCoord / sz2))) +\n                    inCoord;\n                  }\n                  if (inCoord < -len) {\n                    inCoord = inCoord + sz2;\n                  } else {\n                    inCoord = -inCoord - 1.0;\n                  }\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz2 = 2.0 * len;\n                  inCoord = inCoord - sz2 * f32(i32(f32(inCoord / sz2)));\n                  if (inCoord >= len) {\n                    inCoord = sz2 - inCoord - 1.0;\n                  }\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 3) {\n              if (inCoord < 0.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord + len * (f32(i32(f32(-inCoord / sz))) + 1.0);\n                }\n              } else if (inCoord > len - 1.0) {\n                if (len <= 1.0) {\n                  inCoord = 0.0;\n                } else {\n                  let sz = len - 1.0;\n                  inCoord = inCoord - len * f32(i32(f32(inCoord / sz)));\n                }\n              }\n              return clamp(inCoord, 0.0, len - 1.0);\n            } else if (uniforms.fillModeId == 4) {\n              return clamp(outCoord, 0.0, len - 1.0);\n            }\n            return outCoord;\n          }\n          fn readWithFillValue(batch : i32, coordY : i32, coordX : i32,\n            channel : i32) -> f32 {\n            var outputValue : f32;\n            if (0 <= coordY && coordY < uniforms.imageShape[1] && 0 <= coordX && coordX < uniforms.imageShape[2]) {\n                outputValue = getImage(batch, coordY, coordX, channel);\n            } else {\n              outputValue = uniforms.fillValue;\n            }\n            return outputValue;\n          }\n\n          ${main('index')} {\n            if (index < uniforms.size) {\n              let coords = getCoordsFromIndex(index);\n              var outputValue : f32;\n              let batch = coords[0];\n              let x = coords[2];\n              let y = coords[1];\n              let channel = coords[3];\n              let xf = f32(x);\n              let yf = f32(y);\n              let a1 = getTransforms(batch, 0);\n              let a2 = getTransforms(batch, 1);\n              let a3 = getTransforms(batch, 2);\n              let b1 = getTransforms(batch, 3);\n              let b2 = getTransforms(batch, 4);\n              let b3 = getTransforms(batch, 5);\n              let c1 = getTransforms(batch, 6);\n              let c2 = getTransforms(batch, 7);\n              let projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = uniforms.fillValue;\n              } else {\n                let inX = (a1 * xf + a2 * yf + a3) / projection;\n                let inY = (b1 * xf + b2 * yf + b3) / projection;\n                let mapX = mapCoord(inX, f32(uniforms.imageShape[2]));\n                let mapY = mapCoord(inY, f32(uniforms.imageShape[1]));\n\n                if (uniforms.interpolationModeId == 1) {\n                  let coordY = i32(round(mapY));\n                  let coordX = i32(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  let yFloor = floor(mapY);\n                  let xFloor = floor(mapX);\n                  let yCeil = yFloor + 1.0;\n                  let xCeil = xFloor + 1.0;\n                  let valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yFloor), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yFloor), i32(xCeil), channel);\n                  let valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, i32(yCeil), i32(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, i32(yCeil), i32(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutputAtIndex(index, outputValue);\n            }\n          }\n        `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transform, TransformAttrs, TransformInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {TransformProgram} from '../transform_webgpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  backend: WebGPUBackend,\n  attrs: TransformAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape =\n      [batch, outHeight, outWidth,\n       numChannels] as [number, number, number, number];\n\n  const program = new TransformProgram(outShape);\n  const interpolationModeId = interpolation === 'nearest' ? 1 : 2;\n  let fillModeId: number;\n  switch (fillMode) {\n    case 'constant':\n      fillModeId = 1;\n      break;\n    case 'reflect':\n      fillModeId = 2;\n      break;\n    case 'wrap':\n      fillModeId = 3;\n      break;\n    case 'nearest':\n      fillModeId = 4;\n      break;\n    default:\n      fillModeId = 1;\n      break;\n  }\n  const uniformData = [\n    {type: 'int32', data: [interpolationModeId]},\n    {type: 'int32', data: [fillModeId]}, {type: 'float32', data: [fillValue]}\n  ];\n  return backend.runWebGPUProgram(\n      program, [image, transforms], 'float32', uniformData);\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'webgpu',\n  kernelFunc: transform as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\n\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args:\n        {inputs: UnpackInputs, backend: WebGPUBackend, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const x = value;\n  const xRank = x.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(xRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < xRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = x.shape[i];\n    }\n  }\n\n  const toDispose = [];\n\n  const begin = new Array(xRank).fill(0);\n  const size = x.shape.slice();\n  size[axis] = 1;\n  const res: TensorInfo[] = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const sliced = slice({inputs: {x}, backend, attrs: {begin, size}});\n    const reshaped =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: outShape}});\n    res[i] = reshaped;\n\n    toDispose.push(sliced);\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'webgpu',\n  kernelFunc: unpack as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType} from '@tensorflow/tfjs-core';\n\nimport {atomicAddSnippet} from './shader_util';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class UnsortedSegmentSumProgram implements WebGPUProgram {\n  outputShape: number[] = [];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['x', 'segmentIds'];\n  uniforms = 'numSegments : i32, xSize: i32,';\n  workgroupSize: [number, number, number] = [64, 1, 1];\n  atomic = true;\n  type: DataType;\n\n  constructor(inShape: number[], outShape: number[], outputDtype: DataType) {\n    this.outputShape = outShape;\n    this.dispatchLayout = flatDispatchLayout(inShape);\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, inShape, this.workgroupSize);\n    if (outputDtype !== 'float32' && outputDtype !== 'int32') {\n      throw new Error(`UnsortedSegmentSum only supports float32 and int32\n              types, does not support ${outputDtype} type.`);\n    }\n    this.type = outputDtype;\n    this.shaderKey = 'unsortedSegmentSum';\n  }\n\n  getUserCode(): string {\n    const userCode = `\n    ${main('index')} {\n      if (index < uniforms.xSize) {\n        let coords = getXCoordsFromIndex(index);\n        let b = coords[0];\n        let inCol = coords[1];\n\n        let segmentId = i32(getSegmentIds(inCol));\n        if (segmentId >= 0) {\n          let flatIndex = b * uniforms.numSegments + segmentId % uniforms.numSegments;\n          let value = getX(b, inCol);\n\n          ${\n        atomicAddSnippet(\n            '&result[flatIndex]', 'value', this.type as 'float32' | 'int32')}\n        }\n      }\n    }\n  `;\n    return userCode;\n  }\n}\n","/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, TensorInfo, UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {UnsortedSegmentSumProgram} from '../unsorted_segment_sum_webgpu';\n\nimport {fill} from './Fill';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function unsortedSegmentSum(args: {\n  inputs: UnsortedSegmentSumInputs,\n  backend: WebGPUBackend,\n  attrs: UnsortedSegmentSumAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, segmentIds} = inputs;\n  const {numSegments} = attrs;\n\n  const xRank = x.shape.length;\n\n  const toDispose = [];\n\n  let axis = 0;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    toDispose.push(permutedX);\n    axis = backend_util.getInnerMostAxes(1, xRank)[0];\n  }\n\n  const outShape = backend_util.segment_util.computeOutShape(\n      permutedX.shape, axis, numSegments);\n  const inSize = util.sizeFromShape([permutedX.shape[axis]]);\n  const a2D =\n      reshape({inputs: {x: permutedX}, backend, attrs: {shape: [-1, inSize]}});\n  toDispose.push(a2D);\n\n  const dtype = x.dtype;\n  const shape = [a2D.shape[0], numSegments];\n  const output = fill({backend, attrs: {shape, value: 0, dtype}});\n  const program = new UnsortedSegmentSumProgram(a2D.shape, shape, dtype);\n  const uniformData = [\n    {type: 'int32', data: [numSegments]},\n    {type: 'int32', data: [util.sizeFromShape(a2D.shape)]}\n  ];\n  const segResult = backend.runWebGPUProgram(\n      program, [a2D, segmentIds], dtype, uniformData, output);\n\n  const reshaped =\n      reshape({inputs: {x: segResult}, backend, attrs: {shape: outShape}});\n  toDispose.push(segResult);\n  let result = reshaped;\n  if (permutation != null) {\n    toDispose.push(reshaped);\n    const perm = backend_util.getUndoAxesPermutation(permutation);\n    result = transpose({inputs: {x: result}, backend, attrs: {perm}});\n  }\n\n  toDispose.forEach(t => backend.disposeData(t.dataId));\n  return result;\n}\n\nexport const unsortedSegmentSumConfig: KernelConfig = {\n  kernelName: UnsortedSegmentSum,\n  backendName: 'webgpu',\n  kernelFunc: unsortedSegmentSum as unknown as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {broadcastArgsConfig} from './kernels/BroadcastArgs';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {complexConfig} from './kernels/Complex';\nimport {complexAbsConfig} from './kernels/ComplexAbs';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2DConfig} from './kernels/Dilation2D';\nimport {dilation2DBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2DBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {drawConfig} from './kernels/Draw';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fromPixelsConfig} from './kernels/FromPixels';\nimport {fusedBatchNormConfig} from './kernels/FusedBatchNorm';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {lrnConfig} from './kernels/LRN';\nimport {lrnGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {modConfig} from './kernels/Mod';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {searchSortedConfig} from './kernels/SearchSorted';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseSegmentMeanConfig} from './kernels/SparseSegmentMean';\nimport {sparseSegmentSumConfig} from './kernels/SparseSegmentSum';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tensorScatterUpdateConfig} from './kernels/TensorScatterUpdate';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {unpackConfig} from './kernels/Unpack';\nimport {unsortedSegmentSumConfig} from './kernels/UnsortedSegmentSum';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  avgPoolGradConfig,\n  batchMatMulConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  broadcastArgsConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  complexConfig,\n  complexAbsConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv3DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  depthwiseConv2dNativeConfig,\n  diagConfig,\n  dilation2DConfig,\n  dilation2DBackpropFilterConfig,\n  dilation2DBackpropInputConfig,\n  drawConfig,\n  einsumConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  fromPixelsConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedBatchNormConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  log1pConfig,\n  logConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  lrnConfig,\n  lrnGradConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPoolGradConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolWithArgmaxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  modConfig,\n  multinomialConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  rangeConfig,\n  realConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  searchSortedConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseSegmentMeanConfig,\n  sparseSegmentSumConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tensorScatterUpdateConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  unpackConfig,\n  unsortedSegmentSumConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n"],"names":["ENV","env","registerFlag","AdapterInfo","constructor","adapterInfo","this","vendor","architecture","intelGPUGeneration","getIntelGPUGeneration","isIntel","startsWith","Number","match","BufferManager","device","numUsedBuffers","numFreeBuffers","freeBuffers","Map","usedBuffers","numBytesUsed","numBytesAllocated","acquireBuffer","size","usage","mappedAtCreation","reuse","buffer","key","getBufferKey","has","set","get","length","pop","createBuffer","push","releaseBuffer","bufferArray","index","indexOf","Error","destroy","getNumUsedBuffers","getNumFreeBuffers","dispose","forEach","buffers","TextureManager","numUsedTextures","numFreeTextures","freeTextures","usedTextures","acquireTexture","width","height","format","byteSize","getBytesPerElement","getTextureKey","newTexture","shift","createTexture","releaseTexture","texture","textureList","textureIndex","splice","getNumUsedTextures","getNumFreeTextures","textures","symbolicallyComputeStrides","indicesArr","variableName","Math","max","numCoords","shape","map","d","strides","Array","i","atomicAddSnippet","ptr","v","type","PixelsOpType","compileProgram","program","inputsData","output","parallelCompilation","source","inputInfo","outputData","prefixSnippets","flatWorkgroupSize","workgroupSize","outputComponent","isFlatDispatch","pixelsOpType","inoutSnippet","FROM_PIXELS","dataTypeToGPUType","dtype","outShapeStridesType","useGlobalIndex","isFlatDispatchLayout","commonSnippet","join","getCoordsFromIndexSnippet","getUserCode","getStartHeaderString","stridesLength","stridesDataType","uniformDeclaration","variableNames","x","perDataType","getCoordsDataType","charAt","toLowerCase","slice","outputDataType","uniforms","uniformShader","curInsertRe","replace","preInsertRe","_","p1","p2","insertAlignment","atomic","variableComponents","coordsSnippet","outShape","dispatchLayout","y","z","outRank","rank","gatherDimensionsStr","dims","arr","j","dimensions","snippet","getOutputCoordsSnippet","sources","isInfSnippet","getOutputIndexFromCoordsSnippet","outBufferType","component","gpuType","typeSnippet","setOutputSnippet","inputSnippet","res","texName","name","funcName","toUpperCase","inputs","shapeStr","rankStr","getInputAtCoordsSnippet","texFuncSnippet","inRank","util","arraysEqual","broadcastDims","backend_util","getBroadcastDims","rankDiff","getCoordsXYZ","unpackedCoordsSnippet","coordsType","coordsValues","s","getInputByOutputSnippet","getInputSnippet","makeShader","module","createShaderModule","code","label","printShaderString","printShaderArray","split","some","item","shaderKey","includes","console","group","debug","groupEnd","createComputePipelineAsync","compute","entryPoint","layout","createComputePipeline","getMainHeaderString","params","getWorkgroupSizeString","stridesName","computeStrides","coords","assert","dispatch","hasOwnProperty","arrayProduct","product","computeDispatch","outputShape","elementsPerThread","dispatchX","dispatchY","dispatchZ","ceil","computeWorkgroupInfoForMatMul","dimAOuter","dimInner","dimBOuter","transposeA","computeWorkgroupSizeForConv2d","isVec4","dim0","dim1","computeWorkPerThreadForConv2d","flatDispatchLayout","GPUBytesPerElement","isWebGPUSupported","window","WorkerGlobalScope","navigator","gpu","assertNotComplex","tensor","opName","isArray","t","MatMulProgramType","tileSize","every","dim","dimIdx","CPU_HANDOFF_SIZE_THRESHOLD","getNumber","WebGPUBackend","KernelBackend","nextDataId","super","commandQueueOwnedIds","WeakSet","dispatchCountInPass","disposed","downloadWaitMs","tensorDataPendingDisposal","queryResolveBuffer","querySet","querySetCount","stagingPendingDisposal","uniformPendingDisposal","uploadWaitMs","hasReadSyncWarned","hasTimestampQueryWarned","webgpu_util.isWebGPUSupported","pipelineCache","queue","commandEncoder","computePassEncoder","supportTimestampQuery","features","thresholdToIncreaseWorkgroups","bufferManager","textureManager","tensorMap","DataStorage","engine","getBool","dummyCanvas","document","createElement","dummyContext","getContext","configure","body","appendChild","floatPrecision","disposeData","dataId","force","tensorData","refCount","complexTensorInfos","real","imag","releaseResource","delete","memory","numBytesInGPU","numBytesAllocatedInGPU","unreliable","resource","external","GPUBuffer","GPUTexture","incRef","decRef","write","values","id","move","submitQueue","submit","finish","b","ensureCommandEncoderReady","createCommandEncoder","endComputePassEncoder","end","async","pipelines","Promise","all","Object","e","message","keys","warn","stagingBuffer","GPUBufferUsage","COPY_DST","MAP_READ","copyBufferToBuffer","mapAsync","GPUMapMode","READ","getMappedRange","unmap","undefined","getCurrentTexture","convertAndCacheOnCPU","data","readSync","realValues","imagValues","complexVals","convertBackendValuesAndArrayBuffer","mergeRealAndImagArrays","alphaModes","bufferSize","pixelsSize","valsGPU","ArrayBuffer","canvasWidth","canvasHeight","stagingDeviceStorage","OffscreenCanvas","stagingHostStorage","storage","context","GPUTextureUsage","alphaMode","readDataGPUToCPU","offset","copyBufferToTexture","bytesPerRow","willReadFrequently","clearRect","drawImage","stagingValues","getImageData","span","Uint8ClampedArray","k","value","fullyReadCount","floor","remainSize","vals","ps","read","getBufferData","copyBuffer","srcBuffer","dstBuffer","createTensorFromGPUData","webGPUData","zeroCopy","webgpu_util.GPUBytesPerElement","sizeFromShape","STORAGE","COPY_SRC","makeTensorFromDataId","readToGPU","srcTensorData","tensorInfo","makeTensorInfo","tensorRef","makeTensorFromTensorInfo","bufferSync","strings","decodeString","_a","f","oldActiveTimers","activeTimers","newActiveTimers","outerMostTime","programTimersStack","flattenedActiveTimerQueries","flatten","query","filter","flattenedActiveTimerNames","kernelMs","wallMs","sum","ms","isString","encodeString","tensorToBinding","createView","uploadToGPU","mapState","MAP_WRITE","arrayBuffer","Int32Array","Float32Array","makeUniforms","programUniform","currentOffset","preLength","offsets","maxAlignmentOfField","baseAlignment","Uint32Array","uniformBuffer","UNIFORM","writeBuffer","runWebGPUProgram","outputDtype","programDefinedUniform","getTypedArrayFromDType","MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE","limits","maxComputeWorkgroupsPerDimension","dispatchAverage","sqrt","cbrt","reshapeDispatch","input","shapes","types","element","inputShapesEqualsOutShape","broadcastDimsKey","flatDispatchString","webgpu_program.makeShaderKey","webgpu_program.compileProgram","pipeline","recordAndSubmit","bufferShapes","uniformsType","NaN","Infinity","concat","bindings","add","bindGroup","createBindGroup","getBindGroupLayout","entries","binding","shouldTimeProgram","computePassDescriptor","createQuerySet","count","timestampWrites","queryIndex","location","beginComputePass","setPipeline","setBindGroup","dispatchWorkgroups","webgpu_program.PixelsOpType","DRAW","getQueryTime","QUERY_RESOLVE","resolveQuerySet","queryStagingBuffer","BigUint64Array","time","shouldExecuteOnCPU","sizeThreshold","numDataIds","BinaryOpType","registerBackend","gpuDescriptor","powerPreference","adapter","requestAdapter","deviceDescriptor","requiredFeatures","adapterLimits","requiredLimits","maxComputeWorkgroupStorageSize","maxStorageBufferBindingSize","maxBufferSize","maxComputeWorkgroupSizeX","maxComputeInvocationsPerWorkgroup","requestDevice","requestAdapterInfo","getBinaryOpString","useVec4","doOpSnippet","ATAN2","MAX","MIN","MOD","NOT_EQUAL","POW","isNaN","dTypeN","boolN","ADD","COMPLEX_MULTIPLY_IMAG","COMPLEX_MULTIPLY_REAL","DIV","ELU_DER","EQUAL","FLOOR_DIV","GREATER","GREATER_EQUAL","LESS","LESS_EQUAL","LOGICAL_AND","LOGICAL_OR","MUL","PRELU","SQUARED_DIFFERENCE","SUB","UnaryOpType","ERF","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","SELU","SELU_SCALE","SELU_SCALEALPHA","getUnaryOpString","ABS","ACOS","ACOSH","ASIN","ASINH","ATAN","ATANH","COS","COSH","CEIL","ELU","EXP","EXPM1","FLOOR","IS_FINITE","IS_INF","IS_NAN","LINEAR","LOG","LOG1P","LOGICAL_NOT","NEG","LEAKYRELU","RECIPROCAL","RELU","RELU6","ROUND","RSQRT","SIGMOID","SIGN","SIN","SINH","SOFTPLUS","SQRT","SQUARE","STEP","TAN","TANH","TO_INT","activationFnSnippet","activation","hasPreluActivationWeights","packed","coordsLength","activationOpSnippet","dataType","biasActivationSnippet","hasBias","matMulReadFnSource","transposeB","fitAOuter","fitBOuter","fitInner","sampleA","sampleB","matMulReadWriteFnSource","makeMatMulPackedVec4Source","workPerThread","tileInner","splitK","splitedDimInner","broadcastBatch","tileAOuter","tileBOuter","tileAWidth","tileAHight","innerElementSize","rowPerThreadB","rowPerThread","colPerThread","main","transpose","writeDataToSubAVec4Snippet","bCachedStr","accStr","calculateResultSnippet","writeDataToSubASnippet","makeMatMulPackedSource","sequentialAccessByThreads","rowPerThreadA","colPerThreadA","matmulSnippet","readDataFromSubASnippet","MatMulPackedProgram","aShape","bias","preluActivationWeights","isVectorA","workgroupInfo","addBias","getShapeFit","userCode","readVectorASnippet","makeVectorMatrixProductSource","MatMulReduceProgram","workgroupSizeX","MatMulSmallOutputSizeProgram","bShape","makeMatMulSmallOutputSizeSource","MatMulSplitKProgram","BiasActivationProgram","FillProgram","fill","args","backend","attrs","inferDtype","getArrayFromDType","uniformData","fillConfig","kernelName","Fill","backendName","kernelFunc","reshape","xSize","$shape","inferFromImplicitShape","$xSize","reshapeConfig","Reshape","batchMatMulImpl","a","leakyreluAlpha","aRank","bRank","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","broadcast_util","assertAndGetBroadcastShape","a3dShape","b3dShape","a3d","b3d","intermediates","batchDim","out","matmulProgramType","thresholdFlagValue","workgroupsBy32x32","biasActivationProgram","activationInputs","outActivated","outReshaped","_fusedMatMulConfig","_FusedMatMul","BinaryOpComplexProgram","op","BinaryOpProgram","useSharedMemoryWithA","useSharedMemoryWithB","lastDimensionSize","aDivisibleBy4","bDivisibleBy4","isScalarShape","dType","opFnStr","sharedIndexSnippet","accessDataSnippet","identity","identityConfig","Identity","complex","complexInfo","realTensorInfo","imagTensorInfo","complexConfig","Complex","UnaryOpProgram","unaryKernelFunc","opType","cpuKernelImpl","webgpuBackend","$dtype","xData","outValues","binaryKernelFunc","supportsComplex","aData","bData","complexParts","aPart","bPart","aHandle","bHandle","upcastType","realProgram","imagProgram","complexOutput","decodedAVals","fromUint8ToStringArray","decodedBVals","createSimpleBinaryKernelImpl","aVals","bVals","newShape","resultRank","resultStrides","resultSize","result","aStrides","bStrides","aBroadcastDims","bBroadcastDims","loc","indexToLoc","aLoc","aIndex","locToIndex","bLoc","bIndex","addImpl","bitwiseAndImpl","createSimpleUnaryImpl","newValues","ceilImpl","xi","equalImpl","expImpl","exp","expm1Impl","expm1","floorImpl","floorDivImpl","greaterImpl","greaterEqualImpl","lessImpl","lessEqualImpl","logImpl","log","maximumImpl","aValue","bValue","minimumImpl","min","multiplyImpl","notEqualImpl","makeSplits","indices","indicesShape","paramsNestedSplits","numParamsDenseValues","valueSlices","numValues","numSplits","outSplits","splits","lastSplit","validateSplits","nrows","rowLength","start","limit","outDim","outSplitsOutDim","delta","computeFlatOuterDims","orig","numOutDims","outDims","inDim","getValues","paramsDenseValues","paramsDenseValuesShape","paramsDenseValuesDType","valuesShape","valuesOut","numElements","valueSize","denseM","valuesM","outPos","writeValueSlices","INT32_MAX","RowPartitionType","RaggedTensorToTensorOp","shapeShape","valuesDType","defaultValue","defaultValueShape","rowPartitionValues","rowPartitionValuesShapes","rowPartitionTypeStrings","rowPartitionTypes","getRowPartitionTypesHelper","raggedRank","getRaggedRank","getRowPartitionTypeByDimension","dimension","FIRST_DIM_SIZE","getRowPartitionTensor","getMaxWidth","rowPartitionTensor","VALUE_ROWIDS","getMaxWidthValueRowID","ROW_SPLITS","getMaxWidthRowSplit","static","rowSplit","tensorLength","maxWidth","currentWidth","valueRowIds","indexLength","firstEqualIndex","firstEqualIndexValue","tensorShapeFromTensor","tShape","isPartial","makeShape","calculateOutputSize","firstDim","valueShape","validateDefaultValueShape","combineRaggedTensorToTensorShapes","calculateFirstParentOutputIndex","firstDimension","outputIndexMultiplier","firstDimensionOutput","minDimension","currentOutputIndex","calculateOutputIndexRowSplit","parentOutputIndex","outputSize","rowSplitSize","realLength","parentOutputIndexCurrent","calculateOutputIndexValueRowID","indexSize","currentOutputColumn","currentValueRowId","nextValueRowId","calculateOutputIndex","partitionType","getFirstDimensionSize","firstPartitionTensor","firstPartitionType","multiplier","outputTensor","outputIndex","setOutput","valuesBase","outputBase","elementShape","valueElementSize","outputIndexSize","srcShape","tidy","defaultValueTensor","bCastDefault","broadcastTo","dataSync","srcStart","dstStart","dstEnd","srcI","dstI","src","subarray","copyArray","dst","rsqrtImpl","sigmoidImpl","sqrtImpl","squaredDifferenceImpl","diff","staticRegexReplaceImpl","pattern","replaceGlobal","rewrite","RegExp","StringNGramsOp","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","preserveShort","getPadWidth","nGramWidth","getNumNGrams","createNGrams","splitIndex","outputStartIndex","numNGrams","nGramIndex","leftPadding","rightPadding","numTokens","dataStartIndex","nGramSize","n","Uint8Array","nGram","nextNGramIndex","appendToNGram","str","inputDataSize","splitsSize","prevSplit","validSplits","numBatchItems","nGramsSplits","empty","nGrams","outputStartIdx","dataLength","delimiters","skipEmpty","delimiter","token","tokenStart","subImpl","comparePair","valueDiff","select","array","left","right","sd","sign","swap","xVals","weightsVals","weightsDtype","weightsShape","weightsSize","outVals","makeZerosTypedArray","xBuf","weightsBuf","binaryOutput","numRows","numCols","outBuf","inputType","from","zero","toTypedArray","resultData","resultShape","simplyConcat","colOffset","decodedData","tIdx","row","resIdx","col","indicesData","paramsBuf","numSlices","sliceRank","sliceSize","paramsShape","paramsSize","flattenIndex","indicesBuf","flattenOutputShape","originalLoc","batchIdx","indicesIdx","indicesIndex","originalIndex","stop","num","step","reduceSize","xShape","xDtype","minusOne","createScalarValue","reductionAxes","reduceShape","computeOutAndReduceShapes","outDtype","prod","paramsNestedSplitsShapes","outputRaggedRank","numParams","locString","validateIndices","outputNestedSplits","splitsOut","getSplits","outputDenseValues","starts","startsShape","startsDType","limitsShape","deltas","deltasShape","broadcastStarts","broadcastLimits","broadcastDeltas","inSizes","nRows","rtNestedSplits","abs","nVals","rtDenseValues","valueIndex","rowSize","shapesShape","updates","numUpdates","sumDupeIndices","flattenShape","updatesData","TensorBuffer","resultValues","begin","isContinous","slice_util","isSliceContinous","xStrides","flatOffset","computeFlatOffset","inBuf","outLoc","inLoc","idx","fromStringArrayToUint8","indicesDType","denseShape","indicesCount","denseRows","emptyRowIndicator","reverseIndexMap","getSparseFillEmptyRowsIndicesDenseShapeMismatch","rowsAreOrdered","lastIndicesRow","csrOffset","getSparseFillEmptyRowsNegativeIndexErrorMessage","getSparseFillEmptyRowsOutOfRangeIndexErrorMessage","allRowsFull","rowEmpty","outputIndices","outputValues","fullIndicesCount","filledCount","outputI","startingIndex","inputIndices","inputIndicesShape","inputDType","inputShape","targetShape","denseSize","nnz","outputRank","unknownIndex","getSparseReshapeMultipleNegativeOneOutputDimErrorMessage","getSparseReshapeNegativeOutputDimErrorMessage","getSparseReshapeEmptyTensorZeroOutputDimErrorMessage","missing","trunc","getSparseReshapeInputOutputMultipleErrorMessage","getSparseReshapeInputOutputMismatchErrorMessage","inputRank","inputStrides","outputStrides","newIndices","segmentIds","isMean","numIndices","inputFlat","numCol","outputRows","getSparseSegmentReductionNegativeSegmentIdsErrorMessage","outputLength","reduce","uninitializedIndex","outIndex","nextIndex","getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage","getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage","getSparseSegmentReductionIndicesOutOfRangeErrorMessage","newLoc","dataSplits","batchSize","tokens","maxNumEntries","prevTokensLength","nEntries","c","numBuckets","fingerPrint64","modulo","getLowBitsUnsigned","reps","sorted","lastDim","batch","allTopKVals","allTopKIndices","valAndInd","sort","outOffset","topKVals","topKIndices","perm","xRank","newStrides","axis","$axis","parseAxisParam","uniqueElements","inputBuffer","uniqueIndices","is1DTensor","toString","axisValues","m","existingIndex","uniqueIndex","outputTmpShape","outputBuffer","uniqueElementIndex","addImplCPU","castImpl","castImplCPU","ceilImplCPU","concatImpl","concatImplCPU","equalImplCPU","expImplCPU","expm1ImplCPU","floorImplCPU","floorDivImplCPU","gatherNdImpl","gatherNdImplCPU","gatherV2Impl","gatherV2ImplCPU","greaterEqualImplCPU","greaterImplCPU","lessEqualImplCPU","lessImplCPU","logImplCPU","maxImpl","maxImplCPU","maximumImplCPU","minimumImplCPU","multiplyImplCPU","negImpl","negImplCPU","notEqualImplCPU","prodImpl","prodImplCPU","rangeImpl","rangeImplCPU","rsqrtImplCPU","scatterImpl","scatterImplCPU","simpleAbsImpl","simpleAbsImplCPU","sliceImpl","sliceImplCPU","stridedSliceImpl","stridedSliceImplCPU","stringNGramsImpl","stringNGramsImplCPU","subImplCPU","tileImpl","tileImplCPU","topKImpl","topKImplCPU","transposeImpl","transposeImplCPU","uniqueImpl","uniqueImplCPU","shared","absConfig","Abs","acos","acosConfig","Acos","acosh","acoshConfig","Acosh","addKernelFunc","cpuAdd","addConfig","Add","AddNPackedProgram","snippets","variable","operation","addNConfig","AddN","tensors","d1","d2","TransposeSharedProgram","newDim","TransposeProgram","switched","getSwitchedCoords","switchedCoords","cpuTranspose","transposeConfig","Transpose","ReduceProgram","reduceInfo","reduceType","inSize","reduceOp","initValue","outputSnippet","keepDims","toDispose","origAxes","axes","permutedAxes","getAxesPermutation","getInnerMostAxes","assertAxesAreInnerMostDims","reduceOutShape","resOutShape","expandShapeToKeepDim","windowSize","outSize","sumOutType","reduced","allConfig","All","anyConfig","Any","ArgMinMaxProgram","getInputShapeLastDim","splitOutputCoords","argMaxConfig","ArgMax","$x","intermediateTensorInfos","NEGATIVE_INFINITY","argMinConfig","ArgMin","POSITIVE_INFINITY","asin","asinConfig","Asin","asinh","asinhConfig","Asinh","atan","atanConfig","Atan","atan2","atan2Config","Atan2","atanh","atanhConfig","Atanh","PoolWithFilterSizeEqualsOneProgram","convInfo","Pool2DProgram","poolType","computePositions","flattenPositions","includeBatchIndex","updateSnippet","returnValue","Pool3DProgram","reductionIndices","maxConfig","Max","mean","meanConfig","Mean","poolImpl","filterWidth","filterHeight","inShape","inWidth","inHeight","padInfo","reshapeX","reduceX","strideHeight","strideWidth","top","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","computePool2DInfo","avgPool3DConfig","AvgPool3D","dataFormat","computePool3DInfo","avgPoolProgram","strideDepth","front","inDepth","effectiveFilterDepth","AvgPool2DBackpropProgram","AvgPool3DBackpropProgram","avgPool3DGradConfig","AvgPool3DGrad","dy","avgMultiplier","filterDepth","outDepth","outHeight","outWidth","avgPoolGradConfig","AvgPoolGrad","batchMatMulConfig","BatchMatMul","SliceProgram","destSize","sourceCoords","coord","getCoords","coordSum","$begin","$size","parseSliceParams","assertParamsValid","xTensorData","sliceConfig","Slice","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","getSliceSize","reshapedIntermediate","transposedIntermediate","reshapedIntermediate2","sliced","writeSnippet","BincountProgram","hasWeights","bincountConfig","Bincount","weights","bincountInputs","BroadcastArgsProgram","broadcastArgsConfig","BroadcastArgs","s0","s1","s0TensorInfo","s1TensorInfo","s0Vals","s1Vals","broadcastShape","s0Size","s1Size","notEqual","cpuNotEqual","notEqualConfig","NotEqual","realConfig","Real","castConfig","Cast","cast","zerosTensor","tf","zeros","floatX","realPart","hasEncodingLoss","resultType","int","zerosTensorInfo","ceilConfig","Ceil","ClipVec4Program","ClipProgram","clipByValueConfig","ClipByValue","clipValueMin","clipValueMax","ComplexAbsProgram","makeComplexComponentTensorInfo","complexTensor","complexPart","complexAbsConfig","ComplexAbs","programInputs","ConcatProgram","computeOutShape","offsetLength","lastIndex","lastShiftIndex","imagConfig","Imag","reals","imags","realConcated","imagConcated","r","runOnCpu","tensors2D","innerSize","inputsValShapes","finalOutShape","outInfo","maxInputNum","maxStorageBuffersPerShaderStage","reducedInputs","subArray","computeTensors2D","reshapedResult","assertParamsConsistent","$inputs","concatConfig","Concat","Conv2DMMProgram","isChannelsLast","inChannels","outChannels","matMulSource","elementsSize","innerElementSizeX","innerElementSizeW","coordASnippet","coordResSnippet","xHight","xWidth","readXSnippet","getXSnippet","sampleX","sampleW","getWSnippet","resType","aType","bType","conv2dCommonSnippet","Conv2DNaiveProgram","Im2ColProgram","rowDim","colDim","getShapeForBatchMatMul","conv2DImpl","sameSize","useNaiveConv2d","xReshaped","filterReshaped","sharedDim","conv2dByMatMul","x2ColShape","im2ColProgram","x2Col","conv2dWithIm2Col","inputVar","conv2DConfig","Conv2D","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","Conv2DDerInputProgram","channelDim","vec4Snippet","Conv2DDerFilterProgram","filterShape","Conv3DDerFilterProgram","Conv3DDerInputProgram","conv2DBackpropFilterConfig","Conv2DBackpropFilter","Conv2DDerInputMMProgram","conv2dTransposeCommonSnippet","conv2DBackpropInputConfig","Conv2DBackpropInput","Conv3DNaiveProgram","conv3DConfig","Conv3D","computeConv3DInfo","dilationDepth","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","cos","cosConfig","Cos","cosh","coshConfig","Cosh","CropAndResizeProgram","channnel","boxShape","cropSize","method","numBoxes","methodId","cropHeightBiggerThan1","cropWidthBiggerThan1","inputHeightFloat","inputWidthFloat","heightRatio","heightScale","inY","widthRatio","widthScale","inX","cropAndResizeConfig","CropAndResize","image","boxes","boxInd","extrapolationValue","CumOpType","CumProgram","exclusive","reverse","initVal","Prod","val","condition","idxString","getFinalCoord","cumImpl","permutation","permutedX","permutedAxis","log2","prevResult","reverseTransposedResult","getUndoAxesPermutation","cumprodConfig","Cumprod","cumsumConfig","Cumsum","Sum","denseBincountConfig","DenseBincount","xRankOne","DepthToSpaceProgram","getHeightCoordString","getWidthCoordString","getDepthCoordString","getOutputDepthSize","getInputSamplingString","depthToSpaceConfig","DepthToSpace","blockSize","outputHeight","outputWidth","outputDepth","DepthwiseConv2DNCHWSharedProgram","hasPreluActivation","tileAHeight","DepthwiseConv2DVec4Program","virtualWidth","virtualOutputShape","xNumber","DepthwiseConv2DProgram","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","$dilations","DepthwiseConv2DDerFilterProgram","DepthwiseConv2DDerInputProgram","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","DiagProgram","diagConfig","Diag","flat","Dilation2DProgram","dilation2DConfig","Dilation2D","computeDilation2DInfo","Dilation2DBackpropInputProgram","Dilation2DBackpropFilterProgram","dilation2DBackpropFilterConfig","Dilation2DBackpropFilter","dilation2DBackpropInputConfig","Dilation2DBackpropInput","DrawProgram","textureFormat","calculateResult","drawConfig","Draw","canvas","options","imageOptions","alpha","canvasWebGPU","gpuContext","numChannels","STORAGE_BINDING","info","canvas2dContext","multiplyKernelFunc","cpuMultiply","multiplyConfig","Multiply","sumConfig","einsumConfig","Einsum","equation","allDims","summedDims","idDims","decodeEinsumEquation","checkEinsumDimSizes","path","steps","getEinsumComputePath","nSteps","numDimsRemaining","tensorsToDispose","idTerm","permutationIndices","expandDims","dimsToExpand","getEinsumPermutation","isIdentityPermutation","elu","eluConfig","Elu","eluGradConfig","EluGrad","equal","cpuEqual","equalConfig","Equal","erf","erfConfig","Erf","expConfig","Exp","$dim","expandDimsConfig","ExpandDims","expm1Config","Expm1","FFTProgram","fftImpl","inverse","inputSize","innerDimensionSize","input2D","PI","imagPart","complexOutputReshaped","fftConfig","FFT","FlipLeftRightProgram","imageShape","flipLeftRightConfig","FlipLeftRight","floorConfig","Floor","floorDiv","floorDivConfig","FloorDiv","FromPixelsProgram","importVideo","textureLoad","fromPixelsConfig","FromPixels","pixels","isVideo","HTMLVideoElement","isImage","HTMLImageElement","isCanvas","HTMLCanvasElement","isImageBitmap","ImageBitmap","videoWidth","videoHeight","isVideoOrImage","newWillReadFrequently","fromPixels2DContext","RENDER_ATTACHMENT","TEXTURE_BINDING","copyExternalImageToTexture","imageData","pixelArray","BatchNormProgram","meanShape","varianceShape","offsetShape","scaleShape","offsetSnippet","scaleSnippet","fusedBatchNormConfig","FusedBatchNorm","scale","variance","varianceEpsilon","webGPUBackend","batchNormInputs","fusedConv2DConfig","FusedConv2D","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","eitherStridesOrDilationsAreOne","GatherNDProgram","sliceDim","strideString","gatherNdConfig","GatherNd","prepareAndValidate","flattenIndices","flattenX","outValue","GatherProgram","currentCoords","getSourceCoords","gatherV2","batchDims","parsedAxis","shapeInfo","segment_util","collectGatherOpShapeInfo","indicesSize","outerSize","dimSize","indicesValues","indicesBuffer","xValues","xBuffer","gatherV2Config","GatherV2","greater","cpuGreater","greaterConfig","Greater","greaterEqual","cpuGreaterEqual","greaterEqualConfig","GreaterEqual","ifftConfig","IFFT","isFinite","isFiniteConfig","IsFinite","isInf","isInfConfig","IsInf","isNaNConfig","IsNan","leakyReluConfig","LeakyRelu","less","cpuLess","lessConfig","Less","lessEqual","cpuLessEqual","lessEqualConfig","LessEqual","LinSpaceProgram","linSpaceConfig","LinSpace","logConfig","Log","log1p","log1pConfig","Log1p","logicalAnd","logicalAndConfig","LogicalAnd","logicalNot","logicalNotConfig","LogicalNot","logicalOr","logicalOrConfig","LogicalOr","powOperatorSnippet","LRNProgram","LRNSharedProgram","radius","maxAllowRadius","elementsPerWorkgroup","lrnConfig","LRN","depthRadius","beta","LRNGradProgram","lrnGradConfig","LRNGrad","maximum","cpuMaximum","maximumConfig","Maximum","maxPoolConfig","MaxPool","maxPool3DConfig","MaxPool3D","maxPoolProgram","MaxPool2DBackpropProgram","MaxPool3DBackpropProgram","maxPool3DGradConfig","MaxPool3DGrad","maxPool3dPositionsProgram","maxPool3dPositions","maxPool3dBackpropProgram","maxPoolGradConfig","MaxPoolGrad","maxPoolPositionsProgram","maxPoolPositions","maxPoolBackpropProgram","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","includeBatchInIndex","poolOutput","minConfig","Min","minimum","cpuMinimum","minimumConfig","Minimum","MirrorPadProgram","paddings","mode","p","shaderStart","shaderEnd","shaderOutC","unpackedCoords","mirrorPadConfig","MirrorPad","mod","modConfig","Mod","MultinomialProgram","numSamples","SoftmaxProgram","softmax","logits","logitsReshaped","resReshaped","softmaxConfig","Softmax","multinomialConfig","Multinomial","seed","normalized","probs","numOutcomes","negConfig","Neg","nonMaxSuppressionV3Config","NonMaxSuppressionV3","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","selectedIndices","kernel_impls","nonMaxSuppressionV3Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","nonMaxSuppressionV5Impl","OneHotProgram","depth","oneHotConfig","OneHot","onValue","offValue","zerosLike","zerosLikeConfig","ZerosLike","onesLikeConfig","OnesLike","onesLike","packConfig","Pack","assertShapesMatch","expandedT","padCommon","fillZero","PadProgram","padV2Config","PadV2","constantValue","pow","powConfig","Pow","preluConfig","Prelu","prodConfig","rangeConfig","Range","realDiv","realDivConfig","RealDiv","reciprocal","reciprocalConfig","Reciprocal","relu","reluConfig","Relu","relu6","relu6Config","Relu6","ResizeBilinearProgram","newHeight","newWidth","resizeBilinearConfig","ResizeBilinear","images","alignCorners","halfPixelCenters","ResizeBilinearBackpropProgram","resizeBilinearGradConfig","ResizeBilinearGrad","xHeight","yHeight","yWidth","effectiveXSize","effectiveYSize","invHeightScale","invWidthScale","winHeight","winWidth","ResizeNearestNeighborProgram","sourceFracIndexRC","resizeNearestNeighborConfig","ResizeNearestNeighbor","ResizeNearestNeigborBackpropProgram","resizeNearestNeighborGradConfig","ResizeNearestNeighborGrad","ReverseProgram","reverseConfig","Reverse","xShape4D","dims4D","ax","RotateProgram","fillValue","fillSnippet","rotateWithOffsetConfig","RotateWithOffset","radians","center","centerX","centerY","getImageCenter","sin","parseFloat","toFixed","round","roundConfig","Round","rsqrt","rsqrtConfig","Rsqrt","ScatterProgram","flattenXShape","indicesRank","updatesRank","sliceDimGreaterThanOne","stridesType","indicesString","indicesSnippet","outCoordsString","getUpdatesCoordsFromFlatIndex","updatesSnippet","scatterNdConfig","ScatterNd","calculateShapes","SearchSortedProgram","side","searchSortedConfig","SearchSorted","sortedSequence","SelectProgram","cRank","cCoords","abCoords","cCoordVars","abCoordVars","selectConfig","Select","selu","seluConfig","Selu","sigmoid","sigmoidConfig","Sigmoid","signConfig","Sign","sinConfig","Sin","sinh","sinhConfig","Sinh","softplus","softplusConfig","Softplus","SpaceToBatchNDProgram","paddedXShape","reshapedPaddedXShape","paddedXShapeStridesShapeLength","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXShapeStrides","paddedXT","SparseSegmentSumProgram","sparseSize","SparseSegmentIdCountProgram","segmentIdsShape","SparseSegmentMeanProgram","sparseSegmentReduce","isSum","segmentSize","$segmentIds","sparseSegmentSum","$sparseSegmentSum","sparseSegmentIdCount","$sparseSegmentIdCount","sparseSegmentMean","$sparseSegmentMean","sparseSegmentMeanConfig","SparseSegmentMean","sparseSegmentSumConfig","SparseSegmentSum","TileProgram","uniformPrefix","tile","buf","tileConfig","Tile","sparseToDenseConfig","SparseToDense","sparseIndices","sparseValues","updatesBuf","$defaultValue","$sparseIndices","$sparseValues","$denseValues","denseValues","splitVConfig","SplitV","numOrSizeSplits","splitSizes","prepareSplitSize","sliceT","sqrtConfig","Sqrt","squareConfig","Square","squaredDifference","squaredDifferenceConfig","SquaredDifference","stepConfig","Step","StridedSliceProgram","newCoords","outputAxis","stridedSliceConfig","StridedSlice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","finalShapeSparse","finalShape","isIdentity","sliceDim0","isSimpleSlice","$end","$strides","sliceInfo","stringNGramsConfig","StringNGrams","$data","$dataSplits","sub","cpuSub","subConfig","Sub","tan","tanConfig","Tan","tanh","tanhConfig","Tanh","tensorScatterUpdateConfig","TensorScatterUpdate","flattenTensor","SwapProgram","MergeProgram","disposeIntermediateTensorInfoOrNull","roundUpToPow2","pow2","topKConfig","TopK","x2D","kPow2","lastDimPow2","getInputs","runSwap","dir","inc","uniformDataSwap","prevIndices","len","mergeProgram","uniformDataMerge","prevValues","TransformProgram","transformConfig","Transform","transforms","interpolation","fillMode","imageHeight","imageWidth","interpolationModeId","fillModeId","unpackConfig","Unpack","UnsortedSegmentSumProgram","kernelConfigs","UnsortedSegmentSum","numSegments","a2D","segResult","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;+iBAmBA,MAAMA,EAAMC,EAAGA,MAGfD,EAAIE,aAAa,qCAAqC,IAAM,KAM5DF,EAAIE,aAAa,sBAAsB,KAAM,IAO7CF,EAAIE,aAAa,8BAA8B,KAAO,IAMtDF,EAAIE,aAAa,qCAAqC,KAAM,IAM5DF,EAAIE,aAAa,4BAA4B,KAAM,IAQnDF,EAAIE,aAAa,qCAAqC,IAAM,MAM5DF,EAAIE,aAAa,2BAA2B,KAAM,IAKlDF,EAAIE,aAAa,kCAAkC,KAAM,IAKzDF,EAAIE,aAAa,iCAAiC,KAAM,IAOxDF,EAAIE,aAAa,sDAAsD,IAAM,IAK7EF,EAAIE,aAAa,sCAAsC,KAAM,IAO7DF,EAAIE,aAAa,uBAAuB,IAAM,KAG9CF,EAAIE,aAAa,8BAA8B,KAAM,UC5ExCC,EAKXC,YAAYC,GACNA,IACFC,KAAKC,OAASF,EAAYE,OAC1BD,KAAKE,aAAeH,EAAYG,aAChCF,KAAKG,mBAAqBH,KAAKI,wBAElC,CAEOA,wBACN,GAAIJ,KAAKK,UAAW,CAClB,GAAIL,KAAKE,aAAaI,WAAW,OAC/B,OAAOC,OAAOP,KAAKE,aAAaM,MAAM,QACjC,GAAIR,KAAKE,aAAaI,WAAW,MACtC,OAAO,EAEV,CACD,OAAO,CACR,CAEDD,UACE,MAAuB,UAAhBL,KAAKC,MACb,QC1BUQ,EASXX,YAAoBY,GAAAV,KAAMU,OAANA,EARZV,KAAcW,eAAG,EACjBX,KAAcY,eAAG,EACjBZ,KAAAa,YAAwC,IAAIC,IAC5Cd,KAAAe,YAAwC,IAAID,IAE7Cd,KAAYgB,aAAG,EACfhB,KAAiBiB,kBAAG,CAEc,CAEzCC,cACIC,EAAcC,EAA4BC,GAAmB,EAC7DC,GAAQ,GACV,IAAIC,EACJ,MAAMC,EAAMC,EAAaN,EAAMC,GA0B/B,OAxBIE,GACGtB,KAAKa,YAAYa,IAAIF,IACxBxB,KAAKa,YAAYc,IAAIH,EAAK,IAGxBxB,KAAKa,YAAYe,IAAIJ,GAAKK,OAAS,GACrCN,EAASvB,KAAKa,YAAYe,IAAIJ,GAAKM,MACnC9B,KAAKY,mBAELW,EAASvB,KAAKU,OAAOqB,aAAa,CAACZ,OAAMC,QAAOC,qBAChDrB,KAAKiB,mBAAqBE,KAG5BI,EAASvB,KAAKU,OAAOqB,aAAa,CAACZ,OAAMC,QAAOC,qBAChDrB,KAAKiB,mBAAqBE,GAGvBnB,KAAKe,YAAYW,IAAIF,IACxBxB,KAAKe,YAAYY,IAAIH,EAAK,IAE5BxB,KAAKe,YAAYa,IAAIJ,GAAKQ,KAAKT,GAC/BvB,KAAKW,iBACLX,KAAKgB,cAAgBG,EAEdI,CACR,CAEDU,cAAcV,EAAmBD,GAAQ,GACvC,GAA8B,IAA1BtB,KAAKa,YAAYM,KACnB,OAGF,MAAMA,EAAOI,EAAOJ,KAGdK,EAAMC,EAAaN,EAFXI,EAAOH,OAGfc,EAAclC,KAAKe,YAAYa,IAAIJ,GACnCW,EAAQD,EAAYE,QAAQb,GAClC,GAAIY,EAAQ,EACV,MAAM,IAAIE,MAAM,4CAElBH,EAAYC,GAASD,EAAYA,EAAYL,OAAS,GACtDK,EAAYJ,MACZ9B,KAAKW,iBACLX,KAAKgB,cAAgBG,EAEjBG,GACFtB,KAAKa,YAAYe,IAAIJ,GAAKQ,KAAKT,GAC/BvB,KAAKY,mBAELW,EAAOe,UACPtC,KAAKiB,mBAAqBE,EAE7B,CAEDoB,oBACE,OAAOvC,KAAKW,cACb,CAED6B,oBACE,OAAOxC,KAAKY,cACb,CAED6B,UACEzC,KAAKa,YAAY6B,SAAQ,CAACC,EAASnB,KACjCmB,EAAQD,SAAQnB,IACdA,EAAOe,SAAS,GAChB,IAGJtC,KAAKe,YAAY2B,SAAQ,CAACC,EAASnB,KACjCmB,EAAQD,SAAQnB,IACdA,EAAOe,SAAS,GAChB,IAGJtC,KAAKa,YAAc,IAAIC,IACvBd,KAAKe,YAAc,IAAID,IACvBd,KAAKW,eAAiB,EACtBX,KAAKY,eAAiB,EACtBZ,KAAKgB,aAAe,EACpBhB,KAAKiB,kBAAoB,CAC1B,EAGH,SAASQ,EAAaN,EAAcC,GAClC,MAAO,GAAGD,KAAQC,GACpB,OCxGawB,EASX9C,YAAoBY,GAAAV,KAAMU,OAANA,EARZV,KAAe6C,gBAAG,EAClB7C,KAAe8C,gBAAG,EAClB9C,KAAA+C,aAA0C,IAAIjC,IAC9Cd,KAAAgD,aAA0C,IAAIlC,IAE/Cd,KAAYgB,aAAG,EACfhB,KAAiBiB,kBAAG,CAEc,CAEzCgC,eACIC,EAAeC,EAAgBC,EAC/BhC,GACF,MACMiC,EAAWH,EAAQC,EADDG,EAAmBF,GAErC5B,EAAM+B,EAAcL,EAAOC,EAAQC,EAAQhC,GAYjD,GAXKpB,KAAK+C,aAAarB,IAAIF,IACzBxB,KAAK+C,aAAapB,IAAIH,EAAK,IAGxBxB,KAAKgD,aAAatB,IAAIF,IACzBxB,KAAKgD,aAAarB,IAAIH,EAAK,IAG7BxB,KAAKgB,cAAgBqC,EACrBrD,KAAK6C,kBAED7C,KAAK+C,aAAanB,IAAIJ,GAAKK,OAAS,EAAG,CACzC7B,KAAK8C,kBAEL,MAAMU,EAAaxD,KAAK+C,aAAanB,IAAIJ,GAAKiC,QAE9C,OADAzD,KAAKgD,aAAapB,IAAIJ,GAAKQ,KAAKwB,GACzBA,CACR,CAEDxD,KAAKiB,mBAAqBoC,EAE1B,MAAMG,EAAaxD,KAAKU,OAAOgD,cAAc,CAC3CvC,KAAM,CAAC+B,EAAOC,GACdC,SACAhC,UAIF,OAFApB,KAAKgD,aAAapB,IAAIJ,GAAKQ,KAAKwB,GAEzBA,CACR,CAEDG,eAAeC,GACb,GAA+B,IAA3B5D,KAAK+C,aAAa5B,KACpB,OAGF,MAAM+B,EAAQU,EAAQV,MAChBC,EAASS,EAAQT,OACjBC,EAASQ,EAAQR,OAGjB5B,EAAM+B,EAAcL,EAAOC,EAAQC,EAF3BQ,EAAQxC,OAGjBpB,KAAK+C,aAAarB,IAAIF,IACzBxB,KAAK+C,aAAapB,IAAIH,EAAK,IAG7BxB,KAAK+C,aAAanB,IAAIJ,GAAKQ,KAAK4B,GAChC5D,KAAK8C,kBACL9C,KAAK6C,kBAEL,MAAMgB,EAAc7D,KAAKgD,aAAapB,IAAIJ,GACpCsC,EAAeD,EAAYzB,QAAQwB,GACzC,GAAIE,EAAe,EACjB,MAAM,IAAIzB,MACN,4EAGNwB,EAAYE,OAAOD,EAAc,GACjC,MACMT,EAAWH,EAAQC,EADDG,EAAmBF,GAE3CpD,KAAKgB,cAAgBqC,CACtB,CAEDW,qBACE,OAAOhE,KAAK6C,eACb,CAEDoB,qBACE,OAAOjE,KAAK8C,eACb,CAEDL,UACEzC,KAAK+C,aAAaL,SAAQ,CAACwB,EAAU1C,KACnC0C,EAASxB,SAAQkB,IACfA,EAAQtB,SAAS,GACjB,IAGJtC,KAAKgD,aAAaN,SAAQ,CAACwB,EAAU1C,KACnC0C,EAASxB,SAAQkB,IACfA,EAAQtB,SAAS,GACjB,IAGJtC,KAAK+C,aAAe,IAAIjC,IACxBd,KAAKgD,aAAe,IAAIlC,IACxBd,KAAK6C,gBAAkB,EACvB7C,KAAK8C,gBAAkB,EACvB9C,KAAKgB,aAAe,EACpBhB,KAAKiB,kBAAoB,CAC1B,EAGH,SAASsC,EACLL,EAAeC,EAAgBC,EAC/BhC,GACF,MAAO,GAAG8B,KAASC,KAAUC,KAAUhC,GACzC,CAEA,SAASkC,EAAmBF,GAC1B,GAAe,eAAXA,EACF,OAAO,GAEP,MAAM,IAAIf,MAAM,GAAGe,sBAEvB,CCzHgB,SAAAe,EACZC,EAAsBC,GACxB,GAAIC,KAAKC,OAAOH,GAAc,EAC5B,MAAM,IAAI/B,MAAM,4DAGlB,MAAMmC,EAAYJ,EAAWvC,OAEvB4C,EAAQL,EAAWM,KAAIC,GAAK,GAAGN,KADlB,SAC6CM,OAC1DC,EAAU,IAAIC,MAAML,EAAY,GACtCI,EAAQJ,EAAY,GAAKC,EAAMD,EAAY,GAC3C,IAAK,IAAIM,EAAIN,EAAY,EAAGM,GAAK,IAAKA,EACpCF,EAAQE,GAAK,IAAIF,EAAQE,EAAI,QAAQL,EAAMK,EAAI,MAGjD,OAAOF,CACT,CAEO,MAAMG,EACT,CAACC,EAAaC,EAAWC,IACV,UAATA,EACK,aAAaF,mBAAqBC,OAIlC,+HAI6CA,mHAERD,0KC5BpD,IAAYG,GAAZ,SAAYA,GACVA,EAAAA,EAAA,YAAA,GAAA,cACAA,EAAAA,EAAA,KAAA,GAAA,MACD,CAHD,CAAYA,IAAAA,EAGX,CAAA,IAoCM,MAAMC,EACT,CAAC1E,EAAmB2E,EAAwBC,EAC3CC,EAAoBC,KAEnB,MACMC,EAoIZ,SACIC,EAAwBC,EACxBN,GACF,MAAMO,EAA2B,GAC3BC,EAAoBR,EAAQS,cAAc,GAC5CT,EAAQS,cAAc,GAAKT,EAAQS,cAAc,GAwBrD,GAvBAT,EAAQU,gBACJV,EAAQU,gBAAkBV,EAAQU,gBAAkB,EACxDH,EAAe5D,KAAK,wUAWhBgE,EAAeX,GACX,4BACA,yIAEIQ,iEAMgB,MAAxBR,EAAQY,aAAsB,CAChC,MAAMC,EAAeb,EAAQY,eAAiBd,EAAagB,YACvD,gEACIC,EAAkBT,EAAWU,MAAOhB,EAAQU,qBAChD,0DACIK,EAAkBV,EAAU,GAAGW,MAAOhB,EAAQU,qBAChDO,EAC0B,IAA5BX,EAAWlB,MAAM5C,OAAe,YAAc,MAClD+D,EAAe5D,KAAK,2DAEMsE,mIAMpBJ,4EAGN,MAAMK,EAAiBC,EAAqBnB,GAC5C,MAAO,CACLoB,EACAb,EAAec,KAAK,MACpBC,EAA0BhB,EAAWlB,OACrCY,EAAQuB,cACRC,EAAqBN,EAAgBlB,IACrCqB,KAAK,KACR,CAED,IAAII,EACAC,EACAC,EAAqB,gDACzB3B,EAAQ4B,cAAcvE,SAAQ,CAACwE,EAAGpC,KAChC,MAAMqC,EAAcC,EAAkB1B,EAAUZ,GAAGL,MAAM5C,QACzDmF,GACI,GAAGE,EAAEG,OAAO,GAAGC,cAAgBJ,EAAEK,MAAM,aAAaJ,MACxDL,EAAgBpB,EAAUZ,GAAGL,MAAM5C,OAAS,EAC5CkF,EAAkBK,EAAkBN,GACpCE,GACI,GAAGE,EAAEG,OAAO,GAAGC,cAAgBJ,EAAEK,MAAM,mBACnCR,KAAmB,IAE7B,MAAMS,EAAiBJ,EAAkBzB,EAAWlB,MAAM5C,QAC1DmF,GAAsB,cAAcQ,MACpCV,EAAgBnB,EAAWlB,MAAM5C,OAAS,EAC1CkF,EAAkBK,EAAkBN,GACpCE,GAAsB,+BACID,MAEtB1B,EAAQlE,OACV6F,GAAsB,gBAGpB3B,EAAQoC,WACVT,GAAsB3B,EAAQoC,UAEhCT,GAAsB,KACtBA,EAiiBF,SAAyBU,GAEvB,MAAMC,EAAc,wBACpBD,EAAgBA,EAAcE,QAAQD,GAAcnH,GAC3C,cAAgBA,IAIzB,MAAMqH,EAAc,wBAIpB,OAHAH,EAAgBA,EAAcE,QAAQC,GAAa,CAACC,EAAGC,EAAIC,IAClD,MAAMD,iBAAkBC,KAGnC,CA9iBuBC,CAAgBjB,GAErCpB,EAAe5D,KAAKgF,GAGhB3B,EAAQ6C,OACVtC,EAAe5D,KAAK,4FAIpB4D,EAAe5D,KAAK,wEAEhBoE,EAAkBT,EAAWU,MAAOhB,EAAQU,4BAGlDV,EAAQ4B,cAAcvE,SAAQ,CAACwE,EAAGpC,KAChCc,EAAe5D,KAAK,8BACG,EAAI8C,yBAAyBoC,YAChD7B,EAAQ8C,mBACJ/B,EACIV,EAAUZ,GAAGuB,MAAOhB,EAAQ8C,mBAAmBrD,IACnDsB,EAAkBV,EAAUZ,GAAGuB,MAAOhB,EAAQU,+BAChD,IAGmB,KAAvBiB,GACFpB,EAAe5D,KAAK,8BAEhB,EAAIqD,EAAQ4B,cAAcpF,oDAIhC,MAAMuG,EAyUR,SACIC,EACAC,GACF,MAAMpB,EAACA,EAACqB,EAAEA,EAAI,GAAEC,EAAEA,EAAI,IAAMF,EAEtBG,EAAUJ,EAASxG,OACnB6G,EAAOxB,EAAErF,OAAS0G,EAAE1G,OAAS2G,EAAE3G,OAGrC,GAAI6G,IAASD,EACX,MAAO,GAGT,GAAIvB,EAAErF,SAAW4G,EAAS,CAOxB,MALgB,2BADFrB,EAAkBqB,oGAOjC,CAED,IAAIE,EAAsB,GAC1B,MAAMC,EAAO,CAAC1B,EAAGqB,EAAGC,GAEpB,IAAK,IAAI1D,EAAI,EAAGA,EAAI8D,EAAK/G,OAAQiD,IAAK,CACpC,MAAM+D,EAAMD,EAAK9D,GAEjB,GAAmB,IAAf+D,EAAIhH,OAIR,GAAmB,IAAfgH,EAAIhH,OACN8G,GAAuB,QAAQE,EAAI,qBAAqB/D,WACnD,CACL,MAAMF,EAAUT,EAA2B0E,EAAK,qBAChDF,GAAuB,YAAY7D,oBAAoBA,OACvD,IAAK,IAAIgE,EAAI,EAAGA,EAAIlE,EAAQ/C,OAAQiH,IAClCH,GAAuB,QAAQE,EAAIC,aAAahE,OAAOF,EAAQkE,MAE3DA,IAAMlE,EAAQ/C,OAAS,EACzB8G,GAAuB,QAAQE,EAAIC,EAAI,aAC3BhE,QAAQ+D,EAAIC,QAAQlE,EAAQkE,MAExCH,GACI,QAAQ7D,YAAYA,QAAQ+D,EAAIC,QAAQlE,EAAQkE,KAGzD,CACF,CAED,MAAMC,EAAa,GACnB,IAAK,IAAIjE,EAAI,EAAGA,EAAI4D,EAAM5D,IACxBiE,EAAW/G,KAAK,IAAI8C,KAGtB,MAAMuB,EAAQe,EAAkBsB,GAChC,IAAIM,EAAU,2BAA2B3C,UACvCsC,MAEwB,IAAtBI,EAAWlH,OACbmH,GAAW,UAAU3C,UAErB2C,GAAW,UAAU3C,KAAS0C,EAAWrC,KAAK,WAGhD,OAAOsC,CACT,CA5YMC,CAAuBtD,EAAWlB,MAAOY,EAAQiD,gBAE/CY,EAAU,CACdzC,EAAeb,EAAec,KAAK,MAAQyC,EAC3CxC,EAA0BhB,EAAWlB,OAAQ2D,EAC7CgB,EAAgCzD,EAAWlB,MAAM5C,SAE9CwD,EAAQ6C,QACXgB,EAAQlH,KAkdZ,SACIqG,EAAoBgB,EAAyBC,GAC/C,MAAMb,EAAUJ,EAASxG,OACnB0H,EAAUnD,EAAkBiD,EAAeC,GACjD,IAAIN,EACA,gDAAgDQ,EAAYF,oCACtCC,2EAIlBC,EAAYF,EAAW,wCACLC,yBAG1B,GAAId,GAAW,EAAG,CAChB,MAAMG,EAAO,CAAC,KAAM,KAAM,KAAM,KAAM,KAAM,MAAMrB,MAAM,EAAGkB,GACrDvD,EAAOkC,EAAkBqB,GAE/BO,GAAW,gCACcJ,EAAKlE,KAAIC,GAAK,GAAGA,YAAW+B,KAAK,kBACtD8C,EAAYF,2DAC+BpE,KAAQ0D,EAAKlC,KAAK,+CAE/C,IAAd4C,EAAkB,GAAK,MAAMA,wDAG7BV,EAAKlE,KAAIC,GAAK,GAAGA,YAAW+B,KAAK,kBACjC8C,EAAYF,EAAW,+DACoBpE,KAAQ0D,EAAKlC,KAAK,kDAE/C,IAAd4C,EAAkB,GAAK,MAAMA,6BAGlC,CAED,OAAON,CACT,CAtfiBS,CACT9D,EAAWlB,MAAOkB,EAAWU,MAAOhB,EAAQU,kBAGlDV,EAAQ4B,cAAcvE,SAAQ,CAACwE,EAAGpC,KAChCoE,EAAQlH,KAAK,GAAG2E,EAA0BjB,EAAUZ,GAAGL,MAAOyC,KAAK,IAGrE,MAAMwC,EACFhE,EACKhB,KACG,CAACwC,EAAGpC,IAmSlB,SACIY,EAAsB2C,EAAoBiB,EAC1C9C,GACF,IAAImD,EAjIN,SACIjE,EAAsB4D,GACxB,MAAMM,EAAUlE,EAAUmE,KACpBnB,EAAOhD,EAAUjB,MAAM5C,OACvBqD,EAAOkC,EAAkBsB,GACzBoB,EAAW,MAAQF,EAAQvC,OAAO,GAAG0C,cAAgBH,EAAQrC,MAAM,GACnEqB,EAAO,CAAC,KAAM,KAAM,KAAM,KAAM,KAAM,MAAMrB,MAAM,EAAGmB,GACrDsB,EAASpB,EAAKlE,KAAIC,GAAK,GAAGA,YAAW+B,KAAK,MAEhD,GAAIgC,EAAO,EACT,MAAO,cACAoB,UAAiBN,EAAYF,wBACvBE,EAAYF,MAAcM,wBAKzC,MAAMK,EACF,YAAYL,EAAQvC,OAAO,GAAGC,cAAgBsC,EAAQrC,MAAM,UAChE,IAAI2C,EAAU,GAAGxB,KACJ,IAATA,IACFwB,EAAU,MAGZ,MAAO,YACAJ,KAAYE,SAAcR,EAAYF,sBAChCE,EAAYF,MAAcM,uBACnCM,KAAWhF,KAAQ0D,EAAKlC,KAAK,mBACzBuD,KAA0B,IAAdX,EAAkB,GAAK,MAAMA,oBAGnD,CAkGYa,CAAwBzE,EAAW4D,GAE7B5D,EAAUjB,MACd5C,QAAUwG,EAASxG,SAC7B8H,GApGJ,SACIjE,EAAsB2C,EAAoBiB,EAC1C9C,GACF,MAAMoD,EAAUlE,EAAUmE,KACpBO,EAAiBR,EAAQvC,OAAO,GAAG0C,cAAgBH,EAAQrC,MAAM,GAEjEuC,EAAW,MAAQM,EAAiB,WAEpCC,EAAS3E,EAAUjB,MAAM5C,OACzB4G,EAAUJ,EAASxG,OACnBqD,EAAOkC,EAAkBqB,GAK/B,GAAI6B,EAAAA,KAAKC,YAAY7E,EAAUjB,MAAO4D,IAAa7B,EACjD,MAAO,YACFsD,gCAAuCN,EAAYF,sBAC7CE,EAAYF,MAAcM,qCAGhCE,oBAA2B5E,SAAYsE,EAAYF,sBAC7CE,EAAYF,MAAcM,KACjCnB,EAAU,EAAI,mCACA,WAAyB,IAAda,EAAkB,GAAK,MAAMA,sBAK5D,MAAMkB,EACFC,EAAAA,aAAaC,iBAAiBhF,EAAUjB,MAAO4D,GAC7CsC,EAAWlC,EAAU4B,EAE3B,IAAIjC,EAAgB,GAEpB,GAAe,IAAXiC,EACF,MAAO,YACFP,gCAAuCN,EAAYF,wBAC1Cc,yBAGTN,oBAA2B5E,SAAYsE,EAAYF,wBAC1Cc,kBAKZhC,EADEK,EAAU,GAAK+B,EAAc3I,QAAU,EACzB,cAGZ2I,EAAc9F,KAAIC,GAAK,UAAUiG,EAAajG,EAAIgG,YAC7CjE,KAAK,MAIlB,IAAImE,EAAwB,GAC5B,GAAIpC,EAAU,GAAK4B,EAAS,EAC1BQ,EAAwB,cAExB,GAAIpC,EAAU,EAAG,CACf,MAAMqC,EAAa1D,EAAkBiD,GAC/BU,EACFrF,EAAUjB,MAAMC,KAAI,CAACsG,EAAGlG,IAAM,UAAU8F,EAAa9F,EAAI6F,OACpDjE,KAAK,MACdmE,EAAwB,GAAGC,KAAcC,IAC1C,MACCF,EAAwB,SAI5B,MAAMZ,EACF,YAAYL,EAAQvC,OAAO,GAAGC,cAAgBsC,EAAQrC,MAAM,UAC1D2C,EAAU,GAAGG,KAEnB,MAAO,UACFP,gCAAuCN,EAAYF,gEAEpDlB,iBACOoB,EAAYF,MAAcM,uBAA6BM,KAC9DW,MAA0BZ,KACZ,IAAdX,EAAkB,GAAK,MAAMA,uBAG5BQ,sBAA6B5E,SAAYsE,EAAYF,yCAEtDlB,iBACOoB,EAAYF,MAAcM,uBAA6BM,KAC9DW,MAA0BZ,KACZ,IAAdX,EAAkB,GAAK,MAAMA,eAGnC,CASW2B,CACHvF,EAAW2C,EAAUiB,EAAW9C,IAGtC,OAAOmD,CACT,CA/SwBuB,CACNhE,EAAGvB,EAAWlB,MACdY,EAAQ8C,mBAAqB9C,EAAQ8C,mBAAmBrD,GAC3BO,EAAQU,gBACrCV,EAAQiD,eAAepB,EAAErF,SAAW8D,EAAWlB,MAAM5C,UAC5D6E,KAAK,MACdwC,EAAQlH,KAAK0H,GACbR,EAAQlH,KAAKqD,EAAQuB,eACrB,MAAML,EAAiBC,EAAqBnB,GAC5C6D,EAAQlH,KAAK6E,EAAqBN,EAAgBlB,IAElD,OADe6D,EAAQxC,KAAK,KAE9B,CA1RqByE,CAAW7F,EADP,CAACe,MAAOd,EAAOc,MAAO5B,MAAOc,EAAOd,OACLY,GAC5C+F,EAAS1K,EAAO2K,mBAClB,CAACC,KAAM7F,EAAQ8F,MAAOlG,EAAQvF,YAAY+J,OAE9C,IAAI2B,EAAoB7L,EAAGA,MAAGiC,IAAI,uBAClC,GAA0B,KAAtB4J,EAA0B,CAC5BA,EAAoBA,EAAkBlE,cACtC,MAAMmE,EAAmBD,EAAkBE,MAAM,MACvB,QAAtBF,GACAC,EAAiBE,MACbC,GAAQvG,EAAQwG,UAAUvE,cAAcwE,SAASF,QACvDG,QAAQC,MAAM3G,EAAQwG,WACtBE,QAAQE,MAAMxG,GACdsG,QAAQG,WAEX,CAED,OAAI1G,EACK9E,EAAOyL,2BAA2B,CACvCC,QAAS,CAAChB,SAAQiB,WAAY,UAC9Bd,MAAOlG,EAAQvF,YAAY+J,KAC3ByC,OAAQ,SAGH5L,EAAO6L,sBAAsB,CAClCH,QAAS,CAAChB,SAAQiB,WAAY,UAC9Bd,MAAOlG,EAAQvF,YAAY+J,KAC3ByC,OAAQ,QAEX,EAGM9C,EAAc,CAACF,EAAmBpE,EAAO,SACpD,OAAQoE,GACN,KAAK,EACH,MAAO,GAAGpE,IACZ,KAAK,EACH,MAAO,QAAQA,KACjB,KAAK,EACH,MAAO,QAAQA,KACjB,KAAK,EACH,MAAO,QAAQA,KACjB,QACE,MAAM,IAAI7C,MAAM,GAAGiH,eAAuBpE,uBAC7C,EAGG,SAAUkC,EAAkBsB,GAChC,GAAIA,GAAQ,EACV,MAAO,MACF,GAAa,IAATA,EACT,MAAO,YACF,GAAa,IAATA,EACT,MAAO,YACF,GAAa,IAATA,EACT,MAAO,YACF,GAAa,IAATA,EACT,MAAO,OACF,GAAa,IAATA,EACT,MAAO,OAEP,MAAMrG,MAAM,gBAAgBqG,yBAEhC,CAEM,SAAUkC,EAAazI,GAC3B,GAAc,IAAVA,EACF,MAAO,IACF,GAAc,IAAVA,EACT,MAAO,IACF,GAAc,IAAVA,EACT,MAAO,IACF,GAAc,IAAVA,EACT,MAAO,IACF,GAAc,IAAVA,EACT,MAAO,IACF,GAAc,IAAVA,EACT,MAAO,IAEP,MAAME,MAAM,SAASF,yBAEzB,CAIgB,SAAAqK,KAAuBC,GACrC,IAAIzD,EACJ,OAAQyD,EAAO5K,QACb,KAAK,EACHmH,EAAU,8BAGV,MACF,KAAK,EACHA,EAAU,qBACEyD,EAAO,oBAEnB,MACF,QACE,MAAMpK,MAAM,eAEhB,OAAO2G,CACT,CAEgB,SAAAnC,EACZN,EAAyBlB,GAC3B,IAAI2D,EAgBJ,OAfAA,EAAU,UAkBN,SAAiC3D,GACrC,MAAO,gCACoBA,EAAQS,cAAc,OAC7CT,EAAQS,cAAc,OAAOT,EAAQS,cAAc,OAEzD,CAtBO4G,CAAuBrH,4gBAWpBkB,EAAiB,0BAA4B,4BAG9CyC,CACT,CAkMA,MAAMvC,EAAgB,8+EAoDhB0C,EAAe,8FAeLxC,EAA0BlC,EAAiBoF,EAAO,IAChE,MAAMnB,EAAOjE,EAAM5C,OACbiI,EAAoB,KAATD,EACb,MAAMA,EAAKxC,OAAO,GAAG0C,cAAgBF,EAAKtC,MAAM,oBAChD,qBACEoF,EAAuB,KAAT9C,EAChB,GAAGA,EAAKxC,OAAO,GAAGC,cAAgBuC,EAAKtC,MAAM,iBAC7C,kBAEJ,GAAImB,GAAQ,EACV,MAAO,MAAMoB,0CAGf,MAAMlF,EAAU0F,EAAAA,KAAKsC,eAAenI,GAC9B4B,EAAQe,EAAkBsB,GAE1BmE,EAAmB,GACzB,IAAK,IAAI/H,EAAI,EAAGA,EAAI4D,EAAM5D,IACxB+H,EAAO7K,KAAK,IAAI8C,KAGlB,GAAuB,IAAnBF,EAAQ/C,OACV,MAAO,UAAUiI,kEAEb6C,qCAA+CA,6CAIrD,IAAI3D,EAeJ,OAdAA,EAAU,sBACNpE,EACKF,KAAI,CAACoD,EAAGhD,IAQA,GAPO,OAAO+H,EAAO/H,0BACxB6H,KAAe/B,EAAa9F,SAClBA,IAAMF,EAAQ/C,OAAS,EACjC,OAAOgL,EAAO/H,EAAI,iBAAiB+H,EAAO/H,iBACtC6H,KAAe/B,EAAa9F,KAChC,qBAAqB+H,EAAO/H,iBAAiB6H,KACzC/B,EAAa9F,UAGtB4B,KAAK,IAEP,YACAoD,qBAA4BzD,cAC7B2C,mBACO3C,KAASwG,EAAOnG,KAAK,mBAGpC,CAwNA,SAAS0C,EAAgCX,GACvC,IAAIO,EAAU,GACd,OAAQP,GACN,KAAK,EACL,KAAK,EACHO,GAAW,8GAKX,MACF,KAAK,EACHA,GAAW,iKAKX,MACF,KAAK,EACHA,GAAW,+LAKX,MACF,KAAK,EACHA,GAAW,yOAMX,MACF,KAAK,EACHA,GAAW,6UASX,MACF,KAAK,EACHA,GAAW,oYAUX,MACF,QACEsB,EAAIA,KAACwC,QAAO,GAAO,IAAM,eAAerE,aAG5C,OAAOO,CACT,CAEA,SAAShD,EAAeX,GACtB,OAA+B,IAAxBA,EAAQ0H,SAAS,IAAoC,IAAxB1H,EAAQ0H,SAAS,EACvD,UAEgB3G,EAAkBlB,EAAgBoE,EAAY,GAC5D,GAAa,YAATpE,EACF,OAAOsE,EAAYF,EAAW,OACzB,GAAa,UAATpE,GAA6B,SAATA,EAC7B,OAAOsE,EAAYF,EAAW,OAEhC,MAAM,IAAIjH,MAAM,QAAQ6C,sBAC1B,CAsDA,SAASsB,EAAqBnB,GAC5B,QAAIA,EAAQiD,eAAe0E,eAAe,MACF,IAApC3H,EAAQiD,eAAeC,EAAE1G,WAGzBwD,EAAQiD,eAAe0E,eAAe,MACF,IAApC3H,EAAQiD,eAAeE,EAAE3G,OAI/B,CCl0BA,MAAMoL,EAAgBpE,IACpB,IAAIqE,EAAU,EACd,IAAK,IAAIpI,EAAI,EAAGA,EAAI+D,EAAIhH,OAAQiD,IAC9BoI,GAAWrE,EAAI/D,GAEjB,OAAOoI,CAAO,EAiBV,SAAUC,EACZb,EAAmDc,EACnDtH,EAA0C,CAAC,EAAG,EAAG,GACjDuH,EACI,CAAC,EAAG,EAAG,IACb,MAAOC,EAAWC,EAAWC,GAAa,CACxClJ,KAAKmJ,KACDR,EAAaX,EAAOpF,EAAExC,KAAIC,GAAKyI,EAAYzI,OAC1CmB,EAAc,GAAKuH,EAAkB,KAC1Cf,EAAO/D,EAAIjE,KAAKmJ,KACDR,EAAaX,EAAO/D,EAAE7D,KAAIC,GAAKyI,EAAYzI,OAC1CmB,EAAc,GAAKuH,EAAkB,KAC1C,EACXf,EAAO9D,EAAIlE,KAAKmJ,KACDR,EAAaX,EAAO9D,EAAE9D,KAAIC,GAAKyI,EAAYzI,OAC1CmB,EAAc,GAAKuH,EAAkB,KAC1C,GAEb,MAAO,CAACC,EAAWC,EAAWC,EAChC,CAOM,SAAUE,EACZC,EAAmBC,EAAkBC,EACrCC,GAAa,GAQf,MAAMhI,EAA0C,CAAC,EAAG,EAAG,GACjDuH,EAA8C,CAAC,EAAG,EAAG,GAY3D,OAVKS,IACCH,GAAa,IACfN,EAAkB,GAAK,GAGrBO,GAAY,IAAMC,GAAa,KACjC/H,EAAc,GAAK,IAIhB,CAACA,gBAAeuH,oBACzB,CAEM,SAAUU,EACZzB,EAAmDc,EACnDY,GAAS,GACX,GAAIA,EACF,MAAO,CAAC,EAAG,EAAG,GAGhB,MAAMC,EAAOhB,EAAaX,EAAOpF,EAAExC,KAAIC,GAAKyI,EAAYzI,MAClDuJ,EAAOjB,EAAaX,EAAO/D,EAAE7D,KAAIC,GAAKyI,EAAYzI,MASxD,OAAIsJ,GAAQ,EACH,CAAC,EAAG,GAAI,GAEbC,GAAQ,EACH,CAAC,GAAI,EAAG,GAGV,CAAC,GAAI,GAAI,EAClB,CAEM,SAAUC,EACZ7B,EAAmDc,EACnDY,GAAS,GACX,GAAIA,EACF,MAAO,CAAC,EAAG,EAAG,GAGhB,MAAMC,EAAOhB,EAAaX,EAAOpF,EAAExC,KAAIC,GAAKyI,EAAYzI,MAClDuJ,EAAOjB,EAAaX,EAAO/D,EAAE7D,KAAIC,GAAKyI,EAAYzI,MAIxD,OAAIsJ,GAAQ,EACH,CAAC,EAAG,EAAG,GAEZC,GAAQ,EACH,CAAC,EAAG,EAAG,GAGT,CAAC,EAAG,EAAG,EAChB,CAEM,SAAUE,EAAmB3J,GACjC,MAAO,CAACyC,EAAGzC,EAAMC,KAAI,CAACC,EAAGG,IAAMA,IACjC,CAEM,SAAUuJ,EAAmBhI,GACjC,GAAc,YAAVA,GAAiC,UAAVA,GAA+B,SAAVA,GAClC,WAAVA,EACF,OAAO,EACF,GAAc,cAAVA,EACT,OAAO,EAEP,MAAM,IAAIhE,MAAM,iBAAiBgE,IAErC,UAEgBiI,IACd,OAA2B,oBAAXC,QAEsB,oBAAtBC,sBACVC,UAAUC,GAClB,CAEgB,SAAAC,EACZC,EAAiCC,GAC9BhK,MAAMiK,QAAQF,KACjBA,EAAS,CAACA,IAEZA,EAAOlM,SAAQqM,IACJ,MAALA,GACFzE,OAAKwC,OACW,cAAZiC,EAAE1I,OACF,IAAM,GAAGwI,+DAEd,GAEL,CAEA,IAAYG,GAAZ,SAAYA,GACVA,EAAAA,EAAA,oBAAA,GAAA,sBACAA,EAAAA,EAAA,oBAAA,GAAA,sBACAA,EAAAA,EAAA,6BAAA,GAAA,+BACAA,EAAAA,EAAA,oBAAA,GAAA,sBACAA,EAAAA,EAAA,UAAA,GAAA,WACD,CAND,CAAYA,IAAAA,EAMX,CAAA,uRA9Je,SACZC,EAAoBxK,GACtB,GAAIwK,EAASpN,SAAW4C,EAAM5C,OAC5B,MAAM,IAAIQ,MACN,+BAA+B4M,EAASpN,qCACT4C,EAAM5C,oCAG3C,OAAO4C,EAAMyK,OACT,CAACC,EAAaC,IAAmBD,EAAMF,EAASG,IAAY,GAClE,GC8BA,MAAMC,EACF1P,EAAGA,MAAG2P,UAAU,qCA+BpB,MAAaC,UAAsBC,EAAAA,cAiCzBC,aACN,OAAOF,EAAcE,YACtB,CAED3P,YAAYY,EAAmBX,GAE7B,GADA2P,QA1BM1P,KAAA2P,qBAAuB,IAAIC,QAC3B5P,KAAmB6P,oBAAG,EACtB7P,KAAQ8P,UAAG,EACX9P,KAAc+P,eAAG,EAGjB/P,KAAyBgQ,0BAAa,GAKtChQ,KAAkBiQ,mBAAc,KAChCjQ,KAAQkQ,SAAgB,KACxBlQ,KAAamQ,cAAG,EAChBnQ,KAAsBoQ,uBAAgB,GAEtCpQ,KAAsBqQ,uBAAgB,GACtCrQ,KAAYsQ,aAAG,EACftQ,KAAiBuQ,mBAAG,EACpBvQ,KAAuBwQ,yBAAG,GAQ3BC,IACH,MAAM,IAAIpO,MAAM,0CAElBrC,KAAK0Q,cAAgB,GACrB1Q,KAAKU,OAASA,EACdV,KAAK2Q,MAAQjQ,EAAOiQ,MACpB3Q,KAAK4Q,eAAiB,KACtB5Q,KAAK6Q,mBAAqB,KAC1B7Q,KAAKD,YAAc,IAAIF,EAAYE,GACnCC,KAAK8Q,sBAAwB9Q,KAAKU,OAAOqQ,SAASrP,IAAI,mBACtD1B,KAAKgR,8BACDhR,KAAKD,YAAYI,oBAAsB,GAAK,GAAK,EAErDH,KAAKiR,cAAgB,IAAIxQ,EAAcT,KAAKU,QAC5CV,KAAKkR,eAAiB,IAAItO,EAAe5C,KAAKU,QAC9CV,KAAKmR,UAAY,IAAIC,EAAAA,YAAYpR,KAAMqR,EAAAA,UAInC1R,QAAM2R,QAAQ,6BAChBtR,KAAKuR,YAAcC,SAASC,cAAc,UAC1CzR,KAAKuR,YAAYrO,MAAQ,EACzBlD,KAAKuR,YAAYpO,OAAS,EAE1BnD,KAAK0R,aAAe1R,KAAKuR,YAAYI,WAAW,UAChD3R,KAAK0R,aAAaE,UAAU,CAC1BlR,SACA0C,OAAQ,eAGVoO,SAASK,KAAKC,YAAY9R,KAAKuR,aAElC,CAEQQ,iBACP,OAAO,EACR,CASQC,YAAYC,EAAgBC,GAAQ,GAE3C,IAAKlS,KAAKmR,UAAUzP,IAAIuQ,GACtB,OAAO,EAGT,MAAME,EAAanS,KAAKmR,UAAUvP,IAAIqQ,GAOtC,OANIC,EACFC,EAAWC,SAAW,EAEtBD,EAAWC,aAGTD,EAAWC,SAAW,KAIW,MAAjCD,EAAWE,qBACbrS,KAAKgS,YAAYG,EAAWE,mBAAmBC,KAAKL,QACpDjS,KAAKgS,YAAYG,EAAWE,mBAAmBE,KAAKN,SAGlDjS,KAAK2P,qBAAqBjO,IAAIuQ,IAChCjS,KAAKgQ,0BAA0BhO,KAAKiQ,IAC7B,IAGTjS,KAAKwS,gBAAgBP,GACrBjS,KAAKmR,UAAUsB,OAAOR,IAEf,GACR,CAEQS,SACP,MAAO,CACLC,cAAe3S,KAAKiR,cAAcjQ,aAClC4R,uBAAwB5S,KAAKiR,cAAchQ,kBAC3C4R,YAAY,EAEf,CAEOL,gBAAgBP,GACtB,MAAME,EAAanS,KAAKmR,UAAUvP,IAAIqQ,GACjCE,GAAeA,EAAWW,WAK3BX,EAAWY,WAIXZ,EAAWW,oBAAoBE,UACjChT,KAAKiR,cAAchP,cAAckQ,EAAWW,UACnCX,EAAWW,oBAAoBG,YACxCjT,KAAKkR,eAAevN,eAAewO,EAAWW,WAN9CX,EAAWW,SAAW,KASzB,CAGQV,SAASH,GAChB,GAAIjS,KAAKmR,UAAUzP,IAAIuQ,GAAS,CAE9B,OADmBjS,KAAKmR,UAAUvP,IAAIqQ,GACpBG,QACnB,CACD,OAAO,CACR,CAGQc,OAAOjB,GACKjS,KAAKmR,UAAUvP,IAAIqQ,GAC3BG,UACZ,CAGDe,OAAOlB,GACL,GAAIjS,KAAKmR,UAAUzP,IAAIuQ,GAAS,CACXjS,KAAKmR,UAAUvP,IAAIqQ,GAC3BG,UACZ,CACF,CAEQgB,MAAMC,EAAuB5O,EAAiB4B,GAErD,GAAc,cAAVA,GAAmC,MAAVgN,EAC3B,MAAM,IAAIhR,MACN,yEAGN,MAAM4P,EAAS,CAACqB,GAAItT,KAAKyP,cAEzB,OADAzP,KAAKmR,UAAUxP,IAAIsQ,EAAQ,CAAC5L,QAAO5B,QAAO4O,SAAQjB,SAAU,IACrDH,CACR,CAEQsB,KACLtB,EAAgBoB,EAAuB5O,EAAiB4B,EACxD+L,GACF,GAAc,cAAV/L,EACF,MAAM,IAAIhE,MACN,yEAGNrC,KAAKmR,UAAUxP,IAAIsQ,EAAQ,CAAC5L,QAAO5B,QAAO4O,SAAQjB,YACnD,CAEDoB,cACExT,KAAK2Q,MAAM8C,OAAO,CAACzT,KAAK4Q,eAAe8C,WACvC1T,KAAK4Q,eAAiB,KACtB5Q,KAAK6P,oBAAsB,EAE3B7P,KAAK2P,qBAAuB,IAAIC,QAEhC5P,KAAKgQ,0BAA0BtN,SAAQiC,IACrC3E,KAAKwS,gBAAgB7N,GACrB3E,KAAKmR,UAAUsB,OAAO9N,EAAE,IAG1B3E,KAAKqQ,uBAAuB3N,SACxBiR,GAAK3T,KAAKiR,cAAchP,cAAc0R,KAC1C3T,KAAKoQ,uBAAuB1N,SACxBiR,GAAK3T,KAAKiR,cAAchP,cAAc0R,GAAG,KAE7C3T,KAAKgQ,0BAA4B,GACjChQ,KAAKqQ,uBAAyB,GAC9BrQ,KAAKoQ,uBAAyB,EAC/B,CAEDwD,4BACO5T,KAAK4Q,iBACR5Q,KAAK4Q,eAAiB5Q,KAAKU,OAAOmT,uBAErC,CAEDC,wBACM9T,KAAK6Q,qBACP7Q,KAAK6Q,mBAAmBkD,MACxB/T,KAAK6Q,mBAAqB,KAE7B,CAGDmD,oCACE,IAAIC,EACJ,IACEA,QAAkBC,QAAQC,IAAIC,OAAOf,OAAOrT,KAAK0Q,eAIlD,CAHC,MAAO2D,GAEP,MAAM,IAAIhS,MAAMgS,EAAEC,QACnB,CACDF,OAAOG,KAAKvU,KAAK0Q,eAAehM,KAAI,CAAClD,EAAKsD,KACxC9E,KAAK0Q,cAAclP,GAAOyS,EAAUnP,EAAE,GAEzC,CAEMkP,oBAAoBzS,GACzB,GAAI5B,QAAM2R,QAAQ,8BAGhB,OAFAvF,QAAQyI,KACJ,sIACG,KAET,MAAMrT,EAAOI,EAAOJ,KACdsT,EAAgBzU,KAAKiR,cAAc/P,cACrCC,EAAMuT,eAAeC,SAAWD,eAAeE,UACnD5U,KAAK4T,4BACL5T,KAAK8T,wBACL9T,KAAK4Q,eAAeiE,mBAAmBtT,EAAQ,EAAGkT,EAAe,EAAGtT,GACpEnB,KAAKwT,oBAECiB,EAAcK,SAASC,WAAWC,MACxC,MAAM3B,EAASoB,EAAcQ,iBAAiB1N,MAAM,GAgBpD,OAdAkN,EAAcS,QACO,MAAjBT,GACFzU,KAAKiR,cAAchP,cAAcwS,GAK/B9U,QAAM2R,QAAQ,6BAChBhH,EAAIA,KAACwC,YACqBqI,IAAtBnV,KAAK0R,cACL,IAAM,2CACV1R,KAAK0R,aAAa0D,qBAGb/B,CACR,CAEOgC,qBAAqBpD,EAAgBqD,GAE3C,MAAMnD,EAAanS,KAAKmR,UAAUvP,IAAIqQ,GAEtC,OADAE,EAAWkB,OAASiC,EACbnD,EAAWkB,MACnB,CAEQkC,SAAStD,GAChB,MAAME,EAAanS,KAAKmR,UAAUvP,IAAIqQ,IAChCoB,OAACA,EAAMhB,mBAAEA,GAAsBF,EAErC,GAAc,MAAVkB,GAAuC,WAArBlB,EAAW9L,MAC/B,OAAOgN,EAGT,GAAyB,cAArBlB,EAAW9L,MAAuB,CACpC,MAAMmP,EACFxV,KAAKuV,SAASlD,EAAmBC,KAAKL,QACpCwD,EACFzV,KAAKuV,SAASlD,EAAmBE,KAAKN,QACpCyD,EAAcpL,EAAAA,KAAKqL,mCACrBlL,eAAamL,uBAAuBJ,EAAYC,GAAYlU,OAC5D,WAEJ,OADAvB,KAAKqV,qBAAqBpD,EAAQyD,GAC3BA,CACR,CAEI1V,KAAKuQ,oBACRvQ,KAAKuQ,mBAAoB,EACzBxE,QAAQyI,KACJ,uIAIN,MAAMqB,EAAmC,CAAC,SAAU,iBAE9CtU,EAAS4Q,EAAWW,SACpBgD,EAAavU,EAAOJ,KAC1BmJ,EAAAA,KAAKwC,OACDgJ,EAAa,GAAM,GACnB,IAAM,+EAEV,MAAMC,EAAaD,EAAa,EAC1BE,EAAU,IAAIC,YAAYH,GAE1BI,EAAc,IAAKC,EAAe,IAClCC,EACFP,EAAWnR,KAAIoD,GAAK,IAAIuO,gBAAgBH,EAAaC,KACnDG,EAAqB,IAAID,gBAAgBH,EAAaC,GAE5DnW,KAAK8T,wBACLsC,EACK1R,KAAI,CAAC6R,EAASpU,KACb,MAAMqU,EAAUD,EAAQ5E,WAAW,UASnC,OANA6E,EAAQ5E,UAAU,CAChBlR,OAAQV,KAAKU,OACb0C,OAAQ,aACRhC,MAAOqV,gBAAgB9B,SACvB+B,UAAWb,EAAW1T,KAEjBqU,EAAQpB,mBAAmB,IAEnC1Q,KAAI,CAACd,EAASzB,KACb,MACMwU,EACF,CAACzT,EAAeC,EAAgByT,KAC9B5W,KAAK4T,4BACL5T,KAAK4Q,eAAeiG,oBAChB,CACEtV,SACAuV,YAPQZ,KAQRU,UAEF,CACEhT,WAEF,CACEV,QACAC,WAENnD,KAAKwT,cAEL,MAAMgD,EAAUF,EAAmB3E,WAAW,KAAM,CAClDoF,oBAAoB,IAEtBP,EAAQQ,UAAU,EAAG,EAAG9T,EAAOC,GAC/BqT,EAAQS,UAAUb,EAAqBjU,GAAQ,EAAG,GAClD,MAAM+U,EACFV,EAAQW,aAAa,EAAG,EAAGjU,EAAOC,GAAQmS,KACxCoB,EAAYb,EAAW1T,GACvBiV,EACF,IAAIC,kBAAkBrB,EAASY,EAAQ1T,EAAQC,EAAS,GAC5D,IAAK,IAAImU,EAAI,EAAGA,EAAIF,EAAKvV,OAAQyV,GAAK,EACpC,GAAkB,kBAAdZ,EACFU,EAAKE,EAAI,GAAKJ,EAAcI,EAAI,OAC3B,CACL,MAAMC,EAAQL,EAAcI,GAC5BF,EAAKE,GAAKJ,EAAcI,EAAI,GAC5BF,EAAKE,EAAI,GAAKJ,EAAcI,EAAI,GAChCF,EAAKE,EAAI,GAAKC,CACf,CACF,EAGDC,EACFlT,KAAKmT,MAAM1B,EAAU,OACzB,IAAI7S,EAAQgT,EAAa/S,EAASgT,EAAcS,EAAS,EACzD,IAAK,IAAI9R,EAAI,EAAGA,EAAI0S,EAAgB1S,IAElC6R,EAAiBzT,EAAOC,EAAQyT,GAChCA,GAAUV,OAGZ,MAAMwB,EAAa3B,QACnB5S,EAASmB,KAAKmT,MAAMC,EAAaxB,GAC7B/S,EAAS,IAEXwT,EAAiBzT,EAAOC,EAAQyT,GAChCA,GAAgB,KAANzT,GAGZD,EAAQwU,EAAaxB,EACjBhT,EAAQ,GAEVyT,EAAiBzT,EAAO,EAAG0T,EAC5B,IAGP,MAAMe,EACFrN,EAAAA,KAAKqL,mCAAmCK,EAAS7D,EAAW9L,OAEhE,OADArG,KAAKqV,qBAAqBpD,EAAQ0F,GAC3BA,CACR,CAEQ3D,WAAW/B,GAClB,IAAKjS,KAAKmR,UAAUzP,IAAIuQ,GACtB,MAAM,IAAI5P,MAAM,UAAU4P,yBAE5B,MAAME,EAAanS,KAAKmR,UAAUvP,IAAIqQ,IAEhCoB,OAACA,GAAUlB,EAEjB,GAAc,MAAVkB,EACF,OAAOA,EAIT,IAAIsE,EACJ,GAAyB,cAArBxF,EAAW9L,MAAuB,CACpC,MAAMuR,QAAW1D,QAAQC,IAAI,CAC3BnU,KAAK6X,KAAK1F,EAAWE,mBAAmBC,KAAKL,QAC7CjS,KAAK6X,KAAK1F,EAAWE,mBAAmBE,KAAKN,UAGzCuD,EAAaoC,EAAG,GAChBnC,EAAamC,EAAG,GACtBD,EAAOlN,EAAAA,aAAamL,uBAChBJ,EAA4BC,EACjC,KAAM,CACL,MAAMH,QAAatV,KAAK8X,cAAc3F,EAAWW,UACjD6E,EAAOrN,EAAIA,KAACqL,mCAAmCL,EAAMnD,EAAW9L,MACjE,CAED,OADArG,KAAKqV,qBAAqBpD,EAAQ0F,GAC3BA,CACR,CAIOI,WAAWC,GACjB,MAAM7W,EAAO6W,EAAU7W,KACjBC,EAAQ4W,EAAU5W,MAClB6W,EAAYjY,KAAKiR,cAAc/P,cAAcC,EAAMC,GAKzD,OAJApB,KAAK4T,4BACL5T,KAAK8T,wBACL9T,KAAK4Q,eAAeiE,mBAAmBmD,EAAW,EAAGC,EAAW,EAAG9W,GACnEnB,KAAKwT,cACEyE,CACR,CAKQC,wBACLC,EAAwB1T,EAAiB4B,GAC3C,IAAI9E,EAAS4W,EAAW5W,OACxB,GAAc,cAAV8E,EACF,MAAM,IAAIhE,MAAM,uCAElB,MAAM4P,EAAS,CAACqB,GAAItT,KAAKyP,cACzBzP,KAAKmR,UAAUxP,IAAIsQ,EAAQ,CACzB5L,QACA5B,QACA4O,OAAQ,KACRjB,SAAU,EACVW,SAAUoF,EAAWC,WAEvB,MAAMjG,EAAanS,KAAKmR,UAAUvP,IAAIqQ,GAChC9Q,EAAOkX,EAA+BlG,EAAW9L,OACnDiE,EAAAA,KAAKgO,cAAcnG,EAAW1N,OAClC,GAAI0T,EAAW5W,OAAOJ,KAAOA,EAC3B,MAAM,IAAIkB,MAAM,kBACZ8V,EAAW5W,OAAOJ,qCAAqCA,OACtD,IACFgX,EAAW5W,OAAOH,OACjBsT,eAAe6D,QAAU7D,eAAe8D,aACzC9D,eAAe6D,QAAU7D,eAAe8D,UAC3C,MAAM,IAAInW,MACN,oFAQN,OAJ4B,IAAxB8V,EAAWC,WACb7W,EAASvB,KAAK+X,WAAWxW,IAE3B4Q,EAAWW,SAAWvR,EACf8P,EAAAA,SAASoH,qBAAqBxG,EAAQxN,EAAO4B,EAAOrG,KAC5D,CAMQ0Y,UAAUzG,GACjB,MAAM0G,EAAgB3Y,KAAKmR,UAAUvP,IAAIqQ,IACnCoB,OAACA,EAAMhN,MAAEA,EAAK5B,MAAEA,EAAKqO,SAAEA,GAAY6F,EAEzC,GAAc,cAAVtS,EACF,MAAM,IAAIhE,MAAM,wDAGlB,GAAgB,MAAZyQ,EACF,MAAc,MAAVO,EACI,IAAIhR,MAAM,kCAEV,IAAIA,MAAM,mCAIpB,MAAM2V,EAAYlF,EACZ3R,EAAO6W,EAAU7W,KACjBC,EAAQ4W,EAAU5W,MAClBG,EAASvB,KAAKiR,cAAc/P,cAAcC,EAAMC,GACtDpB,KAAK4T,4BACL5T,KAAK8T,wBACL9T,KAAK4Q,eAAeiE,mBAChB/B,EAAuB,EAAGvR,EAAQ,EAAGJ,GACzCnB,KAAKwT,cAEL,MAAMoF,EAAa5Y,KAAK6Y,eAAepU,EAAO4B,GAExCyS,EAAYzH,EAAMA,SAAG0H,yBAAyBH,GAKpD,OAHmB5Y,KAAKmR,UAAUvP,IAAIgX,EAAW3G,QACtCa,SAAWvR,EAEf,CAACuX,YAAWvX,SACpB,CAEDyX,WAA+CjK,GAE7C,MAAMuG,EAAOtV,KAAKuV,SAASxG,EAAEkD,QAC7B,GAAgB,WAAZlD,EAAE1I,MACJ,IAEE,MAAM4S,EAAW3D,EAAsB5Q,KAAIC,GAAK2F,EAAAA,KAAK4O,aAAavU,KAClE,OAAOpD,EAAAA,OAAOwN,EAAEtK,MAAsBsK,EAAE1I,MAAO4S,EAIhD,CAFC,MAAME,GACN,MAAM,IAAI9W,MAAM,mDACjB,CAEH,OAAOd,EAAAA,OAAOwN,EAAEtK,MAAsBsK,EAAE1I,MAAOiP,EAEhD,CAEQtB,WAAWoF,GACbpZ,KAAK8Q,uBAA0B9Q,KAAKwQ,0BACvCzE,QAAQyI,KACJ,yOAKJxU,KAAKwQ,yBAA0B,GAGjC,MAAM6I,EAAkBrZ,KAAKsZ,aACvBC,EAA+B,GAErC,IAAIC,GAAgB,EACW,MAA3BxZ,KAAKyZ,oBACPzZ,KAAKyZ,mBAAqBF,EAC1BC,GAAgB,GAEhBxZ,KAAKsZ,aAAatX,KAAKuX,GAEzBvZ,KAAKsZ,aAAeC,EAEpBH,IAEA,MAAMM,EACFpP,EAAAA,KAAKqP,QAAQ3Z,KAAKsZ,aAAa5U,KAAKC,GAAwBA,EAAEiV,SACzDC,QAAOlV,GAAU,MAALA,IACfmV,EACFxP,EAAAA,KAAKqP,QAAQ3Z,KAAKsZ,aAAa5U,KAAKC,GAAwBA,EAAEkF,QACzDgQ,QAAOlV,GAAU,MAALA,IAErB3E,KAAKsZ,aAAeD,EAEhBG,IACFxZ,KAAKyZ,mBAAqB,MAE5B,MAAM9P,EAAwB,CAC5B2G,aAActQ,KAAKsQ,aACnBP,eAAgB/P,KAAK+P,eACrBgK,SAAU,KACVC,OAAQ,MAGJD,QAAiB7F,QAAQC,IAAIuF,GAQnC,OAPA/P,EAAc,SAAIW,EAAIA,KAAC2P,IAAIF,GAC3BpQ,EAAyB,oBAAI,IACzBoQ,EAASrV,KAAI,CAACC,EAAGG,KAAO,CAAC+E,KAAMiQ,EAA0BhV,GAAIoV,GAAIvV,MAC5DD,KAAIC,GAAK,GAAGA,EAAEkF,SAASlF,EAAEuV,OACzBxT,KAAK,MACd1G,KAAKsQ,aAAe,EACpBtQ,KAAK+P,eAAiB,EACfpG,CACR,CAEDkP,eACIpU,EAAiB4B,EACjBgN,GACY,WAAVhN,GAAgC,MAAVgN,GAAkBA,EAAOxR,OAAS,GACxDyI,EAAAA,KAAK6P,SAAS9G,EAAO,MACvBA,EAAUA,EAA+B3O,KAAIC,GAAK2F,EAAAA,KAAK8P,aAAazV,MAGtE,MAAO,CAACsN,OADOjS,KAAKoT,MAAMC,EAAyB5O,EAAO4B,GAC1C5B,QAAO4B,QACxB,CAEOgU,gBAAgBzL,GACtB,IAAKA,EACH,OAAO,KAGT,MACMkE,EADa9S,KAAKmR,UAAUvP,IAAIgN,EAAOqD,QACjBa,SAE5B,OAAIA,aAAoBE,UACf,CAACzR,OAAQuR,GAEdA,aAAoBG,WACfH,EAASwH,aAGXxH,CACR,CAEDyH,YAAYtI,GACV,MAAME,EAAanS,KAAKmR,UAAUvP,IAAIqQ,GAEtC,GAA2B,MAAvBE,EAAWW,SACb,OAGF,MAAM3R,EAAOkX,EAA+BlG,EAAW9L,OACnDiE,EAAAA,KAAKgO,cAAcnG,EAAW1N,OAClC,IAAIlD,EACJ,MAAMH,EAAQsT,eAAe6D,QAAU7D,eAAe8D,SAClD9D,eAAeC,SACnB,GAAIxC,EAAWkB,OAAQ,CAErB,GADA9R,EAASvB,KAAKiR,cAAc/P,cAAcC,EAAMC,GAAO,GAC/B,aAApBG,EAAOiZ,SAAyB,CAClC,MAAM/F,EAAgBzU,KAAKiR,cAAc/P,cACrCC,EAAMuT,eAAe+F,UAAY/F,eAAe8D,UAAU,GAC1D,GACEkC,EAAcjG,EAAcQ,iBACT,UAArB9C,EAAW9L,OAA0C,SAArB8L,EAAW9L,MAC7C,IAAIsU,WAAWD,GAAa/Y,IAAIwQ,EAAWkB,QAE3C,IAAIuH,aAAaF,GAAa/Y,IAAIwQ,EAAWkB,QAE/CoB,EAAcS,QACdlV,KAAK4T,4BACL5T,KAAK8T,wBACL9T,KAAK4Q,eAAeiE,mBAChBJ,EAAe,EAAGlT,EAAQ,EAAGJ,GAEjCnB,KAAKoQ,uBAAuBpO,KAAKyS,EAClC,KAAM,CACL,MAAMiG,EAAcnZ,EAAO0T,iBACF,UAArB9C,EAAW9L,OAA0C,SAArB8L,EAAW9L,MAC7C,IAAIsU,WAAWD,GAAa/Y,IAAIwQ,EAAWkB,QAE3C,IAAIuH,aAAaF,GAAa/Y,IAAIwQ,EAAWkB,QAE/C9R,EAAO2T,OACR,CAGD/C,EAAWkB,OAAS,IACrB,MACC9R,EAASvB,KAAKiR,cAAc/P,cAAcC,EAAMC,GAElD+Q,EAAWW,SAAWvR,CACvB,CAEOsZ,aAAaC,GACnB,IAAIC,EAAgB,EAChBC,EAAY,EAChB,MAAMC,EAAoB,GAC1B,IAAIC,EAAsB,EAC1BJ,EAAepY,SAASiC,IAKtB,IAAIwW,EACJ,OALsB,IAAlBxW,EAAE2Q,KAAKzT,SACT8C,EAAE2Q,KAAO,CAAC,IAIJ3Q,EAAE2Q,KAAKzT,QACb,KAAK,EACHsZ,EAAgB,EAChB,MACF,KAAK,EACHA,EAAgB,EAChB,MACF,KAAK,EAGL,KAAK,EAGL,KAAK,EAGL,KAAK,EACHA,EAAgB,GAChB,MACF,QACE7Q,OAAKwC,QAAO,GAAO,IAAM,eAAenI,EAAE2Q,KAAKzT,kBAGjC,IAAdmZ,GAAiC,IAAdA,IACrBG,EAAgB,IAEdA,EAAgBD,IAClBA,EAAsBC,GAExBJ,EAAgBzW,KAAKmJ,KAAKsN,EAAgBI,GAAiBA,EAC3DH,EAAYrW,EAAE2Q,KAAKzT,OACnBoZ,EAAQjZ,KAAK+Y,GACbA,GAAiC,EAAhBpW,EAAE2Q,KAAKzT,MAAU,IAGpCkZ,EACIzW,KAAKmJ,KAAKsN,EAAgBG,GAAuBA,EACrD,MAAMR,EAAc,IAAIzE,YAAY8E,GACpCD,EAAepY,SAAQ,CAACiC,EAAGG,KACzB,MAAM8R,EAASqE,EAAQnW,GACR,UAAXH,EAAEO,KACJ,IAAIyV,WAAWD,EAAa9D,EAAQjS,EAAE2Q,KAAKzT,QAAQF,IAAIgD,EAAE2Q,MACrC,WAAX3Q,EAAEO,KACX,IAAIkW,YAAYV,EAAa9D,EAAQjS,EAAE2Q,KAAKzT,QAAQF,IAAIgD,EAAE2Q,MAE1D,IAAIsF,aAAaF,EAAa9D,EAAQjS,EAAE2Q,KAAKzT,QAAQF,IAAIgD,EAAE2Q,KAC5D,IAGH,MAAM+F,EAAgBrb,KAAKiR,cAAc/P,cACrC6Z,EAAerG,eAAeC,SAAWD,eAAe4G,SAI5D,OAHAtb,KAAK2Q,MAAM4K,YAAYF,EAAe,EAAGX,EAAa,EAAGK,GACzD/a,KAAKqQ,uBAAuBrO,KAAKqZ,GAE1B,CAACzE,OAAQ,EAAGzV,KAAM4Z,EAAexZ,OAAQ8Z,EACjD,CAEMG,iBACHnW,EAAuC2E,EACvCyR,EAAuBC,EACvBnW,GAIF,GAHKA,IACHA,EAASvF,KAAK6Y,eAAexT,EAAQ+H,YAAaqO,IAEX,IAArCnR,EAAIA,KAACgO,cAAc/S,EAAOd,OAK5B,OAFAzE,KAAKmR,UAAUvP,IAAI2D,EAAO0M,QAAQoB,OAC9B/I,EAAAA,KAAKqR,uBAAuBpW,EAAOc,MAAoB,GACpDd,EAETvF,KAAKua,YAAYhV,EAAO0M,QACxB5M,EAAQ0H,SAzxBR,EAACrM,EACA2E,KACC,MAAMuW,EACFlb,EAAOmb,OAAOC,iCACZxP,EAASjH,EAAwB,eACjC0H,EAAW1H,EAAkB,SACnC,GAAI0H,EAASmC,OAAOvK,GAAMA,GAAKiX,IAC7B,OAAO7O,EAGTzC,EAAAA,KAAKwC,OACDC,EAAS,GAAK6O,QACGzG,IAAb7I,EAAO/D,QAAgC4M,IAAb7I,EAAO9D,GACrC,IAAM,6DAEV,IAAIuT,EAAkBzX,KAAKmJ,KAAKnJ,KAAK0X,KAAKjP,EAAS,KACnD,OAAIgP,EAAkBH,GACpBG,EAAkBzX,KAAKmJ,KAAKnJ,KAAK2X,KAAKlP,EAAS,KAC/CzC,EAAAA,KAAKwC,OACDiP,GAAmBH,GACnB,IAAM,gDACH,CAACG,EAAiBA,EAAiBA,IAEnC,CAACA,EAAiBA,EAAiB,EAC3C,EAiwBgBG,CAAgBlc,KAAKU,OAAQ2E,GAEhD,MAAMC,EAAa0E,EAAOtF,KAAI,CAACyX,EAAmBrX,KAChD,GAAoB,cAAhBqX,EAAM9V,MACR,MAAM,IAAIhE,MACN,mIAMN,OAFArC,KAAKua,YAAY4B,EAAMlK,QAEhB,CAGL5L,MAAOrG,KAAKmR,UAAUvP,IAAIua,EAAMlK,QAAQ5L,MACxC5B,MAAO0X,EAAM1X,MACboF,KAAMxE,EAAQ4B,cAAcnC,GAC7B,IAGHO,EAAQwG,mBFthBRxG,EAAwBC,EACxBC,GACF,IAAI/D,EAAM6D,EAAQwG,UAClB,GAA4B,MAAxBxG,EAAQY,aACV,OAAOzE,EAGT,MAAM4a,EAAqB,GACrBC,EAAkC,GACxC/W,EAAW5C,SAAQ4Z,IACjBF,EAAOpa,KAAKsa,EAAQ7X,OACpB4X,EAAMra,KAAKsa,EAAQjW,MAAM,IAE3B+V,EAAOpa,KAAKuD,EAAOd,OACnB4X,EAAMra,KAAKuD,EAAOc,OAElB,MAAMmE,EACFlF,EAAWZ,KAAIC,GAAK8F,EAAYA,aAACC,iBAAiB/F,EAAEF,MAAOc,EAAOd,SAChE8X,EACFjX,EAAWZ,KAAIC,GAAK2F,EAAIA,KAACC,YAAY5F,EAAEF,MAAOc,EAAOd,SAAQiC,KAAK,KAChE8V,EAAmBhS,EAAc9F,KAAIC,GAAKA,EAAE+B,KAAK,OAAMA,KAAK,KAE5D+V,EAAqBzW,EAAeX,GAAW,eAAiB,GAOtE,OALA7D,GAAO,KAAO6D,EAAQS,cAAgBT,EAAQS,cAAcY,KAAK,KAAO,IACpE0V,EAAO1X,KAAID,GAASA,EAAM5C,SAAQ6E,KAAK,KAAO2V,EAAM3V,KAAK,KACzDrB,EAAQ4B,cAAcP,KAAK,KAAO8V,EAClCD,EAA4BE,EAEzBjb,CACT,CEyfQkb,CAA6BrX,EAASC,EAAYC,GAEtD,MAAMC,EAAsB7F,EAAGA,MAAG2R,QAAQ,8BAU1C,OATMjM,EAAQwG,aAAa7L,KAAK0Q,gBAC9B1Q,KAAK0Q,cAAcrL,EAAQwG,WAAa8Q,EACpC3c,KAAKU,OAAQ2E,EAASC,EAAYC,EAAQC,IAEhDH,EAAQuX,SAAW5c,KAAK0Q,cAAcrL,EAAQwG,WAEzCrG,GACHxF,KAAK6c,gBAAgBxX,EAASE,EAAQyE,EAAQ0R,GAEzCnW,CACR,CAEOsX,gBACJxX,EAAuCE,EACvCyE,EAAsB0R,GACxB,GAAIrW,EAAQuX,oBAAoB,QAC9B,MAAM,IAAIva,MACN,mFAIN,IAAIyY,EAAiC,GACjCgC,EAA2B,GAC/B,MAAMC,EAAe,QACrB,GAA4B,MAAxB1X,EAAQY,aAAsB,CAChC6U,EAAe9Y,KACX,CAACkD,KAAM,UAAWoQ,KAAM,CAAC0H,MAAO,CAAC9X,KAAM,UAAWoQ,KAAM,CAAC2H,OAC7DH,EAAe9S,EAAOkT,OAAO3X,GAAQb,KAAIC,GAAKA,EAAEF,QAChD,MAAMsY,EAAe,QACrBD,EAAapY,KAAIC,IACfmW,EAAe9Y,KAAK,CAACkD,KAAM6X,EAAczH,KAAM3Q,IAC/C,MAAMC,EAAU0F,EAAAA,KAAKsC,eAAejI,GACpCmW,EAAe9Y,KAAK,CAACkD,KAAM6X,EAAczH,KAAM1Q,GAAS,GAE3D,KAAM,CACL,MAAMA,EAAU0F,EAAIA,KAACsC,eAAerH,EAAOd,OAC3CqW,EAAe9Y,KAAK,CAACkD,KAAM6X,EAAczH,KAAM1Q,GAChD,CACD,GAAIS,EAAQlE,KAAM,CAChB,MAAMA,EAAOmJ,EAAIA,KAACgO,cAAcjT,EAAQ+H,aACxC0N,EAAe9Y,KAAK,CAClBkD,KAAM6X,EACNzH,KAAM,CAACjQ,EAAQU,gBAAkB5E,EAAOkE,EAAQU,gBAAkB5E,IAErE,CAEGua,IACFZ,EAAiB,IAAIA,KAAmBY,IAE1C,MAAMyB,EAAW,CACfnd,KAAKqa,gBAAgB9U,MAAYyE,EAAOtF,KAAIqK,GAAK/O,KAAKqa,gBAAgBtL,KACtE/O,KAAK6a,aAAaC,IAGpB9Q,EAAOtH,SAAQyZ,IACbnc,KAAK2P,qBAAqByN,IAAIjB,EAAMlK,OAAO,IAE7CjS,KAAK2P,qBAAqByN,IAAI7X,EAAO0M,QAErC,MAAMoL,EAAYrd,KAAKU,OAAO4c,gBAAgB,CAC5ChR,OAAQjH,EAAQuX,SAASW,mBAAmB,GAC5CC,QAASL,EAASzY,KAAI,CAACiP,EAAG7O,MAAQ2Y,QAAS3Y,EAAGgO,SAAUa,QAGpD+J,EAAyC,MAArB1d,KAAKsZ,aAC/BtZ,KAAK4T,4BAEL,MAAM+J,EAAkD,CAAA,EACpDD,GAAqB1d,KAAK8Q,uBAC5B9Q,KAAK8T,wBACgB,MAAjB9T,KAAKkQ,WACPlQ,KAAKkQ,SAAWlQ,KAAKU,OAAOkd,eAAe,CACzC1Y,KAAM,YACN2Y,MAAO7d,KAAKmQ,iBAGhBwN,EAAsBG,gBAAkB,CACtC,CACE5N,SAAUlQ,KAAKkQ,SACf6N,WAAY,EACZC,SAAU,aAEZ,CACE9N,SAAUlQ,KAAKkQ,SACf6N,WAAY,EACZC,SAAU,QAGdhe,KAAK6Q,mBACD7Q,KAAK4Q,eAAeqN,iBAAiBN,IAC/B3d,KAAK6Q,qBACf7Q,KAAK6Q,mBACD7Q,KAAK4Q,eAAeqN,iBAAiBN,IAG3C3d,KAAK6Q,mBAAmBqN,YAAY7Y,EAAQuX,UAC5C5c,KAAK6Q,mBAAmBsN,aAAa,EAAGd,GACxCrd,KAAK6Q,mBAAmBuN,mBACpB/Y,EAAQ0H,SAAS,GAAI1H,EAAQ0H,SAAS,GAAI1H,EAAQ0H,SAAS,IAC/D/M,KAAK6P,uBAED6N,GACA/d,EAAAA,MAAMiC,IAAI,sCACI5B,KAAK6P,qBACnBxK,EAAQY,eAAiBoY,EAA4BC,QACvDte,KAAK8T,wBACD4J,EACF1d,KAAKsZ,aAAatX,KACd,CAAC6H,KAAMxE,EAAQvF,YAAY+J,KAAM+P,MAAO5Z,KAAKue,iBAEjDve,KAAKwT,cAGV,CAEDQ,qBACE,IAAKhU,KAAK8Q,sBACR,OAAO,EAGsB,MAA3B9Q,KAAKiQ,qBACPjQ,KAAKiQ,mBAAqBjQ,KAAKiR,cAAc/P,cACpB,EAArBlB,KAAKmQ,cACLuE,eAAe8D,SAAW9D,eAAeC,SACrCD,eAAe8J,gBAEzBxe,KAAK4Q,eAAe6N,gBAChBze,KAAKkQ,SAAU,EAAGlQ,KAAKmQ,cAAenQ,KAAKiQ,mBAAoB,GAEnE,MAAMyO,EAAqB1e,KAAKiR,cAAc/P,cACrB,EAArBlB,KAAKmQ,cACLuE,eAAeE,SAAWF,eAAeC,UAE7C3U,KAAK4Q,eAAeiE,mBAChB7U,KAAKiQ,mBAAoB,EAAGyO,EAAoB,EAC3B,EAArB1e,KAAKmQ,eAETnQ,KAAKwT,oBAECkL,EAAmB5J,SAASC,WAAWC,MAC7C,MAAM0F,EAAc,IAAIiE,eAAeD,EAAmBzJ,kBACpD2J,EAAOre,OAAOma,EAAY,GAAKA,EAAY,IAAM,IAGvD,OAFAgE,EAAmBxJ,QACnBlV,KAAKiR,cAAchP,cAAcyc,GAC1BE,CACR,CAEDC,mBACI7U,EACA8U,EAAgBzP,GAClB,OAAO1P,EAAGA,MAAG2R,QAAQ,uBACjBtH,EAAOkF,OACHiN,GAAsD,MAA7Cnc,KAAKmR,UAAUvP,IAAIua,EAAMlK,QAAQa,UACtCxI,EAAAA,KAAKgO,cAAc6D,EAAM1X,OAASqa,GAC/C,CAEQC,aACP,OAAO/e,KAAKmR,UAAU4N,aAAe/e,KAAKgQ,0BAA0BnO,MACrE,CAEQY,UACHzC,KAAK8P,WAGY,MAAjB9P,KAAKkQ,UACPlQ,KAAKkQ,SAAS5N,UAEhBtC,KAAKiR,cAAcxO,UACnBzC,KAAKkR,eAAezO,UACpBzC,KAAK8P,UAAW,EACjB,ECjhCH,IAAYkP,EDoGKzP,EAAUE,WAAG,EE7F1BnB,KACF2Q,EAAeA,gBAAC,UAAUjL,UACxB,MAAMkL,EAA0C,CAC9CC,gBAAiBxf,EAAGA,MAAGiC,IAAI,4BACvB,YACA,oBAGAwd,QAAgB3Q,UAAUC,IAAI2Q,eAAeH,GAC7CI,EAAwC,CAAA,EAExCC,EAAmB,GACrBH,EAAQrO,SAASrP,IAAI,oBACvB6d,EAAiBvd,KAAK,mBAEpBod,EAAQrO,SAASrP,IAAI,uBACvB6d,EAAiBvd,KAAK,CAAC,uBAEzBsd,EAAiBC,iBACbA,EAEJ,MAAMC,EAAgBJ,EAAQvD,OAC9ByD,EAAiBG,eAAiB,CAChCC,+BACIF,EAAcE,+BAClB5D,iCACI0D,EAAc1D,iCAClB6D,4BAA+BH,EAAcG,4BAC7CC,cAAiBJ,EAAcI,cAC/BC,yBAA4BL,EAAcK,yBAC1CC,kCACIN,EAAcM,mCAGpB,MAAMpf,QAA0B0e,EAAQW,cAAcT,GAChDvf,QAAoBqf,EAAQY,qBAClC,OAAO,IAAIzQ,EAAc7O,EAAQX,EAAY,GAC5C,GD5CL,SAAYif,GACVA,EAAAA,EAAA,IAAA,GAAA,MACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,sBAAA,GAAA,wBACAA,EAAAA,EAAA,sBAAA,GAAA,wBACAA,EAAAA,EAAA,IAAA,GAAA,MACAA,EAAAA,EAAA,QAAA,GAAA,UACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,UAAA,GAAA,YACAA,EAAAA,EAAA,QAAA,GAAA,UACAA,EAAAA,EAAA,cAAA,GAAA,gBACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,WAAA,IAAA,aACAA,EAAAA,EAAA,YAAA,IAAA,cACAA,EAAAA,EAAA,WAAA,IAAA,aACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,UAAA,IAAA,YACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,mBAAA,IAAA,qBACAA,EAAAA,EAAA,IAAA,IAAA,KACD,CAxBD,CAAYA,IAAAA,EAwBX,CAAA,IA2He,SAAAiB,EACZ/a,EAAoBgb,GACtB,IAAIC,EAGJ,EAAG,CACD,OAAQjb,GACN,KAAK8Z,EAAaoB,MAChBD,EAhIM,gCAiIN,MACF,KAAKnB,EAAaqB,IAChBF,EApFI,8BAqFJ,MACF,KAAKnB,EAAasB,IAChBH,EAtFI,8BAuFJ,MACF,KAAKnB,EAAauB,IAChBJ,EAAcD,EAlFL,0jBANL,oKAyFJ,MACF,KAAKlB,EAAawB,UAChBL,EAAcD,EAhEC,sEAJL,gEAqEV,MACF,KAAKlB,EAAayB,IAChBN,EAAcD,EAtDL,ooBARL,+LA+DJ,MACF,QACE,SAGJ,IAAIQ,EACAC,EACAC,EAWJ,OAVIV,GACFQ,EAAQ,YACRC,EAAS,YACTC,EAAQ,eAERF,EAAQ,QACRC,EAAS,MACTC,EAAQ,QAGH,wBACUF,kDACqBC,uCACrBD,kDACqBC,8KAMhCR,sDAEgBQ,gCACZC,6CAGX,OAAQ,GAGT,OAAQ1b,GACN,KAAK8Z,EAAa6B,IAChBV,EAxLM,0BAyLN,MACF,KAAKnB,EAAa8B,sBAChBX,EApLwB,kDAqLxB,MACF,KAAKnB,EAAa+B,sBAChBZ,EAxLwB,kDAyLxB,MACF,KAAKnB,EAAagC,IAChBb,EAzLM,0BA0LN,MACF,KAAKnB,EAAaiC,QAChBd,EA3LU,yDA4LV,MACF,KAAKnB,EAAakC,MAChBf,EA7LQ,iHA8LR,MACF,KAAKnB,EAAamC,UAChBhB,EA3LY,qOA4LZ,MACF,KAAKnB,EAAaoC,QAChBjB,EAvLU,gHAwLV,MACF,KAAKnB,EAAaqC,cAChBlB,EArLgB,iHAsLhB,MACF,KAAKnB,EAAasC,KAChBnB,EAnLO,gHAoLP,MACF,KAAKnB,EAAauC,WAChBpB,EAjLa,iHAkLb,MACF,KAAKnB,EAAawC,YAChB,OAAOtB,EA9KY,+EADL,oCAgLhB,KAAKlB,EAAayC,WAChB,OAAOvB,EA7KW,kGADL,oCA+Kf,KAAKlB,EAAa0C,IAChBvB,EArJM,0BAsJN,MACF,KAAKnB,EAAa2C,MAChB,OAAOzB,EA9GM,yIADL,4CAgHV,KAAKlB,EAAa4C,mBAChBzB,EA5GqB,sCA6GrB,MACF,KAAKnB,EAAa6C,IAChB1B,EA9GM,0BAmHV,MAAO,SACHA,+BAGN,CEtQA,IAAY2B,GAAZ,SAAYA,GACVA,EAAAA,EAAA,IAAA,GAAA,MACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,MAAA,GAAA,QACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,IAAA,GAAA,MACAA,EAAAA,EAAA,KAAA,GAAA,OACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,UAAA,IAAA,YACAA,EAAAA,EAAA,OAAA,IAAA,SACAA,EAAAA,EAAA,OAAA,IAAA,SACAA,EAAAA,EAAA,OAAA,IAAA,SACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,YAAA,IAAA,cACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,UAAA,IAAA,YACAA,EAAAA,EAAA,WAAA,IAAA,aACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,MAAA,IAAA,QACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,QAAA,IAAA,UACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,SAAA,IAAA,WACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,OAAA,IAAA,SACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,IAAA,IAAA,MACAA,EAAAA,EAAA,KAAA,IAAA,OACAA,EAAAA,EAAA,OAAA,IAAA,QACD,CA1CD,CAAYA,IAAAA,EA0CX,CAAA,IAED,MA8DMC,EAAM,sNAIAtX,EAAAA,aAAauX,sBACZvX,EAAAA,aAAawX,uBACbxX,EAAAA,aAAayX,uBACbzX,EAAAA,aAAa0X,uBACb1X,EAAAA,aAAa2X,uBACb3X,EAAAA,aAAa4X,iMAsCpBC,EAAO,mCAEA7X,EAAAA,aAAa8X,2CAEb9X,EAAAA,aAAa+X,2CA0CV,SAAAC,EAAiBvd,EAAmBgb,GAClD,OAAQhb,GACN,KAAK4c,EAAYY,IACf,MA9JM,iBA+JR,KAAKZ,EAAYa,KACf,MA/JO,6EAgKT,KAAKb,EAAYc,MACf,MA3JQ,yEA4JV,KAAKd,EAAYe,KACf,MAvJO,6EAwJT,KAAKf,EAAYgB,MACf,MAnJQ,mBAoJV,KAAKhB,EAAYiB,KACf,MApJO,0EAqJT,KAAKjB,EAAYkB,MACf,MAhJQ,4LAiJV,KAAKlB,EAAYmB,IACf,MArIM,iBAsIR,KAAKnB,EAAYoB,KACf,MAtIO,8DAuIT,KAAKpB,EAAYqB,KACf,MA1IO,kBA2IT,KAAKrB,EAAYsB,IACf,OAAOlD,EApII,wQADL,sDAsIR,KAAK4B,EAAYC,IACf,OAAOA,EACT,KAAKD,EAAYuB,IACf,MAxGM,iBAyGR,KAAKvB,EAAYwB,MACf,MA5IQ,uBA6IV,KAAKxB,EAAYyB,MACf,MA3GQ,mBA4GV,KAAKzB,EAAY0B,UACf,MA5GY,sCA6Gd,KAAK1B,EAAY2B,OACf,MA7GS,wBA8GX,KAAK3B,EAAY4B,OACf,MA9GS,wBA+GX,KAAK5B,EAAY6B,OACf,MA/GS,YAgHX,KAAK7B,EAAY8B,IACf,MAhHM,0DAiHR,KAAK9B,EAAY+B,MACf,MAhHQ,4DAiHV,KAAK/B,EAAYgC,YACf,MA9Gc,2BA+GhB,KAAKhC,EAAYiC,IACf,MA/GM,aAgHR,KAAKjC,EAAYkC,UACf,OAAO9D,EA/GU,sJADL,wDAiHd,KAAK4B,EAAYmC,WACf,MA7Ga,kBA8Gf,KAAKnC,EAAYoC,KACf,OAAOhE,EA1GK,8DAJL,kCA+GT,KAAK4B,EAAYqC,MACf,OAAOjE,EA7GT,iFAFU,6BAgHV,KAAK4B,EAAYsC,MACf,MA3GQ,mBA4GV,KAAKtC,EAAYuC,MACf,MA5GQ,yBA6GV,KAAKvC,EAAYQ,KACf,OAAOA,EACT,KAAKR,EAAYwC,QACf,MAtGU,sCAuGZ,KAAKxC,EAAYyC,KACf,MAvGO,kBAwGT,KAAKzC,EAAY0C,IACf,MAxGM,iBAyGR,KAAK1C,EAAY2C,KACf,MAzGO,6DA0GT,KAAK3C,EAAY4C,SACf,MAvGW,oTAwGb,KAAK5C,EAAY6C,KACf,MAzFO,kBA0FT,KAAK7C,EAAY8C,OACf,MA1FS,gBA2FX,KAAK9C,EAAY+C,KACf,MA3FO,kGA4FT,KAAK/C,EAAYgD,IACf,MAtFM,iBAuFR,KAAKhD,EAAYiD,KACf,MAvFO,qFAwFT,KAAKjD,EAAYkD,OACf,MArFS,wBAuFX,QACE,MAAM,IAAI3iB,MAAM,cAAc6C,yBAEpC,CC3RgB,SAAA+f,EACZC,EAAqCC,GAA4B,EACjEC,GAAS,EAAOC,EAAe,GACjC,GAAmB,OAAfH,EACF,MAAO,GAGT,IAAII,EAAsB,GAC1B,GAAmB,WAAfJ,EACFI,EAAsB7C,EAAiBX,EAAY6B,aAC9C,GAAmB,SAAfuB,EACTI,EAAsB7C,EAAiBX,EAAYoC,KAAMkB,QACpD,GAAmB,QAAfF,EACTI,EAAsB7C,EAAiBX,EAAYsB,IAAKgC,QACnD,GAAmB,UAAfF,EACTI,EAAsB7C,EAAiBX,EAAYqC,MAAOiB,QACrD,GAAmB,UAAfF,EACTI,EAAsBrF,EAAkBjB,EAAa2C,MAAOyD,QACvD,GAAmB,YAAfF,EACTI,EAAsB7C,EAAiBX,EAAYwC,QAASc,OACvD,IAAmB,cAAfF,EAGT,MAAM,IAAI7iB,MAAM,cACZ6iB,sDAHJI,EAAsB7C,EAAiBX,EAAYkC,UAAWoB,EAI/D,CACD,MACMG,EAAW/b,EADG4b,EAAS,EAAI,GAEjC,IAAIH,EAAsB,GAe1B,OAbEA,EADEE,EACoB,6BACAI,kBAAyBF,cAC3CE,kFAEED,aAGgB,6BACAC,kBAAyBF,cAC3CE,gBACED,aAGDL,CACT,CAEgB,SAAAO,EACZC,EAAkBP,GACpB,MAAO,WACDO,EAAU,iDAAmD,aAC7DP,EAAa,qCAAuC,YAE5D,CCpDM,SAAUQ,EACZ5X,EAAqB6X,EAAqBC,GAAY,EACtDC,GAAY,EAAOC,GAAW,EAAOxc,EAAY,GACnDgB,EAAAA,KAAKwC,OACDgB,GAA4B,IAAdxE,IAAoBwE,GAClC,IAAM,cAAcA,2CAChBxE,MACR,MAAMyc,EAAU,WAEZjY,EAAa,iCACA,2CAGXkY,EAAUL,EAAa,iCACA,iCAE7B,MAAO,sDAC0Cnc,EAAYF,yBAC7CE,EAAYF,iBAExBsc,GAAaE,EACTC,EACA,SAEIjY,EACI,0DACA,4EAEViY,gGAM2Cvc,EAAYF,yBAC7CE,EAAYF,iBACxB0c,+BAIN,CAEM,SAAUC,EACZR,EAAkBP,EAAqCpX,EACvD6X,EAAqBC,GAAY,EAAOC,GAAY,EAAOC,GAAW,EACtExc,EAAY,GACd,MAAO,OAEHoc,EACI5X,EAAY6X,EAAYC,EAAWC,EAAWC,EAAUxc,8DAE5DE,EAAYF,cAEZsc,GAAaC,EACT,GACA,yJAIFL,EAAsBC,EAASP,sFAKvC,CAoDM,SAAUgB,EACZC,EAAyBrgB,EACzBgI,GAAa,EAAOsY,EAAY,GAAIC,GAAS,EAAOC,EAAkB,GACtEC,GAAiB,GACnB,MAAMC,EAAa1gB,EAAc,GAAKqgB,EAAc,GAC9CM,EAAa3gB,EAAc,GAAKqgB,EAAc,GAC9CO,EAAa5Y,EAAa0Y,EAAaJ,EACvCO,EAAa7Y,EAAasY,EAAYI,EACtCI,EAAmBF,EAAa5gB,EAAc,GAC9C+gB,EAAgBT,EAAYtgB,EAAc,GAC1CghB,EAAeX,EAAc,GAC7BY,EAAeZ,EAAc,GAanC,OAZA7b,OAAKwC,QACCgB,GAAmC,IAArB8Y,GAA+C,IAArBT,EAAc,KACrDrY,IAAoC,IAArB8Y,GAA+C,IAArBA,KACxCF,EAAa5gB,EAAc,IAAO,GAClCsgB,EAAYtgB,EAAc,IAAO,GAA0B,IAArBqgB,EAAc,IACxD,IAAM,iBAAiBrY,+BACnB8Y,0BAAyCT,EAAc,wDACzBS,uCACrBF,0CACT5gB,EAAc,iBACdsgB,2CACAtgB,EAAc,oBAAoBqgB,EAAc,kBACjD,+CACmCS,WACtCF,EAAaE,OAAsBD,0DAEnCF,EAAaN,EAAc,QAAQC,YAErCY,2EAE2BF,kFAGSA,6CACAC,uBACtBV,EAAS,IAAM,wCAE3BA,IAAWE,EAAiB,QAAU,mDAEtCF,IAAWE,EAAiB,QAAU,gFACIC,4BAG1CH,EAAS,GAAG/hB,KAAKmJ,KAAK6Y,EAAkBF,KAC/B,6BAA6BA,8BACzBC,EAAS,qBAAqBC,IAAoB,yCAErCQ,4EAGAD,6IAGYC,sHAxGxC,EAACG,EAAoBL,IACfK,EACK,iIAGyBL,gBAIzB,4HAGiBA,gBA+FlBM,CAA2BpZ,EAAY8Y,gHAITC,2OAKhBT,kGAlGxB,EAACtY,EAAqB8Y,EAA0BE,EAC/CV,KACC,GAAItY,EACF,MAAO,+BACasY,qIAGEU,mGAIjB,CACL,IAAIK,EAAa,GACbC,EAAS,GACb,IAAK,IAAItiB,EAAI,EAAGA,EAAI8hB,EAAkB9hB,IACpCqiB,GAAc,cAAcriB,mBAAmB8hB,OAC3C9hB,eACJsiB,GACI,uBAAuBtiB,wBAAwBA,gBAErD,MAAO,+BACashB,EAAYQ,sBAC9BO,kCACoBL,0EAElBM,uBAGL,GA2EDC,CACIvZ,EAAY8Y,EAAkBE,EAAcV,mFAIdU,wGAIxC,CAEA,MAAMQ,EAA0BL,GAC1BA,EACK,0IAOA,0IAgBK,SAAAM,EACZpB,EAAyBrgB,EACzBgI,GAAa,EAAOsY,EAAY,GAAIC,GAAS,EAAOC,EAAkB,GACtEkB,GAA4B,EAAOjB,GAAiB,GACtD,MAAMC,EAAaL,EAAc,GAAKrgB,EAAc,GAC9C2gB,EAAaN,EAAc,GAAKrgB,EAAc,GAC9C4gB,EAAa5Y,EAAa0Y,EAAaJ,EACvCO,EAAa7Y,EAAasY,EAAYI,EAC5Clc,EAAAA,KAAKwC,OACD6Z,EAAa7gB,EAAc,IAAO,GAC9B4gB,EAAa5gB,EAAc,IAAO,GAClCsgB,EAAYtgB,EAAc,IAAO,GACrC,IAAM,cAAc6gB,0CAChB7gB,EAAc,kBACd4gB,0CACA5gB,EAAc,iBACdsgB,0CAAkDtgB,EAAc,OACxE,MAAM2hB,EAAgBd,EAAa7gB,EAAc,GAC3C4hB,EAAgBhB,EAAa5gB,EAAc,GAC3C+gB,EAAgBT,EAAYtgB,EAAc,GAC1CghB,EAAeX,EAAc,GAC7BY,EAAeZ,EAAc,GAC7BwB,EAAgBH,EAClB,iIAG4ChB,uDACAC,8LAMxCE,4BAAqC7gB,EAAc,6DAEnD4gB,4BAAqC5gB,EAAc,sBAC/CwhB,EAAuBxZ,kIAK3BsY,4BAAoCtgB,EAAc,iEAElD2gB,4BAAqC3gB,EAAc,qMAMjCsgB,2HAIOW,oCACLX,oDACUW,6EACqBjhB,EAAc,kEAE7BghB,+CAEpChZ,EACI,oCAAoChI,EAAc,OAClD,iCAAiCA,EAAc,4DACbihB,gQAQND,+EACkBhhB,EAAc,kDAC9BihB,iFACkBjhB,EAAc,mGAKtE,sCAC6BghB,wCACAC,6CAEGD,2CACAC,mDACQP,2CAEViB,yCACAC,yCACAb,qKAIIY,6DACEC,uHAGhCJ,EAAuBxZ,6GAKO+Y,6DACEE,4QAQlBX,+GAIOW,gCACLX,gDACUW,4HAIMD,6BAjIV,CAAChZ,GACxBA,EAAa,gDAEA,gDA+HZ8Z,CAAwB9Z,iDACUiZ,oOAUND,2DACEC,2IAOtC,MAAO,mDACuCL,OAAgBC,sDAChBF,OAAgBL,cAE1DY,4BACcX,EAAS,IAAM,0CAE7BA,IAAWE,EAAiB,QAAU,qDAEtCF,IAAWE,EAAiB,QAAU,uDAEtCF,EAAS,GAAG/hB,KAAKmJ,KAAK6Y,EAAkBF,KAC/B,6BAA6BA,gCACvBC,EAAS,qBAAqBC,IAAoB,4CAEpCS,OAAkBD,uHAGXA,+DACEC,yFAIpCY,cAGR,OAiEaE,EAuBX/nB,YACIgoB,EAAkC1a,EAClCU,GAAa,EAAO6X,GAAa,EAAOoC,EAAmB,KAC3D7C,EAAsC,KACtC8C,EAAqC,KACrCR,GAA4B,GAvBhCxnB,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,oDAuBTzH,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,IAC3C,MAAMoF,EAAWE,EAAaga,EAAO,GAAKA,EAAO,GAOjD,GANA9nB,KAAKgO,QAAWJ,EAAW,GAAM,IAAME,GACvBV,EAAY,GAAK,GAAM,GAAKU,IACxCV,EAAY,GAAK,GAAM,IAAMuY,EACjC3lB,KAAK+F,gBAAkB/F,KAAKgO,OAAS,EAAI,EACzChO,KAAKioB,UAA+B,IAAnB7a,EAAY,KAAaU,GAErC9N,KAAKgO,QAAUhO,KAAKioB,UAEvBjoB,KAAKqN,kBAAoB,CAAC,EAAG,EAAG,GAChCrN,KAAK8F,cAAgB,CAAC,GAAI,EAAG,OACxB,CACL,MAAMoiB,EAAgBxa,EAClBN,EAAY,GAAIQ,EAAUR,EAAY,GAAIU,GAC9C9N,KAAK8F,cAAgBoiB,EAAcpiB,cACnC9F,KAAKqN,kBAAoB6a,EAAc7a,iBACxC,CAEDrN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C9F,KAAKqN,mBAET,MAAM8a,EAAkB,MAARJ,EACV5C,EAAsD,MAA1B6C,EAC9BG,GACFnoB,KAAKiH,cAAcjF,KAAK,QAGtBmjB,GACFnlB,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAKwnB,0BAA4BA,EACjCxnB,KAAK8N,WAAaA,EAClB9N,KAAK2lB,WAAaA,EAClB3lB,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlB,0BAA4BA,GAChCnlB,KAAK4lB,UAAW5lB,KAAK6lB,UAAW7lB,KAAK8lB,UAClC9lB,KAAKooB,YAAYhb,EAAY,GAAIA,EAAY,GAAIQ,GACrD5N,KAAK6L,UAAY,gBAAgB7L,KAAKqN,qBAAqBS,KACvD6X,KAAc3lB,KAAKklB,cAAcllB,KAAK4lB,aAAa5lB,KAAK6lB,aACxD7lB,KAAK8lB,YAAY9lB,KAAKgO,UAAUhO,KAAKioB,aACrCjoB,KAAKwnB,2BACV,CAEDY,YAAYza,EAAmBE,EAAmBD,GAEhD,MAAM4Y,EAAaxmB,KAAK8F,cAAc,GAAK9F,KAAKqN,kBAAkB,GAC5DoZ,EAAazmB,KAAK8F,cAAc,GAAK9F,KAAKqN,kBAAkB,IAE7DrN,KAAKgO,QAAUhO,KAAKioB,UAEvBjoB,KAAKomB,UAAoC,EAAxBpmB,KAAK8F,cAAc,GAEpC9F,KAAKomB,UAAYK,EAMnB,MAAO,CAHW9Y,EAAY6Y,GAAe,EAC3B3Y,EAAY4Y,GAAe,EAC5B7Y,EAAW5N,KAAKomB,WAAc,EAEhD,CAEDxf,cACE,MAAMyhB,EAAW,WAEbpD,EACIjlB,KAAKklB,WAAYllB,KAAKmlB,0BAA2BnlB,KAAKgO,kBAE1DiY,EACIjmB,KAAKmoB,QAASnoB,KAAKklB,YACnB,EACAllB,KAAK2lB,WAAY3lB,KAAK4lB,UAAW5lB,KAAK6lB,UAAW7lB,KAAK8lB,SACtD9lB,KAAKgO,OAAS,EAAI,aAEtBhO,KAAKgO,OACDkY,EACIlmB,KAAKqN,kBAAmBrN,KAAK8F,cAAe9F,KAAK8N,WACjD9N,KAAKomB,WAAW,EAAO,MAAM,GAChCpmB,KAAKioB,mBA9JdniB,EAAyCgI,GAAa,GACxDxD,EAAAA,KAAKwC,OACoB,IAArBhH,EAAc,IAAiC,IAArBA,EAAc,IACxC,IAAM,iDAAiDA,OAC3D,MAAMmJ,EAA8B,EAAnBnJ,EAAc,GAC/B,MAAO,mDACuCA,EAAc,eAExDkhB,gLAK2C/X,uYAUxBA,0DAvCE,CAACgY,GACnBA,EAAY,0LAMA,0LAiCkBqB,CAAmBxa,wHAI5BmB,EAAW,uCACdA,6eAgB3B,CAiH8BsZ,CACIvoB,KAAK8F,cAAe9F,KAAK8N,YAC7ByZ,EACIvnB,KAAKqN,kBAAmBrN,KAAK8F,cAC7B9F,KAAK8N,WAAY9N,KAAKomB,WAAW,EAAO,KACxCpmB,KAAKwnB,2BAA2B,WAE9D,OAAOa,CACR,QCzhBUG,GAcX1oB,YACIsN,EAAuCU,GAAa,EACpD6X,GAAa,EAAOoC,EAAmB,KACvC7C,EAAsC,KACtC8C,EAAqC,MAbzChoB,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,oDACXzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAYjD9F,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB,CAACpB,EAAG,GAAIqB,EAAG,CAAC,EAAG,GAAIC,EAAG,CAAC,IAC7CxI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD,MAAMqiB,EAAkB,MAARJ,EACV5C,EAAsD,MAA1B6C,EAC9BG,GACFnoB,KAAKiH,cAAcjF,KAAK,QAGtBmjB,GACFnlB,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAK8N,WAAaA,EAClB9N,KAAK2lB,WAAaA,EAClB3lB,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlB,0BAA4BA,EACjCnlB,KAAK6L,UACD,gBAAgB7L,KAAKklB,cAAcpX,KAAc6X,GACtD,CAED/e,cAhFI,IAAiC6hB,EAwFnC,MAPiB,WACbxD,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlB,qCAE1Cc,EACIjmB,KAAKmoB,QAASnoB,KAAKklB,WAAYllB,KAAK8N,WAAY9N,KAAK2lB,sBArF1B8C,EAsFRzoB,KAAK8F,cAAc,GArFzC,+CACmC2iB,YACtCzB,2VASmDyB,gPAQ3BA,EAAiB,oZAqE5C,QC/BUC,GAcX5oB,YACIgoB,EAAkCa,EAClCvb,EAAuCU,GAAa,EACpD6X,GAAa,EAAOoC,EAAmB,KACvC7C,EAAsC,KACtC8C,EAAqC,MAdzChoB,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,oDACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAahD9F,KAAKoN,YAAcA,EAEnBpN,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,IAC3CxI,KAAK+M,SAAW,CACdzI,KAAKmJ,KAAKL,EAAY,GAAKpN,KAAK8F,cAAc,IAC9CxB,KAAKmJ,KAAKL,EAAY,GAAKpN,KAAK8F,cAAc,IAAKsH,EAAY,IAGjE,MAAM+a,EAAkB,MAARJ,EACZI,GACFnoB,KAAKiH,cAAcjF,KAAK,QAG1B,MAAMmjB,EAAsD,MAA1B6C,EAC9B7C,GACFnlB,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAK8N,WAAaA,EAClB9N,KAAK2lB,WAAaA,EAClB3lB,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlB,0BAA4BA,EACjCnlB,KAAK6L,UACD,yBAAyB7L,KAAKklB,cAAcpX,KAAc6X,GAC/D,CAED/e,cAQE,MAPiB,WACbqe,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlB,qCAE1Cc,EACIjmB,KAAKmoB,QAASnoB,KAAKklB,WAAYllB,KAAK8N,WAAY9N,KAAK2lB,sBAhH3D,SACF7f,GACF,MAAM0gB,EAAa1gB,EAAc,GAC3B2gB,EAAa3gB,EAAc,GAC3BsgB,EAAYI,EAAaC,EAAaD,EAAaC,EACzD,MAAO,iDACqCL,OAAeI,oDACfC,OAAgBL,4dAQ1DY,6XAU2CZ,oUAQfA,qCACAA,wcAYEA,uCACAA,mCAENA,wLAS5B,CAuDQwC,CAAgC5oB,KAAK8F,sBAG1C,QCjHU+iB,GAeX/oB,YACIsN,EAAuCQ,EACvCE,GAAa,EAAO6X,GAAa,GAZrC3lB,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,oDACXzH,KAAa8F,cAA6B,CAAC,EAAG,EAAG,GAIjD9F,KAAMkI,QAAG,EAETlI,KAAesmB,gBAAG,IAKhBhc,EAAIA,KAACwC,OACkB,IAAnBM,EAAY,IACZ,IAAM,iDACVpN,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IAC9C,MAAMwF,GAAUF,GAAc9N,KAAKoN,YAAY,GAAK,GAAM,IACzCU,GAAcF,EAAW,GAAM,IAC5C5N,KAAKoN,YAAY,GAAK,GAAM,EAChCpN,KAAKqN,kBAAoB,CAAC,EAAG,EAAGrN,KAAKsmB,iBACrCtmB,KAAK+F,gBAAkBiI,EAAS,EAAI,EAC/BA,IACChO,KAAKoN,YAAY,GAAK,KACxBpN,KAAKqN,kBAAkB,GAAK,GAE1BrN,KAAKoN,YAAY,GAAK,KACxBpN,KAAKqN,kBAAkB,GAAK,IAIhCrN,KAAK+M,SAAWI,EACZnN,KAAKsI,eACL,CACEtI,KAAKoN,YAAY,GAAIpN,KAAKoN,YAAY,GAAIpN,KAAKoN,YAAY,GAC3DQ,GAEF5N,KAAK8F,cAAe9F,KAAKqN,mBAE7BrN,KAAK8N,WAAaA,EAClB9N,KAAK2lB,WAAaA,EAClB3lB,KAAK6L,UAAY,gBAAgBiC,KAAc6X,KAC3C3lB,KAAKqN,qBAAqBrN,KAAK+F,iBACpC,CAEDa,cACE,MAAM0C,EAAYtJ,KAAK+F,gBA4BvB,MA3BiB,WAEb2f,GACI,EAAO1lB,KAAK2lB,YAAY,GAAO,GAAO,EAAOrc,mEAEjDE,EAAYF,2XAMYA,gCAExBvE,EACI,yBAA0B,IAAGuE,EAAY,EAAI,WAAa,SAC1D,sDAKU,IAAdA,EAAkB4c,EACIlmB,KAAKqN,kBAAmBrN,KAAK8F,cAC7B9F,KAAK8N,WAAY,IAAI,EAAM9N,KAAKsmB,iBACpCiB,EACIvnB,KAAKqN,kBAAmBrN,KAAK8F,cAC7B9F,KAAK8N,WAAY,IAAI,EAAM9N,KAAKsmB,wBAG3D,QAGUwC,GAaXhpB,YACIsN,EAAuB2a,EAAmB,KAC1C7C,EAAsC,KACtC8C,EAAqC,MAbzChoB,KAAQyH,SAAG,GAGXzH,KAAAiH,cAAgB,CAAC,KACjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EASLnB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKmoB,QAAkB,MAARJ,EACf/nB,KAAKmlB,0BAAsD,MAA1B6C,EACjChoB,KAAKklB,WAAaA,EACdllB,KAAKmoB,SACPnoB,KAAKiH,cAAcjF,KAAK,QAGtBhC,KAAKmlB,2BACPnlB,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAK6L,UAAY,kBAAkBqZ,GACpC,CAEDte,cACE,MAAO,SACLqe,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlB,mCAC1C6B,EAAK,2JAIDxB,EAAsBxlB,KAAKmoB,QAASnoB,KAAKklB,4EAKhD,QCxIU6D,GAUXjpB,YAAY2E,GATZzE,KAAaiH,cAAa,GAC1BjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,eACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,MAClB,CAEDjF,cAQE,MAPiB,SACfogB,EAAK,sHAOR,EC1BG,SAAUgC,GAAKC,GAEnB,MAAMC,QAACA,EAAOC,MAAEA,GAASF,GACnBxkB,MAACA,EAAK8S,MAAEA,GAAS4R,EACvB,IAAI9iB,MAACA,GAAS8iB,EAId,GAFA9iB,EAAQA,GAASiE,EAAAA,KAAK8e,WAAW7R,GAEnB,WAAVlR,EAAoB,CAEtB,MAAMgN,EAAS/I,EAAIA,KAAC+e,kBAAkBhjB,EAAOiE,EAAAA,KAAKgO,cAAc7T,IAEhE,OADA4O,EAAO2V,KAAKzR,GACL2R,EAAQrQ,eAAepU,EAAO4B,EAAOgN,EAC7C,CAAM,CACL,MAAMhO,EAAU,IAAI0jB,GAAYtkB,GAC1B6kB,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACiC,KAC9C,OAAO2R,EAAQ1N,iBAAiBnW,EAAS,GAAIgB,EAAOijB,EACrD,CACH,CAEO,MAAMC,GAA2B,CACtCC,WAAYC,EAAIA,KAChBC,YAAa,SACbC,WAAYX,ICxBR,SAAUY,GACZX,GAEF,MAAMjf,OAACA,EAAMmf,MAAEA,GAASF,GAClB/hB,EAACA,GAAK8C,GACNvF,MAACA,GAAS0kB,EAEVU,EAAQvf,EAAIA,KAACgO,cAAcpR,EAAEzC,OAC7BqlB,EAASxf,EAAIA,KAACyf,uBAAuBtlB,EAAOolB,GAC5CG,EAAS1f,EAAAA,KAAKgO,cAAcwR,GAUlC,OARAxf,OAAKwC,OACD+c,IAAUG,GACV,IAAM,kBAAkBF,UAAeE,iCACzB9iB,EAAEzC,cAAcolB,mFAIlCZ,EAAKC,QAAQhW,OAAOhM,EAAE+K,QACf,CAACA,OAAQ/K,EAAE+K,OAAQxN,MAAOqlB,EAAQzjB,MAAOa,EAAEb,MACpD,CAEO,MAAM4jB,GAA8B,CACzCT,WAAYU,EAAOA,QACnBR,YAAa,SACbC,WAAYC,ICJE,SAAAO,IAAgBC,EAC9BA,EAACzW,EACDA,EAAC7F,WACDA,EAAU6X,WACVA,EAAUuD,QACVA,EAAOnB,KACPA,EAAO,KAAIC,uBACXA,EAAyB,KAAIqC,eAC7BA,EAAiB,EAACnF,WAClBA,EAAa,OAEb,MAAMoF,EAAQF,EAAE3lB,MAAM5C,OAChB0oB,EAAQ5W,EAAElP,MAAM5C,OAEhB2oB,EAAc1c,EAAasc,EAAE3lB,MAAM6lB,EAAQ,GAAKF,EAAE3lB,MAAM6lB,EAAQ,GAChEG,EAAc9E,EAAahS,EAAElP,MAAM8lB,EAAQ,GAAK5W,EAAElP,MAAM8lB,EAAQ,GAEhEG,EAAc5c,EAAasc,EAAE3lB,MAAM6lB,EAAQ,GAAKF,EAAE3lB,MAAM6lB,EAAQ,GAChEK,EAAchF,EAAahS,EAAElP,MAAM8lB,EAAQ,GAAK5W,EAAElP,MAAM8lB,EAAQ,GAEhEK,EAAaR,EAAE3lB,MAAM8C,MAAM,GAAI,GAC/BsjB,EAAalX,EAAElP,MAAM8C,MAAM,GAAI,GAE/BujB,EAAYxgB,EAAAA,KAAKgO,cAAcsS,GAC/BG,EAAYzgB,EAAAA,KAAKgO,cAAcuS,GAI/BxiB,EAFoB2iB,EAAAA,eAAeC,2BACrCb,EAAE3lB,MAAM8C,MAAM,GAAI,GAAIoM,EAAElP,MAAM8C,MAAM,GAAI,IACT2V,OAAO,CAACwN,EAAaC,IAExDrgB,EAAIA,KAACwC,OACD0d,IAAgBC,GAChB,IAAM,kCAAkCD,WACjCC,6BAAuCL,EAAE3lB,aACzCkP,EAAElP,wBAAwBqJ,oBACV6X,kBAE3B,MAAMuF,EAAqCpd,EACvC,CAACgd,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,GACvBW,EAAqCxF,EACvC,CAACoF,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGvBS,EAAMxB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGkjB,GAAIlB,UAASC,MAAO,CAAC1kB,MAAOymB,KACvDG,EAAMzB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyM,GAAIuV,UAASC,MAAO,CAAC1kB,MAAO0mB,KACvDG,EAA8B,CAACF,EAAKC,GAEpCE,EAAWjnB,KAAKC,IAAIumB,EAAWC,GAE/B/gB,EAAuB,CAACohB,EAAKC,GAC7BtiB,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAACoV,IAAe,CAACxlB,KAAM,QAASoQ,KAAM,CAACqV,IAC7D,CAACzlB,KAAM,QAASoQ,KAAM,CAACkV,KAGzB,IAAInlB,EACAmmB,EACJ,MAAMpe,EACF,CAACme,EAAUb,EAAaC,GAC5B,IAAIc,EAAoB9rB,EAAGA,MAAGiC,IAAI,8BAClC,GAAI6pB,EAAoB,EAAG,CAWzB,MAAMC,EACF/rB,EAAGA,MAAG2P,UAAU,sDACd0B,EAAgC0a,EAAqB,EACvDA,EACAxC,EAAQlY,8BACN2a,EACFJ,EAAWjnB,KAAKmJ,KAAKid,EAAc,IAAMpmB,KAAKmJ,KAAKkd,EAAc,IAOjEc,EALAE,GAAqB3a,GACpB0Z,GAAe,GACfiB,GAAqD,EAAhC3a,EAEpBua,EAAWb,EAAcC,GAAe,IACtB3b,EAAkBwZ,oBAChB,IAAb+C,GAAkBd,GAAe,IACtBzb,EAAkB6Z,oBAElB7Z,EAAkB0Z,6BAGpB1Z,EAAkB6Y,mBAEzC,CAED,OAAQ4D,GACN,KAAKzc,EAAkBwZ,oBACrBnjB,EAAU,IAAImjB,GACVpb,EAAaU,EAAY6X,EAAYoC,EAAM7C,EAC3C8C,GACJ,MACF,KAAKhZ,EAAkB6Z,oBAOrB,GAJA2C,EAAMxC,GACF,CAACE,UAASC,MAAO,CAAC1kB,MAAO2I,EAAamK,MAAO,EAAGlR,MAAO+jB,EAAE/jB,SAC7DhB,EAAU,IAAIwjB,GACVzb,EAAaqd,EAAa3c,EAAY6X,GACtCoC,GAAQ7C,EAAY,CACtBsG,EACItC,EAAQ1N,iBAAiBnW,EAAS2E,EAAQogB,EAAE/jB,MAAO0C,EAAYyiB,GACnE,MAAMI,EAAwB,IAAI9C,GAC9B0C,EAAI/mB,MAAOsjB,EAAM7C,EAAY8C,GACjC,IAAIsB,EAAc,KAClB,MAAMuC,EAAiC,CAACL,GACpCzD,GACF8D,EAAiB7pB,KAAK+lB,GAEpBC,GACF6D,EAAiB7pB,KAAKgmB,GAEL,cAAf9C,IACFoE,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC+U,KACxCuB,EAAsBnkB,UAAY,iBAEpC,MAAMqkB,EAAe5C,EAAQ1N,iBACzBoQ,EAAuBC,EAAkBL,EAAInlB,MAAOijB,GACxDgC,EAActpB,KAAKwpB,GACnB,MAAMO,EAAcnC,GAChB,CAAC5f,OAAQ,CAAC9C,EAAG4kB,GAAe5C,UAASC,MAAO,CAAC1kB,MAAO4D,KACxDijB,EAActpB,KAAK8pB,GACnB,IAAK,MAAMhnB,KAAKwmB,EACdpC,EAAQlX,YAAYlN,EAAEmN,QAExB,OAAO8Z,CACR,CACD,MAEF,KAAK/c,EAAkB0Z,6BACrBrjB,EAAU,IAAIqjB,GACVwC,EAAUC,EAAU/d,EAAaU,EAAY6X,EAAYoC,EACzD7C,EAAY8C,GAChB,MACF,KAAKhZ,EAAkB6Y,oBAGrB,MAAML,EAA4B0B,EAAQnpB,YAAYM,UACtDgF,EAAU,IAAIwiB,EACVqD,EAAU9d,EAAaU,EAAY6X,EAAYoC,EAAM7C,EACrD8C,EAAwBR,GAC5B,MACF,QACE,MAAM,IAAInlB,MAAM,iCAAiCopB,MAGjD1D,GACF/d,EAAOhI,KAAK+lB,GAEVC,GACFhe,EAAOhI,KAAKgmB,GAEK,cAAf9C,IACFnc,EAAW/G,KAAK,CAACkD,KAAM,UAAWoQ,KAAM,CAAC+U,KACzChlB,EAAQoC,UAAY,iBAEtB+jB,EAAMtC,EAAQ1N,iBAAiBnW,EAAS2E,EAAQogB,EAAE/jB,MAAO0C,EAAYyiB,GACrE,MAAMO,EACFnC,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGskB,GAAMtC,UAASC,MAAO,CAAC1kB,MAAO4D,KACvDijB,EAActpB,KAAKwpB,GACnB,IAAK,MAAM1mB,KAAKwmB,EACdpC,EAAQlX,YAAYlN,EAAEmN,QAExB,OAAO8Z,CACT,CC7KO,MAAMC,GAAmC,CAC9CxC,WAAYyC,EAAYA,aACxBvC,YAAa,SACbC,WAzBI,SAAuBV,GAK3B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BmB,EAACA,EAACzW,EAAEA,EAACoU,KAAEA,EAAIC,uBAAEA,GAA0Bhe,GACvC8D,WAACA,EAAU6X,WAAEA,EAAUT,WAAEA,EAAUmF,eAAEA,GAAkBlB,EAE7D,OAAOgB,GAAgB,CACrBC,IACAzW,IACA7F,aACA6X,aACAuD,UACAnB,OACAC,yBACAqC,iBACAnF,cAEJ,SCpBagH,GAUXpsB,YAAYqsB,EAAkBrE,EAAkBa,GAThD3oB,KAAaiH,cAAG,CAAC,QAAS,QAAS,QAAS,SAK5CjH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAEnD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3C,EAAYA,aAACwgB,2BAA2BnD,EAAQa,GACnE3oB,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,mBAAmBsgB,IACpCnsB,KAAKmsB,GAAKA,CACX,CAEDvlB,cAkBE,MAhBiB,gHADHqZ,EAAkBjgB,KAAKmsB,IAAI,wBAOrCnF,EAAK,gXAWV,QCtCUoF,GAiBXtsB,YAAYqsB,EAAkBrE,EAAkBa,GAU9C,GApBF3oB,KAAImB,MAAG,EACPnB,KAAAiH,cAAgB,CAAC,IAAK,KAUpBjH,KAAKoN,YAAc3C,EAAYA,aAACwgB,2BAA2BnD,EAAQa,GACnE3oB,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAKmsB,GAAKA,EAEVnsB,KAAKqsB,qBACDvE,EAAOjmB,QAAU,GAAK8mB,EAAO9mB,OAAS,GAAKimB,EAAO,GAAK,IAC3D9nB,KAAKssB,qBACD3D,EAAO9mB,QAAU,GAAKimB,EAAOjmB,OAAS,GAAK8mB,EAAO,GAAK,IAEvD3oB,KAAKqsB,sBAAwBrsB,KAAKssB,qBACpCtsB,KAAK+F,gBAAkB,EACvB/F,KAAKmI,mBAAqB,CAAC,EAAG,GAG9BnI,KAAKusB,kBACDvsB,KAAKssB,qBAAuB3D,EAAO,GAAKb,EAAO,GACnD9nB,KAAK6L,UAAY,UAAUsgB,KAAMnsB,KAAKusB,oBACtCvsB,KAAKkF,KAAO,SAGZlF,KAAK8F,cAAgB,CAAC,IAAK,EAAG,OACzB,CACL,MAAM0mB,EACF1E,EAAOjmB,OAAS,GAAKimB,EAAOA,EAAOjmB,OAAS,GAAK,GAAM,EACrD4qB,EACF9D,EAAO9mB,OAAS,GAAK8mB,EAAOA,EAAO9mB,OAAS,GAAK,GAAM,EACvD2qB,GAAiBC,GACnBzsB,KAAK+F,gBAAkB,EACvB/F,KAAKmI,mBAAqB,CAAC,EAAG,IAE3BqkB,IACCliB,OAAKoiB,cAAc/D,IAAyC,IAA9BA,EAAOA,EAAO9mB,OAAS,KACtD4qB,IACCniB,OAAKoiB,cAAc5E,IAAyC,IAA9BA,EAAOA,EAAOjmB,OAAS,KACzD7B,KAAK+F,gBAAkB,EACvB/F,KAAKmI,mBAAqBqkB,EAAgB,CAAC,EAAG,GAAK,CAAC,EAAG,KAEvDxsB,KAAK+F,gBAAkB,EACvB/F,KAAKmI,mBAAqB,CAAC,EAAG,IAEhCnI,KAAKkF,KAAO,YACZlF,KAAK6L,UAAY,UAAUsgB,KAAMnsB,KAAKmI,qBAGtCnI,KAAK8F,cAAgB,CAAC,IAAK,EAAG,EAC/B,CACD9F,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAK+F,gBAAiB,EAAG,GAC/B,CAEDa,cACE,IAAIyhB,EACJ,MAAMsE,EAAiC,IAAzB3sB,KAAK+F,gBAAwB,YAAc,MACnD6mB,EAAU,gCACSD,UAAcA,SAAaA,cAChD1M,EAAkBjgB,KAAKmsB,GAA6B,IAAzBnsB,KAAK+F,iCAIpC,GAAkB,WAAd/F,KAAKkF,KAAmB,CAC1B,MAAM2nB,EAAqB7sB,KAAKusB,kBAAoB,EAChD,UAAUvsB,KAAKoN,YAAYvL,OAAS,KACpC,IACEirB,EAAoB9sB,KAAKssB,qBAC3B,kEACoBO,MACpB,qBAAqBA,mDAEzBxE,EAAW,aACPuE,oDACsC5sB,KAAKusB,gCAC3CvF,EAAK,qIAGahnB,KAAKusB,iEAEvBvsB,KAAKssB,qBAAuB,IAAM,4KAM9BQ,kGAKT,MACCzE,EAAW,YACRuE,aACA5F,EAAK,yGAEuChnB,KAAK+F,yCACrC4mB,sDACAA,4HAOjB,OAAOtE,CACR,EC5HG,SAAU0E,GACZ9D,GACF,MAAMjf,OAACA,GAAUif,GACX/hB,EAACA,GAAK8C,EAGZ,OADAif,EAAKC,QAAQhW,OAAOhM,EAAE+K,QACf,CAACA,OAAQ/K,EAAE+K,OAAQxN,MAAOyC,EAAEzC,MAAO4B,MAAOa,EAAEb,MACrD,CAEO,MAAM2mB,GAA+B,CAC1CxD,WAAYyD,EAAQA,SACpBvD,YAAa,SACbC,WAAYoD,ICFR,SAAUG,GAAQjE,GAEtB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB3W,KAACA,EAAIC,KAAEA,GAAQvI,EAEfmjB,EAAcjE,EAAQrQ,eAAevG,EAAK7N,MAAO,aACjDyoB,EAAUhE,EAAQ/X,UAAUvP,IAAIurB,EAAYlb,QAE5Cmb,EAAiBL,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAGoL,GAAO4W,YAE9CmE,EAAiBN,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAGqL,GAAO2W,YAIpD,OAFAgE,EAAQ7a,mBAAqB,CAACC,KAAM8a,EAAgB7a,KAAM8a,GAEnDF,CACT,CAEO,MAAMG,GAA8B,CACzC9D,WAAY+D,EAAOA,QACnB7D,YAAa,SACbC,WAAYuD,UC7BDM,GAWX1tB,YAAYsN,EAAuB+e,EAAiB1kB,EAAW,IAN/DzH,KAAAiH,cAAgB,CAAC,KAIjBjH,KAAImB,MAAG,EAKLnB,KAAK8F,cAAgB,CADE,IACe,EAAG,GACzC9F,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKmsB,GAAKA,EACO,KAAb1kB,IACFzH,KAAKyH,SAAWA,GAElBzH,KAAK6L,UAAY,SAASsgB,GAC3B,CAEDvlB,cACE,MAAO,wDAED6b,EAAiBziB,KAAKmsB,IAAI,sBAE5BnF,EAAK,kLAOV,ECfG,SAAUyG,IACZC,OAACA,EAAMC,cAAEA,EAAatnB,MAAEA,IAC1B,MAAO,EAAE2D,SAAQkf,cACf,MAAMhiB,EAACA,GAAK8C,EACN4jB,EAAgB1E,EAEhB2E,EAASxnB,GAASa,EAAEb,MAC1B,GAAIunB,EAAc/O,mBAAmB,CAAC3X,KAAwB,MAAjBymB,EAAuB,CAClE,MAAMG,EAAQF,EAAczc,UAAUvP,IAAIsF,EAAE+K,QACtC8b,EAAYJ,EAAcG,EAAMza,OAAsBwa,GAC5D,OAAOD,EAAc/U,eAAe3R,EAAEzC,MAAOopB,EAAQE,EACtD,CAED,MAAM1oB,EAA0B,IAAImoB,GAAetmB,EAAEzC,MAAOipB,GAC5D,OAAOE,EAAcpS,iBAAiBnW,EAAS,CAAC6B,GAAI2mB,EAAO,CAE/D,CAkBgB,SAAAG,IACZN,OAACA,EAAMC,cAAEA,EAAaM,gBAAEA,GAAkB,EAAK5nB,MAAEA,IAEnD,MAAO,EAAE2D,SAAQkf,cACf,MAAMkB,EAACA,EAACzW,EAAEA,GAAK3J,EACT4jB,EAAgB1E,EAEtB,GAAI+E,GAA+B,cAAZ7D,EAAE/jB,MAAuB,CAC9C,MAAM6nB,EAAQN,EAAczc,UAAUvP,IAAIwoB,EAAEnY,QACtCkc,EAAQP,EAAczc,UAAUvP,IAAI+R,EAAE1B,QAC5C,IAAIK,EAAkBC,EACtB,GAAImb,IAAW1O,EAAa0C,KACzBpP,EAAMC,GAAQ,CACb,CAAC2b,EAAM7b,mBAAmBC,KAAM6b,EAAM9b,mBAAmBC,MACzD,CAAC4b,EAAM7b,mBAAmBE,KAAM4b,EAAM9b,mBAAmBE,OACzD7N,KAAI0pB,IACJ,MAAOC,EAAOC,GAASF,EAEjBG,EAAU,CACdtc,OAAQoc,EAAMpc,OACd5L,MAAOgoB,EAAMhoB,MACb5B,MAAO2lB,EAAE3lB,OAEL+pB,EAAU,CACdvc,OAAQqc,EAAMrc,OACd5L,MAAOioB,EAAMjoB,MACb5B,MAAOkP,EAAElP,OAGLY,EAAU,IAAI+mB,GAAgBsB,EAAQtD,EAAE3lB,MAAOkP,EAAElP,OACvD,OAAOmpB,EAAcpS,iBACjBnW,EAAS,CAACkpB,EAASC,GACnBC,EAAUA,WAACJ,EAAMhoB,MAAOioB,EAAMjoB,OAAO,QAEtC,CACL,MAAMqoB,EAAc,IAAIxC,GACpBlN,EAAa+B,sBAAuBqJ,EAAE3lB,MAAOkP,EAAElP,OAC7CkqB,EAAc,IAAIzC,GACpBlN,EAAa8B,sBAAuBsJ,EAAE3lB,MAAOkP,EAAElP,OAE7CuF,EAAS,CACb,CACEiI,OAAQic,EAAM7b,mBAAmBC,KAAKL,OACtC5L,MAAO6nB,EAAM7b,mBAAmBC,KAAKjM,MACrC5B,MAAO2lB,EAAE3lB,OAEX,CACEwN,OAAQic,EAAM7b,mBAAmBE,KAAKN,OACtC5L,MAAO6nB,EAAM7b,mBAAmBE,KAAKlM,MACrC5B,MAAO2lB,EAAE3lB,OAEX,CACEwN,OAAQkc,EAAM9b,mBAAmBC,KAAKL,OACtC5L,MAAO8nB,EAAM9b,mBAAmBC,KAAKjM,MACrC5B,MAAOkP,EAAElP,OAEX,CACEwN,OAAQkc,EAAM9b,mBAAmBE,KAAKN,OACtC5L,MAAO8nB,EAAM9b,mBAAmBE,KAAKlM,MACrC5B,MAAOkP,EAAElP,QAIb6N,EAAOsb,EAAcpS,iBAAiBkT,EAAa1kB,EAAQ,WAC3DuI,EAAOqb,EAAcpS,iBAAiBmT,EAAa3kB,EAAQ,UAC5D,CAED,MAAM4kB,EACF1B,GAAQ,CAACljB,OAAQ,CAACsI,OAAMC,QAAO2W,QAAS0E,IAO5C,OALAA,EAAc5b,YAAYM,EAAKL,QAC/B2b,EAAc5b,YAAYO,EAAKN,QAIxB2c,CACR,CAED,MAAMf,EAASxnB,GAASooB,EAAUA,WAACrE,EAAE/jB,MAAOsN,EAAEtN,OAC9C,IAAiB,WAAZ+jB,EAAE/jB,OAAkC,WAAZsN,EAAEtN,OAC1BunB,EAAc/O,mBAAmB,CAACuL,EAAGzW,MACrB,MAAjBga,EAAuB,CACzB,MAAMO,EAAQN,EAAczc,UAAUvP,IAAIwoB,EAAEnY,QAAQoB,OAC9C8a,EAAQP,EAAczc,UAAUvP,IAAI+R,EAAE1B,QAAQoB,OAC9Cwb,EAA2B,WAAZzE,EAAE/jB,MAEnBoE,EAAYA,aAACqkB,uBAAuBZ,GACpCA,EACEa,EAA2B,WAAZ3E,EAAE/jB,MAEnBoE,EAAYA,aAACqkB,uBAAuBX,GACpCA,GACGJ,EAAW1lB,GACdslB,EAAcvD,EAAE3lB,MAAOkP,EAAElP,MAAOoqB,EAAcE,EAAclB,GAEhE,OAAOD,EAAc/U,eAAexQ,EAAUwlB,EAAQE,EACvD,CACD,MAAM1oB,EAAU,IAAI+mB,GAAgBsB,EAAQtD,EAAE3lB,MAAOkP,EAAElP,OACvD,OAAOmpB,EAAcpS,iBAAiBnW,EAAS,CAAC+kB,EAAGzW,GAAIka,EAAO,CAElE,CC1JM,SAAUmB,GAA6B7C,GAE3C,MAAO,CAACrE,EAAkBa,EAAkBsG,EACpCC,EAAmB7oB,KACzB,MAAM8oB,EAAW1kB,EAAYA,aAACwgB,2BAA2BnD,EAAQa,GAE3DyG,EAAaD,EAASttB,OACtBwtB,EAAgB/kB,EAAAA,KAAKsC,eAAeuiB,GACpCG,EAAahlB,EAAAA,KAAKgO,cAAc6W,GAEhCI,EACFjlB,EAAIA,KAACqR,uBAAuBtV,EAA0BipB,GAEpDhF,EAAQxC,EAAOjmB,OACf0oB,EAAQ5B,EAAO9mB,OAEf2tB,EAAWllB,EAAAA,KAAKsC,eAAekb,GAC/B2H,EAAWnlB,EAAAA,KAAKsC,eAAe+b,GAE/B+G,EAAiBjlB,EAAYA,aAACC,iBAAiBod,EAAQqH,GACvDQ,EAAiBllB,EAAYA,aAACC,iBAAiBie,EAAQwG,GAE7D,GAAIO,EAAe7tB,OAAS8tB,EAAe9tB,SAAW,EACpD,IAAK,IAAIiD,EAAI,EAAGA,EAAIyqB,EAAO1tB,SAAUiD,EACnCyqB,EAAOzqB,GAAKqnB,EAAG8C,EAAMnqB,EAAImqB,EAAMptB,QAASqtB,EAAMpqB,EAAIoqB,EAAMrtB,cAG1D,IAAK,IAAIiD,EAAI,EAAGA,EAAIyqB,EAAO1tB,SAAUiD,EAAG,CACtC,MAAM8qB,EAAMtlB,EAAAA,KAAKulB,WAAW/qB,EAAGsqB,EAAYC,GAErCS,EAAOF,EAAIroB,OAAO+iB,GACxBoF,EAAehtB,SAAQiC,GAAKmrB,EAAKnrB,GAAK,IACtC,MAAMorB,EAASzlB,EAAAA,KAAK0lB,WAAWF,EAAMxF,EAAOkF,GAEtCS,EAAOL,EAAIroB,OAAOgjB,GACxBoF,EAAejtB,SAAQiC,GAAKsrB,EAAKtrB,GAAK,IACtC,MAAMurB,EAAS5lB,EAAAA,KAAK0lB,WAAWC,EAAM1F,EAAOkF,GAE5CF,EAAOzqB,GAAKqnB,EAAG8C,EAAMc,GAASb,EAAMgB,GACrC,CAGH,MAAO,CAACX,EAAQJ,EAAS,CAE7B,CC9CO,MAAMgB,GACTnB,IAA4B,CAAG5E,EAAWzW,IAAcyW,EAAIzW,ICDzD,MAAMyc,GACTpB,IAA4B,CAAG5E,EAAWzW,IAAcyW,EAAIzW,ICC1D,SAAU0c,GACsBlE,GAEpC,MAAO,CAAC9Y,EAAQhN,EAAO8iB,KACrB,MAAMmH,EACFhmB,EAAAA,KAAK+e,kBAAkBhjB,EAAOgN,EAAOxR,QACzC,IAAK,IAAIiD,EAAI,EAAGA,EAAIuO,EAAOxR,SAAUiD,EACnCwrB,EAAUxrB,GAAKqnB,EAAG9Y,EAAOvO,GAAIqkB,GAE/B,OAAOmH,CAAS,CAEpB,CCbO,MAAMC,GAAWF,IAAuBG,GAAOlsB,KAAKmJ,KAAK+iB,KCAzD,MAAMC,GACTzB,IAA6B,CAAC5E,EAAWzW,IAAeyW,IAAMzW,EAAK,EAAI,ICD9D+c,GAAUL,IAAuBG,GAAOlsB,KAAKqsB,IAAIH,KCAjDI,GAAYP,IAAuBG,GAAOlsB,KAAKusB,MAAML,KCArDM,GAAYT,IAAuBG,GAAOlsB,KAAKmT,MAAM+Y,KCArDO,GACT/B,IAA6B,CAAC5E,EAAWzW,IAAcrP,KAAKmT,MAAM2S,EAAIzW,KCDnE,MAAMqd,GACThC,IAA6B,CAAC5E,EAAWzW,IAAeyW,EAAIzW,EAAK,EAAI,ICD5Dsd,GACTjC,IAA6B,CAAC5E,EAAWzW,IAAeyW,GAAKzW,EAAK,EAAI,ICD7Dud,GACTlC,IAA6B,CAAC5E,EAAWzW,IAAeyW,EAAIzW,EAAK,EAAI,ICD5Dwd,GACTnC,IAA6B,CAAC5E,EAAWzW,IAAeyW,GAAKzW,EAAK,EAAI,ICDnE,MAAMyd,GAAUf,IAAuBG,GAAOlsB,KAAK+sB,IAAIb,KCAvD,MAAMc,GAActC,IACtB,CAACuC,EAAQC,IAAWltB,KAAKC,IAAIgtB,EAAkBC,KCDvCC,GAAczC,IACtB,CAACuC,EAAQC,IAAWltB,KAAKotB,IAAIH,EAAkBC,KCFvCG,GAAe3C,IAA4B,CAClDuC,EAAgBC,IAAmBD,EAASC,ICA3C,MAAMI,GACT5C,IAA8B,CAAC5E,EAAGzW,IAAOyW,IAAMzW,EAAK,EAAI,ICuC5D,SAASke,GACLC,EAAqBC,EACrBC,EAAkCC,GACpC,MAAMC,EAAuC,GAC7C,IAAIC,EAAY,EAEhB,MAAMC,EAAYL,EAAalwB,OAAS,EAAImwB,EAAmBnwB,OACzDwwB,EAAY,IAAIxtB,MAAMutB,GAAWpJ,KAAK,MAAMtkB,KAAI,IAAM,CAAC,MApC/D,SACIstB,EAAkCC,GAEpC,IAAK,IAAI9iB,EAAM,EAAGA,EAAM6iB,EAAmBnwB,SAAUsN,EAAK,CACxD,MAAMmjB,EAASN,EAAmB7iB,GAC5BojB,EAAapjB,IAAQ6iB,EAAmBnwB,OAAS,EACnDowB,EACAD,EAAmB7iB,EAAM,GAAGtN,OAChC,GAAsB,IAAlBywB,EAAOzwB,OACT,MAAM,IAAIQ,MAAM,kCAElB,GAAIiwB,EAAO,GAAK,EACd,MAAM,IAAIjwB,MAAM,sCAElB,GAAIiwB,EAAOA,EAAOzwB,OAAS,GAAK0wB,EAC9B,MAAM,IAAIlwB,MAAM,4CAElB,IAAK,IAAIyC,EAAI,EAAGA,EAAIwtB,EAAOzwB,SAAUiD,EACnC,GAAIwtB,EAAOxtB,EAAI,GAAKwtB,EAAOxtB,GACzB,MAAM,IAAIzC,MAAM,kDAGrB,CACH,CAeEmwB,CAAeR,EAAoBC,GASnC,IAAIQ,EAAQ,EACZ,IAAK,IAAItjB,EAAM,EAAGA,EAAM4iB,EAAalwB,OAAS,IAAKsN,EAAK,CACtDsjB,GAASV,EAAa5iB,GACtB,MAAMujB,EAAYX,EAAa5iB,EAAM,GACrC,IAAK,IAAIrK,EAAI,EAAGA,EAAI2tB,EAAQ,IAAK3tB,EAC/ButB,EAAUljB,GAAKnN,KAAK8C,EAAI4tB,EAE3B,CAWD,IAAK,IAAI5tB,EAAI,EAAGA,EAAIgtB,EAAQjwB,SAAUiD,EAAG,CACvC,IAAI6tB,EAAQb,EAAQhtB,GAChB8tB,EAAQd,EAAQhtB,GAAK,EAGzB,IAAK,IAAIqK,EAAM,EAAGA,EAAM6iB,EAAmBnwB,SAAUsN,EAAK,CACxD,MAAMmjB,EAASN,EAAmB7iB,GAC5B0jB,EAAS1jB,EAAM4iB,EAAalwB,OAAS,EAC3C,GAAIgxB,GAAU,EAAG,CACf,MAAMC,EAAkBT,EAAUQ,GAC5BE,EACFD,EAAgBA,EAAgBjxB,OAAS,GAAKywB,EAAOK,GACzD,IAAK,IAAI7pB,EAAI6pB,EAAO7pB,EAAI8pB,IAAS9pB,EAC/BupB,EAAUQ,GAAQ7wB,KAAKswB,EAAOxpB,EAAI,GAAKiqB,EAE1C,CACDJ,EAAQL,EAAOK,GACfC,EAAQN,EAAOM,EAChB,CACGA,IAAUD,IACZT,EAAYlwB,KAAK,CAAC2wB,EAAOC,IACzBT,GAAaS,EAAQD,EAExB,CAED,MAAO,CAACN,YAAWH,cAAaC,YAClC,CAeA,SAASa,GAAqBC,EAAgBC,GAC5C,MAAMC,EAAUF,EAAK1rB,MAAM,EAAG2rB,GAC9B,KAAOC,EAAQtxB,OAASqxB,GACtBC,EAAQnxB,KAAK,GAGf,IAAK,IAAIoxB,EAAQF,EAAYE,EAAQH,EAAKpxB,OAAQuxB,IAChDD,EAAQD,EAAa,IAAMD,EAAKG,GAGlC,OAAOD,CACT,CAsBA,SAASE,GACLC,EAA+BC,EAC/BC,EAAkCtB,EAClCC,GACF,MAAMsB,EAAcF,EAAuBhsB,QAC3CksB,EAAY,GAAKtB,EAEjB,MAAMuB,EAAYppB,EAAIA,KAAC+e,kBACDmK,EACAlpB,EAAAA,KAAKgO,cAAcmb,IAEnCE,EAAcL,EAAkBzxB,OAOtC,OApCF,SACIyxB,EAA+BC,EAC/BrB,EAAsC0B,EAAmBvgB,EACzDogB,GACF,MAAMI,EAASb,GAAqBO,EAAwB,GAAG,GACzDO,EAAUd,GAAqBS,EAAa,GAAG,GAErD,IAAIM,EAAS,EACb,IAAK,MAAMxsB,KAAS2qB,EAClB,IAAK,IAAIptB,EAAIyC,EAAM,GAAIzC,EAAIyC,EAAM,KAAMzC,EAAG,CACxC,IAAK,IAAIgE,EAAI,EAAGA,EAAI8qB,IAAa9qB,EAC/BuK,EAAO0gB,EAASD,EAAUhrB,GAAKwqB,EAAkBxuB,EAAI+uB,EAAS/qB,KAE9DirB,CACH,CAEL,CAgBEC,CACIV,EAAmBC,EAAwBrB,EAF3B,IAAhByB,EAAoB,EAAKA,EAAcJ,EAAuB,GAG9DG,EAAWD,GAER,CAACC,EAAWD,EACrB,CC5KA,MAAMQ,GAAY,WCAlB,IAAOC,GAAmBzpB,EAAYA,aAACypB,iBAGvC,MAAMC,GAGJr0B,YACY2E,EAA2B2vB,EAC3B/gB,EAA4BogB,EAC5BY,EAA+BC,EAC/BC,EACSC,EACAC,EACjBC,GANQ10B,KAAKyE,MAALA,EAA2BzE,KAAUo0B,WAAVA,EAC3Bp0B,KAAMqT,OAANA,EAA4BrT,KAAWyzB,YAAXA,EAC5BzzB,KAAWq0B,YAAXA,EAA+Br0B,KAAYs0B,aAAZA,EAC/Bt0B,KAAiBu0B,kBAAjBA,EACSv0B,KAAkBw0B,mBAAlBA,EACAx0B,KAAwBy0B,yBAAxBA,EAEnBz0B,KAAK20B,kBACDlqB,eAAamqB,2BAA2BF,GAC5C10B,KAAK60B,WAAapqB,EAAYA,aAACqqB,cAAc90B,KAAK20B,kBACnD,CAEOI,+BAA+BC,GACrC,OAAIh1B,KAAK20B,kBAAkB,KAAOT,GAAiBe,eAC1Cj1B,KAAK20B,kBAAkBK,EAAY,GAEnCh1B,KAAK20B,kBAAkBK,EAEjC,CAGOE,sBAAsBF,GAC5B,OAAIh1B,KAAK20B,kBAAkB,KAAOT,GAAiBe,eAC1Cj1B,KAAKw0B,mBAAmBQ,EAAY,GAEpCh1B,KAAKw0B,mBAAmBQ,EAElC,CAEOG,YAAYH,GAClB,MAAMI,EAAqBp1B,KAAKk1B,sBAAsBF,EAAY,GAClE,OAAQh1B,KAAK+0B,+BAA+BC,EAAY,IACtD,KAAKd,GAAiBmB,aACpB,OAAOlB,GAAuBmB,sBAAsBF,GACtD,KAAKlB,GAAiBqB,WACpB,OAAOpB,GAAuBqB,oBAAoBJ,GACpD,QACE,MAAM,IAAI/yB,MAAM,gCACZ6xB,GAAiBl0B,KAAK+0B,+BAClBC,EAAY,OAEzB,CAEDS,2BAA2BC,GACzB,MAAMC,EAAeD,EAAS7zB,OAC9B,GAAqB,IAAjB8zB,GAAuC,IAAjBA,EACxB,OAAO,EAET,IAAIC,EAAW,EACf,IAAK,IAAI9wB,EAAI,EAAGA,EAAI6wB,EAAe,IAAK7wB,EAAG,CACzC,MAAM+wB,EAAeH,EAAS5wB,EAAI,GAAK4wB,EAAS5wB,GAC5C+wB,EAAeD,IACjBA,EAAWC,EAEd,CACD,OAAOD,CACR,CAEDH,6BAA6BK,GAC3B,MAAMC,EAAcD,EAAYj0B,OAChC,GAAoB,IAAhBk0B,EACF,OAAO,EAET,IAAIC,EAAkB,EAClBC,EAAuBH,EAAY,GACnCF,EAAW,EACf,IAAK,IAAI9wB,EAAI,EAAGA,EAAIixB,IAAejxB,EAAG,CACpC,MAAMyS,EAAQue,EAAYhxB,GACtByS,IAAU0e,IACZA,EAAuB1e,EACvBqe,EAAWtxB,KAAKC,IAAIO,EAAIkxB,EAAiBJ,GACzCI,EAAkBlxB,EAErB,CACD,OAAOR,KAAKC,IAAIwxB,EAAcC,EAAiBJ,EAChD,CAEOM,sBACJnnB,EAAeonB,EAAkBC,GAAY,GAC/C,GAAsB,IAAlBD,EAAOt0B,OAAc,CACvB,IAAc,IAAVkN,EAAE,GACJ,MAAO,GAET,MAAM,IAAI1M,MACN,iFACL,CAED,OAAOg0B,GAAUtnB,EAAGqnB,EACrB,CAEOE,oBAAoBC,GAC1B,MAAMC,EAAax2B,KAAKyzB,YAClBc,EAAoBv0B,KAAKu0B,kBAE/B9pB,EAAAA,aAAagsB,0BAA0BlC,EAAmBiC,GAE1D,MAAM/xB,EAAQzE,KAAKk2B,sBAAsBl2B,KAAKyE,MAAOzE,KAAKo0B,YAIpD7E,EAHc9kB,EAAAA,aAAaisB,kCAC7B12B,KAAK60B,WAAYpwB,EAAO+xB,GAIxBjH,EAAO,GAAK,IACdA,EAAO,GAAKgH,GAEd,IAAK,IAAIzxB,EAAI,EAAGA,GAAK9E,KAAK60B,aAAc/vB,EAClCyqB,EAAOzqB,GAAK,IACdyqB,EAAOzqB,GAAK9E,KAAKm1B,YAAYrwB,IAIjC,OAAOyqB,CACR,CAYOoH,gCACJC,EAAwBC,EACxBC,GACF,MAAMC,EAAezyB,KAAKotB,IAAIkF,EAAgBE,GACxCvH,EAAmB,GACzB,IAAIyH,EAAqB,EACzB,IAAK,IAAIlyB,EAAI,EAAGA,EAAIiyB,IACbjyB,EAAGkyB,GAAsBH,EAC9BtH,EAAOvtB,KAAKg1B,GAEd,IAAK,IAAIlyB,EAAIiyB,EAAcjyB,EAAI8xB,IAAkB9xB,EAC/CyqB,EAAOvtB,MAAM,GAMf,OAJAsI,EAAIA,KAACwC,OACDyiB,EAAO1tB,SAAW+0B,GAClB,IAAM,4DAEHrH,CACR,CAEO0H,6BACJvB,EAAsBwB,EACtBL,EAA+BM,GACjC,MAAMC,EAAe1B,EAAS7zB,OACxB0tB,EAAmB,GACzB,IAAK,IAAIzqB,EAAI,EAAGA,EAAIsyB,EAAe,IAAKtyB,EAAG,CACzC,MAAM4tB,EAAYgD,EAAS5wB,EAAI,GAAK4wB,EAAS5wB,GAC7C,IAAIuyB,EAAa/yB,KAAKotB,IAAIyF,EAAYzE,GAClC4E,EAA2BJ,EAAkBpyB,IAEf,IAA9BwyB,IACFD,EAAa,GAEf,IAAK,IAAIvuB,EAAI,EAAGA,EAAIuuB,IAAcvuB,EAChCymB,EAAOvtB,KAAKs1B,GACZA,GAA4BT,EAE9B,IAAK,IAAI/tB,EAAI,EAAGA,EAAI4pB,EAAY2E,IAAcvuB,EAC5CymB,EAAOvtB,MAAM,EAEhB,CACD,GAAIo1B,EAAe,GAAK7H,EAAO1tB,SAAW6zB,EAAS0B,EAAe,GAChE,MAAM,IAAI/0B,MAAM,2BAGlB,OAAOktB,CACR,CAuBOgI,+BACJzB,EAAyBoB,EACzBL,EAA+BM,GACjC,MAAMK,EAAY1B,EAAYj0B,OACxB0tB,EAAmB,GACzB,GAAkB,IAAdiI,EACF,MAAO,GAGT,IAAIC,EAAsB,EACtBC,EAAoB5B,EAAY,GAEpC,GAAI4B,GAAqBR,EAAkBr1B,OACzC,MAAM,IAAIQ,MACN,yBAAyBq1B,6BACrBR,EAAkBr1B,UAG5B,IAAIm1B,EAAqBE,EAAkBQ,GAC3CnI,EAAOvtB,KAAKg1B,GACZ,IAAK,IAAIlyB,EAAI,EAAGA,EAAI0yB,IAAa1yB,EAAG,CAClC,MAAM6yB,EAAiB7B,EAAYhxB,GACnC,GAAI6yB,IAAmBD,EACjBV,GAAsB,MACtBS,EACEA,EAAsBN,EACxBH,GAAsBH,EAEtBG,GAAsB,OAGrB,CAIL,GAHAS,EAAsB,EACtBC,EAAoBC,EAEhBA,GAAkBT,EAAkBr1B,OACtC,MAAM,IAAIQ,MACN,sBAAsBs1B,4BAClBT,EAAkBr1B,UAG5Bm1B,EAAqBE,EAAkBS,EACxC,CACDpI,EAAOvtB,KAAKg1B,EACb,CAED,GAAIzH,EAAO1tB,SAAWi0B,EAAYj0B,OAChC,MAAM,IAAIQ,MAAM,oBAGlB,OAAOktB,CACR,CAEOqI,qBACJ5C,EAAmBkC,EACnBL,EAA+BM,GACjC,MAAM/B,EAAqBp1B,KAAKk1B,sBAAsBF,GAChD6C,EAAgB73B,KAAK+0B,+BAA+BC,GAC1D,OAAQ6C,GACN,KAAK3D,GAAiBmB,aACpB,OAAOr1B,KAAKu3B,+BACRnC,EAAoB8B,EAAmBL,EACvCM,GACN,KAAKjD,GAAiBqB,WACpB,GAAIH,EAAmBvzB,OAAS,EAAIq1B,EAAkBr1B,OACpD,MAAM,IAAIQ,MAAM,mDACZ+yB,EAAmBvzB,OAAS,OAAOq1B,EAAkBr1B,UAE3D,OAAO7B,KAAKi3B,6BACR7B,EAAoB8B,EAAmBL,EACvCM,GACN,QACE,MAAM,IAAI90B,MACN,+BAA+B6xB,GAAiB2D,MAEzD,CAEOC,wBACN,MAAMC,EAAuB/3B,KAAKw0B,mBAAmB,GACrD,GAAsC,IAAlCx0B,KAAK20B,kBAAkB9yB,OACzB,MAAM,IAAIQ,MAAM,iCAElB,MAAM21B,EAAqBh4B,KAAK20B,kBAAkB,GAClD,OAAQqD,GACN,KAAK9D,GAAiBe,eACpB,OAAO8C,EAAqB,GAC9B,KAAK7D,GAAiBmB,aACpB,MAAM,IAAIhzB,MAAM,kDAClB,KAAK6xB,GAAiBqB,WACpB,OAAOv1B,KAAKy0B,yBAAyB,GAAG,GAAK,EAC/C,QACE,MAAM,IAAIpyB,MACN,sBAAsB6xB,GAAiB8D,MAEhD,CAED5rB,UAEE,GAD6BpM,KAAKw0B,mBAAmB,GAC5B3yB,QAAU,EACjC,MAAM,IAAIQ,MACN,wEAGN,MAAMu0B,EAAiB52B,KAAK83B,wBACtBX,EAAan3B,KAAKs2B,oBAAoBM,GACtCqB,EAAuB,IAAIpzB,MAAM7E,KAAK60B,WAAa,GAEzDoD,EAAWA,EAAWp2B,OAAS,GAAK,EACpC,IAAK,IAAIiD,EAAImzB,EAAWp2B,OAAS,EAAGiD,GAAK,IAAKA,EAC5CmzB,EAAWnzB,GAAKmzB,EAAWnzB,EAAI,GAAKqyB,EAAWryB,EAAI,GAGrD,MAAMsI,EAAwBipB,GAAUc,GAAY,GAC9Ce,EACF5tB,OAAK+e,kBACDrpB,KAAKq0B,YAAa/pB,OAAKgO,cAAclL,IAG7C,GADiB6qB,EAAW,GAAKd,EAAW,GAC7B,EAAG,CAChB,IAAIgB,EAAcn4B,KAAK22B,gCACnBC,EAAgBqB,EAAW,GAAId,EAAW,IAC9C,IAAK,IAAIryB,EAAI,EAAGA,GAAK9E,KAAK60B,aAAc/vB,EAAG,CAGzCqzB,EAFuBn4B,KAAK43B,qBACxB9yB,EAAI,EAAGqzB,EAAaF,EAAWnzB,GAAIqyB,EAAWryB,GAEnD,CAED9E,KAAKo4B,UAAUp4B,KAAK60B,WAAYsD,EAAaD,EAAc9qB,EAC5D,CAED,MAAO,CAACA,EAAa8qB,EACtB,CACDE,UACIvD,EAAoBsD,EAAuBD,EAC3C9qB,GACF,GAA4B,IAAxB8qB,EAAar2B,OACf,OAGF,MAAMw2B,EAAar4B,KAAKqT,OAClBilB,EAAaJ,EAEnB,IAAIK,EAAenrB,EAAY7F,QAC/BgxB,EAAeA,EAAahxB,MAAMstB,EAAa,GAC/C,MAAM2D,EAAmBluB,EAAAA,KAAKgO,cAAcigB,GACtCE,EAAkBN,EAAYt2B,OAIpC,IAAIyyB,EAAet0B,KAAKs0B,aACxB,GAAIA,EAAazyB,SAAW22B,GAA4C,IAAxBlE,EAAazyB,OAAc,CACzE,MAAM62B,EAAW14B,KAAKu0B,kBACtBoE,EAAAA,MAAK,KACH,MAAMC,EAAqBhP,EAAAA,QAAQ0K,EAAcoE,GAC3CG,EAAeC,EAAAA,YAAYF,EAAoBL,GACrDjE,EAAeuE,EAAaE,UAAU,GAEzC,CAKD,IAAIC,EAAW,EACXC,EAAW,EACXC,EAAS,EACb,IAAK,IAAIC,EAAO,EAAGA,GAAQV,IAAmBU,EAAM,CAElD,IAAIC,EAAOD,EAAOV,EAAkBN,EAAYgB,IAAS,EAIzD,GAAIC,IAASF,EAAb,CASA,GAAID,EAAWC,EAAQ,CAErB,MAAMG,EAAMhB,EAAWiB,SAASN,EAAWR,GAG3Ce,GAFYjB,EAAWgB,SAASL,EAAWT,GAE5Ba,GADAH,EAASD,GAAYT,EAErC,CAGD,GAAIW,GAAQV,EAAiB,CAE3B,MAAMtB,EAAae,EAAar2B,OAChCu3B,EAAO90B,KAAKmT,MAAM0f,EAAaqB,EAChC,CACD,GAAIY,EAAOF,EACT,GAAiC,IAA7Bl5B,KAAKs0B,aAAazyB,OACpBy2B,EACKgB,SAASJ,EAASV,EAAkBY,EAAOZ,GAC3CxP,KAAKhpB,KAAKs0B,aAAa,IAC5B4E,EAASE,OAET,KAAOA,EAAOF,GAAQ,CAEpBK,GADYjB,EAAW/wB,MAAM2xB,EAASV,GACvBlE,EAAckE,KAC3BU,CACH,CAKDE,EAAO,GAETJ,EAAWG,EAAO,EAClBF,EAAWC,IAGXF,EAAWG,EACXF,EAAWC,EACXA,EAASD,EAAW,EA5CrB,OAFGC,CAgDL,CACF,EAGH,SAASK,GAAUC,EAAiBH,EAAiBl4B,GACnD,IAAK,IAAI2D,EAAI,EAAGA,EAAI3D,EAAM2D,IACxB00B,EAAI10B,GAAKu0B,EAAIv0B,EAEjB,CAEA,SAASuxB,GAAU5xB,EAA4B2xB,GAC7C,MAAM5K,EAAgB,GACtB,IAAK,IAAIrc,KAAO1K,EAAO,CACrB,GAAI0K,EAAM,EAAG,CACX,IAAKinB,EACH,MAAM,IAAI/zB,MAAM,aAAa8M,kBAE/B,GAAIA,GAAO,EACT,MAAM,IAAI9M,MAAM,aAAa8M,mBAE/BA,GAAO,CACR,CACDqc,EAAIxpB,KAAKmN,EACV,CAED,OAAOqc,CACT,CC3bO,MAAMiO,GAAYpJ,IAAuBG,GAAO,EAAIlsB,KAAK0X,KAAKwU,KCA9D,MAAMkJ,GACTrJ,IAAuBG,GAAO,GAAK,EAAIlsB,KAAKqsB,KAAKH,MCD9C,MAAMmJ,GAAWtJ,IAAuBG,GAAOlsB,KAAK0X,KAAKwU,KCAnDoJ,GACT5K,IAA4B,CAAG5E,EAAWzW,KACxC,MAAMkmB,EAAOzP,EAAIzW,EACjB,OAAOkmB,EAAOA,CACf,ICLQC,GAAyBzJ,IAC5B,CAACnpB,EAAWiiB,KAClB,MAAM4Q,QAACA,EAAOC,cAAEA,EAAaC,QAAEA,GAC7B9Q,EAEF,OAAOjiB,EAAEU,QAAQ,IAAIsyB,OAAOH,EAASC,EAAgB,IAAM,IAAKC,EAAQ,ICD5E,MAAME,GAQJr6B,YACIs6B,EAAmBC,EAAuBC,EAC1CC,EAAkBC,EAAkBC,GACtCz6B,KAAKo6B,UAAY9vB,EAAAA,KAAK8P,aAAaggB,GACnCp6B,KAAKq6B,YAAcA,EACnBr6B,KAAKs6B,QAAUhwB,EAAAA,KAAK8P,aAAakgB,GACjCt6B,KAAKu6B,SAAWjwB,EAAAA,KAAK8P,aAAamgB,GAClCv6B,KAAKw6B,SAAWA,EAChBx6B,KAAK06B,cAAgBD,CACtB,CAEOE,YAAYC,GAIlB,OAAOt2B,KAAKotB,IACR1xB,KAAKw6B,SAAW,EAAII,EAAa,EAAI56B,KAAKw6B,SAAUI,EAAa,EACtE,CAEOC,aAAah5B,EAAgB+4B,GACnC,MAAMJ,EAAWx6B,KAAK26B,YAAYC,GAClC,OAAOt2B,KAAKC,IAAI,EAAK1C,EAAS,EAAI24B,EAAYI,EAAc,EAC7D,CAEOE,aACJxlB,EAAoBylB,EAAoBx1B,EACxCy1B,EAA0BC,EAAmBL,GAC/C,IAAK,IAAIM,EAAa,EAAGA,EAAaD,IAAaC,EAAY,CAC7D,MAAMV,EAAWx6B,KAAK26B,YAAYC,GAC5BO,EAAc72B,KAAKC,IAAI,EAAGi2B,EAAWU,GACrCE,EACF92B,KAAKC,IAAI,EAAGi2B,GAAYS,GAAaC,EAAa,KAChDG,EAAYT,GAAcO,EAAcC,GACxCE,EACFP,GAAcI,EAAc,EAAI,EAAID,EAAaV,GAIrD,IAAIe,EAAY,EAEhBA,GAAaJ,EAAcn7B,KAAKs6B,QAAQz4B,OAExC,IAAK,IAAI25B,EAAI,EAAGA,EAAIH,IAAaG,EAC/BD,GAAajmB,EAAKgmB,EAAiBE,GAAG35B,OAGxC05B,GAAaH,EAAep7B,KAAKu6B,SAAS14B,OAG1C05B,IADsBJ,EAAcC,EAAeC,EAAY,GAClCr7B,KAAKo6B,UAAUv4B,OAG5C0D,EAAOy1B,EAAmBE,GAAc,IAAIO,WAAWF,GACvD,MAAMG,EAAQn2B,EAAOy1B,EAAmBE,GAExC,IAAIS,EAAiB,EACrB,MAAMC,EAAiBC,GACnBA,EAAIn5B,SAAS6U,GAAUmkB,EAAMC,KAAoBpkB,IAErD,IAAK,IAAIikB,EAAI,EAAGA,EAAIL,IAAeK,EACjCI,EAAc57B,KAAKs6B,SACnBsB,EAAc57B,KAAKo6B,WAGrB,IAAK,IAAIoB,EAAI,EAAGA,EAAIH,EAAY,IAAKG,EACnCI,EAActmB,EAAKgmB,EAAiBE,IACpCI,EAAc57B,KAAKo6B,WAIrB,GAAIiB,EAAY,EAAG,CAIjBO,EAActmB,EAAKgmB,EAAiBD,EAAY,IAChD,IAAK,IAAIG,EAAI,EAAGA,EAAIJ,IAAgBI,EAClCI,EAAc57B,KAAKo6B,WACnBwB,EAAc57B,KAAKu6B,SAEtB,KAAM,CAKL,IAAK,IAAIiB,EAAI,EAAGA,EAAIJ,EAAe,IAAKI,EACtCI,EAAc57B,KAAKu6B,UACnBqB,EAAc57B,KAAKo6B,WAErBwB,EAAc57B,KAAKu6B,SACpB,CACF,CACF,CAKMnuB,QAAQkJ,EAAoBgd,GAIjC,MAAMwJ,EAAgBxmB,EAAKzT,OACrBk6B,EAAazJ,EAAOzwB,OAC1B,GAAIk6B,EAAa,EAAG,CAClB,IAAIC,EAAY1J,EAAO,GACvB,GAAkB,IAAd0J,EACF,MAAM,IAAI35B,MAAM,oCAAoC25B,KAEtD,IAAK,IAAIl3B,EAAI,EAAGA,EAAIi3B,IAAcj3B,EAAG,CACnC,IAAIm3B,EAAc3J,EAAOxtB,IAAMk3B,EAE/B,GADAC,EAAcA,GAAgB3J,EAAOxtB,IAAMg3B,GACtCG,EACH,MAAM,IAAI55B,MAAM,uBAAuBiwB,EAAOxtB,mBAC1Ck3B,MAAcF,MAEpBE,EAAY1J,EAAOxtB,EACpB,CACD,GAAIk3B,IAAcF,EAChB,MAAM,IAAIz5B,MAAM,gDACZy5B,UAAsBE,IAE7B,CAED,MAAME,EAAgBH,EAAa,EAC7BI,EAAe7xB,EAAIA,KAAC+e,kBAAkB,QAAS0S,GAErD,GAAsB,IAAlBD,GAAsC,IAAfC,EAAkB,CAC3C,MAAMK,EAAsB,IAAIv3B,MAAMi3B,GACtC,IAAK,IAAIh3B,EAAI,EAAGA,GAAKo3B,IAAiBp3B,EACpCq3B,EAAar3B,GAAK,EAEpB,MAAO,CAACs3B,EAAOD,EAChB,CAEDA,EAAa,GAAK,EAClB,IAAK,IAAIr3B,EAAI,EAAGA,GAAKo3B,IAAiBp3B,EAAG,CACvC,MAAMjD,EAASywB,EAAOxtB,GAAKwtB,EAAOxtB,EAAI,GACtC,IAAIm2B,EAAY,EAChBj7B,KAAKq6B,YAAY33B,SAASk4B,IACxBK,GAAaj7B,KAAK66B,aAAah5B,EAAQ+4B,EAAW,IAEhD56B,KAAK06B,eAAiB74B,EAAS,GAAmB,IAAdo5B,IACtCA,EAAY,GAEdkB,EAAar3B,GAAKq3B,EAAar3B,EAAI,GAAKm2B,CACzC,CAED,MAAMoB,EAAuB,IAAIx3B,MAAMs3B,EAAaD,IAEpD,IAAK,IAAIp3B,EAAI,EAAGA,EAAIo3B,IAAiBp3B,EAAG,CACtC,MAAMi2B,EAAazI,EAAOxtB,GAC1B,IAAIw3B,EAAiBH,EAAar3B,GAalC,GAZA9E,KAAKq6B,YAAY33B,SAASk4B,IACxB,MAAM/4B,EAASywB,EAAOxtB,EAAI,GAAKwtB,EAAOxtB,GAChCm2B,EAAYj7B,KAAK66B,aAAah5B,EAAQ+4B,GAC5C56B,KAAK86B,aACDxlB,EAAMylB,EAAYsB,EAAQC,EAAgBrB,EAAWL,GACzD0B,GAAkBrB,CAAS,IAOzBj7B,KAAK06B,eAAiB4B,IAAmBH,EAAar3B,GAAI,CAC5D,MAAMy3B,EAAajK,EAAOxtB,EAAI,GAAKwtB,EAAOxtB,GAG1C,GAAmB,IAAfy3B,EACF,SAKF,MAAM3B,EAAa2B,EAAa,EAAIv8B,KAAKw6B,SACnCS,EAAY,EAClBj7B,KAAK86B,aACDxlB,EAAMylB,EAAYsB,EAAQC,EAAgBrB,EAAWL,EAC1D,CACF,CACD,MAAO,CAACyB,EAAQF,EACjB,EClMH,SAASzwB,GACLmwB,EAAiBW,EAAwBC,EACzClN,GACF,IAAKsM,EAAIh6B,OACP,OAGF,GAA0B,IAAtB26B,EAAW36B,OAAc,CAC3B,IAAK,IAAIiD,EAAI,EAAGA,EAAI+2B,EAAIh6B,SAAUiD,EAChCyqB,EAAOvtB,KAAK65B,EAAIvC,SAASx0B,EAAGA,EAAI,IAElC,MACD,CAED,GAA0B,IAAtB03B,EAAW36B,OAAc,CAC3B,MAAM66B,EAAYF,EAAW,GAC7B,IAAIpjB,EAAIyiB,EAAIz5B,QAAQs6B,GACpB,MAAc,IAAPtjB,GAAU,CACf,MAAMujB,EAAQd,EAAIvC,SAAS,EAAGlgB,GACzBqjB,GAA8B,IAAjBE,EAAM96B,QACtB0tB,EAAOvtB,KAAK26B,GAGdvjB,GADAyiB,EAAMA,EAAIvC,SAASlgB,EAAI,IACfhX,QAAQs6B,EACjB,CAID,YAHKD,GAA4B,IAAfZ,EAAIh6B,QACpB0tB,EAAOvtB,KAAK65B,GAGf,CAGD,IAAIe,EAAa,EACjB,IAAK,IAAI93B,EAAI,EAAGA,EAAI+2B,EAAIh6B,OAAS,EAAGiD,IAClC,GAAKA,IAAM+2B,EAAIh6B,SAA4C,IAAhC26B,EAAWp6B,QAAQy5B,EAAI/2B,IAAa,CAC7D,MAAM63B,EAAQd,EAAIvC,SAASsD,EAAY93B,GAClC23B,GAA8B,IAAjBE,EAAM96B,QACtB0tB,EAAOvtB,KAAK26B,GAEdC,EAAa93B,EAAI,CAClB,CAEL,CCvCO,MAAM+3B,GAAU7N,IAA4B,CAC7CuC,EAAgBC,IAAmBD,EAASC,ICGlD,MAAMsL,GAAc,CAAC1S,EAASzW,KAC5B,MAAMopB,EAAYppB,EAAE4D,MAAQ6S,EAAE7S,MAC9B,OAAqB,IAAdwlB,EAAkB3S,EAAEjoB,MAAQwR,EAAExR,MAAQ46B,CAAS,EAcxD,SAASC,GAAOC,EAAe3lB,EAAW4lB,EAAO,EAAGC,EAAQF,EAAMp7B,OAAS,GACzE,KAAOs7B,EAAQD,GAAM,CAInB,GAAIC,EAAQD,EAAO,IAAK,CACtB,MAAM1B,EAAI2B,EAAQD,EAAO,EACnBp4B,EAAIwS,EAAI4lB,EAAO,EACf10B,EAAIlE,KAAK+sB,IAAImK,GACbxwB,EAAI,GAAM1G,KAAKqsB,IAAI,EAAInoB,EAAI,GAC3B40B,EAAK,GAAM94B,KAAK0X,KAAKxT,EAAIwC,GAAKwwB,EAAIxwB,GAAKwwB,GAAKl3B,KAAK+4B,KAAKv4B,EAAI02B,EAAI,GAGpEwB,GAAOC,EAAO3lB,EAFEhT,KAAKC,IAAI24B,EAAM54B,KAAKmT,MAAMH,EAAIxS,EAAIkG,EAAIwwB,EAAI4B,IACzC94B,KAAKotB,IAAIyL,EAAO74B,KAAKmT,MAAMH,GAAKkkB,EAAI12B,GAAKkG,EAAIwwB,EAAI4B,IAEnE,CAED,MAAMruB,EAAIkuB,EAAM3lB,GAChB,IAAIxS,EAAIo4B,EACJp0B,EAAIq0B,EAOR,IALA7yB,EAAAA,KAAKgzB,KAAKL,EAAOC,EAAM5lB,GAEnBwlB,GAAYG,EAAME,GAAQpuB,GAAK,GACjCzE,EAAAA,KAAKgzB,KAAKL,EAAOC,EAAMC,GAElBr4B,EAAIgE,GAAG,CAIZ,IAHAwB,EAAAA,KAAKgzB,KAAKL,EAAOn4B,EAAGgE,GACpBhE,IACAgE,IACOg0B,GAAYG,EAAMn4B,GAAIiK,GAAK,GAChCjK,GAAQ,EAEV,KAAOg4B,GAAYG,EAAMn0B,GAAIiG,GAAK,GAChCjG,GAAQ,CAEX,CACmC,IAAhCg0B,GAAYG,EAAMC,GAAOnuB,GAC3BzE,EAAAA,KAAKgzB,KAAKL,EAAOC,EAAMp0B,IAEvBA,GAAQ,EACRwB,EAAAA,KAAKgzB,KAAKL,EAAOn0B,EAAGq0B,IAIlBr0B,GAAKwO,IACP4lB,EAAOp0B,EAAI,GAETwO,GAAKxO,IACPq0B,EAAQr0B,EAAI,EAEf,CACH,gDC1EM,SACFy0B,EAAmBC,EAAyBC,EAC5CC,EAAwBv8B,GAC1B,MAAMw8B,EAAcrzB,EAAAA,KAAKgO,cAAcolB,GACjCE,EAAUtzB,EAAIA,KAACuzB,oBAAoB18B,EAAMs8B,GAE/C,IAAK,IAAI34B,EAAI,EAAGA,EAAIy4B,EAAM17B,OAAQiD,IAAK,CACrC,MAAMyS,EAAQgmB,EAAMz4B,GACpB,GAAIyS,EAAQ,EACV,MAAM,IAAIlV,MAAM,iCAGdkV,GAASpW,IAKXy8B,EAAQrmB,IADNomB,EAAc,EACEH,EAAY14B,GAEZ,EAErB,CAED,OAAO84B,CACT,qBAEM,SACFE,EAAuBC,EAA6B58B,EACpD68B,GAAe,GACjB,MAAMC,EAAUH,EAAKr5B,MAAM,GACrBy5B,EAAUJ,EAAKr5B,MAAM,GAErB05B,EAAS58B,EAAAA,OAAO,CAAC08B,EAAS98B,GAAO48B,EAAW13B,OAElD,IAAK,IAAIvB,EAAI,EAAGA,EAAIm5B,EAASn5B,IAC3B,IAAK,IAAIgE,EAAI,EAAGA,EAAIo1B,EAASp1B,IAAK,CAChC,MAAMyO,EAAQumB,EAAKl8B,IAAIkD,EAAGgE,GAC1B,GAAIyO,EAAQ,EACV,MAAM,IAAIlV,MAAM,iCAGdkV,GAASpW,IAIT68B,EACFG,EAAOx8B,IAAI,EAAGmD,EAAGyS,GAEbwmB,EAAW58B,KAAO,EACpBg9B,EAAOx8B,IAAIw8B,EAAOv8B,IAAIkD,EAAGyS,GAASwmB,EAAWn8B,IAAIkD,EAAGgE,GAAIhE,EAAGyS,GAE3D4mB,EAAOx8B,IAAIw8B,EAAOv8B,IAAIkD,EAAGyS,GAAS,EAAGzS,EAAGyS,GAG7C,CAGH,OAAO4mB,CACT,6BCnDM,SACF9qB,EAAoB5O,EAAiB25B,EACrC/3B,GACF,GAAc,UAAVA,EAAmB,CAErB,MAAO,CAAC5B,EAAO,QADMkW,WAAW0jB,KAAKhrB,GAEtC,CAED,GAAc,SAAVhN,EAAkB,CAIpB,MAAMi4B,EAAOh0B,EAAAA,KAAKi0B,aAAa,CAAC,GAAIH,IAE7BI,EAAYC,GAAezP,IAC9B,CAAC5E,EAAGzW,IAAOyW,IAAMzW,EAAK,EAAI,GADIqb,CACDvqB,EAAO,GAAI4O,EAAQirB,EAAM,QAE1D,MAAO,CAACG,EAAa,OAAQD,EAC9B,CACD,MAAM,IAAIn8B,MAAM,iCAAiC+7B,QAAgB/3B,IACnE,yBC3BM,SACF2D,EAAuD3B,EACvDhC,EAAiBq4B,GACnB,MAAMd,EAAUtzB,EAAIA,KAAC+e,kBAAkBhjB,EAAOiE,EAAAA,KAAKgO,cAAcjQ,IAEjE,GAAIq2B,GAA0B,WAAVr4B,EAAoB,CAEtC,IAAIuQ,EAAS,EACb5M,EAAOtH,SAAQyZ,IACb,MAAMhb,EAAOmJ,EAAIA,KAACgO,cAAc6D,EAAM1X,OAErCm5B,EAAuBj8B,IAAIwa,EAAMxE,KAAoBf,GACtDA,GAAUzV,CAAI,GAEjB,KAAM,CACL,IAAIw9B,EAAY,EAEhB30B,EAAOtH,SAAQyZ,IACb,MAAMyiB,EAAwB,WAAVv4B,EAChBoE,eAAaqkB,uBAAuB3S,EAAMxE,MAC1CwE,EAAMxE,KAEV,IAAIknB,EAAO,EAEX,IAAK,IAAIC,EAAM,EAAGA,EAAM3iB,EAAM1X,MAAM,KAAMq6B,EAAK,CAC7C,MAAMC,EAASD,EAAMz2B,EAAS,GAAKs2B,EACnC,IAAK,IAAIK,EAAM,EAAGA,EAAM7iB,EAAM1X,MAAM,KAAMu6B,EACxCpB,EAAQmB,EAASC,GAAOJ,EAAYC,IAEvC,CAEDF,GAAaxiB,EAAM1X,MAAM,EAAE,GAE9B,CAED,OAAOm5B,CACT,0FCnCIqB,EAAyBC,EAA4B74B,EACrD84B,EAAmBC,EAAmBC,EAAmBz6B,EACzD06B,EAAuBC,GACzB,MAAMpB,EAAS58B,EAAAA,OAAO,CAAC49B,EAAWE,GAAYh5B,GAE9C,IAAK,IAAIvB,EAAI,EAAGA,EAAIq6B,EAAWr6B,IAAK,CAClC,MAAM3C,EAAQ,GACd,IAAIq9B,EAAe,EACnB,IAAK,IAAI12B,EAAI,EAAGA,EAAIs2B,EAAWt2B,IAAK,CAClC,MAAMqG,EAAM8vB,EAAYn6B,EAAIs6B,EAAYt2B,GACxC02B,GAAgBrwB,EAAMvK,EAAQkE,GAC9B3G,EAAMH,KAAKmN,EACZ,CACD,GAAIqwB,EAAe,GAAKA,GAAgBD,EAAaF,EACnD,MAAM,IAAIh9B,MACN,oBAAoBF,yBAA6Bm9B,KAGvD,IAAK,IAAIhoB,EAAI,EAAGA,EAAI+nB,EAAW/nB,IAC7B6mB,EAAO9qB,OAAOvO,EAAIu6B,EAAY/nB,GAC1B4nB,EAAUt9B,OAAOs9B,EAAUrP,WAAW2P,EAAeH,EAAY/nB,GAExE,CAED,OAAO6mB,CACT,wBCzBIL,EAA0B2B,EAC1BC,GACF,MAAMvB,EAAS58B,EAAMA,OAACm+B,EAAoB5B,EAAKz3B,OAC/C,IAAK,IAAIvB,EAAI,EAAGA,EAAIq5B,EAAOh9B,OAAQ2D,EAAG,CACpC,MAEM66B,EAFSxB,EAAOtO,WAAW/qB,GAEIyC,QAC/Bq4B,EAAWD,EAAY,GACvBE,EAAaF,EAAY,GACzBG,EAAeL,EAAWzP,WAAW,CAAC4P,EAAUC,IACtDF,EAAY,GAAKF,EAAWpsB,OAAOysB,GAEnC,MAAMC,EAAgBjC,EAAK9N,WAAW2P,GAElC,GAAKI,GAAiBA,EAAgBjC,EAAKzqB,OAAOxR,SACpDs8B,EAAO9qB,OAAOvO,GAAKg5B,EAAKzqB,OAAO0sB,GAElC,CAED,OAAO5B,CACT,wFCpBIxL,EAAeqN,EAAcC,GAC/B,MAAMC,GAAQF,EAAOrN,IAAUsN,EAAM,GAE/B5sB,EAAS/I,EAAIA,KAACuzB,oBAAoBoC,EAAK,WAC7C5sB,EAAO,GAAKsf,EACZ,IAAK,IAAI7tB,EAAI,EAAGA,EAAIuO,EAAOxR,OAAQiD,IACjCuO,EAAOvO,GAAKuO,EAAOvO,EAAI,GAAKo7B,EAG9B,OAAO7sB,CACT,qBCXM,SACF4b,EAAmBkR,EAAoB93B,EACvChC,GACF,MAAMsR,EAAOrN,EAAIA,KAACqR,uBACdtV,EAA0BiE,EAAAA,KAAKgO,cAAcjQ,IAEjD,IAAK,IAAIvD,EAAI,EAAGA,EAAI6S,EAAK9V,SAAUiD,EAAG,CACpC,MAAM8R,EAAS9R,EAAIq7B,EACnB,IAAI57B,EAAM0qB,EAAMrY,GAChB,IAAK,IAAI9N,EAAI,EAAGA,EAAIq3B,IAAcr3B,EAAG,CACnC,MAAMyO,EAAQ0X,EAAMrY,EAAS9N,IACzBvI,OAAOmgB,MAAMnJ,IACbA,EAAQhT,KACVA,EAAMgT,EAET,CACDI,EAAK7S,GAAKP,CACX,CACD,OAAOoT,CACT,iECfwB4lB,EAAmB6C,EAAkBC,GAE3D,MAAMC,EACFh2B,EAAAA,KAAKi2B,mBAAmB,EAA2BF,GACvD,OAAO1O,GAAa,GAAIyO,EAAQE,EAAU/C,EAAO8C,EACnD,2BCLM,SACFD,EAAkBC,EAAkB9C,EACpCiD,GAEF,MAAOn4B,EAAUo4B,GACbh2B,EAAYA,aAACi2B,0BAA0BN,EAAQI,GAC7CG,EAAWlS,EAAAA,WAAW4R,EAAQ,SAC9BzC,EAAUtzB,EAAIA,KAACuzB,oBACDvzB,EAAAA,KAAKgO,cAAcjQ,GAAWs4B,GAC5CR,EAAa71B,EAAAA,KAAKgO,cAAcmoB,GAEtC,IAAK,IAAI37B,EAAI,EAAGA,EAAI84B,EAAQ/7B,SAAUiD,EAAG,CACvC,MAAM8R,EAAS9R,EAAIq7B,EACnB,IAAIS,EAAO,EACX,IAAK,IAAI93B,EAAI,EAAGA,EAAIq3B,IAAcr3B,EAChC83B,GAAQrD,EAAM3mB,EAAS9N,GAEzB80B,EAAQ94B,GAAK87B,CACd,CAED,MAAO,CAAChD,UAASv1B,WAAUs4B,WAC7B,4BpBqJI3O,EAAkC6O,EAClCvN,EAA+BC,EAC/BC,EAAkC1B,EAClCC,EACA+O,GACF,GAAkC,IAA9B9O,EAAmBnwB,OACrB,MAAM,IAAIQ,MAAM,wCAGlB,GAA2C,IAAvCw+B,EAAyB,GAAGh/B,OAC9B,MAAM,IAAIQ,MAAM,qCAKlB,GA7LF,SACIyvB,EAAqBC,EAAwBgP,GAC/CjP,EAAQpvB,SAAQ,CAACP,EAAe2C,KAC9B,GAAI3C,EAAQ,GAAKA,GAAS4+B,EAAW,CACnC,MAAMC,EACF12B,OAAKulB,WACG/qB,EAAGitB,EAAalwB,OAAQyI,EAAIA,KAACsC,eAAemlB,IAC/CrrB,KAAK,KACd,MAAM,IAAIrE,MACN,WAAW2+B,QAAgB7+B,mBAAuB4+B,KACvD,IAEL,CA+KEE,CAAgBnP,EAASC,EADP8O,EAAyB,GAAG,GAAK,GAGb,IAAlCtN,EAAuB1xB,OACzB,MAAM,IAAIQ,MAAM,+BAElB,MAAM4vB,EAAuBsB,EAAuB,IAI9ClB,UAACA,EAASH,YAAEA,EAAWC,UAAEA,GAAaN,GACxCC,EAASC,EAAcC,EAAoBC,GAGzCiP,EA7FR,SAAmB7O,GACjB,MAAM8O,EAA0B,GAChC,IAAK,IAAIr8B,EAAI,EAAGA,EAAIutB,EAAUxwB,SAAUiD,EAAG,CACzC,MAAMstB,EAAYC,EAAUvtB,GAAGjD,OACzBywB,EAAShoB,EAAIA,KAAC+e,kBAAkB,QAAS+I,GAC/C+O,EAAUn/B,KAAKswB,GAEfD,EAAUvtB,GAAGpC,SAAQ,CAAC6U,EAAOzO,IAAcwpB,EAAOxpB,GAAKyO,GACxD,CAED,OAAO4pB,CACT,CAkF6BC,CAAU/O,GAC/BgP,EAAoBhO,GACtBC,EAAmBC,EAAwBC,EAC3CtB,EAAaC,GAEjB,MAAO,CAAC+O,EAAoBG,EAAkB,GAAIA,EAAkB,GACtE,kBC5MgB,SACZC,EAAoBC,EAAuBC,EAC3C3lB,EAAoB4lB,EAAuBC,EAC3CC,GAEF,GAAIJ,EAAY1/B,OAAS,EACvB,MAAM,IAAIQ,MAAM,qCAElB,GAAIo/B,EAAY5/B,OAAS,EACvB,MAAM,IAAIQ,MAAM,qCAElB,GAAIs/B,EAAY9/B,OAAS,EACvB,MAAM,IAAIQ,MAAM,qCAIlB,MAAMu/B,EAAyC,IAAvBL,EAAY1/B,OAC9BggC,EAAyC,IAAvBJ,EAAY5/B,OAC9BigC,EAAyC,IAAvBH,EAAY9/B,OAI9BkgC,EAAoB,GACrBH,GACHG,EAAQ//B,KAAKu/B,EAAY,IAEtBM,GACHE,EAAQ//B,KAAKy/B,EAAY,IAEtBK,GACHC,EAAQ//B,KAAK2/B,EAAY,IAG3B,IAAK,IAAI78B,EAAI,EAAGA,EAAIi9B,EAAQlgC,SAAUiD,EACpC,GAAIi9B,EAAQj9B,KAAOi9B,EAAQj9B,EAAI,GAC7B,MAAM,IAAIzC,MAAM,uDAGpB,MAAM2/B,EAA2B,IAAnBD,EAAQlgC,OAAe,EAAIkgC,EAAQ,GAG3CE,EACF33B,EAAAA,KAAK+e,kBAAkB,QAAS2Y,EAAQ,GAC5CC,EAAe,GAAK,EACpB,IAAK,IAAInD,EAAM,EAAGA,EAAMkD,IAASlD,EAAK,CACpC,MAAMnM,EAAQiP,EAAkBN,EAAO,GAAKA,EAAOxC,GAC7ClM,EAAQiP,EAAkBhmB,EAAO,GAAKA,EAAOijB,GAC7C/L,EAAQ+O,EAAkBJ,EAAO,GAAKA,EAAO5C,GACnD,GAAc,IAAV/L,EACF,MAAM,IAAI1wB,MAAM,uBAElB,IAAIlB,EACJ,GAAM4xB,EAAQ,GAAOH,EAAQD,GAAaI,EAAQ,GAAOH,EAAQD,EAC/DxxB,EAAO,OAIP,GAFAA,EAAOmD,KAAKmJ,KAAKnJ,KAAK49B,KAAKtP,EAAQD,GAASI,IAExC5xB,EAAO8yB,GACT,MAAM,IAAI5xB,MAAM,oDAGpB4/B,EAAenD,EAAM,GAAKmD,EAAenD,GAAO39B,CACjD,CAED,MAAMghC,EAAQF,EAAeD,GAGvBI,EACF93B,EAAIA,KAAC+e,kBAAkBmY,EAAaW,GAExC,IAAIE,EAAa,EACjB,IAAK,IAAIvD,EAAM,EAAGA,EAAMkD,IAASlD,EAAK,CACpC,MAAMwD,EAAUL,EAAenD,EAAM,GAAKmD,EAAenD,GACzD,IAAIvnB,EAAQqqB,EAAkBN,EAAO,GAAKA,EAAOxC,GACjD,MAAM/L,EAAQ+O,EAAkBJ,EAAO,GAAKA,EAAO5C,GACnD,IAAK,IAAIh6B,EAAI,EAAGA,EAAIw9B,IAAWx9B,EAC7Bs9B,EAAcC,KAAgB9qB,EAC9BA,GAASwb,CAEZ,CAED,MAAO,CAACkP,EAAgBG,EAC1B,2BC4WM,SACF39B,EAAmB89B,EAAuBlvB,EAC1CogB,EAAuBY,EAAuBC,EAC9CC,EAA6BC,EAC7BC,EACAE,GACF,OAAO,IAAIR,GACA1vB,EAAO89B,EAAalvB,EAAQogB,EAAaY,EAAaC,EACtDC,EAAmBC,EAAoBC,EACvCE,GACNvoB,SACP,YmB3cM,SACFumB,EAAeqN,EAAcE,EAC7B75B,GAKF,GAJsBssB,IAAUqN,GACIrN,EAAQqN,GAAQE,EAAO,GACvBF,EAAOrN,GAASuN,EAAO,EAIzD,OAAO51B,OAAKuzB,oBAAoB,EAAGx3B,GAGrC,MAAMstB,EAAcrvB,KAAK49B,IAAI59B,KAAKmJ,MAAMuyB,EAAOrN,GAASuN,IAClD7sB,EAAS/I,EAAIA,KAACuzB,oBAAoBlK,EAAattB,GAEjD25B,EAAOrN,GAAkB,IAATuN,IAGlBA,GAAQ,GAGV7sB,EAAO,GAAKsf,EACZ,IAAK,IAAI7tB,EAAI,EAAGA,EAAIuO,EAAOxR,OAAQiD,IACjCuO,EAAOvO,GAAKuO,EAAOvO,EAAI,GAAKo7B,EAE9B,OAAO7sB,CACT,2BCpBM,SAEFye,EAAmC0Q,EACnC/9B,EAAiB0yB,EAAoBkI,EAAmBoD,EACxDrD,EAAmBx6B,EACnB0vB,EACAoO,GACF,MAAMC,EAAe,CAACxL,EAAakI,EAAWA,GAExCJ,EAAcnN,EAAQze,OACtBuvB,EAAcJ,EAAQnvB,OAE5B,GAAmB,IAAf8jB,EACF,OAAO51B,SAAOkD,EAAsB+9B,EAAQn8B,OAG9C,MAAM83B,EAAU7J,aAAwBuO,EAAYA,aAChDvO,EACA/yB,EAAAA,OAAOohC,EAAcH,EAAQn8B,OACL,iBAAjBiuB,GAEwB,iBAAjBA,EADf6J,EAAO9qB,OAAoB2V,KAAKsL,GAGA,kBAAjBA,GACf6J,EAAO9qB,OAAsB2V,MAAMsL,GAGtC,IAAK,IAAIxvB,EAAI,EAAGA,EAAI29B,EAAY39B,IAAK,CACnC,MAAM3C,EAAQ,GACd,IAAIq9B,EAAe,EACnB,IAAK,IAAI12B,EAAI,EAAGA,EAAIs2B,EAAWt2B,IAAK,CAClC,MAAMqG,EAAM8vB,EAAYn6B,EAAIs6B,EAAYt2B,GACxC3G,EAAMH,KAAKmN,GACXqwB,GAAgBrwB,EAAMvK,EAAQkE,EAC/B,CAED,GAAI02B,EAAe,GAAKA,GAAgBrI,EAAakI,EACnD,MAAM,IAAIh9B,MAAM,oBAAoBF,yBAA6BsC,KAGnE,IAAK,IAAI6S,EAAI,EAAGA,EAAI+nB,EAAW/nB,IACzBorB,EACDvE,EAAO9qB,OAAsBmsB,EAAeH,EAAY/nB,IACpDsrB,EAA2B99B,EAAIu6B,EAAY/nB,GAEhD6mB,EAAO9qB,OAAOmsB,EAAeH,EAAY/nB,GAAsB,IAAjBkrB,EAAQ95B,KAClDk6B,EAAY,GACZA,EAAY99B,EAAIu6B,EAAY/nB,EAGrC,CAED,OAAO6mB,CACT,+BCxDM,SAAwBxmB,GAC5B,MAAMmrB,EAAe,IAAIloB,aAAajD,EAAK9V,QAC3C,IAAK,IAAIiD,EAAI,EAAGA,EAAI6S,EAAK9V,SAAUiD,EACjCg+B,EAAah+B,GAAKR,KAAK49B,IAAIvqB,EAAK7S,IAElC,OAAOg+B,CACT,YCNM,SACFnrB,EAAqBorB,EAAiB5hC,EAAgBsD,EACtD4B,GACF,MAAM28B,EAAcC,EAAAA,WAAWC,iBAAiBz+B,EAAOs+B,EAAO5hC,GACxDU,EAASyI,EAAAA,KAAKgO,cAAcnX,GAC5BgiC,EAAW74B,EAAAA,KAAKsC,eAAenI,GAErC,GAAIu+B,EAAa,CACf,MAAMI,EAAaH,EAAUA,WAACI,kBAAkBN,EAAOI,GAEvD,MAAc,WAAV98B,EACMsR,EAAsBpQ,MAAM67B,EAAYA,EAAavhC,GAGvD8V,EAAoB2hB,SAAS8J,EAAYA,EAAavhC,EAC/D,CAED,MAAM+8B,EAAwB,WAAVv4B,EAChBoE,EAAYA,aAACqkB,uBAAuBnX,GACpCA,EAEE2rB,EAAQ/hC,EAAMA,OAACkD,EAAO4B,EAAOu4B,GAC7BT,EAAS58B,EAAAA,OAAOJ,EAAMkF,GAC5B,IAAK,IAAIvB,EAAI,EAAGA,EAAIq5B,EAAOh9B,OAAQ2D,EAAG,CACpC,MAAMy+B,EAASpF,EAAOtO,WAAW/qB,GAC3B0+B,EAAQD,EAAO7+B,KAAI,CAAC++B,EAAa36B,IAAM26B,EAAMV,EAAMj6B,KACzDq1B,EAAOx8B,IAAI2hC,EAAM1hC,OAAO4hC,MAAWD,EACpC,CAED,MAAc,WAAVl9B,EACKoE,eAAai5B,uBAAuBvF,EAAO9qB,QAE7C8qB,EAAO9qB,MAChB,0BCpCgB,SACZye,EAAqBC,EAAwB4R,EAC7CtwB,EAAoBghB,EAAuBuP,EAC3CtP,GAEF,MAAMuP,EAAe9R,EAAa,GAC5B+R,EAAYF,EAAW,GAEvBG,EAA+B,IAAIl/B,MAAMi/B,GACzCE,EAA4B,IAAIn/B,MAAMg/B,GAEtCn7B,EAAOqpB,EAAa,GAE1B,GAAkB,IAAd+R,EAAiB,CACnB,GAAqB,IAAjBD,EACF,MAAM,IAAIxhC,MACNoI,EAAAA,aAAaw5B,gDACTJ,IAIV,MAAO,CAFev5B,EAAIA,KAAC+e,kBAAkBsa,EAAc,GAG1C,CAAC,EAAGj7B,GAFA4B,EAAIA,KAAC+e,kBAAkBgL,EAAa,GAEf0P,EAAmBC,EAE9D,CAED,IAAIE,GAAiB,EACjBC,EAAiB,EACrB,MAAMC,EAAsB,IAAIv/B,MAAMi/B,GAAW9a,KAAK,GAEtD,IAAK,IAAIlkB,EAAI,EAAGA,EAAI++B,IAAgB/+B,EAAG,CAErC,MAAMg6B,EAAMhN,EAAQhtB,EAAI4D,GACxB,GAAIo2B,EAAM,EACR,MAAM,IAAIz8B,MACNoI,EAAYA,aAAC45B,gDAAgDv/B,EAAGg6B,IAEtE,GAAIA,GAAOgF,EACT,MAAM,IAAIzhC,MACNoI,eAAa65B,kDACTx/B,EAAGg6B,EAAKgF,MAEhBM,EAAUtF,GACZoF,EAAiBA,GAAmBpF,GAAOqF,EAC3CA,EAAiBrF,CAClB,CAED,IAAIyF,GAAc,EAClB,IAAK,IAAIzF,EAAM,EAAGA,EAAMgF,IAAahF,EAAK,CAExC,MAAM0F,EAA+B,IAAnBJ,EAAUtF,GAC5BiF,EAAkBjF,GAAO0F,EACzBD,EAAcA,IAAgBC,EAE9BJ,EAAUtF,GAAOx6B,KAAKC,IAAI6/B,EAAUtF,GAAM,GAOtCA,EAAM,IACRsF,EAAUtF,IAAQsF,EAAUtF,EAAM,GAErC,CAED,GAAIyF,GAAeL,EAAgB,CACjC,MAAMO,EAA4B3S,EAC5B4S,EAA2BrxB,EACjC,IAAK,IAAIvO,EAAI,EAAGA,EAAI++B,IAAgB/+B,EAClCk/B,EAAgBl/B,GAAKA,EAEvB,MAAO,CACL2/B,EAAe,CAACZ,EAAcn7B,GAAOg8B,EAAcX,EACnDC,EAEH,CAAM,CACL,MAAMW,EAAmBP,EAAUN,EAAY,GACzCW,EACFn6B,EAAAA,KAAK+e,kBAAkBsa,EAAcgB,EAAmBj8B,GAEtDg8B,EACFp6B,EAAIA,KAAC+e,kBAAkBgL,EAAasQ,GAClCC,EAAwB,IAAI//B,MAAMi/B,GAAW9a,KAAK,GAGxD,IAAK,IAAIlkB,EAAI,EAAGA,EAAI++B,IAAgB/+B,EAAG,CAErC,MAAMg6B,EAAMhN,EAAQhtB,EAAI4D,GAClBkO,EAASguB,EAAY9F,GACrB+F,GAAoB,IAAR/F,EAAa,EAAIsF,EAAUtF,EAAM,IAAMloB,EACzDguB,EAAY9F,KACZ,IAAK,IAAIh2B,EAAI,EAAGA,EAAIJ,IAAQI,EAE1B27B,EAAcI,EAAUn8B,EAAOI,GAAKgpB,EAAQhtB,EAAI4D,EAAOI,GAEzD47B,EAAaG,GAAWxxB,EAAOvO,GAE/Bk/B,EAAgBl/B,GAAK+/B,CACtB,CAGD,IAAK,IAAI/F,EAAM,EAAGA,EAAMgF,IAAahF,EAAK,CAExC,GAAiB,IADA8F,EAAY9F,GACT,CAClB,MAAMgG,EAAyB,IAARhG,EAAa,EAAIsF,EAAUtF,EAAM,GAIxD2F,EAAcK,EAAgBp8B,EAAO,GAAKo2B,EAC1C,IAAK,IAAIE,EAAM,EAAGA,EAAMt2B,IAAQs2B,EAC9ByF,EAAcK,EAAgBp8B,EAAOs2B,GAAO,EAE9C0F,EAAaI,GAAiBxQ,CAC/B,CACF,CACD,MAAO,CACLmQ,EAAe,CAACE,EAAkBj8B,GAAOg8B,EAAcX,EACvDC,EAEH,CACH,oBCzHM,SACFe,EAA0BC,EAA6BC,EACvDC,EACAC,GACF,MAAMC,EAAY96B,EAAAA,KAAKgO,cAAc4sB,GAC/BG,EAAML,EAAkB,GACxBM,EAAaH,EAAYtjC,OAIzBuL,EAAwB,GAC9B,IAAIF,EAAU,EACVq4B,GAAgB,EACpB,IAAK,IAAI5gC,EAAI,EAAGA,EAAI2gC,IAAc3gC,EAAG,CACnC,MAAMxD,EAAOgkC,EAAYxgC,GACzB,IAAc,IAAVxD,EAAa,CACf,IAAsB,IAAlBokC,EACF,MAAM,IAAIljC,MACNoI,EAAYA,aACP+6B,yDACGD,EAAc5gC,IAE5B4gC,EAAe5gC,EACfyI,EAAYpL,KAAK,EAClB,KAAM,CACL,GAAIb,EAAO,EACT,MAAM,IAAIkB,MACNoI,EAAYA,aAACg7B,8CACT9gC,EAAGxD,IAEb+L,GAAW/L,EACXiM,EAAYpL,KAAKb,EAClB,CACF,CACD,IAAsB,IAAlBokC,EAAqB,CACvB,GAAIr4B,GAAW,EACb,MAAM,IAAI7K,MACNoI,eAAai7B,wDAEnB,MAAMC,EAAUrhC,KAAKshC,MAAMR,EAAYl4B,GACvC,GAAIA,EAAUy4B,IAAYP,EACxB,MAAM,IAAI/iC,MACNoI,EAAYA,aAACo7B,gDACTX,EAAY93B,IAGtBA,EAAYm4B,GAAgBI,CAC7B,CAED,GADmBr7B,EAAAA,KAAKgO,cAAclL,KACnBg4B,EACjB,MAAM,IAAI/iC,MACNoI,EAAYA,aAACq7B,gDACTZ,EAAY93B,IAGtB,MAAM24B,EAAYb,EAAWrjC,OACvBmkC,EAAyB,GAC/B,GAAID,EAAY,EAAG,CACjBC,EAAaD,EAAY,GAAK,EAC9B,IAAK,IAAIphC,EAAIohC,EAAY,EAAGphC,GAAK,IAAKA,EACpCqhC,EAAarhC,GAAKqhC,EAAarhC,EAAI,GAAKugC,EAAWvgC,EAAI,EAE1D,CAED,MAAMshC,EAA0B,GAChC,GAAIX,EAAa,EAAG,CAClBW,EAAcX,EAAa,GAAK,EAChC,IAAK,IAAI3gC,EAAI2gC,EAAa,EAAG3gC,GAAK,IAAKA,EACrCshC,EAActhC,GAAKshC,EAActhC,EAAI,GAAKyI,EAAYzI,EAAI,EAE7D,CAED,MAAMuhC,EACF57B,EAAAA,KAAK+e,kBAAkB4b,EAAYI,EAAMC,GAC7C,IAAK,IAAIxgC,EAAI,EAAGA,EAAIugC,IAAOvgC,EAAG,CAC5B,IAAIwO,EAAK,EACT,IAAK,IAAIxK,EAAI,EAAGA,EAAIi9B,IAAaj9B,EAE/BwK,GAAMyxB,EAAajgC,EAAIihC,EAAYj9B,GAAKk9B,EAAal9B,GAEvD,IAAK,IAAIA,EAAI,EAAGA,EAAIw8B,IAAcx8B,EAEhCo9B,EAAWphC,EAAIwgC,EAAax8B,GAAKxE,KAAKshC,MAAMtyB,EAAK2yB,EAAcn9B,IAC/DwK,GAAM2yB,EAAcn9B,EAEvB,CACD,MAAO,CAACo9B,EAAY,CAACb,EAAKC,GAAal4B,EACzC,sCCtFI+O,EAAmB+oB,EAAsBD,EACzCnT,EAAqBqU,EAAwBC,GAAS,EACtD9R,EAAe,GACjB,MAAM+R,EAAavU,EAAQjwB,OAGrBykC,EAAsB,CAACpB,EAAW,GAAI/oB,EAAMta,OAASqjC,EAAW,IAChEqB,EAASD,EAAU,GAKnBE,EADFH,EAAa,EAAIF,EAAWE,EAAa,GAAK,EAAI,EAGtD,GAAIG,EAAa,EACf,MAAM,IAAInkC,MACNoI,eAAag8B,2DAGnB,MAAMr5B,EAAc83B,EAAW39B,QAC/B6F,EAAY,GAAKo5B,EAEjB,MAAME,EACFt5B,EAAYu5B,QAAO,CAACz5B,EAASqK,IAAUrK,EAAUqK,GAAO,GAEtDhS,EAAS+E,EAAIA,KAAC+e,kBAAkB4b,EAAYyB,GAIlD,GAAmB,IAAfL,EAIF,OAHIG,EAAa,GACfjhC,EAAOyjB,KAAKsL,GAEP,CAAC/uB,EAAQ6H,GAGlB,GAAIo5B,GAAc,EAChB,MAAM,IAAInkC,MACNoI,eAAag8B,2DAGnB,IAAI9T,EAAQ,EAAG5e,EAAM,EAEjB6yB,EAAqB,EACrBC,EAAWV,EAAWxT,GAE1B,OAAa,CAEX,IAAImU,EAAY,EAChB,GAAI/yB,EAAMsyB,EAAY,CAEpB,GADAS,EAAYX,EAAWpyB,GACnB8yB,IAAaC,EAAW,GACxB/yB,EACF,QACD,CAED,GAAI8yB,GAAYC,EACd,MAAM,IAAIzkC,MAAMoI,EAAYA,aACvBs8B,+DAER,CAED,GAAIF,EAAW,GAAKA,GAAYL,EAC9B,MAAM,IAAInkC,MACNoI,EAAYA,aAACu8B,yDACTH,EAAUL,IAKhBK,EAAWD,GACbrhC,EAAOyjB,KAAKsL,EAAcsS,EAAqBL,EAAQM,EAAWN,GAGpE,IAAK,IAAIzhC,EAAI6tB,EAAO7tB,EAAIiP,IAAOjP,EAAG,CAChC,MAAM3C,EAAQ2vB,EAAQhtB,GACtB,GAAI3C,EAAQ,GAAKA,GAASmkC,EAAU,GAClC,MAAM,IAAIjkC,MACNoI,eAAaw8B,uDACTniC,EAAGgtB,EAAQhtB,GAAIwhC,EAAU,KAEnC,IAAK,IAAIx9B,EAAI,EAAGA,EAAIy9B,EAAQz9B,IAC1BvD,EAAOshC,EAAWN,EAASz9B,IAAMqT,EAAMha,EAAQokC,EAASz9B,EAE3D,CAED,GAAIs9B,EACF,IAAK,IAAIt9B,EAAI,EAAGA,EAAIy9B,EAAQz9B,IAC1BvD,EAAOshC,EAAWN,EAASz9B,IAAMiL,EAAM4e,EAQ3C,GAJAA,EAAQ5e,IACNA,EACF6yB,EAAqBC,EAAW,EAChCA,EAAWC,EACP/yB,EAAMsyB,EACR,KAEH,CAOD,OAJIO,EAAqBJ,GACvBjhC,EAAOyjB,KAAKsL,EAAcsS,EAAqBL,EAAQC,EAAaD,GAG/D,CAAChhC,EAAQ6H,EAClB,kFC5GM,SACF/E,EAAoBy1B,EAAuBl5B,EAC3Cm+B,GACF,MAAM5E,EAAS58B,EAAMA,OAAC8G,EAAUy1B,EAAKz3B,OAErC,IAAK,IAAIvB,EAAI,EAAGA,EAAIq5B,EAAOh9B,KAAM2D,IAAK,CACpC,MAAM8qB,EAAMuO,EAAOtO,WAAW/qB,GAExBoiC,EAAmB,IAAIriC,MAAM+qB,EAAI/tB,QACvC,IAAK,IAAIiH,EAAI,EAAGA,EAAIo+B,EAAOrlC,OAAQiH,IACjCo+B,EAAOp+B,GAAK8mB,EAAI9mB,GAAKlE,EAAQkE,GAAKi6B,EAAMj6B,GAE1Cq1B,EAAOx8B,IAAIm8B,EAAKl8B,OAAOslC,MAAYtX,EACpC,CAED,OAAOuO,CACT,4BpBsLI7oB,EAAoB6xB,EAAwB/M,EAC5CC,EAAuBC,EAAiBC,EAAkBC,EAC1DC,GACF,OAAO,IAAIN,GACAC,EAAWC,EAAaC,EAASC,EAAUC,EAC3CC,GACNruB,QAAQkJ,EAAM6xB,EACrB,2BChKIhrB,EAAqBugB,EACrBD,GACF,MAAM2K,EAAYjrB,EAAMta,OAGlBwlC,EAAuB,GAE7B,IAAIlQ,EAAa,EACbmQ,EAAgB,EACpB,MAAMjB,EAAuB,IAAIxhC,MAAMuiC,GACvC,IAAK,IAAItiC,EAAI,EAAGA,EAAIsiC,IAAatiC,EAAG,CAClC,MAAMyiC,EAAmBF,EAAOxlC,OAChC6J,GAAMyQ,EAAMrX,GAAI43B,EAAWD,EAAW4K,GACtC,MAAMG,EAAWH,EAAOxlC,OAAS0lC,EACjClB,EAAWvhC,GAAK0iC,EAChBrQ,GAAcqQ,EACdF,EAAgBhjC,KAAKC,IAAI+iC,EAAeE,EACzC,CAED,MAAM1V,EAAUxnB,EAAAA,KAAK+e,kBAAkB,QAAsB,EAAb8N,GAC1C9jB,EAAuB,IAAIxO,MAAMsyB,GACjC1yB,EAA0B,CAAC2iC,EAAWE,GAE5C,IAAIG,EAAI,EACR,IAAK,IAAI3iC,EAAI,EAAGA,EAAIsiC,IAAatiC,EAC/B,IAAK,IAAIgE,EAAI,EAAGA,EAAIu9B,EAAWvhC,KAAMgE,EAEnCgpB,EAAY,EAAJ2V,GAAS3iC,EACjBgtB,EAAY,EAAJ2V,EAAQ,GAAK3+B,EACrBuK,EAAOo0B,GAAKJ,EAAOI,KACjBA,EAIN,MAAO,CAAC3V,EAASze,EAAQ5O,EAC3B,6BoBhFgB,SACZ0X,EAAqBurB,GACvB,MAAMniC,EAAS+E,EAAAA,KAAK+e,kBAAkB,QAASlN,EAAMta,QAErD,IAAK,IAAIiD,EAAI,EAAGA,EAAIqX,EAAMta,SAAUiD,EAClCS,EAAOT,GACHwF,OAAKq9B,cAAcxrB,EAAMrX,IAAI8iC,OAAOF,GAAYG,qBAGtD,OAAOtiC,CACT,sBCLgB,SACZu4B,EACAgK,GACF,MAAM3Y,EAAqB,IAAItqB,MAAMi5B,EAAKp1B,MAC1C,IAAK,IAAI5D,EAAI,EAAGA,EAAIqqB,EAASttB,OAAQiD,IACnCqqB,EAASrqB,GAAKg5B,EAAKr5B,MAAMK,GAAKgjC,EAAKhjC,GAErC,MAAMyqB,EAAShuB,EAAMA,OAAC4tB,EAAU2O,EAAKz3B,OACrC,IAAK,IAAIvB,EAAI,EAAGA,EAAIyqB,EAAOlc,OAAOxR,SAAUiD,EAAG,CAC7C,MAAMoiC,EAAS3X,EAAOM,WAAW/qB,GAE3B66B,EAAwB,IAAI96B,MAAMi5B,EAAKp1B,MAC7C,IAAK,IAAII,EAAI,EAAGA,EAAI62B,EAAY99B,OAAQiH,IACtC62B,EAAY72B,GAAKo+B,EAAOp+B,GAAKg1B,EAAKr5B,MAAMqE,GAG1C,MAAMi3B,EAAgBjC,EAAK9N,WAAW2P,GAEtCpQ,EAAOlc,OAAOvO,GAAKg5B,EAAKzqB,OAAO0sB,EAChC,CACD,OAAOxQ,CACT,WnBkDM,SACFroB,EAAek5B,EAAkBC,EAAyB/oB,EAC1DywB,GAGF,MAAMC,EAAU5H,EAAOA,EAAOv+B,OAAS,IAChComC,EAAO9mC,GAAQ,CAAC+F,EAAErF,OAASmmC,EAASA,GACrCE,EAAc59B,EAAAA,KAAKqR,uBAAuB0kB,EAAQ4H,EAAQ3wB,GAC1D6wB,EAAiB79B,EAAAA,KAAKqR,uBAAuB,QAASssB,EAAQ3wB,GAEpE,IAAK,IAAI3D,EAAI,EAAGA,EAAIs0B,EAAOt0B,IAAK,CAC9B,MAAMiD,EAASjD,EAAIxS,EACbwW,EAAOzQ,EAAEoyB,SAAS1iB,EAAQA,EAASzV,GAEzC,IAAIinC,EAAoB,IAAIvjC,MAAM8S,EAAK9V,QACvC8V,EAAKjV,SACD,CAAC6U,EAAepV,IAAkBimC,EAAUjmC,GAAS,CAACoV,QAAOpV,WAE7DmV,EAAI8wB,EAAUvmC,SAChBm7B,GAAOoL,EAAW9wB,GAClB8wB,EAAYA,EAAU7gC,MAAM,EAAG+P,IAG7BywB,GACFK,EAAUC,KAAKvL,IAGjB,MAAMwL,EAAY30B,EAAI2D,EAChBixB,EAAWL,EAAY5O,SAASgP,EAAWA,EAAYhxB,GACvDkxB,EAAcL,EAAe7O,SAASgP,EAAWA,EAAYhxB,GACnE,IAAK,IAAIxS,EAAI,EAAGA,EAAIwS,EAAGxS,IACrByjC,EAASzjC,GAAKsjC,EAAUtjC,GAAGyS,MAC3BixB,EAAY1jC,GAAKsjC,EAAUtjC,GAAG3C,KAEjC,CAGD,MAAMiL,EAAcgzB,EAAO74B,QAG3B,OAFA6F,EAAYA,EAAYvL,OAAS,GAAKyV,EAE/B,CACL/V,SAAO6L,EAA4BizB,EAAQ6H,GAC3C3mC,SAAO6L,EAA4B,QAAS+6B,GAEhD,gBoBvHM,SACF5K,EAAmB6C,EAAkB/5B,EAAiBoiC,EACtDtZ,GACF,MAAMuZ,EAAQtI,EAAOv+B,OACfgoB,EAAQvf,EAAAA,KAAKgO,cAAc8nB,GAC3B+C,EAAW74B,EAAAA,KAAKsC,eAAewzB,GAC/BuI,EAAar+B,EAAAA,KAAKsC,eAAeuiB,GAEjCI,EAASjlB,EAAIA,KAACqR,uBAChBtV,EAA0BiE,EAAAA,KAAKgO,cAAc6W,IAEjD,IAAK,IAAIrqB,EAAI,EAAGA,EAAI+kB,IAAS/kB,EAAG,CAC9B,MAAM8qB,EAAMtlB,EAAAA,KAAKulB,WAAW/qB,EAAG4jC,EAAOvF,GAGhC+D,EAAmB,IAAIriC,MAAM+qB,EAAI/tB,QACvC,IAAK,IAAIiD,EAAI,EAAGA,EAAIoiC,EAAOrlC,OAAQiD,IACjCoiC,EAAOpiC,GAAK8qB,EAAI6Y,EAAK3jC,IAIvByqB,EADiBjlB,EAAAA,KAAK0lB,WAAWkX,EAAQwB,EAAOC,IAC7BpL,EAAMz4B,EAC1B,CACD,OAAOyqB,CACT,aCzBM,SACFlc,EAAuBu1B,EAAcnkC,EAAiB4B,GAMxD,MAAMwiC,EAAQv+B,EAAAA,KAAKw+B,eAAeF,EAAMnkC,GAAO,GAyDzC0qB,EAAW,CAAC,EAAG1qB,EAAM,GAAI,GAC/B,IAAK,IAAIK,EAAI,EAAGA,EAAI+jC,EAAO/jC,IACzBqqB,EAAS,IAAM1qB,EAAMK,GAEvBqqB,EAAS,GAAK1qB,EAAMokC,GACpB,IAAK,IAAI/jC,EAAI+jC,EAAQ,EAAG/jC,EAAIL,EAAM5C,OAAQiD,IACxCqqB,EAAS,IAAM1qB,EAAMK,GAKvB,MAAMikC,EAAiB,IAAIjoC,IAGrBgxB,EAAU,IAAInX,WAAWlW,EAAMokC,IAE/BG,EAAc,IAAInG,EAAYA,aAAC1T,EAAU9oB,EAAOgN,GAGhD41B,EAA0B,GAC1BC,EAA6B,IAAhB/Z,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAK,IAAIrqB,EAAI,EAAGA,EAAIL,EAAMokC,GAAQ/jC,IAAK,CAErC,IAAIwX,EACJ,GAAI4sB,EAEF5sB,EAAUjJ,EAAOvO,GAAGqkC,eACf,CACL,MAAMC,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAIla,EAAS,GAAIka,IAC/B,IAAK,IAAI7N,EAAI,EAAGA,EAAIrM,EAAS,GAAIqM,IAC/B4N,EAAWpnC,KAAKgnC,EAAYpnC,IAAIynC,EAAGvkC,EAAG02B,IAG1Clf,EAAU8sB,EAAW1iC,KAAK,IAC3B,CAGD,MAAM4iC,EAAgBP,EAAennC,IAAI0a,GACzC,GAAqB,MAAjBgtB,EACFxX,EAAQhtB,GAAKwkC,MACR,CACL,MAAMC,EAAcR,EAAe5nC,KACnC4nC,EAAepnC,IAAI2a,EAASitB,GAC5BzX,EAAQhtB,GAAKykC,EACbN,EAAcjnC,KAAK8C,EACpB,CACF,CAKD,MAAM0kC,EAAiBra,EAAS5nB,QAChCiiC,EAAe,GAAKT,EAAe5nC,KACnC,MAAMsoC,EAAe,IAAI5G,EAAAA,aAAa2G,EAAgBnjC,GACtD4iC,EAAcvmC,SAAQ,CAACgnC,EAAoB5kC,KACzC,IAAK,IAAIukC,EAAI,EAAGA,EAAIla,EAAS,GAAIka,IAC/B,IAAK,IAAI7N,EAAI,EAAGA,EAAIrM,EAAS,GAAIqM,IAC/BiO,EAAa9nC,IAAIqnC,EAAYpnC,IAAIynC,EAAGK,EAAoBlO,GAAI6N,EAAGvkC,EAAG02B,EAErE,IAKH,MAAMpuB,EAAc3I,EAAM8C,QAG1B,OAFA6F,EAAYy7B,GAASW,EAAe,GAE7B,CACL9E,aAAc+E,EAAap2B,OAC3BjG,cACA0kB,UAEJ,GChIA,MACE3B,QAASwZ,GACTC,SAAUC,GACVtZ,SAAUuZ,GACVC,WAAYC,GACZvZ,UAAWwZ,GACXvZ,QAASwZ,GACTtZ,UAAWuZ,GACXrZ,UAAWsZ,GACXrZ,aAAcsZ,GACdC,aAAcC,GACdC,aAAcC,GACdxZ,iBAAkByZ,GAClB1Z,YAAa2Z,GACbxZ,cAAeyZ,GACf1Z,SAAU2Z,GACVzZ,QAAS0Z,GACTC,QAASC,GACT1Z,YAAa2Z,GACbxZ,YAAayZ,GACbvZ,aAAcwZ,GACdC,QAASC,GACTzZ,aAAc0Z,GACdC,SAAUC,GACVC,UAAWC,GACXjS,UAAWkS,GACXC,YAAaC,GACbC,cAAeC,GACfC,UAAWC,GACXC,iBAAkBC,GAClBC,iBAAkBC,GAClBxP,QAASyP,GACTC,SAAUC,GACVC,SAAUC,GACVC,cAAeC,GACfC,WAAYC,IACVC,GC1CS7K,GACTzU,GAAgB,CAACC,OAAQ5L,EAAYY,IAAKiL,cAAeoe,KAEhDiB,GAA0B,CACrCxjB,WAAYyjB,EAAGA,IACfvjB,YAAa,SACbC,WAAYuY,ICLDgL,GAAOzf,GAAgB,CAACC,OAAQ5L,EAAYa,OAE5CwqB,GAA2B,CACtC3jB,WAAY4jB,EAAIA,KAChB1jB,YAAa,SACbC,WAAYujB,ICLDG,GAAQ5f,GAAgB,CAACC,OAAQ5L,EAAYc,QAE7C0qB,GAA4B,CACvC9jB,WAAY+jB,EAAKA,MACjB7jB,YAAa,SACbC,WAAY0jB,ICLDG,GAAgBxf,GACzB,CAACN,OAAQ1O,EAAa6B,IAAK8M,cAAe8f,GAAQxf,iBAAiB,IAE1Dyf,GAA0B,CACrClkB,WAAYmkB,EAAGA,IACfjkB,YAAa,SACbC,WAAY6jB,UCTDI,GAUX9tC,YAAYsc,GAJZpc,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcgP,EAAO,GAC1Bpc,KAAKiH,cAAgBmV,EAAO1X,KAAI,CAACoD,EAAGhD,IAAM,IAAIA,MAC9C9E,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAC5BnmB,KAAK6L,UAAY,MAClB,CAEDjF,cACE,MAAMinC,EAAqB,GAE3B7tC,KAAKiH,cAAcvE,SAAQorC,IACzBD,EAAS7rC,KAAK,QAAQ8rC,UAAiBA,2BAAkC,IAG3E,MAAMC,EAAY/tC,KAAKiH,cACAvC,KAAIopC,GACI,IAAIA,MAEZpnC,KAAK,OAc5B,MAZiB,WACbsgB,EAAK,2CACiBhnB,KAAKmmB,kEACCnmB,KAAKmmB,wIAG3B0nB,EAASnnC,KAAK,0DACcqnC,4CAMvC,EC1BI,MAAMC,GAA2B,CACtCxkB,WAAYykB,EAAIA,KAChBvkB,YAAa,SACbC,WAnBI,SAAeV,GAEnB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,EAEpBilB,EAAUlkC,EAChB,GAAuB,IAAnBkkC,EAAQrsC,OACV,OAAOkrB,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAGgnC,EAAQ,IAAKhlB,YAG5C,MAAM7iB,EACF6nC,EAAQxpC,KAAIqK,GAAKA,EAAE1I,QAAOsgC,QAAO,CAACwH,EAAIC,IAAO3f,EAAAA,WAAW0f,EAAIC,KAC1DhyB,EAAS8xB,EAAQxpC,KAAIqK,GAAKA,EAAEtK,QAC5BY,EAAU,IAAIuoC,GAAkBxxB,GACtC,OAAO8M,EAAQ1N,iBAAiBnW,EAAS6oC,EAAS7nC,EACpD,SCjBagoC,GASXvuC,YAAYgoB,EAAkBwmB,GAR9BtuC,KAAAiH,cAAgB,CAAC,KAMjBjH,KAAa8F,cAA6B,CAAC,GAAI,GAAI,GAGjD,MAAMsH,EAAwB,IAAIvI,MAAMijB,EAAOjmB,QAC/C,IAAK,IAAIiD,EAAI,EAAGA,EAAIsI,EAAYvL,OAAQiD,IACtCsI,EAAYtI,GAAKgjB,EAAOwmB,EAAOxpC,IAEjC9E,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,IACnCvI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAAe,CAAC,EAAG,EAAG,IAEtE9F,KAAK6L,UAAY,iBAClB,CAEDjF,cACE0D,OAAKwC,OACD9M,KAAK8F,cAAc,KAAO9F,KAAK8F,cAAc,IAC7C,IAAM,gDACF9F,KAAK8F,cAAc,QAAQ9F,KAAK8F,cAAc,OACtD,MAAMmJ,EAAWjP,KAAK8F,cAAc,GAsBpC,MArBiB,kDAC0B9F,KAAK8F,cAAc,GAAK,OAC/D9F,KAAK8F,cAAc,eACnBkhB,+CAC+B/X,6DACAA,iSAQJA,yDACAA,gLAQhC,QCnDUs/B,GAWXzuC,YAAYgoB,EAAkBwmB,GAV9BtuC,KAAAiH,cAAgB,CAAC,KAKjBjH,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGL,MAAMiM,EAAwB,IAAIvI,MAAMijB,EAAOjmB,QAC/C,IAAK,IAAIiD,EAAI,EAAGA,EAAIsI,EAAYvL,OAAQiD,IACtCsI,EAAYtI,GAAKgjB,EAAOwmB,EAAOxpC,IAEjC9E,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAE5BnmB,KAAKsuC,OAASA,EACdtuC,KAAK6L,UAAY,aAAayiC,GAC/B,CAED1nC,cACE,MAAMP,EAAQe,EAAkBpH,KAAKoN,YAAYvL,QAC3C2sC,EAAWC,GAAkBzuC,KAAKsuC,QAexC,MAbiB,WACbtnB,EAAK,0CACgBhnB,KAAKmmB,kEACEnmB,KAAKmmB,uLAIjCnmB,KAAKoN,YAAYvL,2BACTwE,KAASmoC,gEAMtB,EAGG,SAAUC,GAAkBH,GAChC,MAAM5lC,EAAO4lC,EAAOzsC,OACpB,GAAI6G,EAAO,EACT,MAAMrG,MAAM,sBAAsBqG,0BAEpC,MAAMgmC,EAAiB,IAAI7pC,MAAM6D,GACjC,IAAK,IAAI5D,EAAI,EAAGA,EAAIwpC,EAAOzsC,OAAQiD,IACjC4pC,EAAeJ,EAAOxpC,IAAM,UAAU8F,EAAa9F,KAGrD,OAAO4pC,EAAehoC,MACxB,CCrDM,SAAUugB,GAAUgC,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNy+B,KAACA,GAAQtf,EACTyE,EAAgB1E,EAEhBwf,EAAQxhC,EAAEzC,MAAM5C,OAChBstB,EAAqB,IAAItqB,MAAM6jC,GACrC,IAAK,IAAI5jC,EAAI,EAAGA,EAAIqqB,EAASttB,OAAQiD,IACnCqqB,EAASrqB,GAAKoC,EAAEzC,MAAMgkC,EAAK3jC,IAE7B,GAAIokB,EAAQrK,mBAAmB,CAAC3X,IAAK,CACnC,MACMmM,EADQua,EAAczc,UAAUvP,IAAIsF,EAAE+K,QACvBoB,OACf0a,EAAY4gB,GAAat7B,EAAQnM,EAAEzC,MAAOyC,EAAEb,MAAOoiC,EAAMtZ,GAC/D,OAAOjG,EAAQrQ,eAAesW,EAAUjoB,EAAEb,MAAO0nB,EAClD,CACD,GAAuB,IAAnB7mB,EAAEzC,MAAM5C,QAAgByI,EAAAA,KAAKC,YAAYk+B,EAAM,CAAC,EAAG,IAAK,CAC1D,MAAMpjC,EAAU,IAAIgpC,GAAuBnnC,EAAEzC,MAAOgkC,GACpD,OAAO7a,EAAcpS,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MACvD,CACD,MAAMhB,EAAU,IAAIkpC,GAAiBrnC,EAAEzC,MAAOgkC,GAC9C,OAAO7a,EAAcpS,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MACxD,CAEO,MAAMuoC,GAAgC,CAC3CplB,WAAYqlB,EAASA,UACrBnlB,YAAa,SACbC,WAAY1C,UCpCD6nB,GAYXhvC,YACIivC,EACAC,EACAnvB,GATJ7f,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,oBAGXzH,KAAImB,MAAG,EAMLnB,KAAKklC,WAAa,CAAC6J,EAAW3H,UAAW2H,EAAWE,QACpD,MAAO7hC,GACH3C,eAAai2B,0BAA0B1gC,KAAKklC,WAAY,CAAC,IAC7DllC,KAAKoN,YAAqC,IAAvBA,EAAYvL,OAAe,CAAC,GAAKuL,EAKhD2hC,EAAWE,QAAU,OAASpvB,GAA4B,IAC5D7f,KAAK8F,cAAgB,CAAC,IAAK,EAAG,GACrBipC,EAAWE,QAAU,KAC9BjvC,KAAK8F,cAAgB,CAAC,IAAK,EAAG,GAE9B9F,KAAK8F,cAAgB,CAAC,GAAI,EAAG,GAE/B9F,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAG9CpN,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgBtI,KAAKoN,YAAa,CAAC,EAAG,EAAG,IAElEpN,KAAKgvC,WAAaA,EAClBhvC,KAAK6L,UAAY,UAAUmjC,GAC5B,CAEDpoC,cACE,IAAIsoC,EAAW,GACXC,EAAY,MAChB,MAAM1mB,EAAiBzoB,KAAK8F,cAAc,GAClB,QAApB9F,KAAKgvC,YAA4C,QAApBhvC,KAAKgvC,YACpCE,EAAW,+HAIa,QAApBlvC,KAAKgvC,WAAuB,IAAM,yDAEtCG,EAAY,kBACiB,QAApBnvC,KAAKgvC,YAA4C,SAApBhvC,KAAKgvC,WAC3CE,EAAW,uCACkB,SAApBlvC,KAAKgvC,YACdE,EAAW,uCACXC,EAAY,OACiB,QAApBnvC,KAAKgvC,YACdE,EAAW,2DACXC,EAAY,OACiB,QAApBnvC,KAAKgvC,aACdE,EAAW,2DACXC,EAAY,OAGd,MAAMC,EAAoC,SAApBpvC,KAAKgvC,WAEvB,uEACA,4CAoDJ,MA9CiB,4GAJW,sDACmBvmB,wJAYf,IAA5BzoB,KAAKoN,YAAYvL,OACb,eACA,wFAGHmlB,EAAK,kDACuByB,+EAEV0mB,sGAE0B1mB,gHAE9BA,oEAEVymB,2IAKgCzmB,uSAM/BymB,gOAQFE,+BAKT,EClHG,SAAUzI,GACZz/B,EAAe0hC,EAAuByG,EACtCL,EAAyB9lB,GAC3B,MAAMwf,EAAQxhC,EAAEzC,MAAM5C,OAChBytC,EAAY,GAEZC,EAAWjlC,EAAAA,KAAKw+B,eAAeF,EAAM1hC,EAAEzC,OAC7C,IAAI+qC,EAAOD,EACX,MAAME,EAAehlC,EAAYA,aAACilC,mBAAmBF,EAAM9G,GAE3D,IAAIvsB,EAAQjV,EACQ,MAAhBuoC,IACFtzB,EAAQ8K,GAAU,CAACjd,OAAQ,CAAC9C,KAAIiiB,MAAO,CAACsf,KAAMgH,GAAevmB,YAC7DsmB,EAAO/kC,EAAYA,aAACklC,iBAAiBH,EAAK3tC,OAAQ6mC,GAClD4G,EAAUttC,KAAKma,IAGjB1R,EAAAA,aAAamlC,2BAA2BZ,EAAYQ,EAAM9G,GAE1D,MAAOmH,EAAgBpP,GACnBh2B,EAAAA,aAAai2B,0BAA0BvkB,EAAM1X,MAAO+qC,GACxD,IAMI7lC,EANAmmC,EAAcD,EAOlB,GANIR,IAEFS,EAAcrlC,EAAAA,aAAaslC,qBAAqBF,EAAgBN,IAI9C,QAAfP,GAAuC,SAAfA,IACzB9lB,EAAQrK,mBAAmB,CAAC1C,IAiBzB,CACL,MAAM8yB,EAAS3kC,EAAAA,KAAKgO,cAAcmoB,GAI5BsO,EAAa,CAACiB,WAAYf,EAAQA,SAAQ7H,UAHlC98B,EAAIA,KAACgO,cAAc6D,EAAM1X,OACbwqC,EAEiCgB,QAAS,GAC9D5pC,EAAuB,SAAf2oC,EAAwB,UAAYkB,aAAWhpC,EAAEb,OACzDijB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC25B,KAEnB5pC,EAAU,IAAIypC,GAChBC,EAAYC,EAAY9lB,EAAQxoB,OAAOmb,OAAOgE,0BAC5CswB,EACFjnB,EAAQ1N,iBAAiBnW,EAAS,CAAC8W,GAAQ9V,EAAOijB,GACtDgmB,EAAUttC,KAAKmuC,GAEfxmC,EAAMigB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGipC,GAAUhnB,MAAO,CAAC1kB,MAAOqrC,GAAc5mB,WACnE,KAlCwC,CACvC,MAAMqU,EAAQrU,EAAQ/X,UAAUvP,IAAIua,EAAMlK,QAAQoB,OAClD,OAAQ27B,GACN,IAAK,MACH,MAAMjhB,EAAYid,GACdzN,EAAOjzB,OAAKgO,cAAcmoB,GAAcqP,EAAa5oC,EAAEb,OAC3DsD,EAAMuf,EAAQrQ,eAAei3B,EAAa5oC,EAAEb,MAAO0nB,GACnD,MACF,IAAK,OACH,MAAM6P,QAACA,EAAOv1B,SAAEA,EAAQs4B,SAAEA,GACtB6K,GAAYrvB,EAAM1X,MAAO0X,EAAM9V,MAAOk3B,EAAOiS,GACjD7lC,EAAMuf,EAAQrQ,eAAexQ,EAAUs4B,EAAU/C,GACjD,MACF,QACE,MAAM,IAAIv7B,MACN,GAAG2sC,8CAEZ,CAqBD,OAFAM,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtCtI,CACT,CCjEO,MAAMymC,GAA0B,CACrC5mB,WAAY6mB,EAAGA,IACf3mB,YAAa,SACbC,WAbI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNqlC,SAACA,EAAQzG,KAAEA,GAAQzf,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,MAAOnmB,EAC1C,GCEO,MAAMonB,GAA0B,CACrC9mB,WAAY+mB,EAAGA,IACf7mB,YAAa,SACbC,WAbI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNqlC,SAACA,EAAQzG,KAAEA,GAAQzf,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,MAAOnmB,EAC1C,SCTasnB,GAcX1wC,YAAYolC,EAAsB0D,EAAcoG,GAThDhvC,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,uBAIXzH,KAAImB,MAAG,EAIL,MAAMquC,EAAO,CAAC5G,GAEd5oC,KAAKmsB,GAAoB,QAAf6iB,EAAuB,IAAM,IAGvC,MAAO5hC,EAAaqzB,GAChBh2B,EAAYA,aAACi2B,0BAA0BwE,EAAYsK,GAEvDxvC,KAAKoN,YAAqC,IAAvBA,EAAYvL,OAAe,CAAC,GAAKuL,EACpDpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAM1C9C,OAAKgO,cAAcmoB,GAAe,IACpCzgC,KAAKkF,KAAO,QACZlF,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,iBAEhD9F,KAAKkF,KAAO,SAGZlF,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgBtI,KAAKoN,YAAa,CAAC,EAAG,EAAG,KAGpEpN,KAAKklC,WAAaA,EAClBllC,KAAK6L,UAAY,aAAa7L,KAAKmsB,MAAMnsB,KAAKkF,MAC/C,CAED0B,cACE,MAAM6hB,EAAiBzoB,KAAK8F,cAAc,GACpC2qC,EAAuB,IACI,IAA3BzwC,KAAKklC,WAAWrjC,OACX,kBAEA,mBAAmB+I,EAAa5K,KAAKklC,WAAWrjC,OAAS,KAI9D6uC,EAAoB,KACxB,IAAI1nC,EAAU,GACd,GAAgC,IAA5BhJ,KAAKoN,YAAYvL,OACY,IAA3B7B,KAAKklC,WAAWrjC,SAClBmH,GAAW,sBAGb,IAAK,IAAIlE,EAAI,EAAGA,EAAI9E,KAAKoN,YAAYvL,OAAQiD,IAC3CkE,GAAW,gBAAgB4B,EAAa9F,MAG5C,OAAOkE,CAAO,EAGhB,GAAkB,WAAdhJ,KAAKkF,KAAmB,CAoD1B,MA/CiB,yGAJW,oDACeujB,sDACDA,wBASxCzB,EAAK,iDACuByB,kCACPgoB,6QAMPhoB,wCACWioB,yDACc1wC,KAAKmsB,sRASF1D,iTAMtBzoB,KAAKmsB,gcAgB5B,CAmBC,MAlBiB,WACfnF,EAAK,2KAIoB0pB,yCACFD,8FAEIC,sCACP1wC,KAAKmsB,+LAW9B,ECpHI,MAAMwkB,GAA6B,CACxCnnB,WAAYonB,EAAMA,OAClBlnB,YAAa,SACbC,WA5BI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,GAAQzf,EAEf,IAAIqmB,EAAOllC,EAAAA,KAAKw+B,eAAeF,EAAM1hC,EAAEzC,OACvC,MAAMgrC,EAAehlC,EAAAA,aAAailC,mBAAmBF,EAAMtoC,EAAEzC,MAAM5C,QACnE,IAAIgvC,EAAK3pC,EACT,MAAM4pC,EAA0B,GACZ,MAAhBrB,IACFoB,EAAK5pB,GAAU,CAACjd,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAACsf,KAAMgH,KACpDqB,EAAwB9uC,KAAK6uC,GAC7BrB,EAAO/kC,EAAAA,aAAaklC,iBAAiBH,EAAK3tC,OAAQgvC,EAAGpsC,MAAM5C,SAG7D4I,eAAamlC,2BAA2B,SAAU,CAACJ,EAAK,IAAKqB,EAAGpsC,MAAM5C,QACtE,MAAMwD,EAAU,IAAImrC,GAAiBK,EAAGpsC,MAAO+qC,EAAK,GAAI,OAClDlmB,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC/U,OAAOwwC,qBAC/CvlB,EAAMtC,EAAQ1N,iBAAiBnW,EAAS,CAACwrC,GAAK,QAASvnB,GAE7D,OADAwnB,EAAwBpuC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UACpDuZ,CACT,GCEO,MAAMwlB,GAA6B,CACxCxnB,WAAYynB,EAAMA,OAClBvnB,YAAa,SACbC,WA5BI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,GAAQzf,EAEf,IAAIqmB,EAAOllC,EAAAA,KAAKw+B,eAAeF,EAAM1hC,EAAEzC,OACvC,MAAMgrC,EAAehlC,EAAAA,aAAailC,mBAAmBF,EAAMtoC,EAAEzC,MAAM5C,QACnE,IAAIgvC,EAAK3pC,EACT,MAAM4pC,EAA0B,GACZ,MAAhBrB,IACFoB,EAAK5pB,GAAU,CAACjd,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAACsf,KAAMgH,KACpDqB,EAAwB9uC,KAAK6uC,GAC7BrB,EAAO/kC,EAAAA,aAAaklC,iBAAiBH,EAAK3tC,OAAQgvC,EAAGpsC,MAAM5C,SAG7D4I,eAAamlC,2BAA2B,SAAU,CAACJ,EAAK,IAAKqB,EAAGpsC,MAAM5C,QACtE,MAAMwD,EAAU,IAAImrC,GAAiBK,EAAGpsC,MAAO+qC,EAAK,GAAI,OAClDlmB,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC/U,OAAO2wC,qBAC/C1lB,EAAMtC,EAAQ1N,iBAAiBnW,EAAS,CAACwrC,GAAK,QAASvnB,GAE7D,OADAwnB,EAAwBpuC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UACpDuZ,CACT,GCxBa2lB,GAAO1jB,GAAgB,CAACC,OAAQ5L,EAAYe,OAE5CuuB,GAA2B,CACtC5nB,WAAY6nB,EAAIA,KAChB3nB,YAAa,SACbC,WAAYwnB,ICLDG,GAAQ7jB,GAAgB,CAACC,OAAQ5L,EAAYgB,QAE7CyuB,GAA4B,CACvC/nB,WAAYgoB,EAAKA,MACjB9nB,YAAa,SACbC,WAAY2nB,ICLDG,GAAOhkB,GAAgB,CAACC,OAAQ5L,EAAYiB,OAE5C2uB,GAA2B,CACtCloB,WAAYmoB,EAAIA,KAChBjoB,YAAa,SACbC,WAAY8nB,ICPDG,GAAQ5jB,GAAiB,CAACN,OAAQ1O,EAAaoB,QAE/CyxB,GAA4B,CACvCroB,WAAYsoB,EAAKA,MACjBpoB,YAAa,SACbC,WAAYioB,ICHDG,GAAQtkB,GAAgB,CAACC,OAAQ5L,EAAYkB,QAE7CgvB,GAA4B,CACvCxoB,WAAYyoB,EAAKA,MACjBvoB,YAAa,SACbC,WAAYooB,UCPDG,GAUXpyC,YAAYqyC,GALZnyC,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,uBACXzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GACnD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,6BAClB,CAEDjF,cAiBE,MAhBiB,WACbogB,EAAK,gbAgBV,QCtCUorB,GAiBXtyC,YACIqyC,EAAmCE,EACnCC,GAAmB,EAAOC,GAAmB,EAC7CC,GAAoB,GACtB,GAhBFxyC,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SACJ,8GAGJzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAEnD9F,KAAImB,MAAG,EASY,QAAbkxC,GAAsBC,EACxB,MAAM,IAAIjwC,MAAM,8CAGlBrC,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKqyC,SAAWA,EAChBryC,KAAKsyC,iBAAmBA,EACxBtyC,KAAKuyC,iBAAmBA,EACxBvyC,KAAKwyC,kBAAoBA,EACzBxyC,KAAK6L,UAAY,UAAUwmC,KAAYC,KACnCC,KAAoBC,GACzB,CAED5rC,cACE,IAAI6rC,EACJ,GAAsB,QAAlBzyC,KAAKqyC,SACPI,EAAgB,+DACX,GAAIzyC,KAAKsyC,iBAAkB,CAMhCG,EAAgB,+KALIzyC,KAAKuyC,iBACpBvyC,KAAKwyC,kBACD,yFACA,0DACL,6CAOL,MACCC,EAAgB,yCAGlB,IAAIC,EAAc,cACI,QAAlB1yC,KAAKqyC,WACPK,EAAc,iCA8ChB,MA3CiB,WACb1rB,EAAK,kVAULhnB,KAAKsyC,iBACD,8FAGA,qBACsB,QAAlBtyC,KAAKqyC,SAAqB,MAAQ,8kBAiBlCI,8CAKRzyC,KAAKsyC,iBAAmB,2CACA,2BAA2BI,iCAKxD,QAGUC,GAeX7yC,YACIqyC,EAAmCE,EACnCC,GAAmB,EAAOC,GAAmB,EAC7CC,GAAoB,GACtB,GAdFxyC,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SACJ,uFACJzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAEnD9F,KAAImB,MAAG,EASY,QAAbkxC,GAAsBC,EACxB,MAAM,IAAIjwC,MAAM,8CAGlBrC,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKqyC,SAAWA,EAChBryC,KAAKsyC,iBAAmBA,EACxBtyC,KAAKuyC,iBAAmBA,EACxBvyC,KAAKwyC,kBAAoBA,EACzBxyC,KAAK6L,UAAY,UAAUwmC,KAAYC,KACnCC,KAAoBC,GACzB,CAED5rC,cACE,IAAI6rC,EACJ,GAAsB,QAAlBzyC,KAAKqyC,SACPI,EAAgB,2CACX,GAAIzyC,KAAKsyC,iBAAkB,CAMhCG,EAAgB,+KALIzyC,KAAKuyC,iBACpBvyC,KAAKwyC,kBACD,kHACA,oFACL,kGAOL,MACCC,EAAgB,yCAGlB,IAAIC,EAAc,cACI,QAAlB1yC,KAAKqyC,WACPK,EAAc,iCAsDhB,MAnDiB,WACb1rB,EAAK,yYAYLhnB,KAAKsyC,iBACD,8FAGA,qBACsB,QAAlBtyC,KAAKqyC,SAAqB,MAAQ,4vBAsBhCI,+DAMVzyC,KAAKsyC,iBAAmB,2CACA,2BAA2BI,iCAKxD,EC9NG,SAAUnuC,GACZ0kB,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4oC,iBAACA,EAAgBvD,SAAEA,GAAYlmB,EAErC,OAAOwd,GAAOz/B,EAAG0rC,EAAkBvD,EAAU,MAAOnmB,EACtD,CAEO,MAAM2pB,GAA0B,CACrCrpB,WAAYspB,EAAGA,IACfppB,YAAa,SACbC,WAAYplB,ICbR,SAAUwuC,GACZ9pB,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNqlC,SAACA,EAAQzG,KAAEA,GAAQzf,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,OAAQnmB,EAC3C,CAEO,MAAM8pB,GAA2B,CACtCxpB,WAAYypB,EAAIA,KAChBvpB,YAAa,SACbC,WAAYopB,ICPR,SAAUG,GACZhsC,EAAeirC,EAAmCE,EAClDnpB,GACF,GAA6B,IAAzBipB,EAASgB,aAA+C,IAA1BhB,EAASiB,cACvC9oC,EAAIA,KAACC,YAAY4nC,EAASkB,QAASlB,EAAS9pC,UAC9C,OAAO0kB,GAAS,CAAC/iB,OAAQ,CAAC9C,KAAIgiB,YAGhC,GAAIipB,EAASgB,cAAgBhB,EAASmB,SAClCnB,EAASiB,eAAiBjB,EAASoB,UAAmC,IAAvBpB,EAAS/K,WAC9B,UAA1B+K,EAASqB,QAAQtuC,KAAkB,CACrC,MAAMrD,EAASqF,EAAEzC,MAAM5C,OACjB4xC,EAAW7pB,GAAQ,CACvB5f,OAAQ,CAAC9C,KACTgiB,UACAC,MAAO,CACL1kB,MAAO,CACLyC,EAAEzC,MAAM5C,EAAS,GAAKqF,EAAEzC,MAAM5C,EAAS,GACvCqF,EAAEzC,MAAM5C,EAAS,OAIvB,IAAI6xC,EACa,QAAbrB,EACFqB,EAAUX,GACN,CAAC/oC,OAAQ,CAAC9C,EAAGusC,GAAWvqB,UAASC,MAAO,CAACyf,KAAM,EAAGyG,UAAU,MAEhE/kC,OAAKwC,OAAoB,QAAbulC,GAAoB,IAAM,qBAAqBA,MAC3DqB,EAAUnvC,GAAI,CACZyF,OAAQ,CAAC9C,EAAGusC,GACZvqB,UACAC,MAAO,CAACypB,iBAAkB,EAAGvD,UAAU,MAI3C,MAAM9f,EAAS3F,GACX,CAAC5f,OAAQ,CAAC9C,EAAGwsC,GAAUxqB,UAASC,MAAO,CAAC1kB,MAAO0tC,EAAS9pC,YAG5D,OAFA6gB,EAAQlX,YAAYyhC,EAASxhC,QAC7BiX,EAAQlX,YAAY0hC,EAAQzhC,QACrBsd,CACR,CAED,IAAIlqB,EACJ,MAAM0D,EACF,CAAC,CAAC7D,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,eAsB5D,OArB8B,IAA1BzB,EAASiB,cAA+C,IAAzBjB,EAASgB,YAC1C9tC,EAAU,IAAI6sC,GAAmCC,IAEhC,QAAbE,EACFhtC,EAAU,IAAI+sC,GAAcD,EAAU,QAEtC7nC,OAAKwC,OAAoB,QAAbulC,GAAoB,IAAM,qBAAqBA,MAC3DhtC,EAAU,IAAI+sC,GAAcD,EAAU,QAGxCppC,EAAW/G,KACP,CAACkD,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAAQ,CACpEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBAE3C,CAAC7uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,SAAUpB,EAASmB,UAAW,CAC5DpuC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS6B,sBAAuB7B,EAAS8B,yBAIjD/qB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAO0C,EACzD,CC5DO,MAAMmrC,GAA8B,CACzC1qB,WAAY2qB,EAAOA,QACnBzqB,YAAa,SACbC,WAjBI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNoqC,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGC,gBAAEA,GAAmBnrB,EAMpD,OAAO+pB,GAAShsC,EAJCuD,EAAAA,aAAa8pC,kBAC1BrtC,EAAEzC,MAA2C2vC,EAAYxvC,EAF3C,EAGHyvC,EAAKC,GAES,MAAOprB,EACtC,GC2BO,MAAMsrB,GAAgC,CAC3ChrB,WAAYirB,EAASA,UACrB/qB,YAAa,SACbC,WA1CI,SAAoBV,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNoqC,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAUJ,gBAAEA,GAAmBnrB,EAG1DgpB,EAAW1nC,EAAAA,aAAakqC,kBAC1BztC,EAAEzC,MAAmD2vC,EAAYxvC,EAHzB,CAAC,EAAG,EAAG,GAIpCyvC,EAAKC,EAAiBI,GAC/BE,EAAiB,IAAIjC,GAAcR,EAAU,OAC7CppC,EAAa,CACjB,CACE7D,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KACI,CAAC68B,EAASqB,QAAQsB,MAAO3C,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAEtE,CACEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS4C,QAAS5C,EAASoB,SAAUpB,EAASmB,UAEvD,CACEpuC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAsB7C,EAAS6B,sBACxC7B,EAAS8B,wBAIf,OAAO/qB,EAAQ1N,iBAAiBo5B,EAAgB,CAAC1tC,GAAIA,EAAEb,MAAO0C,EAChE,SCrCaksC,GAYXn1C,YAAYqyC,GAPZnyC,KAAAiH,cAAgB,CAAC,MACjBjH,KAAAyH,SACI,sJAEJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAE5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,mBAClB,CAEDjF,cAwCE,MAvCiB,WACbogB,EAAK,kzCAuCV,QAGUkuB,GAWXp1C,YAAYqyC,GANZnyC,KAAAiH,cAAgB,CAAC,MACjBjH,KAAAyH,SAAW,+IAEXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAE5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,mBAClB,CAEDjF,cAkDE,MAjDiB,WACbogB,EAAK,yoDAiDV,EC/FI,MAAMmuB,GAAoC,CAC/C3rB,WAAY4rB,EAAaA,cACzB1rB,YAAa,SACbC,WA/CI,SAAwBV,GAK5B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEl5B,MAAEA,GAASnS,EACd9C,EAAIiV,GACJi4B,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGC,gBAAEA,GAAmBnrB,EAE9CgpB,EAAW1nC,EAAAA,aAAakqC,kBAC1BztC,EAAEzC,MAAmD2vC,EAAYxvC,EACjE,EAAmByvC,EAAKC,GACtBjvC,EAAU,IAAI6vC,GAAyB/C,GACvCmD,EACF,GAAKnD,EAASoD,YAAcpD,EAASiB,aAAejB,EAASgB,aAC3D7pB,EAAc,CAClB,CACEpkB,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAuB,EAAI7C,EAASqB,QAAQsB,MACrD3C,EAAS6B,sBAAwB,EAAI7B,EAASqB,QAAQK,IACtD1B,EAAS8B,qBAAuB,EAAI9B,EAASqB,QAAQtW,OAGzD,CACEh4B,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAsB7C,EAAS6B,sBACxC7B,EAAS8B,uBAGb,CAAC/uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqD,WAChC,CAACtwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,UAAWoQ,KAAM,CAACggC,KAE3B,OAAOpsB,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,GAAKnuC,EAAEb,MAAOijB,EAC1D,GCNO,MAAMqsB,GAAkC,CAC7CnsB,WAAYosB,EAAWA,YACvBlsB,YAAa,SACbC,WAtCI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEl5B,MAAEA,GAASnS,EACd9C,EAAIiV,EACVxN,EAAiB,CAAC0mC,EAAIl5B,GAAQ,eAC9B,MAAMi4B,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,GAAOlrB,EAE7BgpB,EAAW1nC,eAAa8pC,kBAC1BrtC,EAAEzC,MAA2C2vC,EAAYxvC,EACzD,EAAmByvC,GACjBhvC,EAAU,IAAI4vC,GAAyB9C,GACvCmD,EAAgB,GAAKnD,EAASiB,aAAejB,EAASgB,aACtD7pB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cAAe,CACpE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6B,sBAAwB,EAAI7B,EAASqB,QAAQK,IACtD1B,EAAS8B,qBAAuB,EAAI9B,EAASqB,QAAQtW,OAGzD,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBAAiB,CACxE7uC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS6B,sBAAuB7B,EAAS8B,uBAElD,CAAC/uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,UAAWoQ,KAAM,CAACggC,KAE3B,OAAOpsB,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,GAAKnuC,EAAEb,MAAOijB,EAC1D,GCtBO,MAAMusB,GAAkC,CAC7CrsB,WAAYssB,EAAWA,YACvBpsB,YAAa,SACbC,WAfI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BmB,EAACA,EAACzW,EAAEA,GAAK3J,GACT8D,WAACA,EAAU6X,WAAEA,GAAcwD,EAEjC,OAAOgB,GAAgB,CAACC,IAAGzW,IAAG7F,aAAY6X,aAAYuD,WACxD,SCZa6sB,GAaXj2C,YAAY6yB,EAAiBqjB,GAZ7Bh2C,KAAAiH,cAAgB,CAAC,UAOjBjH,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc4oC,EACnBh2C,KAAK0I,KAAOstC,EAASn0C,OACrB7B,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAE5BnmB,KAAK2yB,MAAQA,EACb3yB,KAAKyH,SAAW,WAAWL,EAAkBurB,EAAM9wB,YACnD7B,KAAK6L,UAAY,OAClB,CAEDjF,cACE,MAAMP,EAAQe,EAAkBpH,KAAK0I,MAC/ButC,EA6BV,SAAmBvtC,GACjB,GAAa,IAATA,EACF,MAAO,YACF,GAAIA,GAAQ,EACjB,OAAOmE,GAAOtF,MAAM,EAAGmB,GAAMhE,KAAIwxC,GAAS,aAAaA,MAASxvC,KAAK,KAErE,MAAMrE,MAAM,oBAAoBqG,yBAEpC,CArCyBytC,CAAUn2C,KAAK0I,MACpC,IAAI0tC,EAEFA,EADwB,IAAtBp2C,KAAK2yB,MAAM9wB,OACF7B,KAAKoN,YAAY1I,KAAI,CAACoD,EAAGhD,IAC3B,yCAGE9E,KAAKoN,YAAY1I,KAAI,CAACoD,EAAGhD,IAC3B,aAAa+H,GAAO/H,uBACvB8F,EAAa9F,eAAe+H,GAAO/H,QAc3C,MAViB,WACbkiB,EAAK,+EAEe3gB,oEAEhB+vC,EAAS1vC,KAAK,sDACoBuvC,gCAK3C,EAGH,MAAMppC,GAAS,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,KCpDnC,SAAUtF,GACZ0hB,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN+4B,MAACA,EAAK5hC,KAAEA,GAAQgoB,GAEfktB,EAAQC,GAASrT,EAAAA,WAAWsT,iBAAiBrvC,EAAG67B,EAAO5hC,GAG9D,GAFA8hC,EAAAA,WAAWuT,kBAAkBtvC,EAAGmvC,EAAQC,GAEpCptB,EAAQrK,mBAAmB,CAAC3X,KAAmB,WAAZA,EAAEb,MAAoB,CAC3D,MAAMowC,EAAcvtB,EAAQ/X,UAAUvP,IAAIsF,EAAE+K,QACtC8b,EAAYke,GACdwK,EAAYpjC,OAAsBgjC,EAAQC,EAAOpvC,EAAEzC,MAAOyC,EAAEb,OAChE,OAAO6iB,EAAQrQ,eAAey9B,EAAOpvC,EAAEb,MAAO0nB,EAC/C,CAED,GAAkC,IAA9BzjB,OAAKgO,cAAcg+B,GACrB,OAAOptB,EAAQrQ,eAAey9B,EAAOpvC,EAAEb,MAAO,IAIhD,MAAMhB,EAAU,IAAI0wC,GAAaM,EAAQC,GACnChtB,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAM+gC,IAC3C,OAAOntB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EACzD,CAEO,MAAMotB,GAA4B,CACvCltB,WAAYmtB,EAAKA,MACjBjtB,YAAa,SACbC,WAAYpiB,ICsBDqvC,GAAqC,CAChDptB,WAAYqtB,EAAcA,eAC1BntB,YAAa,SACbC,WArD6BV,IAK7B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN8sC,WAACA,EAAUC,MAAEA,GAAS5tB,EAE5B7e,EAAIA,KAACwC,OACD5F,EAAEzC,MAAM5C,QAAU,GAClB,IAAM,0EAEV,MAAM++B,EAAOkW,EAAWnQ,QAAO,CAACvc,EAAGzW,IAAMyW,EAAIzW,IAEvCqjC,EAAWvsC,EAAAA,aAAawsC,YAAY/vC,EAAEzC,MAAOqyC,EAAYlW,GACzDsW,EAAWzsC,EAAAA,aAAa0sC,YAAYH,EAASn1C,OAAQi1C,EAAWj1C,QAChEu1C,EACF3sC,EAAAA,aAAa4sC,oBAAoBnwC,EAAEzC,MAAOqyC,EAAYlW,GACpD0W,EACF7sC,EAAAA,aAAa8sC,oBAAoBR,EAAOD,EAAWj1C,QACjDw9B,EACF50B,EAAAA,aAAa+sC,aAAaJ,EAAkBL,EAAOD,EAAWj1C,QAE5DytC,EAAY,GAEZmI,EACF7tB,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAOuyC,KAC5CU,EAAyBzwB,GAC3B,CAACjd,OAAQ,CAAC9C,EAAGuwC,GAAuBvuB,UAASC,MAAO,CAACsf,KAAMyO,KACzDS,EAAwB/tB,GAAQ,CACpC5f,OAAQ,CAAC9C,EAAGwwC,GACZxuB,UACAC,MAAO,CAAC1kB,MAAO2yC,KAEXQ,EAASrwC,GAAM,CACnByC,OAAQ,CAAC9C,EAAGywC,GACZzuB,UACAC,MAAO,CAAC4Z,MAAOuU,EAAkBn2C,KAAMk+B,KASzC,OANAiQ,EAAUttC,KAAKy1C,GACfnI,EAAUttC,KAAK01C,GACfpI,EAAUttC,KAAK21C,GAEfrI,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtC2lC,CAAM,GCnDTC,GAAe,wDAEf9yC,EAAiB,iBAAkB,QAAS,0BAUrC+yC,GAaXh4C,YACI2E,EAAkCszC,EAClC/Z,GAAe,GAdnBh+B,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,sBACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EACTlI,KAAU+3C,YAAG,EACb/3C,KAAYg+B,cAAG,EAMbh+B,KAAKoN,YAAc3I,EACnBzE,KAAK0I,KAAOjE,EAAM5C,OAClB7B,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKg+B,aAAeA,EAChBA,IACFh+B,KAAKkI,QAAS,GAEhBlI,KAAK+3C,WAAaA,EACd/3C,KAAK+3C,YACP/3C,KAAKiH,cAAcjF,KAAK,KAE1BhC,KAAK6L,UACD,YAAY7L,KAAK+3C,cAAc/3C,KAAKg+B,gBAAgBh+B,KAAK0I,MAC9D,CAED9B,cA4BE,MA3BiB,SACf5G,KAAKg+B,aA1CgB,gHA0CoB6Z,SAC3C7wB,EAAK,mBAEa,IAAdhnB,KAAK0I,KACD,8IAII1I,KAAKg+B,aAAe,EACCh+B,KAAK+3C,WAAa,cAAgB,kEAI3D,wNAKI/3C,KAAKg+B,aACD,EACCh+B,KAAK+3C,WAAa,2BAA6B,8GAOjE,EChDI,MAAMC,GAA+B,CAC1CxuB,WAAYyuB,EAAQA,SACpBvuB,YAAa,SACbC,WA3BI,SACFV,GAGF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACgxC,QAAEA,GAAWluC,GACf7I,KAACA,GAAQgoB,EAETU,EAAQvf,EAAIA,KAACgO,cAAcpR,EAAEzC,OAE7BszC,EADcztC,EAAIA,KAACgO,cAAc4/B,EAAQzzC,OACd,EAC3B0yB,EAAuB,CAACh2B,GACxBkF,EAAQ6xC,EAAQ7xC,MAEhBd,EAASyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAO0yB,EAAY5f,MAAO,EAAGlR,WAC7DhB,EAAU,IAAIyyC,GAAgB,CAACjuB,GAAQkuB,GACvCzuB,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAACnU,KACtCg3C,EAA+BJ,EAAa,CAAC7wC,EAAGgxC,GAAW,CAAChxC,GAIlE,OAHYgiB,EAAQ1N,iBAChBnW,EAAS8yC,EAAgB9xC,EAAOijB,EAAa/jB,EAGnD,SC1Ba6yC,GAUXt4C,YAAY2E,GATZzE,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KAAM,MACvBjH,KAAQyH,SAAG,+BACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc,CAAC3I,GACpBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,eAClB,CAEDjF,cA2BE,MA1BiB,OACjBogB,EAAK,0nBA0BN,ECjBI,MAAMqxB,GAAoC,CAC/C7uB,WAAY8uB,EAAaA,cACzB5uB,YAAa,SACbC,WA/BI,SAAwBV,GAI5B,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpBsvB,GAACA,EAAEC,GAAEA,GAAMxuC,EAEjB,GAAIkf,EAAQrK,mBAAmB,CAAC05B,EAAIC,IAAM,CACxC,MAAMC,EAAevvB,EAAQ/X,UAAUvP,IAAI22C,EAAGtmC,QACxCymC,EAAexvB,EAAQ/X,UAAUvP,IAAI42C,EAAGvmC,QACxC0mC,EAASF,EAAaplC,OACtBulC,EAASF,EAAarlC,OACtBwlC,EAAiBpuC,EAAAA,aAAawgB,2BAChCpmB,MAAMw5B,KAAKsa,GAAS9zC,MAAMw5B,KAAKua,IACnC,OAAO1vB,EAAQrQ,eACX,CAACggC,EAAeh3C,QAAS,QAAS8Y,WAAW0jB,KAAKwa,GACvD,CAED,MAAMC,EAASxuC,EAAIA,KAACgO,cAAcigC,EAAG9zC,OAC/Bs0C,EAASzuC,EAAIA,KAACgO,cAAckgC,EAAG/zC,OAC/B0yB,EAAa7yB,KAAKC,IAAIu0C,EAAQC,GAE9B1zC,EAAU,IAAI+yC,GAAqBjhB,GACnC7N,EACF,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAACwjC,IAAU,CAAC5zC,KAAM,QAASoQ,KAAM,CAACyjC,KAC7D,OAAO7vB,EAAQ1N,iBAAiBnW,EAAS,CAACkzC,EAAIC,GAAK,QAASlvB,EAC9D,GCzBa0vB,GAAWhrB,GAAiB,CACvCN,OAAQ1O,EAAawB,UACrBna,MAAO,OACPsnB,cAAesrB,KAGJC,GAA+B,CAC1C1vB,WAAY2vB,EAAQA,SACpBzvB,YAAa,SACbC,WAAYqvB,ICVR,SAAU1mC,GAAK2W,GAEnB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB9M,MAACA,GAASnS,EAGhB,OAAO+iB,GAAS,CAAC/iB,OAAQ,CAAC9C,EAFRgiB,EAAQ/X,UAAUvP,IAAIua,EAAMlK,QAEPI,mBAAmBC,MAAO4W,WACnE,CAEO,MAAMkwB,GAA2B,CACtC5vB,WAAY6vB,EAAIA,KAChB3vB,YAAa,SACbC,WAAYrX,IC6DP,MAAMgnC,GAA2B,CACtC9vB,WAAY+vB,EAAIA,KAChB7vB,YAAa,SACbC,WArEI,SAAU6vB,EACZvwB,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN3D,MAACA,GAAS8iB,EAGhB,GAAc,cAAV9iB,EAAuB,CACzB,GAAgB,cAAZa,EAAEb,MACJ,OAAO0mB,GAAS,CAAC/iB,OAAQ,CAAC9C,KAAIgiB,YAIhC,MAAMuwB,EAAcC,EAAGC,MAAMzyC,EAAEzC,OACzBm1C,EAASJ,EAAK,CAACxvC,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC9iB,MAAO,aAEpDkpB,EACFrC,GAAQ,CAACljB,OAAQ,CAACsI,KAAMsnC,EAAQrnC,KAAMknC,GAAcvwB,YAKxD,OAHAuwB,EAAYh3C,UACZymB,EAAQlX,YAAY4nC,EAAO3nC,QAEpBsd,CACR,CAGD,GAAgB,cAAZroB,EAAEb,MAAuB,CAC3B,MAAMwzC,EAAWvnC,GAAK,CAACtI,OAAQ,CAACmS,MAAOjV,GAAIgiB,YACrCqG,EAASiqB,EAAK,CAACxvC,OAAQ,CAAC9C,EAAG2yC,GAAW3wB,UAASC,MAAO,CAAC9iB,WAE7D,OADA6iB,EAAQlX,YAAY6nC,EAAS5nC,QACtBsd,CACR,CAED,IAAKjlB,EAAIA,KAACwvC,gBAAgB5yC,EAAEb,MAAOA,GAAQ,CAGzC,MAAMkpB,EAASxC,GAAS,CAAC/iB,OAAQ,CAAC9C,KAAIgiB,YACtC,MAAO,CAACjX,OAAQsd,EAAOtd,OAAQxN,MAAO8qB,EAAO9qB,MAAO4B,QACrD,CAED,GAAI6iB,EAAQrK,mBAAmB,CAAC3X,IAAK,CACnC,MAAMmM,EAAS6V,EAAQ/X,UAAUvP,IAAIsF,EAAE+K,QAAQoB,QACxCorB,EAAasb,EAAYvb,GAC5BqL,GAAYx2B,EAAQnM,EAAEzC,MAAOyC,EAAEb,MAAOA,GAC1C,OAAO6iB,EAAQrQ,eAAe4lB,EAAasb,EAAYvb,EACxD,CAED,GAAc,UAAVn4B,EACF,OCxDY,SAAI8V,EAAmB+M,GACrC,MAAM7jB,EAAU,IAAImoB,GAAerR,EAAM1X,MAAOqd,EAAYkD,QACtDzf,EAAS2jB,EAAQ1N,iBAAiBnW,EAAS,CAAC8W,GAAQ,SAC1D,MAAO,CAAClK,OAAQ1M,EAAO0M,OAAQxN,MAAOc,EAAOd,MAAO4B,MAAOd,EAAOc,MACpE,CDoDW2zC,CAAI9yC,EAAGgiB,GAGhB,GAAc,SAAV7iB,EAAkB,CACpB,MAAM4zC,EAAkB/wB,EAAQrQ,eAC5B,GAAI,OAAQvO,EAAIA,KAACqR,uBAAuB,OAAQ,IAI9C4T,EAASypB,GAAS,CAAChvC,OAFU,CAACogB,EAAGljB,EAAGyM,EAAGsmC,GAEE/wB,YAE/C,OADAA,EAAQlX,YAAYioC,EAAgBhoC,QAC7Bsd,CACR,CAED,MAAM,IAAIltB,MAAM,iCAAiC6E,EAAEb,YAAYA,IACjE,GEvEaoH,GACTggB,GAAgB,CAACC,OAAQ5L,EAAYqB,KAAMwK,cAAemc,KAEjDoQ,GAA2B,CACtC1wB,WAAY2wB,EAAIA,KAChBzwB,YAAa,SACbC,WAAYlc,UCRD2sC,GAYXt6C,YAAYsN,GATZpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,8BAGXzH,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAe+F,gBAAG,EAClB/F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAC5BnmB,KAAK6L,UAAY,UAClB,CAEDjF,cAYE,MAXiB,WACbogB,EAAK,2WAWV,QClCUqzB,GAYXv6C,YAAYsN,GATZpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,8BAGXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAGlD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,MAClB,CAEDjF,cAaE,MAZiB,WACbogB,EAAK,8TAYV,ECTI,MAAMszB,GAAkC,CAC7C9wB,WAAY+wB,EAAWA,YACvB7wB,YAAa,SACbC,WAzBI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNwwC,aAACA,EAAYC,aAAEA,GAAgBtxB,EAErC,IAAI9jB,EACJ,MAAMikB,EAAc,CAClB,CAACpkB,KAAM,UAAWoQ,KAAM,CAACklC,IACzB,CAACt1C,KAAM,UAAWoQ,KAAM,CAACmlC,KAO3B,OAJEp1C,EADEiF,EAAAA,KAAKgO,cAAcpR,EAAEzC,OAAS,GAAM,EAC5B,IAAI21C,GAAgBlzC,EAAEzC,OAEtB,IAAI41C,GAAYnzC,EAAEzC,OAEvBykB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EACzD,SCxBaoxB,GASX56C,YAAY2E,GARZzE,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,OAAQ,QACzBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,YAClB,CAEDjF,cAcE,MAbiB,SACfogB,EAAK,+cAaR,EC5BH,SAAS2zB,GACLC,EAA2BC,GAC7B,MAAO,CACL5oC,OAAQ4oC,EAAY5oC,OACpB5L,MAAOw0C,EAAYx0C,MACnB5B,MAAOm2C,EAAcn2C,MAEzB,CAmBO,MAAMq2C,GAAiC,CAC5CtxB,WAAYuxB,EAAUA,WACtBrxB,YAAa,SACbC,WApBI,SACFV,GACF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,GAAK8C,EAEN8jB,EAAQ5E,EAAQ/X,UAAUvP,IAAIsF,EAAE+K,QAEhC5M,EAAU,IAAIq1C,GAAkBxzC,EAAEzC,OAClCu2C,EAAgB,CACpBL,GAA+BzzC,EAAG4mB,EAAMzb,mBAAmBC,MAC3DqoC,GAA+BzzC,EAAG4mB,EAAMzb,mBAAmBE,OAG7D,OAAO2W,EAAQ1N,iBACXnW,EAAS21C,EAAeA,EAAc,GAAG30C,MAC/C,SC5Ba40C,GAYXn7C,YAAYsc,GANZpc,KAAQyH,SAAG,GACXzH,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAILnB,KAAKoN,YACD3C,EAAAA,aAAaywC,gBAAgB9+B,EAAQ,GACzCpc,KAAKiH,cAAgBmV,EAAO1X,KAAI,CAACoD,EAAGhD,IAAM,IAAIA,MAC9C9E,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAE5BnmB,KAAKm7C,aAAe/+B,EAAOva,OAAS,EACpC,IAAK,IAAIiD,EAAI,EAAGA,EAAI9E,KAAKm7C,aAAcr2C,IACrC9E,KAAKyH,UAAY,SAAS3C,WAE5B9E,KAAK6L,UAAY,QAClB,CAEDjF,cACE,MAAMinC,EAAqB,GAC3B,GAAI7tC,KAAKm7C,aAAe,EAAG,CACzBtN,EAAS7rC,KACL,uFACJ,IAAK,IAAI8C,EAAI,EAAGA,EAAI9E,KAAKm7C,aAAcr2C,IACrC+oC,EAAS7rC,KACL,gCAAgC,CAAC8C,kDAE7BA,6BAA6BA,EAAI,UAE3C,MAAMs2C,EAAYp7C,KAAKm7C,aACjBE,EAAiBr7C,KAAKm7C,aAAe,EAC3CtN,EAAS7rC,KAAK,oDACVo5C,6BAAqCC,SAC1C,MACCxN,EAAS7rC,KAAK,yDAiBhB,MAdiB,WACbglB,EAAK,0CACgBhnB,KAAKmmB,kEACEnmB,KAAKmmB,yMAM3B0nB,EAASnnC,KAAK,sDAMzB,EC7DG,SAAU6L,GAAK0W,GAEnB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB9M,MAACA,GAASnS,EAGhB,OAAO+iB,GAAS,CAAC/iB,OAAQ,CAAC9C,EAFRgiB,EAAQ/X,UAAUvP,IAAIua,EAAMlK,QAEPI,mBAAmBE,MAAO2W,WACnE,CAEO,MAAMoyB,GAA2B,CACtC9xB,WAAY+xB,EAAIA,KAChB7xB,YAAa,SACbC,WAAYpX,aCNEw3B,GACZ//B,EAAsB4+B,EAAc1f,GACtC,MAAM7iB,EAAQ2D,EAAO,GAAG3D,MACxB,GAAc,cAAVA,EAAuB,CACzB,MAAMm1C,EAAQxxC,EAAOtF,KAAKqK,GAAMuD,GAAK,CAACtI,OAAQ,CAACmS,MAAOpN,GAAIma,cACpDuyB,EAAQzxC,EAAOtF,KAAKqK,GAAMwD,GAAK,CAACvI,OAAQ,CAACmS,MAAOpN,GAAIma,cAEpDwyB,EAAe3R,GAAWyR,EAAO5S,EAAM1f,GACvCyyB,EAAe5R,GAAW0R,EAAO7S,EAAM1f,GAEvCqG,EACFrC,GAAQ,CAACljB,OAAQ,CAACsI,KAAMopC,EAAcnpC,KAAMopC,GAAezyB,YAO/D,OALAsyB,EAAM94C,SAAQk5C,GAAK1yB,EAAQlX,YAAY4pC,EAAE3pC,UACzCwpC,EAAM/4C,SAAQoC,GAAKokB,EAAQlX,YAAYlN,EAAEmN,UACzCiX,EAAQlX,YAAY0pC,EAAazpC,QACjCiX,EAAQlX,YAAY2pC,EAAa1pC,QAE1Bsd,CACR,CAED,IAAIssB,EAAW3yB,EAAQrK,mBAAmB7U,GAY1C,GAJc,WAAV3D,IACFw1C,GAAW,GAGTA,EAAU,CAQZ,MAAMC,EAAY9xC,EAAOtF,KAAIqK,IAC3B,MAAMgtC,EAAYzxC,EAAIA,KAACgO,cAAcvJ,EAAEtK,MAAM8C,MAAMqhC,IAEnD,OAAOhf,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG6H,GAAIma,UAASC,MAAO,CAAC1kB,MADnC,EAAE,EAAGs3C,KACsC,IAGrDC,EAAkBF,EAAUp3C,KAAIqK,IAC7B,CAAC4I,KAAMuR,EAAQ3T,SAASxG,EAAEkD,QAASxN,MAAOsK,EAAEtK,UAI/C4D,EACFoC,EAAAA,aAAaywC,gBAAgBY,EAAUp3C,KAAIqK,GAAKA,EAAEtK,QAAQ,GACxDi6B,EAAyC,IAA1Bod,EAAU,GAAGr3C,MAAM,GAClCm5B,EACFoM,GAAcgS,EAAiB3zC,EAAUhC,EAAOq4B,GAE9Cud,EACFxxC,EAAAA,aAAaywC,gBAAgBlxC,EAAOtF,KAAIqK,GAAKA,EAAEtK,QAAQmkC,GAErDsT,EAAUhzB,EAAQrQ,eAAeojC,EAAe51C,EAAOu3B,GAI7D,OAFAke,EAAUp5C,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtCiqC,CACR,CAID,MAAMC,EAAcjzB,EAAQxoB,OAAOmb,OAAOugC,gCAAkC,EAC5E,GAAIpyC,EAAOnI,OAASs6C,EAAa,CAC/B,MAAME,EAAgB,GACtB,IAAK,IAAIv3C,EAAI,EAAGA,EAAIkF,EAAOnI,OAAQiD,GAAKq3C,EAAa,CACnD,MAAMG,EAAWtyC,EAAOzC,MAAMzC,EAAGA,EAAIq3C,GACrCE,EAAcr6C,KAAK+nC,GAAWuS,EAAU1T,EAAM1f,GAC/C,CACD,MAAMqG,EAASwa,GAAWsS,EAAezT,EAAM1f,GAE/C,IAAK,MAAMpkB,KAAKu3C,EACdnzB,EAAQlX,YAAYlN,EAAEmN,QAGxB,OAAOsd,CACR,CAED,MAAMusB,UAACA,EAASzzC,SAAEA,GAyBpB,SACI2B,EAAsB4+B,EAAc1f,GACtC,MAAM7gB,EAAWoC,EAAAA,aAAaywC,gBAAgBlxC,EAAOtF,KAAIqK,GAAKA,EAAEtK,QAAQmkC,GAYxE,MAAO,CAACkT,UAXU9xC,EAAOtF,KAAIqK,GAAK6a,GAAQ,CACX5f,OAAQ,CAAC9C,EAAG6H,GACZma,UACAC,MAAO,CACL1kB,MAAO,CACL6F,EAAIA,KAACgO,cAAcvJ,EAAEtK,MAAM8C,MAAM,EAAGqhC,IACpCt+B,EAAIA,KAACgO,cAAcvJ,EAAEtK,MAAM8C,MAAMqhC,UAKjDvgC,WACrB,CAxCgCk0C,CAAiBvyC,EAAQ4+B,EAAM1f,GACvD9M,EAAS,EAAY1X,KAAIqK,GAAKA,EAAEtK,QAChCY,EAAU,IAAI41C,GAAc7+B,GAE5BkN,EAAqD,GACrDrO,EAAoB,IAAIpW,MAAMuX,EAAOva,OAAS,GACpD,GAAIoZ,EAAQpZ,OAAS,EAAG,CACtBoZ,EAAQ,GAAKmB,EAAO,GAAG,GACvBkN,EAAYtnB,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAAC2F,EAAQ,MAChD,IAAK,IAAInW,EAAI,EAAGA,EAAImW,EAAQpZ,OAAQiD,IAClCmW,EAAQnW,GAAKmW,EAAQnW,EAAI,GAAKsX,EAAOtX,GAAG,GACxCwkB,EAAYtnB,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAAC2F,EAAQnW,KAEnD,CAED,MAAM6E,EAAMuf,EAAQ1N,iBAChBnW,EAASy2C,EAAWA,EAAU,GAAGz1C,MAAOijB,GAC5CwyB,EAAUp5C,SAAQk5C,GAAK1yB,EAAQlX,YAAY4pC,EAAE3pC,UAE7C,MAAMuqC,EACF5yB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAO4D,KAEvD,OADA6gB,EAAQlX,YAAYrI,EAAIsI,QACjBuqC,CACT,CCjHM,SAAUt/B,GACZ+L,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B2f,KAACA,GAAQzf,EAET0f,EAAQv+B,OAAKw+B,eAAeF,EAAM5+B,EAAO,GAAGvF,OAAO,GAEnD2X,EAASpS,EAAOtF,KAAIqK,GAAKA,EAAEtK,QACjCgG,EAAAA,aAAagyC,uBAAuBrgC,EAAQysB,GAE5C,MAAMxgC,EACFoC,EAAAA,aAAaywC,gBAAgBlxC,EAAOtF,KAAIqK,GAAKA,EAAEtK,QAAQokC,GAC3D,GAAqC,IAAjCv+B,OAAKgO,cAAcjQ,GACrB,OAAO6gB,EAAQrQ,eAAexQ,EAAU2B,EAAO,GAAG3D,MAAO,IAI3D,MAAMq2C,EAAU1yC,EAAO6P,QAAO9K,GAAKzE,EAAAA,KAAKgO,cAAcvJ,EAAEtK,OAAS,IACjE,OAAuB,IAAnBi4C,EAAQ76C,OACHkrB,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAGw1C,EAAQ,IAAKxzB,YAGrC6gB,GAAW2S,EAAS7T,EAAO3f,EACpC,CAEO,MAAMyzB,GAA6B,CACxCnzB,WAAYozB,EAAMA,OAClBlzB,YAAa,SACbC,WAAYzM,UCiGD2/B,GA0BX/8C,YACIqyC,EAAmCxkC,EAAmBE,EACtDD,EAAkBua,GAAU,EAC5BjD,EAAsC,KACtCC,GAA4B,EAAOqC,GAA4B,GAzBnExnB,KAAAiH,cAAgB,CAAC,IAAK,KAEtBjH,KAAQyH,SACJ,0IAuBFzH,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAK88C,eAAyC,iBAAxB3K,EAASuC,WAC/B10C,KAAKgO,SACEmkC,EAAS4K,WAAa,GAAM,GAAK5K,EAAS4K,WAAa,GAAM,IAC9D/8C,KAAK88C,gBACL3K,EAASuD,SAAW,GAAM,IAAM11C,KAAK88C,iBACvC3K,EAAS6K,YAAc,GAAM,EACjCh9C,KAAKsI,eAAiBtI,KAAK88C,eAAiB,CAAC51C,EAAG,CAAC,GAAIqB,EAAG,CAAC,EAAG,GAAIC,EAAG,CAAC,IACxB,CAACtB,EAAG,CAAC,EAAG,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,IACpExI,KAAK8F,cAAgBiI,EACjB/N,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAKgO,QAChDhO,KAAKqN,kBAAoBc,EACrBnO,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAKgO,QAEhDhO,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C9F,KAAKqN,mBAELrN,KAAKgO,QACPhO,KAAK+F,gBAAkB,EACnB/F,KAAK88C,gBAAkB3K,EAAS4K,WAAa,GAAM,GACrD/8C,KAAK4mB,iBAAmB,EACxB5mB,KAAKmI,mBAAqB,CAAC,EAAG,KAE9BnI,KAAK4mB,iBAAmB,EACxB5mB,KAAKmI,mBAAqB,CAAC,EAAG,IAG5BggB,IACFnoB,KAAKiH,cAAcjF,KAAK,QACxBhC,KAAKmI,mBAAmBnG,KAAK,IAG3BmjB,IACFnlB,KAAKiH,cAAcjF,KAAK,0BACxBhC,KAAKmI,mBAAmBnG,KAAK,MAG/BhC,KAAK4mB,iBAAmB5mB,KAAKqN,kBAAkB,GAC3C8a,GACFnoB,KAAKiH,cAAcjF,KAAK,QAGtBmjB,GACFnlB,KAAKiH,cAAcjF,KAAK,2BAI5BhC,KAAKwnB,0BAA4BA,EACjCxnB,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlB,0BAA4BA,EAEjCnlB,KAAKwmB,WAAaxmB,KAAK8F,cAAc,GAAK9F,KAAKqN,kBAAkB,GACjErN,KAAKymB,WAAazmB,KAAK8F,cAAc,GAAK9F,KAAKqN,kBAAkB,GACjErN,KAAKomB,UAAY9hB,KAAKC,IAClBvE,KAAK8F,cAAc,GAAK9F,KAAK4mB,iBAAkB5mB,KAAK8F,cAAc,IAEtE9F,KAAK4lB,UAAYjY,EAAY3N,KAAKwmB,YAAe,EACjDxmB,KAAK6lB,UAAYhY,EAAY7N,KAAKymB,YAAe,EACjDzmB,KAAK8lB,SAAWlY,EAAW5N,KAAKomB,WAAc,EAE9CpmB,KAAK6L,UAAY,YAAY7L,KAAKqN,qBAAqBrN,KAAKklB,eACxDllB,KAAK4lB,aAAa5lB,KAAK6lB,aAAa7lB,KAAK8lB,YAAY9lB,KAAKgO,UAC1DhO,KAAK4mB,oBAAoB5mB,KAAK88C,kBAC9B98C,KAAKwnB,2BACV,CAED5gB,cACE,MAAMq2C,EAAej9C,KAAKgO,OACtBkY,EACIlmB,KAAKqN,kBAAmBrN,KAAK8F,eAAgB9F,KAAK88C,eAClD98C,KAAKomB,WACTmB,EACIvnB,KAAKqN,kBAAmBrN,KAAK8F,eAAgB9F,KAAK88C,eAClD98C,KAAKomB,WAAW,EAAO,KAAMpmB,KAAKwnB,2BACpC01B,EACFl9C,KAAKgO,OAAS,CAAChO,KAAK4mB,iBAAkB,EAAG,GAAK,CAAC,EAAG,EAAG,GASzD,MARiB,SA3OrB,SACIk2B,EAAyBl3B,EAAoBC,EAC7CC,EAAmBqC,GAAU,EAC7BjD,EAAsC,KACtCC,GAA4B,EAAOg4B,EAAoB,EACvDC,EAAoB,EAAGx2B,EAAmB,GAC5C,MAwBMy2B,EAAgBP,EAAiB,iEAGA,iEAIjCQ,EAAkBR,EAAiB,2HAOA,2HAQnCS,EAAST,EAAiB,qBAAuB,qBACjDU,EAASV,EAAiB,qBAAuB,qBACjDhe,EAAMge,EAAiB,MAAQ,MAC/B9d,EAAM8d,EAAiB,MAAQ,MAC/BW,EAAe,sEAGjBX,EAAiB,uBAAyB,+CAC3Bhe,qCACAA,qCAEFE,gEACAA,iQAGDA,wCACIx1B,EAAY2zC,6JAGFI,4BAAiCC,iBACvDH,kFAlEY,CAACz2B,IACnB,OAAQA,GACN,KAAK,EACH,MAAO,uBACT,KAAK,EACH,MAAO,gEACT,KAAK,EACH,MAAO,2BACT,QACE,MAAM,IAAIvkB,MACN,oBAAoBukB,uBAC3B,EAyDK82B,CAAYP,qCAIdQ,EAAUb,EAAkBl3B,GAAaE,EAAW,WACpD23B,IACoD,+EAElDA,4BAEKj0C,EAAY2zC,WACSr3B,GAAYD,EAAY,WACpD43B,IACoD,+EAElDA,4BAEKj0C,EAAY2zC,WAEnBS,EAAU,GA1EI,CAACh3B,IACnB,OAAQA,GACN,KAAK,EACH,MAAO,4CACT,KAAK,EACH,MAAO,kDACT,QACE,MAAM,IAAIvkB,MACN,oBAAoBukB,uBAC3B,EAiEgBi3B,CAAYT,KAEzBU,EAAUt0C,EAAYod,GACtBm3B,EAAyBv0C,EAAjBszC,EAA6BK,EACAC,GACrCY,EAAyBx0C,EAAjBszC,EAA6BM,EACAD,GAwB3C,MAvBiB,WAEbl4B,EACIC,EAAYC,EAAgD,IAArByB,EAAwB,8DAChBm3B,gBAC/CjB,EAAiBa,EAAUC,wEAGoBI,gBAC/ClB,EAAiBc,EAAUD,+EAG2BG,4IAK1DhB,EAAiB,uBAAyB,oCACtCQ,cACA93B,EAAsB2C,EAASjD,uGAKzC,CAiHQ+4B,CACIj+C,KAAK88C,eAAgB98C,KAAK4lB,UAAW5lB,KAAK6lB,UAAW7lB,KAAK8lB,SAC1D9lB,KAAKmoB,QAASnoB,KAAKklB,WAAYllB,KAAKmlB,0BACpC+3B,EAAa,GAAIA,EAAa,GAAIA,EAAa,YACrDD,OAGH,QCrPUiB,GAcXp+C,YACIqyC,EAAmChqB,GAAU,EAC7CjD,EAAsC,KACtCC,GAA4B,GAZhCnlB,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SACJ,oFACJzH,KAAa8F,cAA6B,CAAC,EAAG,EAAG,GAU/C9F,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAK88C,eAAyC,iBAAxB3K,EAASuC,WAC/B10C,KAAKsI,eAAiBtI,KAAK88C,eAAiB,CAAC51C,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IACxB,CAACtB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IACpExI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlB,0BAA4BA,EAE7BgD,GACFnoB,KAAKiH,cAAcjF,KAAK,QAGtBmjB,GACFnlB,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAK6L,UAAY,eAAe7L,KAAKklB,cAAcllB,KAAK88C,gBACzD,CAEDl2C,cAwDE,MAvDiB,YAEbqe,EACIjlB,KAAKklB,WAAYllB,KAAKmlB,2BAA2B,EAAO,gvBAmB5DnlB,KAAK88C,eAAiB,oCACA,iJAGjBt3B,EAAsBxlB,KAAKmoB,QAASnoB,KAAKklB,2HAI7C8B,EAAK,oHAGchnB,KAAK88C,eAAiB,aAAe,uCACzC98C,KAAK88C,eAAiB,aAAe,uCACrC98C,KAAK88C,eAAiB,aAAe,ucAOrD98C,KAAK88C,eAAiB,sBACA,oEAEtB98C,KAAK88C,eAAiB,gDACA,gRAU3B,QCnGUqB,GAaXr+C,YAAYsN,EAAuB0vC,GAZnC98C,KAAAiH,cAAgB,CAAC,KACjBjH,KAAAyH,SACI,kIAMJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK88C,eAAiBA,EACtB98C,KAAK6L,UAAY,UAAU7L,KAAK88C,gBACjC,CAEDl2C,cACE,MAAMw3C,EAASp+C,KAAK88C,eAAiB,EAAI,EACnCuB,EAASr+C,KAAK88C,eAAiB,EAAI,EAEnChe,EAAM9+B,KAAK88C,eAAiB,YAAc,YAC1C9d,EAAMh/B,KAAK88C,eAAiB,YAAc,YAC1CY,EAAc19C,KAAK88C,eAAiB,8BACA,8BA0B1C,MAxBiB,SACf91B,EAAK,mJAIS8X,yBACAE,uPAIgBof,wVAMEC,2CAChBX,0FAQnB,EC/BH,SAASY,GACL75C,EAAiBq4C,GACnB,MAAMj7C,EAAS4C,EAAM5C,OACrB,OAAIA,GAAU,EACLi7C,EACH,IACKr4C,EAAM8C,MAAM,GAAI,GACnB9C,EAAM5C,EAAS,GAAK4C,EAAM5C,EAAS,GACnC4C,EAAM5C,EAAS,IAEjB,IACK4C,EAAM8C,MAAM,GAAI,GAAgB9C,EAAM5C,EAAS,GAClD4C,EAAM5C,EAAS,GAAK4C,EAAM5C,EAAS,KAE/Bi7C,GAA6B,IAAXj7C,GAAgB4C,EAAM,GAAK,EAChD,CAACA,EAAM,GAAI,GAEX,IAEX,CAkNM,SAAU85C,IAAWr3C,EACzBA,EAAC2S,OACDA,EAAMs4B,SACNA,EAAQjpB,QACRA,EAAOnB,KACPA,EAAO,KAAIC,uBACXA,EAAyB,KAAIqC,eAC7BA,EAAiB,EAACnF,WAClBA,EAAa,OAEb,MAAMO,EAAkB,MAARsC,EACV5C,EAAsD,MAA1B6C,EAC5B80B,EAAyC,iBAAxB3K,EAASuC,WAC1B8J,EAAW1B,GACb3K,EAASiB,eAAiBjB,EAASoB,UACnCpB,EAASgB,cAAgBhB,EAASmB,SACR,UAA1BnB,EAASqB,QAAQtuC,KACfu5C,EAAiB9+C,EAAGA,MAAG2R,QAAQ,iCAErC,IAAKmtC,IACAD,GAC2B,IAA1BrM,EAASiB,cAA+C,IAAzBjB,EAASgB,aACZ,IAA5BhB,EAAS2B,gBAAmD,IAA3B3B,EAAS4B,eAChB,IAA1B5B,EAASwB,cAA+C,IAAzBxB,EAASyB,cACb,SAA1BzB,EAASqB,QAAQtuC,MACS,UAA1BitC,EAASqB,QAAQtuC,OACtB,OAvOJ,UAAwBgC,EACtBA,EAAC2S,OACDA,EAAMs4B,SACNA,EAAQjpB,QACRA,EAAOnB,KACPA,EAAO,KAAIC,uBACXA,EAAyB,KAAIqC,eAC7BA,EAAiB,EAACnF,WAClBA,EAAa,OAEb,MAAM43B,EAAyC,iBAAxB3K,EAASuC,WAC1B5mC,GAAagvC,EAObxxB,EAA8B,GACpC,IAAIozB,EACAC,EAEJ,GARiB7B,GACb3K,EAASiB,eAAiBjB,EAASoB,UACnCpB,EAASgB,cAAgBhB,EAASmB,SACR,UAA1BnB,EAASqB,QAAQtuC,KAKP,CACZ,MAAM05C,EACFzM,EAASoB,SAAWpB,EAASmB,QAAUnB,EAAS4K,WACpD2B,EAAY90B,GAAQ,CAClB5f,OAAQ,CAAC9C,KACTgiB,UACAC,MAAO,CAAC1kB,MAAO,CAAC,EAAG0tC,EAAS/K,UAAWwX,MAEzCD,EAAiB/0B,GAAQ,CACvB5f,OAAQ,CAAC9C,EAAG2S,GACZqP,UACAC,MAAO,CAAC1kB,MAAO,CAAC,EAAGm6C,EAAWzM,EAAS6K,eAE1C,MACC0B,EAAY90B,GAAQ,CAClB5f,OAAQ,CAAC9C,KACTgiB,UACAC,MAAO,CACL1kB,MAAOq4C,EACH,CACE3K,EAAS/K,UAAW+K,EAASoB,SAAWpB,EAASmB,QACjDnB,EAAS4K,YAEX,CACE5K,EAAS/K,UAAW+K,EAAS4K,WAC7B5K,EAASoB,SAAWpB,EAASmB,YAIvCqL,EAAiB/0B,GAAQ,CACvB5f,OAAQ,CAAC9C,EAAG2S,GACZqP,UACAC,MAAO,CAAC1kB,MAAO,CAAC,EAAG0tC,EAAS4K,WAAY5K,EAAS6K,gBAMrD,GAHA1xB,EAActpB,KAAK08C,GACnBpzB,EAActpB,KAAK28C,GAEW,MAA1B32B,EAAgC,CAClC,MAAMmd,EACFmZ,GAAuBt2B,EAAuBvjB,MAAOq4C,GACtC,MAAf3X,IACFnd,EAAyB4B,GAAQ,CAC/B5f,OAAQ,CAAC9C,EAAG8gB,GACZkB,UACAC,MAAO,CAAC1kB,MAAO0gC,KAEjB7Z,EAActpB,KAAKgmB,GAEtB,CAED,GAAY,MAARD,EAAc,CAChB,MAAMod,EAAcmZ,GAAuBv2B,EAAKtjB,MAAOq4C,GACpC,MAAf3X,IACFpd,EAAO6B,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG6gB,GAAOmB,UAASC,MAAO,CAAC1kB,MAAO0gC,KAC3D7Z,EAActpB,KAAK+lB,GAEtB,CAED,MAAMwH,EAASpF,GAAgB,CAC7BC,EAAG0yB,EAAiB4B,EAAYC,EAChChrC,EAAGmpC,EAAiB6B,EAAiBD,EACrC5wC,aACA6X,YAzEiB,EA0EjBuD,UACAnB,OACA7C,aACA8C,yBACAqC,mBAEImB,EAAM5B,GACR,CAAC5f,OAAQ,CAAC9C,EAAGqoB,GAASrG,UAASC,MAAO,CAAC1kB,MAAO0tC,EAAS9pC,YAC3DijB,EAActpB,KAAKutB,GAEnB,IAAK,MAAMzqB,KAAKwmB,EACdpC,EAAQlX,YAAYlN,EAAEmN,QAGxB,OAAOuZ,CACT,CAkIWqzB,CAAe,CACpB33C,IACA2S,SACAs4B,WACAjpB,UACAnB,OACA7C,aACA8C,yBACAqC,mBAIJ,MAAMqB,EAAqB/rB,EAAGA,MAAG2P,UAC/B,sDACI0B,EAAiC0a,EAAqB,EACxDA,EAAqBxC,EAAQlY,8BAC3B2a,EAAoBwmB,EAAS/K,UAC/B9iC,KAAKmJ,KAAM0kC,EAASsD,UAAYtD,EAASuD,SAAY,IACrDpxC,KAAKmJ,KAAK0kC,EAAS6K,YAAc,IACrC,GAAIr9C,EAAGA,MAAG2R,QAAQ,uCACdqa,GAAqB3a,EACvB,OAnJJ,UAA0B9J,EACxBA,EAAC2S,OACDA,EAAMs4B,SACNA,EAAQjpB,QACRA,EAAOnB,KACPA,EAAO,KAAIC,uBACXA,EAAyB,KAAIqC,eAC7BA,EAAiB,EAACnF,WAClBA,EAAa,OAQb,MAAMiuB,YACJA,EAAWC,aACXA,EAAY2J,WACZA,EAAUnJ,YACVA,EAAWD,aACXA,EAAYH,QACZA,EAAOkC,SACPA,EAAQD,UACRA,EAAS1B,cACTA,EAAaD,eACbA,EAAcY,WACdA,GACEvC,EAEE2K,EAAgC,iBAAfpI,EAEjBkK,EAAYzL,EAAcC,EAAe2J,EACzC7e,EAAUuX,EAAYC,EACtBoJ,EAAahC,EAAiB,CAAC3K,EAAS/K,UAAWlJ,EAAS0gB,GAC9B,CAACzM,EAAS/K,UAAWwX,EAAW1gB,GAE9D6gB,EAAgB,IAAIZ,GAAcW,EAAYhC,GAC9C/zC,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAACk+B,EAAQK,IAAKL,EAAQtW,OAC5C,CAACh4B,KAAM,QAASoQ,KAAM,CAACq+B,EAAcC,IACrC,CAAC1uC,KAAM,QAASoQ,KAAM,CAACw+B,EAAgBC,IACvC,CAAC7uC,KAAM,QAASoQ,KAAM,CAACogC,IACvB,CAACxwC,KAAM,QAASoQ,KAAM,CAACynC,EAAa5J,IACpC,CAACjuC,KAAM,QAASoQ,KAAM,CAACynC,KAEnBiC,EACF91B,EAAQ1N,iBAAiBujC,EAAe,CAAC73C,GAAIA,EAAEb,MAAO0C,GAEpDuiB,EAA8B,GACpCA,EAActpB,KAAKg9C,GAEnB,MAAML,EAAiB/0B,GACnB,CAAC5f,OAAQ,CAAC9C,EAAG2S,GAASqP,UAASC,MAAO,CAAC1kB,MAAO,CAAC,EAAGm6C,GAAY,MAGlE,GAFAtzB,EAActpB,KAAK28C,GAEW,MAA1B32B,EAAgC,CAClC,MAAMmd,EACFmZ,GAAuBt2B,EAAuBvjB,MAAOq4C,GACtC,MAAf3X,IACFnd,EAAyB4B,GAAQ,CAC/B5f,OAAQ,CAAC9C,EAAG8gB,GACZkB,UACAC,MAAO,CAAC1kB,MAAO0gC,KAEjB7Z,EAActpB,KAAKgmB,GAEtB,CAED,GAAY,MAARD,EAAc,CAChB,MAAMod,EAAcmZ,GAAuBv2B,EAAKtjB,MAAOq4C,GACpC,MAAf3X,IACFpd,EAAO6B,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG6gB,GAAOmB,UAASC,MAAO,CAAC1kB,MAAO0gC,KAC3D7Z,EAActpB,KAAK+lB,GAEtB,CAED,MAEMwH,EAASpF,GAAgB,CAC7BC,EAAG0yB,EAAiBkC,EAAQL,EAC5BhrC,EAAGmpC,EAAiB6B,EAAiBK,EACrClxC,YALiBgvC,EAMjBn3B,YALiB,EAMjBuD,UACAnB,OACA7C,aACA8C,yBACAqC,mBAEImB,EAAM5B,GACR,CAAC5f,OAAQ,CAAC9C,EAAGqoB,GAASrG,UAASC,MAAO,CAAC1kB,MAAO0tC,EAAS9pC,YAC3DijB,EAActpB,KAAKutB,GACnB,IAAK,MAAMzqB,KAAKwmB,EACdpC,EAAQlX,YAAYlN,EAAEmN,QAGxB,OAAOuZ,CACT,CAiDWyzB,CAAiB,CACtB/3C,IACA2S,SACAs4B,WACAjpB,UACAnB,OACAC,yBACAqC,iBACAnF,eAIJ,IAAI7f,EACJ,MAAMmuC,EAAU,CAACrB,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,MAClDn0B,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,IAAIk+B,IAC1B,CAACtuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,iBAE3D,GAAI0K,EACFp5C,EAAU,IAAI64C,GACV/L,EAAU1sB,EAASP,EAAYC,OAC9B,CACL,MAAMxX,EAAYmvC,EAAiB3K,EAASsD,UAAYtD,EAASuD,SAC9BvD,EAAS6K,YACtCnvC,EAAYivC,EAAiB3K,EAAS6K,YACT7K,EAASsD,UAAYtD,EAASuD,SAC3D9nC,EACFukC,EAASiB,aAAejB,EAASgB,YAAchB,EAAS4K,WAC5Dh0C,EAAW/G,KACP,CAACkD,KAAM,QAASoQ,KAAM,CAAC3H,IAAa,CAACzI,KAAM,QAASoQ,KAAM,CAACzH,IAC3D,CAAC3I,KAAM,QAASoQ,KAAM,CAAC1H,KAG3B,MAAM4Z,EAA4B0B,EAAQnpB,YAAYM,UACtDgF,EAAU,IAAIw3C,GACV1K,EAAUxkC,EAAWE,EAAWD,EAAU6X,EAASP,EACnDC,EAA2BqC,EAChC,CAED,MAAM8D,EAA8B,GAC9B4zB,EAAyB,CAACh4C,EAAG2S,GAC/B4L,IACGq3B,GAAwC,IAAtB/0B,EAAKtjB,MAAM5C,SAChCkmB,EAAO6B,GACH,CAAC5f,OAAQ,CAAC9C,EAAG6gB,GAAOmB,UAASC,MAAO,CAAC1kB,MAAO,CAACsjB,EAAKtjB,MAAM,GAAI,EAAG,MACnE6mB,EAActpB,KAAK+lB,IAErBm3B,EAASl9C,KAAK+lB,IAEZ5C,IACG23B,GAA0D,IAAxC90B,EAAuBvjB,MAAM5C,SAClDmmB,EAAyB4B,GAAQ,CAC/B5f,OAAQ,CAAC9C,EAAG8gB,GACZkB,UACAC,MAAO,CAAC1kB,MAAO,CAACujB,EAAuBvjB,MAAM,GAAI,EAAG,MAEtD6mB,EAActpB,KAAKgmB,IAErBk3B,EAASl9C,KAAKgmB,IAEG,cAAf9C,IACFnc,EAAW/G,KAAK,CAACkD,KAAM,UAAWoQ,KAAM,CAAC+U,KACzChlB,EAAQoC,UAAY,iBAEtB,MAAM+jB,EAAMtC,EAAQ1N,iBAAiBnW,EAAS65C,EAAUh4C,EAAEb,MAAO0C,GACjE,IAAK,MAAMjE,KAAKwmB,EACdpC,EAAQlX,YAAYlN,EAAEmN,QAExB,OAAOuZ,CACT,CCpWO,MAAM2zB,GAA6B,CACxC31B,WAAY41B,EAAMA,OAClB11B,YAAa,SACbC,WAhBI,SACFV,GACF,MAAMjf,OAACA,EAAMmf,MAAEA,EAAKD,QAAEA,GAAWD,GAC3B/hB,EAACA,EAAC2S,OAAEA,GAAU7P,GACdpF,QAACA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAU2K,UAAEA,EAAS/K,gBAAEA,GAAmBnrB,EACzDm2B,EAAc70C,EAAAA,aAAa80C,wBAAwB7K,GAKzD,OAAO6J,GAAW,CAACr3C,IAAG2S,SAAQs4B,SAJb1nC,EAAYA,aAAC+0C,kBAC1Bt4C,EAAEzC,MACFoV,EAAOpV,MAA2CG,EAASy6C,EAAWhL,EACtEC,GAAiB,EAAuBgL,GACJp2B,WAC1C,SCbau2B,GAeX3/C,YAAYqyC,GAdZnyC,KAAAiH,cAAgB,CAAC,KAAM,KACvBjH,KAAQyH,SACJ,0FAKJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EACPnB,KAAMgO,QAAG,EACThO,KAAammB,cAAG,EAIdnmB,KAAKoN,YAAc+kC,EAASkB,QAC5BrzC,KAAK88C,eAAyC,iBAAxB3K,EAASuC,WAC/B10C,KAAKgO,OAAShO,KAAK88C,gBAAkB3K,EAAS6K,YAAc,GAAM,GAC9D7K,EAAS4K,WAAa,GAAM,EAC5B/8C,KAAKgO,QAEPhO,KAAKmmB,cAAgB,EACrBnmB,KAAK+F,gBAAkB,EACvB/F,KAAK8F,cAAgB,CAAC,EAAG,EAAG,GAC5B9F,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IAC9CxI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC,EAAG9F,KAAKmmB,cAAe,MAE5BnmB,KAAKmB,MAAO,EACZnB,KAAKmmB,cAAgB,EACrBnmB,KAAK8F,cAAgB,CAAC,GAAI,EAAG,GAC7B9F,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,gBAElD9F,KAAK6L,UAAY,kBAAkB7L,KAAK88C,kBAAkB98C,KAAKgO,UAC3DhO,KAAKmmB,eACV,CAEDvf,cACE,MAAMw3C,EAASp+C,KAAK88C,eAAiB,EAAI,EACnCuB,EAASr+C,KAAK88C,eAAiB,EAAI,EACnC4C,EAAa1/C,KAAK88C,eAAiB,EAAI,EAEvC6C,EAAc,SAClB34B,4JAG4BhnB,KAAKmmB,2SAODnmB,KAAKmmB,8CACfnmB,KAAKmmB,8tHAgFLnmB,KAAKmmB,uQAQ7B,OAAOnmB,KAAKgO,OACR,SACF2xC,UAEE,SACF34B,EAAK,2JAIe04B,kDAEgBtB,cAC9BC,mpCA2BAr+C,KAAK88C,eAAiB,+BACA,qPAU/B,QAGU8C,GAYX9/C,YAAYqyC,GAXZnyC,KAAAiH,cAAgB,CAAC,IAAK,MACtBjH,KAAQyH,SACJ,0HAKJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS0N,YAC5B7/C,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK88C,eAAyC,iBAAxB3K,EAASuC,WAC/B10C,KAAK6L,UAAY,mBAAmB7L,KAAK88C,gBAC1C,CAEDl2C,cACE,MAAO,SACLogB,EAAK,27BAyBShnB,KAAK88C,geAgBtB,QAGUgD,GAYXhgD,YAAYqyC,GAXZnyC,KAAAiH,cAAgB,CAAC,IAAK,MACtBjH,KAAAyH,SACI,iKAMJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS0N,YAC5B7/C,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,iBAClB,CAEDjF,cACE,MAAO,SACLogB,EAAK,gyCAwCR,QAGU+4B,GAWXjgD,YAAYqyC,GAVZnyC,KAAAiH,cAAgB,CAAC,KAAM,KACvBjH,KAAAyH,SAAW,4IAMXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAC5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,gBAClB,CAEDjF,cACE,MAAO,SACLogB,EAAK,yxDAqDR,ECxXI,MAAMg5B,GAA2C,CACtDx2B,WAAYy2B,EAAoBA,qBAChCv2B,YAAa,SACbC,WA/BI,SAA+BV,GAKnC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACmuC,GAAEA,GAAMrrC,GACVpF,QAACA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAUJ,gBAAEA,EAAeuL,YAAEA,GAAe12B,EAE3Dm2B,EAAc70C,EAAAA,aAAa80C,wBAAwB7K,GACnDvC,EAAW1nC,EAAYA,aAAC+0C,kBAC1Bt4C,EAAEzC,MAA2Co7C,EAAaj7C,EAC1D,EAAmByvC,EAAKC,GAAiB,EACzCgL,GAEEj6C,EAAU,IAAIu6C,GAAuBzN,GACrC7oB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS/K,YAChC,CAACliC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,WAChC,CAACruC,KAAM,QAASoQ,KAAM,CAAC68B,EAASmB,WAElC,OAAOpqB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAGmuC,GAAKnuC,EAAEb,MAAOijB,EAC7D,SC6Da42B,GAcXpgD,YAAYqyC,GATZnyC,KAAAiH,cAAgB,CAAC,IAAK,KAEtBjH,KAAQyH,SACJ,4IAOFzH,KAAKoN,YAAc+kC,EAASkB,QAE5B/oC,EAAIA,KAACwC,OACuB,iBAAxBqlC,EAASuC,YACT,IAAM,gCACV10C,KAAKgO,OACDmkC,EAAS4K,WAAa,GAAM,GAAK5K,EAAS6K,YAAc,GAAM,EAClEh9C,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,EAAG,GAAIC,EAAG,CAAC,IAC9CxI,KAAK8F,cAAgBiI,EACjB/N,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAKgO,QAChDhO,KAAKqN,kBAAoBc,EACrBnO,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAKgO,QAEhDhO,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C9F,KAAKqN,mBAELrN,KAAKgO,SACPhO,KAAK+F,gBAAkB,EACvB/F,KAAKmI,mBAAqB,CAAC,EAAG,IAGhCnI,KAAK6L,UACD,oBAAoB7L,KAAKgO,UAAUhO,KAAKqN,mBAC7C,CAEDzG,cACE,MAAMq2C,EAAej9C,KAAKgO,OACtBkY,EAA2BlmB,KAAKqN,kBAAmBrN,KAAK8F,eACxDyhB,EAAuBvnB,KAAKqN,kBAAmBrN,KAAK8F,eAKxD,MAJiB,SAnIrB,SAAsC8gB,EAAmB,GACvD,MA2CMb,EAAU,okBAbDvc,EAAYod,qHAGZpd,EAAYod,qNAQvBA,8BAKSpd,EAAYod,WAoCzB,MAlCiB,wDAEbpd,EAAYod,aACZb,gEAIAvc,EAAYod,0cAvDI,CAACA,IACnB,OAAQA,GACN,KAAK,EACH,MAAO,0DACT,KAAK,EACH,MAAO,ujBAUT,QACE,MAAM,IAAIvkB,MACN,oBAAoBukB,uBAC3B,EA8CGi3B,CAAYj3B,yBAEPpd,EAAYod,iFAInBpd,EAAYod,2TASZA,yBAIN,CAgDMu5B,CAA6BngD,KAAKgO,OAAS,EAAI,WAC/CivC,SAGH,ECrFI,MAAMmD,GAA0C,CACrD52B,WAAY62B,EAAmBA,oBAC/B32B,YAAa,SACbC,WAtDI,SAA8BV,GAKlC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEx7B,OAAEA,GAAU7P,GACfk7B,WAACA,EAAUtgC,QAAEA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAUJ,gBAAEA,GAAmBnrB,EAE1Dm2B,EAAc70C,EAAAA,aAAa80C,wBAAwB7K,GACnDvC,EAAW1nC,EAAYA,aAAC+0C,kBAC1Bta,EAAYrrB,EAAOpV,MAA2CG,EAC9D,EAAmByvC,EAAKC,GAAiB,EAAOgL,GAE9Cv2C,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CACEjuC,KAAM,QACNoQ,KAAM,CACJ68B,EAASiB,aAAe,EAAIjB,EAASqB,QAAQK,IAC7C1B,EAASgB,YAAc,EAAIhB,EAASqB,QAAQtW,OAGhD,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CACE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS/K,UAAW+K,EAASsD,UAAWtD,EAASuD,SACjDvD,EAAS6K,eAIf,IAAI33C,EAEJ,GAAI1F,EAAGA,MAAG2R,QAAQ,sCACU,iBAAxB6gC,EAASuC,WACXrvC,EAAU,IAAIo6C,GAAsBtN,OAC/B,CACL9sC,EAAU,IAAI66C,GAAwB/N,GACtC,MAAMxkC,EAAYwkC,EAASoB,SAAWpB,EAASmB,QACzCzlC,EAAYskC,EAAS4K,WACrBnvC,EACFukC,EAASiB,aAAejB,EAASgB,YAAchB,EAAS6K,YAC5Dj0C,EAAW/G,KACP,CAACkD,KAAM,SAAUoQ,KAAM,CAAC3H,IACxB,CAACzI,KAAM,SAAUoQ,KAAM,CAACzH,IACxB,CAAC3I,KAAM,SAAUoQ,KAAM,CAAC1H,IAC7B,CACD,OAAOsb,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,EAAIx7B,GAAS,UAAW9Q,EACpE,SClDau3C,GAWXxgD,YAAYqyC,GANZnyC,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SACJ,oFACJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,aAClB,CAEDjF,cAoFE,MAnFiB,SACfogB,EAAK,quGAmFR,ECvEI,MAAMu5B,GAA6B,CACxC/2B,WAAYg3B,EAAMA,OAClB92B,YAAa,SACbC,WArCI,SACFV,GACF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,GAAU7P,GACdpF,QAACA,EAAOyvC,IAAEA,EAAGgL,UAAEA,GAAal2B,EAE5BgpB,EAAW1nC,EAAAA,aAAag2C,kBAC1Bv5C,EAAEzC,MACFoV,EAAOpV,MAAmDG,EAC1Dy6C,EAAWhL,GAETb,EACF,CAACrB,EAASqB,QAAQsB,MAAO3C,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,MAC9Dn0B,EAAa,CACjB,CACE7D,KAAM,QACNoQ,KAAM,CAAC68B,EAASoD,YAAapD,EAASiB,aAAcjB,EAASgB,cAE/D,CAACjuC,KAAM,QAASoQ,KAAM,IAAIk+B,IAAW,CACnCtuC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAASuO,cAAevO,EAAS2B,eAAgB3B,EAAS4B,iBAI1D1uC,EAAU,IAAIi7C,GAAmBnO,GACjC9rC,EAAQooB,EAAAA,WAAWvnB,EAAEb,MAAOwT,EAAOxT,OACzC,OAAO6iB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAG2S,GAASxT,EAAO0C,EAC/D,GCGO,MAAM43C,GAA6C,CACxDn3B,WAAYo3B,EAAsBA,uBAClCl3B,YAAa,SACbC,WAtCI,SAAiCV,GAKrC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACmuC,GAAEA,GAAMrrC,GACVpF,QAACA,EAAOyvC,IAAEA,EAAGwL,YAAEA,GAAe12B,EAE9BgpB,EAAW1nC,eAAag2C,kBAC1Bv5C,EAAEzC,MAAmDo7C,EAAaj7C,EAClE,EAAmByvC,GAEjBhvC,EAAU,IAAIy6C,GAAuB3N,GACrC7oB,EAAc,CAClB,CACEpkB,KAAM,QACNoQ,KACI,CAAC68B,EAASqB,QAAQsB,MAAO3C,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAEtE,CACEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS/K,YAChC,CAACliC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqD,WAChC,CAACtwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS4C,UAChC,CAAC7vC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,WAChC,CAACruC,KAAM,QAASoQ,KAAM,CAAC68B,EAASmB,WAElC,OAAOpqB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAGmuC,GAAKA,EAAGhvC,MAAOijB,EAC9D,GCOO,MAAMu3B,GAA4C,CACvDr3B,WAAYs3B,EAAqBA,sBACjCp3B,YAAa,SACbC,WA3CI,SAAgCV,GAKpC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEx7B,OAAEA,GAAU7P,GACfpF,QAACA,EAAOyvC,IAAEA,EAAGnP,WAAEA,GAAc/b,EAE7BgpB,EAAW1nC,eAAag2C,kBAC1Bvb,EAAYrrB,EAAOpV,MACnBG,EAAS,EAAmByvC,GAE1BhvC,EAAU,IAAI06C,GAAsB5N,GACpC7oB,EAAc,CAClB,CACEpkB,KAAM,QACNoQ,KAAM,CAAC68B,EAASoD,YAAapD,EAASiB,aAAcjB,EAASgB,cAE/D,CACEjuC,KAAM,QACNoQ,KAAM,CACJ68B,EAASoD,YAAc,EAAIpD,EAASqB,QAAQsB,MAC5C3C,EAASiB,aAAe,EAAIjB,EAASqB,QAAQK,IAC7C1B,EAASgB,YAAc,EAAIhB,EAASqB,QAAQtW,OAGhD,CACEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqD,WAChC,CAACtwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS6K,eAGlC,OAAO9zB,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,EAAIx7B,GAASw7B,EAAGhvC,MAAOijB,EACnE,GCrCay3B,GAAMtzB,GAAgB,CAACC,OAAQ5L,EAAYmB,MAE3C+9B,GAA0B,CACrCx3B,WAAYy3B,EAAGA,IACfv3B,YAAa,SACbC,WAAYo3B,ICLDG,GAAOzzB,GAAgB,CAACC,OAAQ5L,EAAYoB,OAE5Ci+B,GAA2B,CACtC33B,WAAY43B,EAAIA,KAChB13B,YAAa,SACbC,WAAYu3B,UCRDG,GAaXvhD,YACIwhD,EAAkBC,EAA4BC,EAC9CC,GAVJzhD,KAAaiH,cAAG,CAAC,QAAS,QAAS,UACnCjH,KAAQyH,SAAG,4BACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAIlD9F,KAAImB,MAAG,EAKL,MAAOugD,GAAcH,EACrBvhD,KAAKoN,YAAc,CAACs0C,EAAUF,EAAS,GAAIA,EAAS,GAAIF,GACxDthD,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK2hD,SAAsB,aAAXF,EAAwB,EAAI,EAC5CzhD,KAAK4hD,sBAAwB5hD,KAAKoN,YAAY,GAAK,EACnDpN,KAAK6hD,qBAAuB7hD,KAAKoN,YAAY,GAAK,EAClDpN,KAAK6L,UAAY,iBAAiB7L,KAAK2hD,YACnC3hD,KAAK4hD,yBAAyB5hD,KAAK6hD,sBACxC,CAEDj7C,cACE,MAAOk7C,EAAkBC,GACrB,CAAC,kCAAmC,oCAEjCC,EAAaC,EAAaC,GAAOliD,KAAK4hD,sBACzC,CACE,IAAIE,qCACJ,yBACA,MAAMA,6BAER,CACE,MACA,MACA,mBAAmBA,MAElBK,EAAYC,EAAYC,GAAOriD,KAAK6hD,qBACvC,CACE,IAAIE,qCACJ,wBACA,MAAMA,4BAER,CACE,MACA,MACA,mBAAmBA,KA+DzB,MAzDiB,SACf/6B,EAAK,mIAGsBg7B,sCACDG,6dAeHF,iCACDG,0BACPF,wCACcJ,4HAIdO,wCACcN,2KAKtB/hD,KAAK2hD,qqCAyBf,ECnHI,MAgBMW,GAAoC,CAC/C94B,WAAY+4B,EAAaA,cACzB74B,YAAa,SACbC,WAnB4BV,IAK5B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bu5B,MAACA,EAAKC,MAAEA,EAAKC,OAAEA,GAAU14C,GACzBw3C,SAACA,EAAQC,OAAEA,EAAMkB,mBAAEA,GAAsBx5B,EAEzC9jB,EAAU,IAAIg8C,GAChBmB,EAAM/9C,MAAM,GAAIg+C,EAAMh+C,MAA2B+8C,EAAUC,GACzDn4B,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACqtC,KAC9C,OAAOz5B,EAAQ1N,iBACXnW,EAAS,CAACm9C,EAAOC,EAAOC,GAAS,UAAWp5B,EAAY,GCf9D,IAAYs5B,IAAZ,SAAYA,GACVA,EAAA,KAAA,IACAA,EAAA,IAAA,GACD,CAHD,CAAYA,KAAAA,GAGX,CAAA,UAEYC,GAcX/iD,YACIqsB,EAAe1nB,EAAiBq+C,EAAoBC,GAVxD/iD,KAAAiH,cAAgB,CAAC,KAGjBjH,KAAQyH,SAAG,eACXzH,KAAImB,MAAG,EAOLnB,KAAK8F,cAAgB,CAAC,IAAK,EAAG,GAC9B9F,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK8iD,UAAYA,EACjB9iD,KAAK+iD,QAAUA,EACf/iD,KAAKmsB,GAAKA,EACVnsB,KAAK6L,UAAY,OAAO7L,KAAKmsB,MAAMnsB,KAAK8iD,aAAa9iD,KAAK+iD,SAC3D,CAEDn8C,cACE,MAAM8B,EAAO1I,KAAKoN,YAAYvL,OACxBmhD,EAAUhjD,KAAKmsB,KAAOy2B,GAAUK,KAAO,MAAQ,MAC/CC,EAAMljD,KAAK8iD,UAAYE,EACA,QAAQ7M,GAAUztC,EAAM,SAAU1I,KAAKmsB,OAC9DtqB,EAAS7B,KAAKoN,YAAYpN,KAAKoN,YAAYvL,OAAS,GAC1D,IAAIshD,EAAY,GACZC,EAAY,GAWhB,OAPIpjD,KAAK8iD,WACPK,EAAYnjD,KAAK+iD,QAAU,WAAUlhD,EAAS,GAAM,WACpDuhD,EAAYpjD,KAAK+iD,QAAU,UAAY,YAEvCI,EAAYnjD,KAAK+iD,QAAU,gBAAgBlhD,IAAW,cACtDuhD,EAAapjD,KAAK+iD,QAAU,aAAe,cAEtC,WACH/7B,EAAK,2HAIQq8B,GAAc36C,EAAM,SAAU1I,KAAKmsB,4BACnC+2B,wEAENC,8BACQC,kBACVC,GAAc36C,EAAM,SAAU1I,KAAKmsB,8BAC/BnsB,KAAKmsB,YAAYgqB,GAAUztC,EAAM,SAAU1I,KAAKmsB,oFAM9D,EAGH,SAASgqB,GAAUztC,EAAcmB,EAAcsiB,GAC7C,GAAa,IAATzjB,EACF,MAAO,GAAGmB,IACL,GAAa,IAATnB,EACT,MAAO,GAAGmB,QAAWA,MAChB,GAAa,IAATnB,EACT,MAAO,GAAGmB,QAAWA,QAAWA,MAC3B,GAAa,IAATnB,EACT,MAAO,GAAGmB,QAAWA,QAAWA,QAAWA,MAE3C,MAAMxH,MAAM,cAAc8pB,cAAezjB,yBAE7C,CAEA,SAAS26C,GAAc36C,EAAcmB,EAAcsiB,GACjD,GAAa,IAATzjB,EACF,MAAO,GAAGmB,IACL,GAAa,IAATnB,EACT,MAAO,GAAGmB,MACL,GAAa,IAATnB,EACT,MAAO,GAAGmB,MACL,GAAa,IAATnB,EACT,MAAO,GAAGmB,MAEV,MAAMxH,MAAM,cAAc8pB,cAAezjB,yBAE7C,CC3FgB,SAAA46C,GACZn3B,EAAejlB,EAAegiB,EAAwB0f,EACtDka,EAAoBC,GACtB,MAAMra,EAAQxhC,EAAEzC,MAAM5C,OAChB0hD,EAAc94C,EAAAA,aAAailC,mBAAmB,CAAC9G,GAAOF,GAC5D,IAAI8a,EAAYt8C,EACG,MAAfq8C,IACFC,EAAYv8B,GAAU,CAACjd,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAACsf,KAAM8a,MAE7D,MAAME,EAAeh5C,EAAAA,aAAaklC,iBAAiB,EAAGjH,GAAO,GAE7D,GAAI+a,IAAiB/a,EAAQ,EAC3B,MAAM,IAAIrmC,MACN,oDACI6E,EAAEzC,MAAM5C,OAAS,kBACL+mC,KAEtB,MAAMznC,EAAOqiD,EAAU/+C,MAAMg/C,GAC7B,IAAIl0B,EAASxC,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAGs8C,GAAYt6B,YAM/C,IAAK,IAAIpkB,EAAI,EAAGA,GAAKR,KAAKmJ,KAAKnJ,KAAKo/C,KAAKviD,IAAS,EAAG2D,IAAK,CACxD,MAAMO,EAAU,IAAIw9C,GAAW12B,EAAIq3B,EAAU/+C,OAAO,EAAOs+C,GACrDY,EAAap0B,EACbjG,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACxQ,KAC9CyqB,EACIrG,EAAQ1N,iBAAiBnW,EAAS,CAACkqB,GAASA,EAAOlpB,MAAOijB,GAC9DJ,EAAQlX,YAAY2xC,EAAW1xC,OAChC,CAGD,GAAI6wC,EAAW,CACb,MAAMz9C,EAAU,IAAIw9C,GAAW12B,EAAIq3B,EAAU/+C,MAAOq+C,EAAWC,GACzDY,EAAap0B,EACbjG,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC,KAC9Cia,EACIrG,EAAQ1N,iBAAiBnW,EAAS,CAACkqB,GAASA,EAAOlpB,MAAOijB,GAC9DJ,EAAQlX,YAAY2xC,EAAW1xC,OAChC,CAED,GAAmB,MAAfsxC,EAAqB,CACvB,MACMK,EAA0B38B,GAC5B,CAACjd,OAAQ,CAAC9C,EAAGqoB,GAASrG,UAASC,MAAO,CAACsf,KAFhBh+B,EAAAA,aAAao5C,uBAAuBN,MAO/D,OAHAr6B,EAAQlX,YAAYud,EAAOtd,QAC3BiX,EAAQlX,YAAYwxC,EAAUvxC,QAEvB2xC,CACR,CAED,OAAOr0B,CACT,CChDO,MAAMu0B,GAA8B,CACzCt6B,WAAYu6B,EAAOA,QACnBr6B,YAAa,SACbC,WAZI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,EAAIka,UAAEA,EAASC,QAAEA,GAAW55B,EACnC,OAAOm6B,GAAQV,GAAUK,KAAM/7C,EAAGgiB,EAAS0f,EAAMka,EAAWC,EAC9D,GCEO,MAAMiB,GAA6B,CACxCx6B,WAAYy6B,EAAMA,OAClBv6B,YAAa,SACbC,WAZI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,EAAIka,UAAEA,EAASC,QAAEA,GAAW55B,EACnC,OAAOm6B,GAAQV,GAAUsB,IAAKh9C,EAAGgiB,EAAS0f,EAAMka,EAAWC,EAC7D,GCsBO,MAAMoB,GAAoC,CAC/C36B,WAAY46B,EAAaA,cACzB16B,YAAa,SACbC,WA/BI,SAAwBV,GAK5B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACgxC,QAAEA,GAAWluC,GACf7I,KAACA,EAAI68B,aAAEA,GAAgB7U,EAEvBk7B,EAA8B,IAAnBn9C,EAAEzC,MAAM5C,OAEnBk2C,EADcztC,EAAIA,KAACgO,cAAc4/B,EAAQzzC,OACd,EAC3B4B,EAAQ6xC,EAAQ7xC,MAChBwjB,EACFw6B,EAAW,CAACn9C,EAAEzC,MAAM,IAAM,CAACyC,EAAEzC,MAAM,GAAIyC,EAAEzC,MAAM,IAI7Cc,EAASyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAFlC4/C,EAAW,CAACljD,GAAQ,CAAC+F,EAAEzC,MAAM,GAAItD,GAEoBoW,MAAO,EAAGlR,WAC7DhB,EAAU,IAAIyyC,GAAgBjuB,EAAOkuB,EAAY/Z,GACjD1U,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAACnU,KACtCg3C,EAA+BJ,EAAa,CAAC7wC,EAAGgxC,GAAW,CAAChxC,GAIlE,OAHYgiB,EAAQ1N,iBAChBnW,EAAS8yC,EAAgB9xC,EAAOijB,EAAa/jB,EAGnD,SC9Ba++C,GAWXxkD,YAAYsN,EAAuBsnC,GAVnC10C,KAAAiH,cAAgB,CAAC,KAMjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EACPnB,KAAQyH,SAAG,mBAGTzH,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,gBAAgB6oC,IACjC10C,KAAK00C,WAAaA,CACnB,CAED9tC,cAsBE,MArBiB,WACbogB,EAAK,wJAIOhnB,KAAKukD,8CACLvkD,KAAKwkD,6CACLxkD,KAAKykD,gTAOXzkD,KAAK0kD,oFAGG1kD,KAAK2kD,wFAKxB,CAEOJ,uBACN,MAAwB,SAApBvkD,KAAK00C,WACA,YAEA,WAEV,CAEO8P,sBACN,MAAwB,SAApBxkD,KAAK00C,WACA,YAEA,WAEV,CAEO+P,sBACN,MAAwB,SAApBzkD,KAAK00C,WACA,YAEA,WAEV,CAEOgQ,qBACN,MAAwB,SAApB1kD,KAAK00C,WACA,uBAEA,sBAEV,CAEOiQ,yBACN,MAAwB,SAApB3kD,KAAK00C,WACA,4BAEA,2BAEV,ECnDI,MAAMkQ,GAAmC,CAC9Cp7B,WAAYq7B,EAAYA,aACxBn7B,YAAa,SACbC,WAjCI,SAAuBV,GAK3B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN86C,UAACA,EAASpQ,WAAEA,GAAcvrB,EAE1Bie,EAAYlgC,EAAEzC,MAAM,GAKpBsgD,GAJ8B,SAAfrQ,EAAyBxtC,EAAEzC,MAAM,GAAKyC,EAAEzC,MAAM,IAIhCqgD,EAC7BE,GAJ6B,SAAftQ,EAAyBxtC,EAAEzC,MAAM,GAAKyC,EAAEzC,MAAM,IAIjCqgD,EAC3BG,GAJ6B,SAAfvQ,EAAyBxtC,EAAEzC,MAAM,GAAKyC,EAAEzC,MAAM,KAIhCqgD,EAAYA,GAMxCx7B,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAACwvC,KAGnBz/C,EAAU,IAAIi/C,GARgB,SAAf5P,EACjB,CAACtN,EAAW2d,EAAcC,EAAaC,GACvC,CAAC7d,EAAW6d,EAAaF,EAAcC,GAMUtQ,GACrD,OAAOxrB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EACzD,SC3Ba47B,GAcXplD,YACIsN,EAAuBgmC,EAAsBD,EAC7ChrB,GAAU,EAAOjD,EAAsC,KACvDigC,GAAqB,GAZzBnlD,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,wCACXzH,KAAa8F,cAA6B,CAAC,GAAI,GAAI,GAWjD9F,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IAC9CxI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAE5CqiB,GACFnoB,KAAKiH,cAAcjF,KAAK,QAEtBmjD,GACFnlD,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlD,mBAAqBA,EAC1BnlD,KAAKozC,aAAeA,EACpBpzC,KAAKmzC,YAAcA,EACnBnzC,KAAK6L,UAAY,iBAAiB7L,KAAKklB,cAAcllB,KAAKozC,gBACtDpzC,KAAKmzC,aACV,CAEDvsC,cACE,MAAMwtC,EAAap0C,KAAKmzC,YAAcnzC,KAAKozC,aACrCvtC,EACF7F,KAAK8F,cAAc,GAAK9F,KAAK8F,cAAc,GAAK9F,KAAK8F,cAAc,GACjEs/C,EAAcplD,KAAK8F,cAAc,GAAK9F,KAAKozC,aAAe,EAC1D1sB,EAAa1mB,KAAK8F,cAAc,GAAK9F,KAAKmzC,YAAc,EAwE9D,MAtEiB,WACbluB,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlD,oBAAoB,EAAO,yDAE3Bz+B,OAAgB0+B,wDAChBplD,KAAKmzC,iBAC/CnzC,KAAKozC,kUAULpsB,giBAgBAo+B,4BAAsCplD,KAAK8F,cAAc,6DAEzD4gB,4BAAqC1mB,KAAK8F,cAAc,4VAUxDsuC,EAAavuC,EACT,gBAAgBuuC,KAChB,kBAAkBA,wBACdvuC,oDAGgB7F,KAAKmzC,+CACLnzC,KAAKmzC,+KAOLnzC,KAAKozC,iEACHpzC,KAAKmzC,qNAM7B3tB,EAAsBxlB,KAAKmoB,QAASnoB,KAAKklB,oLAOhD,QCtHUmgC,GAgBXvlD,YACIqyC,EAAmChqB,GAAU,EAC7CjD,EAAsC,KAAMigC,GAAqB,GAbrEnlD,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SAAG,4DACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAammB,cAAG,EAKhBnmB,KAAe+F,gBAAG,EAMhB/F,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKslD,aAAehhD,KAAKmJ,KAAKzN,KAAKoN,YAAY,GAAKpN,KAAKmmB,eACrDnmB,KAAKmmB,cACT,MAAMo/B,EAAqB,CACzBvlD,KAAKoN,YAAY,GAAIpN,KAAKoN,YAAY,GAAIpN,KAAKslD,aAC/CtlD,KAAKoN,YAAY,IAEnBpN,KAAKsI,eAAiB8F,EAAmBm3C,GAEzCvlD,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBi9C,EAAoBvlD,KAAK8F,cAC9C,CAAC9F,KAAK+F,gBAAkB/F,KAAKmmB,cAAe,EAAG,IAEnD7b,EAAIA,KAACwC,OACuB,iBAAxBqlC,EAASuC,YACT,IAAM,gCAENvsB,GACFnoB,KAAKiH,cAAcjF,KAAK,QAEtBmjD,GACFnlD,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAKmyC,SAAWA,EAChBnyC,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlD,mBAAqBA,EAE1BnlD,KAAK6L,UACD,iBAAiBqZ,KAAcllB,KAAKmyC,SAASiB,gBACzCpzC,KAAKmyC,SAASgB,eAAenzC,KAAKmyC,SAASwB,gBAC3C3zC,KAAKmyC,SAASyB,eAAe5zC,KAAKmmB,eAC3C,CAEDvf,cACE,MAAM4+C,GAAWxlD,KAAKmmB,cAAgB,GAAKnmB,KAAKmyC,SAASyB,YACrD5zC,KAAKmyC,SAASgB,YACZQ,EAAe3zC,KAAKmyC,SAASwB,aAC7BC,EAAc5zC,KAAKmyC,SAASyB,YA4DlC,MA1DiB,WACb3uB,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlD,oBAAoB,EAAM,uRASpEn+B,EAAK,2DACiChnB,KAAK+F,yDACb/F,KAAK+F,wGAEI/F,KAAKmmB,uDACdnmB,KAAKmmB,gNAKWwtB,MAC9CC,yIAI+B4R,+CACExlD,KAAKmmB,gDAChBnmB,KAAKmmB,sLAKHnmB,KAAKmyC,SAASiB,wJAGZoS,6HAGExlD,KAAKmyC,SAASgB,mHAEdnzC,KAAKmmB,qEAEjCytB,wHAMsB5zC,KAAKmmB,uMAIrBX,EAAsBxlB,KAAKmoB,QAASnoB,KAAKklB,uIAOpD,QCtHUugC,GAiBX3lD,YACIqyC,EAAmChqB,GAAU,EAC7CjD,EAAsC,KAAMigC,GAAqB,GAdrEnlD,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAAyH,SAAW,kIAGXzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAMnD9F,KAAImB,MAAG,EAKLnB,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK88C,eAAyC,iBAAxB3K,EAASuC,WAE3BvsB,GACFnoB,KAAKiH,cAAcjF,KAAK,QAEtBmjD,GACFnlD,KAAKiH,cAAcjF,KAAK,0BAG1BhC,KAAKmyC,SAAWA,EAChBnyC,KAAKmoB,QAAUA,EACfnoB,KAAKklB,WAAaA,EAClBllB,KAAKmlD,mBAAqBA,EAC1BnlD,KAAK6L,UAAY,aAAa7L,KAAKklB,cAAcllB,KAAK88C,gBACvD,CAEDl2C,cACE,MAAM82C,EAAc19C,KAAK88C,eAAiB,2BACA,2BAsE1C,MApEiB,WACb73B,EAAoBjlB,KAAKklB,WAAYllB,KAAKmlD,oBAAoB,EAAO,eAErEn+B,EAAK,6KAKLhnB,KAAK88C,eAAiB,KAAO,wEACT98C,KAAK88C,eAAiB,EAAI,2xCA4BvBY,0sBAoBAA,yKAMjBl4B,EAAsBxlB,KAAKmoB,QAASnoB,KAAKklB,wHAMpD,EC1DI,MAAMwgC,GAA4C,CACvDl8B,WAAYm8B,EAAqBA,sBACjCj8B,YAAa,SACbC,WAzDI,SAAgCV,GAKpC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,GAAU7P,GACdpF,QAACA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAU2K,UAAEA,EAAS/K,gBAAEA,GAAmBnrB,EACzDm2B,EAAc70C,EAAAA,aAAa80C,wBAAwB7K,GACzD,IAAIkR,EAAavG,EACC,MAAduG,IACFA,EAAa,CAAC,EAAG,IAGnB,MAAMzT,EAAW1nC,EAAYA,aAAC+0C,kBAC1Bt4C,EAAEzC,MACFoV,EAAOpV,MAA2CG,EAASghD,EAC3DvR,EAAKC,GAAiB,EAAsBgL,GAC1Cv2C,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,SAAUpB,EAASmB,WAG/CwJ,EAAyC,iBAAxB3K,EAASuC,WAChC,IAAIrvC,EA2BJ,OAzBKy3C,GAAkB3K,EAASoB,SAAW,IAAMpB,EAASmB,QAAU,IACtC,IAA1BnB,EAASwB,cAA+C,IAAzBxB,EAASyB,aACb,IAA3BzB,EAAS4B,eAAmD,IAA5B5B,EAAS2B,gBACzC3B,EAAS4K,aAAe5K,EAAS6K,YACnC33C,EAAU,IAAI6/C,GACV/S,EAAS9pC,SAAU8pC,EAASiB,aAAcjB,EAASgB,aAErD2J,GAAkB3K,EAASsD,UAAY,GAAKtD,EAASuD,SAAW,GAChEvD,EAASyB,aAAe,GACxBzB,EAAS4K,aAAe5K,EAAS6K,aACL,IAA5B7K,EAAS2B,gBAAmD,IAA3B3B,EAAS4B,eAC1C5B,EAAS4K,WAAa,GAAM,GAC9B13C,EAAU,IAAIggD,GAA2BlT,GACzCppC,EAAW/G,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAACjQ,EAAQigD,kBAE/CjgD,EAAU,IAAIogD,GAAuBtT,GACrCppC,EAAW/G,KACP,CAACkD,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,eAChC,CAACluC,KAAM,QAASoQ,KAAM,CAAC68B,EAASgB,cAChC,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cAAe,CACpE1uC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,kBAI1C7qB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAG2S,GAAS3S,EAAEb,MAAO0C,EACjE,SCvDa88C,GAYX/lD,YAAYqyC,GAPZnyC,KAAAiH,cAAgB,CAAC,IAAK,MACtBjH,KAAAyH,SACI,2KAEJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS0N,YAE5B7/C,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,kCAClB,CAEDjF,cAqCE,MApCiB,WACbogB,EAAK,0iCAoCV,QAGU8+B,GAWXhmD,YAAYqyC,GANZnyC,KAAAiH,cAAgB,CAAC,KAAM,KACvBjH,KAAAyH,SAAW,4HAEXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAE5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,iCAClB,CAEDjF,cA4CE,MA3CiB,WACbogB,EAAK,s3CA2CV,ECtGI,MAAM++B,GAA0D,CACrEv8B,WAAYw8B,EAAmCA,oCAC/Ct8B,YAAa,SACbC,WA/BI,SAA8CV,GAKlD,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACmuC,GAAEA,GAAMrrC,GACVpF,QAACA,EAAOy6C,UAAEA,EAAShL,IAAEA,EAAGC,gBAAEA,EAAeuL,YAAEA,GAAe12B,EAE1DgpB,EAAW1nC,EAAAA,aAAa+0C,kBAC1Bt4C,EAAEzC,MAA2Co7C,EAAaj7C,EAC1Dy6C,EAAWhL,EAAKC,GAAiB,GAE/BjvC,EAAU,IAAIwgD,GAAgC1T,GAC9C7oB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,WAChC,CAACruC,KAAM,QAASoQ,KAAM,CAAC68B,EAASmB,UAChC,CAACpuC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS/K,YAChC,CAACliC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS6K,YAAc7K,EAAS4K,cAEzD,OAAO7zB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAGmuC,GAAK,UAAW/rB,EAC/D,GCIO,MAAM28B,GAAyD,CACpEz8B,WAAY08B,EAAkCA,mCAC9Cx8B,YAAa,SACbC,WAjCI,SAA6CV,GAKjD,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEx7B,OAAEA,GAAU7P,GACfpF,QAACA,EAAOy6C,UAAEA,EAAShL,IAAEA,EAAGC,gBAAEA,EAAepP,WAAEA,GAAc/b,EAEzDgpB,EAAW1nC,EAAAA,aAAa+0C,kBAC1Bta,EAAYrrB,EAAOpV,MAA2CG,EAC9Dy6C,EAAWhL,EAAKC,GAAiB,GAE/BjvC,EAAU,IAAIygD,GAA+B3T,GAC7C7oB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cAAe,CACpE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAASiB,aAAe,EAAIjB,EAASqB,QAAQK,IAC7C1B,EAASgB,YAAc,EAAIhB,EAASqB,QAAQtW,OAGhD,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,WAChC,CAACxwC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS6K,YAAc7K,EAAS4K,cAEzD,OAAO7zB,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,EAAIx7B,GAASw7B,EAAGhvC,MAAOijB,EACnE,SC9Ba68B,GASXrmD,YAAYqB,GAJZnB,KAAAiH,cAAgB,CAAC,KACjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc,CAACjM,EAAMA,GAC1BnB,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,MAClB,CAEDjF,cAUE,MATiB,WACbogB,EAAK,+OASV,ECLI,MAAMo/B,GAA2B,CACtC58B,WAAY68B,EAAIA,KAChB38B,YAAa,SACbC,WAxBI,SAAeV,GAEnB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,GAAK8C,EAEN3B,EAAW,IAAInB,EAAEzC,SAAUyC,EAAEzC,OAC7BolB,EAAQvf,EAAIA,KAACgO,cAAcpR,EAAEzC,OAE7B6hD,EAAO18B,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAO,CAAColB,MAEtDxkB,EAAU,IAAI8gD,GAAYt8B,GAC1BlgB,EAAMuf,EAAQ1N,iBAAiBnW,EAAS,CAACihD,GAAOA,EAAKjgD,OAErDmlB,EAAM5B,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAO4D,KAK/D,OAHA6gB,EAAQlX,YAAYs0C,EAAKr0C,QACzBiX,EAAQlX,YAAYrI,EAAIsI,QAEjBuZ,CACT,SCpBa+6B,GAWXzmD,YAAYqyC,GANZnyC,KAAAiH,cAAgB,CAAC,IAAK,KACtBjH,KAAQyH,SACJ,mFACJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAAS9pC,SAC5BrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,YAClB,CAEDjF,cAkCE,MAjCiB,YACZogB,EAAK,slCAiCX,EC3BI,MAAMw/B,GAAiC,CAC5Ch9B,WAAYi9B,EAAUA,WACtB/8B,YAAa,SACbC,WA/BI,SAAqBV,GAKzB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,GAAU7P,GACdpF,QAACA,EAAOyvC,IAAEA,EAAGgL,UAAEA,GAAal2B,EAE5BgpB,EAAW1nC,EAAAA,aAAai8C,sBAC1Bx/C,EAAEzC,MACFoV,EAAOpV,MAAmCG,EAASyvC,EACnD,OAAyBgL,GACvB7L,EAAU,CAACrB,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,MAClD5T,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,IAAIk+B,IAC1B,CAACtuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,iBAGrD1uC,EAAU,IAAIkhD,GAAkBpU,GAItC,OAFIjpB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAG2S,GAAS3S,EAAEb,MAAOijB,EAG9D,SCzBaq9B,GAYX7mD,YAAYqyC,EAAmC12B,GAM7C,GAbFzb,KAAaiH,cAAG,CAAC,IAAK,IAAK,MAC3BjH,KAAQyH,SACJ,iGACJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EAIPlI,KAAKoN,YAAc+kC,EAASkB,QAC5BrzC,KAAKsI,eAAiB8F,EAAmB+jC,EAAS9pC,UAClDrI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgB6pC,EAAS9pC,SAAUrI,KAAK8F,eAE7B,YAAhB2V,GAA6C,UAAhBA,EAC/B,MAAM,IAAIpZ,MAAM,8FACcoZ,WAEhCzb,KAAKkF,KAAOuW,EACZzb,KAAK6L,UAAY,yBAClB,CAEDjF,cAiDE,MA9CiB,YACZogB,EAAK,miDAwCNjiB,EACI,uBAAwB,QAAS/E,KAAKkF,oCAK/C,QAGU0hD,GAYX9mD,YACIqyC,EAAmC1tC,EACnCgX,GAMF,GAfFzb,KAAaiH,cAAG,CAAC,IAAK,IAAK,MAC3BjH,KAAQyH,SACJ,iGACJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EAMPlI,KAAKoN,YAAc+kC,EAAS0N,YAC5B7/C,KAAKsI,eAAiB8F,EAAmB+jC,EAAS9pC,UAClDrI,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgB6pC,EAAS9pC,SAAUrI,KAAK8F,eAE7B,YAAhB2V,GAA6C,UAAhBA,EAC/B,MAAM,IAAIpZ,MAAM,+FACcoZ,WAEhCzb,KAAKkF,KAAOuW,EACZzb,KAAK6L,UAAY,0BAClB,CAEDjF,cAgDE,MA7CiB,YACZogB,EAAK,w/CAuCNjiB,EACI,uBAAwB,QAAS/E,KAAKkF,oCAK/C,EC/HI,MAAM2hD,GAA+C,CAC1Dr9B,WAAYs9B,EAAwBA,yBACpCp9B,YAAa,SACbC,WAhCI,SAAmCV,GAKvC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,EAAMw7B,GAAEA,GAAMrrC,GAClBpF,QAACA,EAAOyvC,IAAEA,EAAGgL,UAAEA,GAAal2B,EAE5BgpB,EAAW1nC,EAAAA,aAAai8C,sBAC1Bx/C,EAAEzC,MACFoV,EAAOpV,MAAmCG,EAASyvC,EACnD,OAAyBgL,GAEvBh5C,EAAQwT,EAAOxT,MACfhB,EACF,IAAIuhD,GAAgCzU,EAAUt4B,EAAOpV,MAAO4B,GAC1DijB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBACzD,CAAC7uC,KAAM,QAASoQ,KAAM,CAAChL,EAAIA,KAACgO,cAAc65B,EAAS9pC,aAE/C9C,EAASyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAOoV,EAAOpV,MAAO8S,MAAO,EAAGlR,WACrE,OAAO6iB,EAAQ1N,iBACXnW,EAAS,CAAC6B,EAAG2S,EAAQw7B,GAAKhvC,EAAOijB,EAAa/jB,EACpD,GCEO,MAAMwhD,GAA8C,CACzDv9B,WAAYw9B,EAAuBA,wBACnCt9B,YAAa,SACbC,WAhCI,SAAkCV,GAKtC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,EAAMw7B,GAAEA,GAAMrrC,GAClBpF,QAACA,EAAOyvC,IAAEA,EAAGgL,UAAEA,GAAal2B,EAE5BgpB,EAAW1nC,EAAAA,aAAai8C,sBAC1Bx/C,EAAEzC,MACFoV,EAAOpV,MAAmCG,EAASyvC,EACnD,OAAyBgL,GAEvBh5C,EAAQa,EAAEb,MACVhB,EAAU,IAAIshD,GAA+BxU,EAAU9rC,GACvDijB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,aAAcjB,EAASgB,cACvD,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBACzD,CAAC7uC,KAAM,QAASoQ,KAAM,CAAChL,EAAIA,KAACgO,cAAc65B,EAAS9pC,aAE/C9C,EACFyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAO0tC,EAASkB,QAAS97B,MAAO,EAAGlR,WAC9D,OAAO6iB,EAAQ1N,iBACXnW,EAAS,CAAC6B,EAAG2S,EAAQw7B,GAAKhvC,EAAOijB,EAAa/jB,EACpD,SC5Ba0hD,GAaXnnD,YACIuI,EAAoBnD,EAAgBgiD,GAbxClnD,KAAAiH,cAAgB,CAAC,SACjBjH,KAAQyH,SAAG,cAKXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAGlD9F,KAAAiG,aAAed,EAAamZ,KAC5Bte,KAAImB,MAAG,EAILnB,KAAKoN,YAAc/E,EACnBrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKkF,KAAOA,EACZlF,KAAKknD,cAAgBA,EACrBlnD,KAAK6L,UAAY,QAAQ3G,KAAQgiD,GAClC,CAEDtgD,cACE,IAAIugD,EACJ,MAAM5vC,EAAsB,YAAdvX,KAAKkF,KAAqB,QAAU,gBAClDiiD,EAAkB,+DAEF5vC,yBACAA,yBACAA,yCAEAA,cAqBhB,MAlBiB,oEAEbvX,KAAKknD,kCACJlgC,EAAK,+QAKCmgC,qRAWZ,ECGI,MAAMC,GAA2B,CACtC59B,WAAY69B,EAAIA,KAChB39B,YAAa,SACbC,WA5DI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bu5B,MAACA,GAASx4C,GACVs9C,OAACA,EAAMC,QAAEA,GAAWp+B,GACnBhmB,EAAQD,GAASs/C,EAAM/9C,MAAM8C,MAAM,EAAG,IACvCigD,aAACA,GAAgBD,GAAW,GAC5BE,GAAQD,aAAA,EAAAA,EAAeC,QAAS,EAKhCrkD,EAAS8lB,EAAQxoB,OAAOqQ,SAASrP,IAAI,sBACvC,aACA,aACE2G,EAAW,CAAClF,EAAQD,GACpBmC,EAAU,IAAI4hD,GAAY5+C,EAAUm6C,EAAMn8C,MAAOjD,GACvDkkD,EAAOpkD,MAAQA,EACfokD,EAAOnkD,OAASA,EAChB,MAAMumB,EAAc,SACpB,IACIg+B,EADAC,EAAaL,EAAO31C,WAAW+X,GAE9Bi+B,IACHD,EAAe,IAAIrxC,gBAAgBnT,EAAOC,GAC1CwkD,EAAaD,EAAa/1C,WAAW+X,IAEvC,MAAMk+B,EAAqC,IAAvBpF,EAAM/9C,MAAM5C,OAAe2gD,EAAM/9C,MAAM,GAAK,EAChEkjD,EAAW/1C,UAAU,CACnBlR,OAAQwoB,EAAQxoB,OAChB0C,SACAhC,MAAOqV,gBAAgBoxC,gBACvBnxC,UAAW,kBAGb,MAAM+E,EAAc,QACdlW,EAAS2jB,EAAQrQ,eAAexQ,EAAUoT,GAC1CqsC,EAAO5+B,EAAQ/X,UAAUvP,IAAI2D,EAAO0M,QAC1C61C,EAAKh1C,SAAW60C,EAAWvyC,oBAC3B0yC,EAAK/0C,UAAW,EAEhB,MAAMuW,EACF,CAAC,CAACpkB,KAAM,SAAUoQ,KAAM,CAACsyC,IAAe,CAAC1iD,KAAM,UAAWoQ,KAAM,CAACmyC,KAGrE,GAFAv+B,EAAQ1N,iBAAiBnW,EAAS,CAACm9C,GAAQ/mC,EAAa6N,EAAa/jB,GAEjEmiD,EAAc,CAChB,MAAMK,EAAkBT,EAAO31C,WAAW,MAC1C,IAAKo2C,EACH,MAAM,IAAI1lD,MACN,6EAEN0lD,EAAgB9wC,UAAUywC,EAAc,EAAG,EAC5C,CAED,OADAx+B,EAAQlX,YAAYzM,EAAO0M,QACpBuwC,CACT,GCvDawF,GAAqBh6B,GAAiB,CACjDN,OAAQ1O,EAAa0C,IACrBiM,cAAes6B,GACfh6B,iBAAiB,IAGNi6B,GAA+B,CAC1C1+B,WAAY2+B,EAAQA,SACpBz+B,YAAa,SACbC,WAAYq+B,ICVR,SAAU/tC,GACZgP,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,EAAIyG,SAAEA,GAAYlmB,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,MAAOnmB,EAC1C,CAEO,MAAMk/B,GAA0B,CACrC5+B,WAAY06B,EAAGA,IACfx6B,YAAa,SACbC,WAAY1P,IC+DP,MAAMouC,GAA6B,CACxC7+B,WAAY8+B,EAAMA,OAClB5+B,YAAa,SACbC,WA3EI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bs/B,SAACA,GAAYp/B,EACb+kB,EAAUlkC,GAEVw+C,QAACA,EAAOC,WAAEA,EAAUC,OAAEA,GACxBj+C,eAAak+C,qBAAqBJ,EAAUra,EAAQrsC,QACxD4I,EAAYA,aAACm+C,oBAAoBJ,EAAQ3mD,OAAQ6mD,EAAQxa,GACzD,MAAM2a,KAACA,EAAIC,MAAEA,GAASr+C,EAAYA,aAACs+C,qBAAqBN,EAAYC,GAE9DM,EAASF,EAAMjnD,OACrB,IAAI2pB,EAAuB,KACvBy9B,EAAmBT,EAAQ3mD,OAC/B,MAAMqnD,EAAiC,GACvC,IAAK,IAAIpkD,EAAI,EAAGA,EAAIkkD,IAAUlkD,EAAG,CAC/B,IAAK,MAAMqkD,KAAUL,EAAMhkD,GAAI,CAC7B,MAAOskD,mBAAoB3gB,EAAM4gB,WAAYC,GACzC7+C,eAAa8+C,qBAAqBN,EAAkBP,EAAOS,IAC/D,IAAIjiD,EACAuD,EAAYA,aAAC++C,sBAAsB/gB,GACrCvhC,EAAIgnC,EAAQib,IAEZjiD,EAAI+f,GAAU,CAACjd,OAAQ,CAAC9C,EAAGgnC,EAAQib,IAAUjgC,UAASC,MAAO,CAACsf,UAC9DygB,EAAiBlnD,KAAKkF,IAExB,MAAMi+B,EAAwBj+B,EAAEzC,MAAM8C,QACtC,IAAK,IAAI+P,EAAI,EAAGA,EAAIgyC,EAAaznD,SAAUyV,EACzC6tB,EAAYphC,OAAOulD,EAAahyC,GAAI,EAAG,GAGpChN,EAAIA,KAACC,YAAYrD,EAAEzC,MAAO0gC,KAC7Bj+B,EAAI0iB,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAO0gC,KAClD+jB,EAAiBlnD,KAAKkF,IAEZ,OAARskB,EACFA,EAAMtkB,GAGNskB,EACIw8B,GAAmB,CAACh+C,OAAQ,CAACogB,EAAGljB,EAAGyM,EAAG6X,GAAMtC,YAChDggC,EAAiBlnD,KAAKwpB,GAEzB,CACG1mB,EAAIkkD,EAAS,IACXH,EAAK/jD,IAAM,IACb0mB,EAAMvR,GAAI,CACRjQ,OAAQ,CAAC9C,EAAGskB,GACZtC,UACAC,MAAO,CACLyf,KAAMigB,EAAK/jD,IAAM0jD,EAAQ3mD,OAASonD,GAClC5Z,UAAU,KAGd6Z,EAAiBlnD,KAAKwpB,IAExBy9B,IAEH,CAGD,IAAK,MAAMrwC,KAAcswC,EACnBtwC,IAAe4S,GAGnBtC,EAAQlX,YAAY4G,EAAW3G,QAGjC,OAAOuZ,CACT,GC3Eai+B,GAAMh8B,GAAgB,CAACC,OAAQ5L,EAAYsB,MAE3CsmC,GAA0B,CACrClgC,WAAYmgC,EAAGA,IACfjgC,YAAa,SACbC,WAAY8/B,ICODG,GAA8B,CACzCpgC,WAAYqgC,EAAOA,QACnBngC,YAAa,SACbC,WAZGV,IACC,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpBosB,GAACA,EAAE9sC,EAAEA,GAAKyB,EAEV3E,EACF,IAAI+mB,GAAgBpN,EAAaiC,QAASo0B,EAAG5wC,MAAO8D,EAAE9D,OAC1D,OAAOykB,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,EAAI9sC,GAAI8sC,EAAGhvC,MAAM,GCPpDyjD,GAAQ97B,GACjB,CAACN,OAAQ1O,EAAakC,MAAO7a,MAAO,OAAQsnB,cAAeo8B,KAElDC,GAA4B,CACvCxgC,WAAYygC,EAAKA,MACjBvgC,YAAa,SACbC,WAAYmgC,ICNDI,GAAMz8B,GAAgB,CAACC,OAAQ5L,EAAYC,MAE3CooC,GAA0B,CACrC3gC,WAAY4gC,EAAGA,IACf1gC,YAAa,SACbC,WAAYugC,ICNDv5B,GAAMlD,GAAgB,CACjCC,OAAQ5L,EAAYuB,IACpBsK,cAAeuc,GACf7jC,MAAO,YAGIgkD,GAA0B,CACrC7gC,WAAY8gC,EAAGA,IACf5gC,YAAa,SACbC,WAAYgH,ICTR,SAAU04B,GAAWpgC,GAKzB,MAAMjf,OAACA,EAAMmf,MAAEA,EAAKD,QAAEA,GAAWD,GAC3B9Z,IAACA,GAAOga,GACRhN,MAACA,GAASnS,EAEV+7B,EAAY5pB,EAAM1X,MAAM5C,OACxBstB,EAAWhT,EAAM1X,MAAM8C,QAC7B,IAAIgjD,EAAOp7C,EAWX,OAVIA,EAAM,IAER7E,EAAIA,KAACwC,SACCi5B,EAAY,IAAM52B,GACpB,IAAM,mCAAoC42B,EAAY,OAClDA,OACRwkB,EAAOxkB,EAAY52B,EAAM,GAE3BggB,EAASprB,OAAOwmD,EAAM,EAAG,GAElB3gC,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGiV,GAAQ+M,UAASC,MAAO,CAAC1kB,MAAO0qB,IAC9D,CAEO,MAAMq7B,GAAiC,CAC5ChhC,WAAYihC,EAAUA,WACtB/gC,YAAa,SACbC,WAAY0/B,IC5BDx4B,GACTpD,GAAgB,CAACC,OAAQ5L,EAAYwB,MAAOqK,cAAewc,KAElDugB,GAA4B,CACvClhC,WAAYmhC,EAAKA,MACjBjhC,YAAa,SACbC,WAAYkH,UCRD+5B,GAWX9qD,YAAYwJ,EAA0B7E,GAVtCzE,KAAAiH,cAA0B,CAAC,OAAQ,QACnCjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,8CACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAILnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKsJ,UAAYA,EACjBtJ,KAAK6L,UAAY,OAAOvC,GACzB,CAED1C,cAsCE,MAlCiB,uFAHmB,SAAnB5G,KAAKsJ,UAClB,oCACA,4uBA4BF0d,EAAK,gLAQR,WCvDa6jC,GACZ3jD,EAAe4jD,EAAkB5hC,GACnC,MAAM4E,EAAQ5E,EAAQ/X,UAAUvP,IAAIsF,EAAE+K,QAEhC84C,EAAYzgD,EAAIA,KAACgO,cAAcpR,EAAEzC,OAEjCumD,EAAqB9jD,EAAEzC,MAAMyC,EAAEzC,MAAM5C,OAAS,GAG9CytC,EAAY,GACZ2b,EAAUrhC,GACZ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAO,CAJ5BsmD,EAAYC,EAIwBA,MAClD1b,EAAUttC,KAAKipD,GAEf,MAAM7qB,EAAS6qB,EAAQxmD,MACjBiqB,EAAc,IAAIk8B,GAAW,OAAQxqB,GACrCzR,EAAc,IAAIi8B,GAAW,OAAQxqB,GAErCp2B,EAAS,CACb,CACEiI,OAAQ6b,EAAMzb,mBAAmBC,KAAKL,OACtC5L,MAAOynB,EAAMzb,mBAAmBC,KAAKjM,MACrC5B,MAAO27B,GAET,CACEnuB,OAAQ6b,EAAMzb,mBAAmBE,KAAKN,OACtC5L,MAAOynB,EAAMzb,mBAAmBE,KAAKlM,MACrC5B,MAAO27B,IAML9W,EAAc,CAClB,CAACpkB,KAAM,UAAWoQ,KAAM,CAHCw1C,EAAU,EAAMxmD,KAAK4mD,IAAM,EAAM5mD,KAAK4mD,KAI/D,CAAChmD,KAAM,UAAWoQ,KAAM,CAHNw1C,EAAU1qB,EAAO,GAAK,KAMpCyZ,EACF3wB,EAAQ1N,iBAAiBkT,EAAa1kB,EAAQ,UAAWsf,GAC7DgmB,EAAUttC,KAAK63C,GACf,MAAMsR,EACFjiC,EAAQ1N,iBAAiBmT,EAAa3kB,EAAQ,UAAWsf,GAC7DgmB,EAAUttC,KAAKmpD,GAEf,MAAMv8B,EACF1B,GAAQ,CAACljB,OAAQ,CAACsI,KAAMunC,EAAUtnC,KAAM44C,GAAWjiC,YACvDomB,EAAUttC,KAAK4sB,GAEf,MAAMw8B,EACFxhC,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG0nB,GAAgB1F,UAASC,MAAO,CAAC1kB,MAAOyC,EAAEzC,SAInE,OAFA6qC,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtCm5C,CACT,CCjDO,MAAMC,GAA0B,CACrC7hC,WAAY8hC,EAAGA,IACf5hC,YAAa,SACbC,WAXI,SAAcV,GAElB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB9M,MAACA,GAASnS,EAEhB,OAAO6gD,GAAQ1uC,GAAO,EAAqB+M,EAC7C,SCTaqiC,GASXzrD,YAAY0rD,GARZxrD,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAco+C,EACnBxrD,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,eAClB,CAEDjF,cAWE,MAViB,WACbogB,EAAK,wTAUV,EC1BI,MAAMykC,GAAoC,CAC7CjiC,WAAYkiC,EAAaA,cACzBhiC,YAAa,SACbC,WAAY,EAAE3f,SAAQkf,cACpB,MAAMs5B,MAACA,GAASx4C,EACV4jB,EAAgB1E,EAEhB7jB,EAAU,IAAIkmD,GAAsB/I,EAAmB/9C,OAG7D,OADImpB,EAAcpS,iBAAiBnW,EAAS,CAACm9C,GAAQA,EAAMn8C,MAC9C,GCVNoR,GACTgW,GAAgB,CAACC,OAAQ5L,EAAYyB,MAAOoK,cAAeyc,KAElDuhB,GAA4B,CACvCniC,WAAYoiC,EAAKA,MACjBliC,YAAa,SACbC,WAAYlS,ICNDo0C,GAAW79B,GAAiB,CACvCN,OAAQ1O,EAAamC,UACrBwM,cAAe0c,GACfhkC,MAAO,UAGIylD,GAA+B,CAC1CtiC,WAAYuiC,EAAQA,SACpBriC,YAAa,SACbC,WAAYkiC,UCZDG,GAWXlsD,YAAYsN,EAAuBw6C,EAAqBqE,GAAc,GARtEjsD,KAAAiG,aAAed,EAAagB,YAC5BnG,KAAAoN,YAAwB,CAAC,GAGzBpN,KAAaiH,cAAa,GAC1BjH,KAAa8F,cACT,CAAC,IAAK,EAAG,GAGX9F,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC8hD,EAAa,EAAG,IAErB5nD,KAAKisD,YAAcA,EACnBjsD,KAAK6L,UAAY,cAAc7L,KAAKisD,aACrC,CAEDrlD,cACE,MAAMslD,EAAclsD,KAAKisD,YACrB,0CACA,4CAGJ,MAAO,0CADHjsD,KAAKisD,YAAc,mBAAqB,6BAGxCjlC,EAAK,8LAIYklC,+KAOtB,ECrCI,MAAMC,GAAiC,CAC5C3iC,WAAY4iC,EAAUA,WACtB1iC,YAAa,SACbC,WAMI,SAAqBV,GAKzB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,EACjC,IAAIojC,OAACA,GAAUriD,EACf,MAAM49C,YAACA,GAAez+B,EAEtB,GAAc,MAAVkjC,EACF,MAAM,IAAIhqD,MAAM,4DAGlB,MAAMiqD,EAAwC,sCAC1CD,aAAkBE,iBAChBC,EAAwC,sCAC1CH,aAAkBI,iBAChBC,EAA2C,uCAC/BL,aAAkBM,mBACF,oBAArB,iBACRN,aAAkBh2C,gBACjBu2C,EACuB,oBAAzB,aAAwCP,aAAkBQ,aAEvD3pD,EAAOC,GAAUmpD,EACpB,CACGD,EAA4BS,WAC5BT,EAA4BU,aAE/B,CAACV,EAAOnpD,MAAOmpD,EAAOlpD,QACpBiK,EAAc,CAACjK,EAAQD,EAAO0kD,GAM9BoF,EAAiBV,GAAWE,EAClC,GAAII,GAAiBF,GAAYM,EAAgB,CAC/C,IAAIl6C,EAIG,CACL,GAAIk6C,EAAgB,CAClB,MAAMC,EACFttD,EAAGA,MAAG2R,QAAQ,yCACS,MAAvB47C,IACAD,IAA0Bl2C,KAC5BA,GAAqBk2C,EACrBC,GAAsB17C,SAASC,cAAc,UAAUE,WACnD,KAAM,CAACoF,yBAEbm2C,GAAoB5F,OAAOpkD,MAAQA,EACnCgqD,GAAoB5F,OAAOnkD,OAASA,EACpC+pD,GAAoBj2C,UAChBo1C,EAA+C,EAAG,EAAGnpD,EAAOC,GAChEkpD,EAASa,GAAoB5F,MAC9B,CAED,MAAMlmD,EAAQqV,gBAAgB9B,SAC1B8B,gBAAgB02C,kBAAoB12C,gBAAgB22C,gBAClDhqD,EAAS,aACTQ,EAAUslB,EAAQhY,eAAejO,eACnCmK,EAAY,GAAIA,EAAY,GAAIhK,EAAQhC,GAC5C8nB,EAAQvY,MAAM08C,2BACV,CAAC5nD,OAAQ4mD,GAA4C,CAACzoD,WACtD,CAACwJ,EAAY,GAAIA,EAAY,KACjC0F,EAAWlP,CACZ,CAED,MAAMzC,EAAOmJ,EAAAA,KAAKgO,cAAclL,GAC1BxI,EAAU0F,EAAAA,KAAKsC,eAAeQ,GAC9B/H,EACF,IAAI2mD,GAAkB5+C,EAAaw6C,EAtCrC,OAwCIt+B,EAAc,CAClB,CAACpkB,KAAM,SAAUoQ,KAAM,CAACnU,IAAQ,CAAC+D,KAAM,SAAUoQ,KAAM,CAACsyC,IACxD,CAAC1iD,KAAM,SAAUoQ,KAAM,IAAI1Q,KAEvBuX,EAAQ+M,EAAQrQ,eAAe,CAAC1V,EAAQD,GAAQ,SACzCgmB,EAAQ/X,UAAUvP,IAAIua,EAAMlK,QACpCa,SAAWA,EAEhB,MAAMyc,EACFrG,EAAQ1N,iBAAiBnW,EAAS,CAAC8W,GAAQ,QAASmN,GAExD,OADAJ,EAAQlX,YAAYmK,EAAMlK,QACnBsd,CACR,CAID,MAAM+9B,EAAajB,EAA8C/2C,KACjE,IAAIi4C,EAAaD,EACjB,GAAmB,MAAf1F,GAAuC,IAAhBA,EAAmB,CAC5C2F,EAAa,IAAI9xB,WAAW4wB,EAAOnpD,MAAQmpD,EAAOlpD,OAASykD,GAE3D,MAAMrrB,EAAa+wB,EAAUzrD,OAC7B,IAAIiH,EAAI,EACR,IAAK,IAAIhE,EAAI,EAAGA,EAAIy3B,EAAYz3B,IAC1BA,EAAI,EAAI8iD,IACV2F,EAAWzkD,KAAOwkD,EAAUxoD,GAGjC,CAED,MAAMS,EACF2jB,EAAQrQ,eAAezL,EAAa,QAAS,IAAIuN,WAAW4yC,IAEhE,OADArkC,EAAQ3O,YAAYhV,EAAO0M,QACpB1M,CACT,GAhHA,IAAI2nD,GACAn2C,GAAqBpX,EAAGA,MAAG2R,QAAQ,+CCV1Bk8C,GAcX1tD,YACIsgC,EAAkBqtB,EAAqBC,EACvCC,EAA4BC,GAVhC5tD,KAAQyH,SAAG,yBAEXzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GAInD9F,KAAImB,MAAG,EAKLnB,KAAKiH,cAAgB,CAAC,IAAK,OAAQ,YACnCwD,EAAAA,aAAawgB,2BAA2BmV,EAAQqtB,GAChDhjD,EAAAA,aAAawgB,2BAA2BmV,EAAQstB,GAChD1tD,KAAKoN,YAAcgzB,EACnBpgC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAE7B,MAAf6nD,IACFljD,EAAAA,aAAawgB,2BAA2BmV,EAAQutB,GAChD3tD,KAAKiH,cAAcjF,KAAK,WAER,MAAd4rD,IACFnjD,EAAAA,aAAawgB,2BAA2BmV,EAAQwtB,GAChD5tD,KAAKiH,cAAcjF,KAAK,UAE1BhC,KAAK2tD,YAAcA,EACnB3tD,KAAK4tD,WAAaA,EAClB5tD,KAAK6L,UAAY,WAClB,CAEDjF,cACE,IAAIinD,EAAgB,MACI,MAApB7tD,KAAK2tD,cACPE,EAAgB,iCAGlB,IAAIC,EAAe,MACI,MAAnB9tD,KAAK4tD,aACPE,EAAe,gCAiBjB,MAdiB,WACb9mC,EAAK,kQAMiB6mC,kCACDC,sOAO1B,EC9DI,MAAMC,GAAqC,CAChDvkC,WAAYwkC,EAAcA,eAC1BtkC,YAAa,SACbC,WAAY,EAAE3f,SAAQmf,QAAOD,cAC3B,MAAMhiB,EAACA,EAAC+mD,MAAEA,EAAKr3C,OAAEA,EAAMm8B,KAAEA,EAAImb,SAAEA,GAAYlkD,GACrCmkD,gBAACA,GAAmBhlC,EACpBilC,EAAgBllC,EAChBmlC,EAAkB,CAACnnD,EAAa6rC,EAAgBmb,GACtD,IAAIP,EAAc,KACJ,MAAV/2C,IACF+2C,EAAc/2C,EAAOnS,MACrB4pD,EAAgBrsD,KAAK4U,IAEvB,IAAIg3C,EAAa,KACJ,MAATK,IACFL,EAAaK,EAAMxpD,MACnB4pD,EAAgBrsD,KAAKisD,IAEvB,MAAM5oD,EAAU,IAAImoD,GAChBtmD,EAAEzC,MAAOsuC,EAAKtuC,MAAOypD,EAASzpD,MAAOkpD,EAAaC,GAChDtkC,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC64C,KAC9C,OAAOC,EAAc5yC,iBACjBnW,EAASgpD,EAAiBnnD,EAAEb,MAAOijB,EAAY,GCahD,MAAMglC,GAAkC,CAC7C9kC,WAAY+kC,EAAWA,YACvB7kC,YAAa,SACbC,WAtCI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,EAAMkO,KAAEA,EAAIC,uBAAEA,GAA0Bhe,GAC5CpF,QACJA,EAAOyvC,IACPA,EAAGK,WACHA,EAAU2K,UACVA,EAAS/K,gBACTA,EAAepvB,WACfA,EAAUmF,eACVA,GACElB,EAEEm2B,EAAc70C,EAAAA,aAAa80C,wBAAwB7K,GAMzD,OAAO6J,GAAW,CAChBr3C,IACA2S,SACAs4B,SARe1nC,EAAYA,aAAC+0C,kBAC1Bt4C,EAAEzC,MACFoV,EAAOpV,MAA2CG,EAASy6C,EAAWhL,EACtEC,GAAiB,EAAuBgL,GAM1Cp2B,UACAnB,OACAC,yBACAqC,iBACAnF,cAEJ,GCuCO,MAAMspC,GAA2C,CACtDhlC,WAAYilC,EAAoBA,qBAChC/kC,YAAa,SACbC,WA3EI,SAA+BV,GAKnC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC2S,OAAEA,EAAMkO,KAAEA,EAAIC,uBAAEA,GAA0Bhe,GAC5CpF,QAACA,EAAOyvC,IAAEA,EAAGgL,UAAEA,EAAS/K,gBAAEA,EAAepvB,WAAEA,EAAUmF,eAAEA,GACzDlB,EAEJ,IAAIy8B,EAAavG,EACC,MAAduG,IACFA,EAAa,CAAC,EAAG,IAGnBt7C,EAAIA,KAACwC,OACDrC,eAAaikD,+BAA+B9pD,EAASghD,IACrD,IACI,gFAAkBhhD,oBAA0BghD,OAEpD,MAAMzT,EAAW1nC,EAAYA,aAAC+0C,kBAC1Bt4C,EAAEzC,MACFoV,EAAOpV,MAA2CG,EAASghD,EAC3DvR,EAAKC,GAAiB,GAEpB0G,EAA8B,CAAC9zC,EAAG2S,GAElC4L,EAAkB,MAARsC,EACV5C,EAAsD,MAA1B6C,EAE9BvC,GACFu1B,EAAch5C,KAAK+lB,GAEjB5C,GACF61B,EAAch5C,KAAKgmB,GAGrB,MAAMjf,EAAa,CACjB,CAAC7D,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,SAAUpB,EAASmB,WAGrD,IAAIjuC,EA2BJ,OA1BI8sC,EAASsD,UAAY,GAAKtD,EAASuD,SAAW,GAC9CvD,EAASyB,aAAe,GACxBzB,EAAS4K,aAAe5K,EAAS6K,aACL,IAA5B7K,EAAS2B,gBAAmD,IAA3B3B,EAAS4B,eAC1C5B,EAAS4K,WAAa,GAAM,GAC9B13C,EAAU,IAAIggD,GACVlT,EAAU1sB,EAASP,EAAYC,GACnCpc,EAAW/G,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAACjQ,EAAQigD,kBAE/CjgD,EAAU,IAAIogD,GACVtT,EAAU1sB,EAASP,EAAYC,GACnCpc,EAAW/G,KACP,CAACkD,KAAM,QAASoQ,KAAM,CAAC68B,EAASiB,eAChC,CAACluC,KAAM,QAASoQ,KAAM,CAAC68B,EAASgB,cAChC,CAACjuC,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cAAe,CACpE1uC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,kBAG9B,cAAf7uB,IACFnc,EAAW/G,KAAK,CAACkD,KAAM,UAAWoQ,KAAM,CAAC+U,KACzChlB,EAAQoC,UAAY,iBAGlByhB,EAAQ1N,iBAAiBnW,EAAS21C,EAAe,UAAWjyC,EAGlE,SCzEa4lD,GAUX7uD,YAAY8uD,EAAkBnqD,GAL9BzE,KAAAiH,cAA0B,CAAC,IAAK,WAEhCjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,YAAY+iD,IAC7B5uD,KAAK4uD,SAAWA,EAChB5uD,KAAKyH,SAAW,6BAA6BL,EAAkBwnD,KAChE,CAEDhoD,cACE,IAAIioD,EAEFA,EADE7uD,KAAK4uD,SAAW,EACH,sBAEA,mBAiBjB,MAfiB,WACb5nC,EAAK,uSAMiB6nC,oLAS3B,ECOI,MAAMC,GAA+B,CAC1CtlC,WAAYulC,EAAQA,SACpBrlC,YAAa,SACbC,WAhDI,SACFV,GACF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpBxc,OAACA,EAAMqlB,QAAEA,GAAW9nB,EAEpB+nB,EAAeD,EAAQrtB,MACvB26B,EAAYrN,EAAaA,EAAalwB,OAAS,GAC/C09B,EAAaj1B,EAAIA,KAACgO,cAAc7L,EAAOhI,QAEtCg6B,EAAaU,EAAWE,EAAWz6B,GACtC6F,EAAAA,aAAaukD,mBAAmBviD,EAAQqlB,GAEtCm9B,EAAiBrlC,GACnB,CAAC5f,OAAQ,CAAC9C,EAAG4qB,GAAU5I,UAASC,MAAO,CAAC1kB,MAAO,CAAC06B,EAAWC,MACzD8vB,EAAWtlC,GAAQ,CACvB5f,OAAQ,CAAC9C,EAAGuF,GACZyc,UACAC,MAAO,CAAC1kB,MAAO,CAAE6F,OAAKgO,cAAc7L,EAAOhI,OAAS46B,EAAYA,MAElE,GAAInW,EAAQrK,mBAAmB,CAACpS,EAAQqlB,KACnB,WAAjBrlB,EAAOpG,MAAoB,CAC7B,MAAM44B,EAAc/V,EAAQ3T,SAASuc,EAAQ7f,QACvCitB,EAAYhW,EAAQlQ,WAA4BvM,GAChD0iD,EAAW5kB,GACbtL,EAAaC,EAAWzyB,EAAOpG,MAAO84B,EAAWC,EAAWC,EAC5Dz6B,EAAS6H,EAAOhI,MAAO86B,GAE3B,OAAOrW,EAAQrQ,eAAe4lB,EAAahyB,EAAOpG,MAAO8oD,EAAS97C,OACnE,CACD,MAAMhO,EAAU,IAAIspD,GAAgBvvB,EAAW,CAACD,EAAWE,IACrD/V,EACF,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAAC8pB,IAAa,CAACl6B,KAAM,QAASoQ,KAAM1Q,IACzD+E,EAAMuf,EAAQ1N,iBAChBnW,EAAS,CAAC6pD,EAAUD,GAAiBC,EAAS7oD,MAAOijB,GAEnD0tB,EACFptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAOg6B,KAMvD,OAJAvV,EAAQlX,YAAYi9C,EAAeh9C,QACnCiX,EAAQlX,YAAYk9C,EAASj9C,QAC7BiX,EAAQlX,YAAYrI,EAAIsI,QAEjB+kC,CACT,SChDaoY,GAUXtvD,YAAYgoB,EAAkB1a,GAL9BpN,KAAAiH,cAA0B,CAAC,IAAK,WAChCjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc0a,EAAOvgB,QAC1BvH,KAAK8nB,OAASA,EACd9nB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,QAClB,CAEDjF,cACE,MAAMqvC,EAgBV,SAAyBnuB,GACvB,MAAMunC,EAAgB,CAAC,UAAW,UAAW,UAAW,WAClDpZ,EAAe,GACrB,IAAK,IAAInxC,EAAI,EAAGA,EAAIgjB,EAAOjmB,OAAQiD,IACvB,IAANA,EACFmxC,EAAaj0C,KAAK,UAElBi0C,EAAaj0C,KAAK,GAAGqtD,EAAcvqD,MAGvC,OAAOmxC,EAAavvC,MACtB,CA3ByB4oD,CAAgBtvD,KAAK8nB,QAW1C,MAViB,WACbd,EAAK,4SAKuCivB,gCAKjD,EC5BG,SAAUsZ,GACZtmC,GAGF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAAC4qB,QAAEA,GAAW9nB,GACf4+B,KAACA,EAAI4mB,UAAEA,GAAarmC,EAIpBsmC,EAAanlD,EAAIA,KAACw+B,eAAeF,EAAM1hC,EAAEzC,OAAO,GAEhDirD,EAAYjlD,EAAYA,aAACklD,aAAaC,yBACxC1oD,EAAG4qB,EAAS29B,EAAYD,GAEtBK,EAAcvlD,EAAIA,KAACgO,cAAcwZ,EAAQrtB,OAEzC6qC,EAAY,GAEZ4f,EAAWtlC,GAAQ,CACvB5f,OAAQ,CAAC9C,KACTgiB,UACAC,MAAO,CACL1kB,MAAO,CACLirD,EAAUtoB,UAAWsoB,EAAUI,UAAWJ,EAAUK,QACpDL,EAAUrwB,cAKVG,EAAe5V,GAAQ,CAC3B5f,OAAQ,CAAC9C,EAAG4qB,GACZ5I,UACAC,MAAO,CAAC1kB,MAAO,CAACirD,EAAUtoB,UAAWyoB,EAAcH,EAAUtoB,cAG/DkI,EAAUttC,KAAKktD,GACf5f,EAAUttC,KAAKw9B,GAEf,MAAME,EAAqB,CACzBgwB,EAAUtoB,UAAWsoB,EAAUI,UAAWD,EAAcH,EAAUtoB,UAClEsoB,EAAUrwB,WAGZ,GAAInW,EAAQrK,mBAAmB,CAAC3X,EAAG4qB,IAAW,CAC5C,MACMk+B,EADoB9mC,EAAQ/X,UAAUvP,IAAI49B,EAAavtB,QACrBoB,OAClC48C,EACF1uD,EAAAA,OAAOi+B,EAAa/6B,MAAO+6B,EAAan5B,MAAO2pD,GAG7CE,EADqBhnC,EAAQ/X,UAAUvP,IAAIstD,EAASj9C,QACvBoB,OAC7B88C,EACF5uD,EAAAA,OAAO2tD,EAASzqD,MAAOyqD,EAAS7oD,MAAO6pD,GACrC/xB,EAASsM,GAAgB0lB,EAASF,EAAevwB,GAIvD,OAFA4P,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtCiX,EAAQrQ,eACX62C,EAAUtiD,YAAa+wB,EAAO93B,MAAO83B,EAAO9qB,OACjD,CAED,MAAMhO,EAAU,IAAI+pD,GAAcF,EAASzqD,MAAOi7B,GAC5C/1B,EAAMuf,EAAQ1N,iBAChBnW,EAAS,CAAC6pD,EAAU1vB,GAAe0vB,EAAS7oD,OAChDipC,EAAUttC,KAAK2H,GAEf,MAAMqtC,EAAWptB,GACb,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAOirD,EAAUtiD,eAEzD,OADAkiC,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UACtC+kC,CACT,CAEO,MAAMoZ,GAA+B,CAC1C5mC,WAAY6mC,EAAQA,SACpB3mC,YAAa,SACbC,WAAY4lC,IC9EDe,GAAUtiC,GAAiB,CACtCN,OAAQ1O,EAAaoC,QACrBuM,cAAe4iC,GACflqD,MAAO,SAGImqD,GAA8B,CACzChnC,WAAYinC,EAAOA,QACnB/mC,YAAa,SACbC,WAAY2mC,ICTDI,GAAe1iC,GAAiB,CAC3CN,OAAQ1O,EAAaqC,cACrBhb,MAAO,OACPsnB,cAAegjC,KAGJC,GAAmC,CAC9CpnC,WAAYqnC,EAAYA,aACxBnnC,YAAa,SACbC,WAAY+mC,ICDP,MAAMI,GAA2B,CACtCtnC,WAAYunC,EAAIA,KAChBrnC,YAAa,SACbC,WAXI,SAAeV,GAEnB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB9M,MAACA,GAASnS,EAEhB,OAAO6gD,GAAQ1uC,GAAO,EAAoB+M,EAC5C,GCNa8nC,GACTvjC,GAAgB,CAACC,OAAQ5L,EAAY0B,UAAWnd,MAAO,SAE9C4qD,GAA+B,CAC1CznC,WAAY0nC,EAAQA,SACpBxnC,YAAa,SACbC,WAAYqnC,ICNDG,GACT1jC,GAAgB,CAACC,OAAQ5L,EAAY2B,OAAQpd,MAAO,SAE3C+qD,GAA4B,CACvC5nC,WAAY6nC,EAAKA,MACjB3nC,YAAa,SACbC,WAAYwnC,ICRDzwC,GACT+M,GAAgB,CAACC,OAAQ5L,EAAY4B,OAAQrd,MAAO,SAE3CirD,GAA4B,CACvC9nC,WAAY+nC,EAAKA,MACjB7nC,YAAa,SACbC,WAAYjJ,ICUP,MAAM8wC,GAAgC,CAC3ChoC,WAAYioC,EAASA,UACrB/nC,YAAa,SACbC,WAjBI,SAAoBV,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNy9C,MAACA,GAASt+B,EACVG,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACmyC,KACxCpiD,EACF,IAAImoB,GAAetmB,EAAEzC,MAAOqd,EAAYkC,UAAW,gBACvD,OAAOkF,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAI,UAAWoiB,EAC3D,GCZaooC,GAAO1jC,GAChB,CAACN,OAAQ1O,EAAasC,KAAMjb,MAAO,OAAQsnB,cAAegkC,KAEjDC,GAA2B,CACtCpoC,WAAYqoC,EAAIA,KAChBnoC,YAAa,SACbC,WAAY+nC,ICNDI,GAAY9jC,GAAiB,CACxCN,OAAQ1O,EAAauC,WACrBlb,MAAO,OACPsnB,cAAeokC,KAGJC,GAAgC,CAC3CxoC,WAAYyoC,EAASA,UACrBvoC,YAAa,SACbC,WAAYmoC,UCZDI,GAUXpyD,YAAY2E,GATZzE,KAAaiH,cAAa,GAC1BjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,2BACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc,CAAC3I,GACpBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,UAClB,CAEDjF,cAQE,MAPiB,WACbogB,EAAK,6JAOV,ECdI,MAAMmrC,GAA+B,CAC1C3oC,WAAY4oC,EAAQA,SACpB1oC,YAAa,SACbC,WAfI,SAAmBV,GAEvB,MAAMC,QAACA,EAAOC,MAAEA,GAASF,GACnB0J,MAACA,EAAKqN,KAAEA,EAAIC,IAAEA,GAAO9W,EACrB+W,GAAQF,EAAOrN,IAAUsN,EAAM,GAE/B56B,EAAU,IAAI6sD,GAAgBjyB,GAC9B3W,EACF,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACqd,IAAS,CAACztB,KAAM,UAAWoQ,KAAM,CAAC4qB,KAChE,OAAOhX,EAAQ1N,iBAAiBnW,EAAS,GAAI,UAAWikB,EAC1D,GCVa+H,GACT5D,GAAgB,CAACC,OAAQ5L,EAAY8B,IAAK+J,cAAemd,KAEhDunB,GAA0B,CACrC7oC,WAAY8oC,EAAGA,IACf5oC,YAAa,SACbC,WAAY0H,ICLDkhC,GAAQ9kC,GAAgB,CAACC,OAAQ5L,EAAY+B,QAE7C2uC,GAA4B,CACvChpC,WAAYipC,EAAKA,MACjB/oC,YAAa,SACbC,WAAY4oC,ICNDG,GACT1kC,GAAiB,CAACN,OAAQ1O,EAAawC,YAAanb,MAAO,SAElDssD,GAAiC,CAC5CnpC,WAAYopC,EAAUA,WACtBlpC,YAAa,SACbC,WAAY+oC,ICLDG,GAAaplC,GAAgB,CAACC,OAAQ5L,EAAYgC,cAElDgvC,GAAiC,CAC5CtpC,WAAYupC,EAAUA,WACtBrpC,YAAa,SACbC,WAAYkpC,ICNDG,GAAYhlC,GAAiB,CAACN,OAAQ1O,EAAayC,aAEnDwxC,GAAgC,CAC3CzpC,WAAY0pC,EAASA,UACrBxpC,YAAa,SACbC,WAAYqpC,ICNRG,GAAqB,kSAYdC,GAUXtzD,YAAYsgC,GATZpgC,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,qDACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcgzB,EACnBpgC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,KAClB,CAEDjF,cAyBE,MAxBiB,SACfogB,EAAK,ghBAiBDmsC,0EAOP,QAGUE,GAWXvzD,YAAYsgC,EAAkBkzB,GAV9BtzD,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,qDACXzH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GACnD9F,KAAcuzD,eAAG,GAIfjpD,EAAAA,KAAKwC,OACDwmD,GAAUtzD,KAAKuzD,gBACf,IAAM,wCACFvzD,KAAKuzD,qCAAqCD,MAElDtzD,KAAKoN,YAAcgzB,EAInBpgC,KAAKwzD,qBAAuBxzD,KAAK8F,cAAc,GAAK,EAAI9F,KAAKuzD,eAC7DvzD,KAAKsI,eAAiB,CAACpB,EAAG,CAAC,GAAIqB,EAAG,CAAC,GAAIC,EAAG,CAAC,EAAG,IAC9CxI,KAAK+M,SAAWI,EAAgBnN,KAAKsI,eAAgBtI,KAAKoN,YAAa,CACrEpN,KAAKwzD,qBAAsBxzD,KAAK8F,cAAc,GAAI9F,KAAK8F,cAAc,KAEvE9F,KAAK6L,UAAY,YAClB,CAEDjF,cAkCE,MAjCiB,2CACmB5G,KAAK8F,cAAc,0CACxB9F,KAAKwzD,qDACXxzD,KAAKuzD,0BAE5BvsC,q2BAuBImsC,yFAMP,EC/FI,MAAMM,GAA0B,CACrCjqC,WAAYkqC,EAAGA,IACfhqC,YAAa,SACbC,WA9BI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN2pD,YAACA,EAAW5rC,KAAEA,EAAI0/B,MAAEA,EAAKmM,KAAEA,GAAQzqC,EAOzC,IAAI9jB,EAEFA,EADEsuD,EAAc,GACN,IAAIP,GAAWlsD,EAAEzC,OAEjB,IAAI4uD,GAAiBnsD,EAAEzC,MAAOkvD,GAE1C,MAAMrqC,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAACq+C,IAAe,CAACzuD,KAAM,UAAWoQ,KAAM,CAACyS,IAC/D,CAAC7iB,KAAM,UAAWoQ,KAAM,CAACmyC,IAAS,CAACviD,KAAM,UAAWoQ,KAAM,CAACs+C,KAI7D,OAFY1qC,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EAG9D,SC3BauqC,GAUX/zD,YAAYolC,GATZllC,KAAWoN,YAAa,GAIxBpN,KAAaiH,cAAG,CAAC,aAAc,cAAe,MAC9CjH,KAAQyH,SAAG,0DACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc83B,EACnBllC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,UAClB,CAEDjF,cAoDE,MAnDiB,SACfogB,EAAK,wmDAmDR,ECnDI,MAAM8sC,GAA8B,CACzCtqC,WAAYuqC,EAAOA,QACnBrqC,YAAa,SACbC,WArBI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACqB,EAAEA,EAAC8sC,GAAEA,GAAMrrC,GACb2pD,YAACA,EAAW5rC,KAAEA,EAAI0/B,MAAEA,EAAKmM,KAAEA,GAAQzqC,EAEnC9jB,EAAU,IAAIwuD,GAAe3sD,EAAEzC,OAC/B6kB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAACq+C,IAAe,CAACzuD,KAAM,UAAWoQ,KAAM,CAACyS,IAC/D,CAAC7iB,KAAM,UAAWoQ,KAAM,CAACmyC,IAAS,CAACviD,KAAM,UAAWoQ,KAAM,CAACs+C,KAK7D,OAFI1qC,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAGqB,EAAG8sC,GAAKnuC,EAAEb,MAAOijB,EAG7D,GCfa0qC,GAAUhmC,GAAiB,CACtCN,OAAQ1O,EAAaqB,IACrBsN,cAAesmC,KAGJC,GAA8B,CACzC1qC,WAAY2qC,EAAOA,QACnBzqC,YAAa,SACbC,WAAYqqC,ICIP,MAAMI,GAA8B,CACzC5qC,WAAY6qC,EAAOA,QACnB3qC,YAAa,SACbC,WAjBI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNoqC,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGC,gBAAEA,GAAmBnrB,EAMpD,OAAO+pB,GAAShsC,EAJCuD,EAAAA,aAAa8pC,kBAC1BrtC,EAAEzC,MAA2C2vC,EAAYxvC,EAF3C,EAGHyvC,EAAKC,GAES,MAAOprB,EACtC,GC2BO,MAAMorC,GAAgC,CAC3C9qC,WAAY+qC,EAASA,UACrB7qC,YAAa,SACbC,WA1CI,SAAoBV,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNoqC,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGK,WAAEA,EAAUJ,gBAAEA,GAAmBnrB,EAG1DgpB,EAAW1nC,EAAAA,aAAakqC,kBAC1BztC,EAAEzC,MAAmD2vC,EAAYxvC,EAHzB,CAAC,EAAG,EAAG,GAIpCyvC,EAAKC,EAAiBI,GAC/B8f,EAAiB,IAAI7hB,GAAcR,EAAU,OAC7CppC,EAAa,CACjB,CACE7D,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KACI,CAAC68B,EAASqB,QAAQsB,MAAO3C,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAEtE,CACEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS4C,QAAS5C,EAASoB,SAAUpB,EAASmB,UAEvD,CACEpuC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAsB7C,EAAS6B,sBACxC7B,EAAS8B,wBAIf,OAAO/qB,EAAQ1N,iBAAiBg5C,EAAgB,CAACttD,GAAIA,EAAEb,MAAO0C,EAChE,SCrCa0rD,GAYX30D,YAAYqyC,GAPZnyC,KAAAiH,cAAgB,CAAC,KAAM,UACvBjH,KAAAyH,SACI,gIAEJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAE5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,mBAClB,CAEDjF,cA8CE,MA7CiB,WACbogB,EAAK,iqDA6CV,QAGU0tC,GAWX50D,YAAYqyC,GANZnyC,KAAAiH,cAAgB,CAAC,KAAM,UACvBjH,KAAAyH,SAAW,wHAEXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc+kC,EAASkB,QAE5BrzC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,mBAClB,CAEDjF,cA2DE,MA1DiB,WACbogB,EAAK,gnEA0DV,EC/EI,MAAM2tC,GAAoC,CAC/CnrC,WAAYorC,EAAaA,cACzBlrC,YAAa,SACbC,WA7EI,SAAwBV,GAK5B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEl5B,MAAEA,GAASnS,EACd9C,EAAIiV,GACJi4B,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGC,gBAAEA,GAAmBnrB,EAG9CgpB,EAAW1nC,EAAAA,aAAakqC,kBAC1BztC,EAAEzC,MAAmD2vC,EAAYxvC,EAHzB,CAAC,EAAG,EAAG,GAIpCyvC,EAAKC,GAEdugB,EACF,IAAIliB,GAAcR,EAAU,OAAO,GACvC,IAAI7oB,EAAc,CAChB,CACEpkB,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KACI,CAAC68B,EAASqB,QAAQsB,MAAO3C,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAEtE,CACEh4B,KAAM,QACNoQ,KAAM,CAAC68B,EAAS4C,QAAS5C,EAASoB,SAAUpB,EAASmB,UAEvD,CACEpuC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAsB7C,EAAS6B,sBACxC7B,EAAS8B,wBAIf,MAAM6gB,EAAqB5rC,EAAQ1N,iBAC/Bq5C,EAA2B,CAAC3tD,GAAI,QAASoiB,GAEvCyrC,EAA2B,IAAIL,GAAyBviB,GAC9D7oB,EAAc,CACZ,CACEpkB,KAAM,QACNoQ,KAAM,CAAC68B,EAAS0C,YAAa1C,EAASwB,aAAcxB,EAASyB,cAE/D,CACE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAuB,EAAI7C,EAASqB,QAAQsB,MACrD3C,EAAS6B,sBAAwB,EAAI7B,EAASqB,QAAQK,IACtD1B,EAAS8B,qBAAuB,EAAI9B,EAASqB,QAAQtW,OAGzD,CACEh4B,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6C,qBAAsB7C,EAAS6B,sBACxC7B,EAAS8B,uBAGb,CAAC/uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqD,WAChC,CAACtwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,YAElC,MAAMnmB,EAASrG,EAAQ1N,iBACnBu5C,EAA0B,CAAC1f,EAAIyf,GAAqB5tD,EAAEb,MAAOijB,GAGjE,OAFAJ,EAAQlX,YAAY8iD,EAAmB7iD,QAEhCsd,CACT,GCpBO,MAAMylC,GAAkC,CAC7CxrC,WAAYyrC,EAAWA,YACvBvrC,YAAa,SACbC,WAtDI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BosB,GAACA,EAAEl5B,MAAEA,EAAK5W,OAAEA,GAAUyE,EACtB9C,EAAIiV,EACVxN,EAAiB,CAACwN,EAAO5W,GAAS,eAClC,MAAM6uC,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGC,gBAAEA,GAAmBnrB,EAE9CgpB,EAAW1nC,EAAAA,aAAa8pC,kBAC1BrtC,EAAEzC,MAA2C2vC,EAAYxvC,EACzD,EAAmByvC,EAAKC,GAEtB4gB,EAA0B,IAAI9iB,GAAcD,EAAU,OAAO,GACnE,IAAI7oB,EAAc,CAChB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBACzD,CAAC7uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,SAAUpB,EAASmB,UAAW,CAC5DpuC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS6B,sBAAuB7B,EAAS8B,wBAGpD,MAAMkhB,EAAmBjsC,EAAQ1N,iBAC7B05C,EAAyB,CAAChuD,GAAI,QAASoiB,GAErC8rC,EAAyB,IAAIX,GAAyBtiB,GAC5D7oB,EAAc,CACZ,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cAAe,CACpE1uC,KAAM,QACNoQ,KAAM,CACJ68B,EAAS6B,sBAAwB,EAAI7B,EAASqB,QAAQK,IACtD1B,EAAS8B,qBAAuB,EAAI9B,EAASqB,QAAQtW,OAGzD,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBAAiB,CACxE7uC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS6B,sBAAuB7B,EAAS8B,uBAElD,CAAC/uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASsD,YAChC,CAACvwC,KAAM,QAASoQ,KAAM,CAAC68B,EAASuD,YAElC,MAAMnmB,EAASrG,EAAQ1N,iBACnB45C,EAAwB,CAAC/f,EAAI8f,GAAmBjuD,EAAEb,MAAOijB,GAG7D,OAFAJ,EAAQlX,YAAYmjD,EAAiBljD,QAE9Bsd,CACT,GCRO,MAAM8lC,GAAwC,CACnD7rC,WAAY8rC,EAAiBA,kBAC7B5rC,YAAa,SACbC,WA7CI,SAA4BV,GAKhC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BmrB,WAACA,EAAUxvC,QAAEA,EAAOyvC,IAAEA,EAAGkhB,oBAAEA,GAAuBpsC,GAClDjiB,EAACA,GAAK8C,EAEZM,EAAAA,KAAKwC,OACkB,IAAnB5F,EAAEzC,MAAM5C,QACR,IAAM,uDACFqF,EAAEzC,MAAM5C,YAChB,MAAMw9C,EAA8B,CAAC,EAAG,GACxC/0C,EAAIA,KAACwC,OACDrC,eAAaikD,+BAA+B9pD,EAASy6C,IACrD,IACI,wEAAez6C,oBAA0By6C,OAEjD,MAAMlN,EAAW1nC,eAAa8pC,kBAC1BrtC,EAAEzC,MAA2C2vC,EAAYxvC,EACzDy6C,EAAWhL,GAET/qB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC68B,EAASwB,aAAcxB,EAASyB,cACvD,CAAC1uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASqB,QAAQK,IAAK1B,EAASqB,QAAQtW,OAC9D,CAACh4B,KAAM,QAASoQ,KAAM,CAAC68B,EAAS2B,eAAgB3B,EAAS4B,gBACzD,CAAC7uC,KAAM,QAASoQ,KAAM,CAAC68B,EAASoB,SAAUpB,EAASmB,UAAW,CAC5DpuC,KAAM,QACNoQ,KAAM,CAAC68B,EAAS6B,sBAAuB7B,EAAS8B,wBAGpD,IAAI5uC,EAAU,IAAI+sC,GAAcD,EAAU,OAAO,GACjD,MAAMqjB,EACFtsC,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,GAKpD,OAHAjkB,EAAU,IAAI+sC,GAAcD,EAAU,OAAO,GAAM,EAAMojB,GAGlD,CAACC,EADJtsC,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAI,QAASoiB,GAEtD,GC/BO,MAAMmsC,GAA0B,CACrCjsC,WAAYksC,EAAGA,IACfhsC,YAAa,SACbC,WAbI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,EAAIyG,SAAEA,GAAYlmB,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,MAAOnmB,EAC1C,GCPaysC,GAAU3nC,GAAiB,CACtCN,OAAQ1O,EAAasB,IACrBqN,cAAeioC,KAGJC,GAA8B,CACzCrsC,WAAYssC,EAAOA,QACnBpsC,YAAa,SACbC,WAAYgsC,UCXDI,GAYXj2D,YACIsgC,EAAkB41B,EAClBC,GAXJj2D,KAAQyH,SAAG,GAGXzH,KAAAiH,cAAgB,CAAC,KACjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAGlD9F,KAAImB,MAAG,EAKLnB,KAAKoN,YAAc4oD,EAAStxD,KACxB,CAACwxD,EAAGpxD,IAAMoxD,EAAE,GAAqB91B,EAAOt7B,GAAKoxD,EAAE,KACnDl2D,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKogC,OAASA,EACd41B,EAAStxD,KAAI,CAACoD,EAAGhD,KACf9E,KAAKyH,UAAY,OAAO3C,gBAAgB,IAE1C9E,KAAK4W,OAAkB,YAATq/C,EAAqB,EAAI,EACvCj2D,KAAK6L,UAAY,aAAaoqD,GAC/B,CAEDrvD,cACE,MAAM8B,EAAO1I,KAAKogC,OAAOv+B,OAEnB8wB,EAAQ3yB,KAAKogC,OAAO17B,KAAI,CAACoD,EAAGhD,IAAM,eAAeA,SAAQ4B,KAAK,KAC9DqN,EAAM/T,KAAKogC,OACA17B,KACG,CAACoD,EAAGhD,IAAM,eAAeA,yBACrB4D,EAAO,EAAI,IAAI5D,KAAO,OAC7B4B,KAAK,KAEhByvD,EAAuB,IAATztD,EAAa,QAAU,WACrC0tD,EAAqB,IAAT1tD,EAAa,MAAQ,SACjC2tD,EAAsB,IAAT3tD,EAAa,OAAS,UACnCrC,EAAQe,EAAkBsB,GAC1B4tD,EAAiB5tD,EAAO,EAC1B,CAAC,YAAa,YAAa,YAAa,aAAanB,MAAM,EAAGmB,GAC9D,SAEJ,MAAO,WACHse,EAAK,2EAEW3gB,KAASssB,4BACXtsB,KAAS0N,uFAECrL,oCACd2tD,OAAgBF,uBAClBE,OAAgBF,WAAqBE,OAC7Cr2D,KAAK4W,kCACWy/C,QAAiBD,uBACzBC,QAAiBD,gBAAwBC,OACjDr2D,KAAK4W,qHAI4B0/C,gCAItC,EChEI,MAAMC,GAAgC,CAC3C/sC,WAAYgtC,EAASA,UACrB9sC,YAAa,SACbC,WAAY,EAAE3f,SAAQmf,QAAOD,cAC3B,MAAMhiB,EAACA,GAAK8C,GACNgsD,SAACA,EAAQC,KAAEA,GAAQ9sC,EACnBilC,EAAgBllC,EAEhBI,EAAc0sC,EAAStxD,KAAIwxD,IACxB,CAAChxD,KAAM,QAASoQ,KAAM,CAAC4gD,EAAE,GAAIA,EAAE,QAElC7wD,EAAU,IAAI0wD,GAAiB7uD,EAAEzC,MAAOuxD,EAAUC,GAIxD,OAFI7H,EAAc5yC,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EAE7C,GChBJmtC,GAAMzoC,GAAiB,CAACN,OAAQ1O,EAAauB,MAE7Cm2C,GAA0B,CACrCltC,WAAYmtC,EAAGA,IACfjtC,YAAa,SACbC,WAAY8sC,UCPDG,GAUX92D,YAAYsnC,EAAmByvB,GAT/B72D,KAAAiH,cAA0B,CAAC,SAC3BjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,gCACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc,CAACg6B,EAAWyvB,GAC/B72D,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,aAClB,CAEDjF,cAmCE,MAlCiB,iXAWfogB,EAAK,6rBAwBR,QCvDU8vC,GAQXh3D,YAAYsN,GAPZpN,KAAAiH,cAAgB,CAAC,UAQfjH,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAW,CAAC/M,KAAKoN,YAAY,GAAI,EAAG,GACrCpN,KAAKoN,YAAY,IAAM,KACzBpN,KAAK8F,cAAgB,CAAC,IAAK,EAAG,GAE9B9F,KAAK8F,cAAgB,CAAC,GAAI,EAAG,GAE/B9F,KAAK6L,UAAY,SAClB,CAEDjF,cA6DE,MA5DiB,yCACiB5G,KAAK8F,cAAc,+GAGjC9F,KAAK8F,cAAc,YACrCkhB,EAAK,0jDAwDR,EC9EG,SAAU+vC,GACZ9tC,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+tC,OAACA,GAAUhtD,GACXmF,IAACA,GAAOga,EAER8tC,EAAiBrtC,GAAQ,CAC7B5f,OAAQ,CAAC9C,EAAG8vD,GACZ9tC,UACAC,MAAO,CACL1kB,MAAO,CACL6F,EAAAA,KAAKgO,cAAc0+C,EAAOvyD,OAASuyD,EAAOvyD,MAAM0K,GAAM6nD,EAAOvyD,MAAM0K,OAInE9J,EAAU,IAAIyxD,GAAeG,EAAexyD,OAC5CkF,EAAMuf,EAAQ1N,iBAAiBnW,EAAS,CAAC4xD,GAAiBD,EAAO3wD,OACjE6wD,EACFttC,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAOuyD,EAAOvyD,SAG9D,OAFAykB,EAAQlX,YAAYilD,EAAehlD,QACnCiX,EAAQlX,YAAYrI,EAAIsI,QACjBilD,CACT,CAEO,MAAMC,GAA8B,CACzC3tC,WAAY4tC,EAAOA,QACnB1tC,YAAa,SACbC,WAAYotC,ICHP,MAAMM,GAAkC,CAC7C7tC,WAAY8tC,EAAWA,YACvB5tC,YAAa,SACbC,WA5BI,SAAsBV,GAK1B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+tC,OAACA,GAAUhtD,GACX6sD,WAACA,EAAUU,KAAEA,EAAIC,WAAEA,GAAcruC,EAEjCsuC,EAAQD,EACVR,EACAD,GACI,CAAC/sD,OAAQ,CAACgtD,UAAS9tC,UAASC,MAAO,CAACha,IAAK6nD,EAAOvyD,MAAM5C,OAAS,KACjEulC,EAAYqwB,EAAMhzD,MAAM,GACxBizD,EAAcD,EAAMhzD,MAAM,GAC1BY,EAAU,IAAIuxD,GAAmBxvB,EAAWyvB,GAC5CvtC,EACF,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACiiD,IAAQ,CAACryD,KAAM,QAASoQ,KAAM,CAACoiD,KACvD/tD,EAAMuf,EAAQ1N,iBAAiBnW,EAAS,CAACoyD,GAAQ,QAASnuC,GAIhE,OAHKkuC,GACHtuC,EAAQlX,YAAYylD,EAAMxlD,QAErBtI,CACT,GCHO,MAAMguD,GAA0B,CACrCnuC,WAAYouC,EAAGA,IACfluC,YAAa,SACbC,WApBI,SAAcV,GAElB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,GAAK8C,EAEZ,GAAIkf,EAAQrK,mBAAmB,CAAC3X,IAAK,CACnC,MAAM4mB,EAAQ5E,EAAQ/X,UAAUvP,IAAIsF,EAAE+K,SAC/B8b,EAAWoB,GACdkc,GAAWvd,EAAMza,OAAsBnM,EAAEzC,MAAOyC,EAAEb,OACtD,OAAO6iB,EAAQrQ,eAAesW,EAAUjoB,EAAEb,MAAO0nB,EAClD,CAED,MAAM1oB,EAAU,IAAImoB,GAAetmB,EAAEzC,MAAOqd,EAAYiC,KAExD,OAAOmF,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAClD,GCCO,MAAMwxD,GAA0C,CACrDruC,WAAYsuC,EAAmBA,oBAC/BpuC,YAAa,SACbC,WA1BI,SAA8BV,GAKlCld,QAAQyI,KACJ,kGAGJ,MAAMxK,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bw5B,MAACA,EAAKsV,OAAEA,GAAU/tD,GAClBguD,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,GAAkB/uC,EAEhDgvC,EAAYjvC,EAAQ3T,SAASktC,EAAMxwC,QACnCmmD,EAAalvC,EAAQ3T,SAASwiD,EAAO9lD,SAErComD,gBAACA,GAAmBC,EAAAA,aAAaC,wBACnCJ,EAAWC,EAAYJ,EAAeC,EAAcC,GAExD,OAAOhvC,EAAQrQ,eACX,CAACw/C,EAAgBx2D,QAAS,QAAS,IAAI8Y,WAAW09C,GACxD,GCcO,MAAMG,GAA0C,CACrDhvC,WAAYivC,EAAmBA,oBAC/B/uC,YAAa,SACbC,WArCI,SAA8BV,GAKlCld,QAAQyI,KACJ,kGAGJ,MAAMxK,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bw5B,MAACA,EAAKsV,OAAEA,GAAU/tD,GAClBguD,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAcQ,aAAEA,GAAgBvvC,EAE9DgvC,EAAYjvC,EAAQ3T,SAASktC,EAAMxwC,QACnCmmD,EAAalvC,EAAQ3T,SAASwiD,EAAO9lD,QAErC0mD,EAAmBX,EACnBY,EAAkBX,EAClBY,EAAoBX,EACpBY,EAAkBJ,GAElBL,gBAACA,EAAeU,eAAEA,GACpBT,EAAYA,aAACU,wBACTb,EAAWC,EAAYO,EAAkBC,EACzCC,EAAmBC,GAE3B,MAAO,CACL5vC,EAAQrQ,eACJ,CAACw/C,EAAgBx2D,QAAS,QAAS,IAAI8Y,WAAW09C,IACtDnvC,EAAQrQ,eACJ,CAACkgD,EAAel3D,QAAS,UAAW,IAAI+Y,aAAam+C,IAE7D,SCjCaE,GAUXn5D,YAAYumC,EAAoB6yB,GALhCl5D,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,iCACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc,CAACi5B,EAAY6yB,GAChCl5D,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,QAClB,CAEDjF,cAWE,MAViB,WACbogB,EAAK,gSAUV,ECFI,MAAMmyC,GAA6B,CACxC3vC,WAAY4vC,EAAMA,OAClB1vC,YAAa,SACbC,WA5BI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B6I,QAACA,GAAW9nB,GACZ3D,MAACA,EAAK6yD,MAAEA,EAAKG,QAAEA,EAAOC,SAAEA,GAAYnwC,EAEpC0mC,EAAcvlD,EAAIA,KAACgO,cAAcwZ,EAAQrtB,OACzCY,EAAU,IAAI4zD,GAAcpJ,EAAaqJ,GACzCliB,EACFptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG4qB,GAAU5I,UAASC,MAAO,CAAC1kB,MAAO,CAACorD,MAEtDvmC,EACF,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC+jD,IAAW,CAACn0D,KAAM,UAAWoQ,KAAM,CAACgkD,KAC5D/pC,EACFrG,EAAQ1N,iBAAiBnW,EAAS,CAAC2xC,GAAW3wC,EAAOijB,GACzDJ,EAAQlX,YAAYglC,EAAS/kC,QAE7B,MACMuZ,EAAM5B,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGqoB,GAASrG,UAASC,MAAO,CAAC1kB,MAD1C,IAAIqtB,EAAQrtB,MAAOy0D,MAIpC,OAFAhwC,EAAQlX,YAAYud,EAAOtd,QAEpBuZ,CACT,GCpBM,SAAU+tC,GACZtwC,GACF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,GAAK8C,EACZ,GAAgB,cAAZ9C,EAAEb,MAAuB,CAC3B,MAAMwzC,EAAWvnC,GAAK,CAACtI,OAAQ,CAACmS,MAAOjV,GAAIgiB,YACrC0yB,EAAI2d,GAAU,CAACvvD,OAAQ,CAAC9C,EAAG2yC,GAAW3wB,YACtCiiC,EAAW54C,GAAK,CAACvI,OAAQ,CAACmS,MAAOjV,GAAIgiB,YACrCpkB,EAAIy0D,GAAU,CAACvvD,OAAQ,CAAC9C,EAAGikD,GAAWjiC,YAEtCqG,EAASrC,GAAQ,CAACljB,OAAQ,CAACsI,KAAMspC,EAAGrpC,KAAMzN,GAAIokB,YAOpD,OALAA,EAAQlX,YAAY6nC,EAAS5nC,QAC7BiX,EAAQlX,YAAY4pC,EAAE3pC,QACtBiX,EAAQlX,YAAYm5C,EAASl5C,QAC7BiX,EAAQlX,YAAYlN,EAAEmN,QAEfsd,CACR,CACC,OAAOvG,GAAK,CACVG,MAAO,CACL1kB,MAAOyC,EAAEzC,MACT4B,MAAOa,EAAEb,MACTkR,MAAmB,WAAZrQ,EAAEb,MAAqB,GAAK,GAErC6iB,WAGN,CAEO,MAAMswC,GAAgC,CAC3ChwC,WAAYiwC,EAASA,UACrB/vC,YAAa,SACbC,WAAY4vC,ICNP,MAAMG,GAA+B,CAC1ClwC,WAAYmwC,EAAQA,SACpBjwC,YAAa,SACbC,WA7BI,SAAUiwC,EACZ3wC,GACF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,GAAK8C,EAEZ,GAAgB,WAAZ9C,EAAEb,MACJ,MAAM,IAAIhE,MAAM,gDACX,GAAgB,cAAZ6E,EAAEb,MAAuB,CAClC,MAAMwzC,EAAWvnC,GAAK,CAACtI,OAAQ,CAACmS,MAAOjV,GAAIgiB,YACrC0yB,EAAIge,EAAS,CAAC5vD,OAAQ,CAAC9C,EAAG2yC,GAAW3wB,YACrCiiC,EAAW54C,GAAK,CAACvI,OAAQ,CAACmS,MAAOjV,GAAIgiB,YACrCpkB,EAAIy0D,GAAU,CAACvvD,OAAQ,CAAC9C,EAAGikD,GAAWjiC,YAEtCqG,EAASrC,GAAQ,CAACljB,OAAQ,CAACsI,KAAMspC,EAAGrpC,KAAMzN,GAAIokB,YAOpD,OALAA,EAAQlX,YAAY6nC,EAAS5nC,QAC7BiX,EAAQlX,YAAY4pC,EAAE3pC,QACtBiX,EAAQlX,YAAYm5C,EAASl5C,QAC7BiX,EAAQlX,YAAYlN,EAAEmN,QAEfsd,CACR,CACC,OAAOvG,GAAK,CAACG,MAAO,CAAC1kB,MAAOyC,EAAEzC,MAAO4B,MAAOa,EAAEb,MAAOkR,MAAO,GAAI2R,WAEpE,GCUO,MAAM2wC,GAA2B,CACtCrwC,WAAYswC,EAAIA,KAChBpwC,YAAa,SACbC,WAzCI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B2f,KAACA,GAAQzf,EAEf,GAAsB,IAAlBnf,EAAOnI,OACT,OAAOwnD,GACH,CAACr/C,OAAQ,CAACmS,MAAOnS,EAAO,IAAKkf,UAASC,MAAO,CAACha,IAAKy5B,KAGzD,MAAMnkC,EAAQuF,EAAO,GAAGvF,MAClB4B,EAAQ2D,EAAO,GAAG3D,MAExB2D,EAAOtH,SAAQqM,IACbzE,EAAIA,KAACyvD,kBACDt1D,EAAOsK,EAAEtK,MACT,yDACJ6F,EAAIA,KAACwC,OACDzG,IAAU0I,EAAE1I,OACZ,IAAM,yDAAwD,IAGpE,MAAMyqC,EAAwC,GAQxCvhB,EAASrS,GAAO,CAAClT,OAPCA,EAAOtF,KAAIqK,IACjC,MAAMirD,EACF3Q,GAAW,CAACr/C,OAAQ,CAACmS,MAAOpN,GAAIma,UAASC,MAAO,CAACha,IAAKy5B,KAE1D,OADAkI,EAAwB9uC,KAAKg4D,GACtBA,CAAS,IAG8B9wC,UAASC,MAAO,CAACyf,UAIjE,OAFAkI,EAAwBpuC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEpDsd,CACT,YCvCgB0qC,GAAUx1D,EAAiBy1D,GAAW,GACpD,MAAMxxD,EAAOjE,EAAM5C,OACbqD,EAAOkC,EAAkBsB,GACzBiqB,EAAQluB,EAAMC,KAAI,CAACoD,EAAGhD,IAAM,eAAeA,SAAQ4B,KAAK,KACxDqN,EAAMtP,EACKC,KACG,CAACoD,EAAGhD,IAAM,eAAeA,yBACrB4D,EAAO,EAAI,IAAI5D,KAAO,OAC7B4B,KAAK,KAYtB,MAAO,yBAXYgC,EAAO,EAAI,GAAGxD,KAAQytB,KAAW,GAAGA,2BACtCjqB,EAAO,EAAI,GAAGxD,KAAQ6O,KAAS,GAAGA,qBAG/CrL,EAAO,EAAI,4BAA8B,6BAEzCA,EAAO,EAAI,2BAA6B,+DASVwxD,EAAW,EAAM,sIAP5BxxD,EAAO,EAC1B,CAAC,YAAa,YAAa,YAAa,aAAanB,MAAM,EAAGmB,GAC9D,4BAWN,OAEayxD,GAWXr6D,YAAYsgC,EAAkB41B,GAN9Bh2D,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,uBACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc4oD,EAAStxD,KACxB,CAACwxD,EAAGpxD,IAAMoxD,EAAE,GAAqB91B,EAAOt7B,GAAKoxD,EAAE,KACnDl2D,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChDkwD,EAAStxD,KAAI,CAACoD,EAAGhD,KACf9E,KAAKyH,UAAY,OAAO3C,gBAAgB,IAE1C9E,KAAKogC,OAASA,EACdpgC,KAAK6L,UAAY,KAClB,CAEDjF,cASE,MARiB,WACbogB,EAAK,wHAGDizC,GAAUj6D,KAAKogC,mCAKxB,EC9DI,MA2BMg6B,GAA4B,CACvC5wC,WAAY6wC,EAAKA,MACjB3wC,YAAa,SACbC,WA7BGV,IAGC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNgsD,SAACA,EAAQsE,cAAEA,GAAiBnxC,EAClC,GAAI6sC,EAAS9mD,OAAMgnD,GAAK5rD,OAAKC,YAAY2rD,EAAG,CAAC,EAAG,MAC9C,OAAOnpC,GAAS,CAAC/iB,OAAQ,CAAC9C,KAAIgiB,YAEhC,GAAoC,IAAhC5e,EAAIA,KAACgO,cAAcpR,EAAEzC,OAAc,CAMrC,OAAOukB,GAAK,CACVE,UACAC,MAAO,CAAC1kB,MALUuxD,EAAStxD,KACzB,CAACwxD,EAAGpxD,IACAoxD,EAAE,GAAqBhvD,EAAEzC,MAAMK,GAAKoxD,EAAE,KAGhB3+C,MAAO+iD,EAAej0D,MAAOa,EAAEb,QAE9D,CACD,MAAMijB,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAACglD,KAC9CtE,EAAStxD,KAAIwxD,GAAK5sC,EAAYtnB,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAAC4gD,EAAE,GAAIA,EAAE,QAClE,MAAM7wD,EAAU,IAAI80D,GAAWjzD,EAAEzC,MAAOuxD,GACxC,OAAO9sC,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EAAY,GC1B5DixC,GAAMvsC,GAAiB,CAClCN,OAAQ1O,EAAayB,MAGV+5C,GAA0B,CACrChxC,WAAYixC,EAAGA,IACf/wC,YAAa,SACbC,WAAY4wC,ICIP,MAAMG,GAA4B,CACvClxC,WAAYmxC,EAAKA,MACjBjxC,YAAa,SACbC,WAZI,SAAgBV,GAEpB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB/hB,EAACA,EAACugD,MAAEA,GAASz9C,EAEb3E,EAAU,IAAI+mB,GAAgBpN,EAAa2C,MAAOza,EAAEzC,MAAOgjD,EAAMhjD,OACvE,OAAOykB,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,EAAGugD,GAAQ,UACvD,GCCO,MAAMmT,GAA2B,CACtCpxC,WAAYy5B,EAAIA,KAChBv5B,YAAa,SACbC,WAbI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN4+B,KAACA,EAAIyG,SAAEA,GAAYlmB,EAEzB,OAAOwd,GAAOz/B,EAAG0hC,EAAMyG,EAAU,OAAQnmB,EAC3C,GCAa2xC,GAA4B,CACvCrxC,WAAYsxC,EAAKA,MACjBpxC,YAAa,SACbC,WAVGV,IACC,MAAMC,QAACA,EAAOC,MAAEA,GAASF,GACnB0J,MAACA,EAAKqN,KAAEA,EAAIE,KAAEA,EAAI75B,MAAEA,GAAS8iB,EAC7B9V,EAASq4B,GAAa/Y,EAAOqN,EAAME,EAAM75B,GAC/C,OAAO6iB,EAAQrQ,eAAe,CAACxF,EAAOxR,QAASwE,EAAOgN,EAAO,GCLtD0nD,GAAU/sC,GAAiB,CAACN,OAAQ1O,EAAagC,MAEjDg6C,GAA8B,CACzCxxC,WAAYyxC,EAAOA,QACnBvxC,YAAa,SACbC,WAAYoxC,ICNDG,GAAaztC,GAAgB,CAACC,OAAQ5L,EAAYmC,aAElDk3C,GAAiC,CAC5C3xC,WAAY4xC,EAAUA,WACtB1xC,YAAa,SACbC,WAAYuxC,ICLDG,GAAO5tC,GAAgB,CAACC,OAAQ5L,EAAYoC,OAE5Co3C,GAA2B,CACtC9xC,WAAY+xC,EAAIA,KAChB7xC,YAAa,SACbC,WAAY0xC,ICLDG,GAAQ/tC,GAAgB,CAACC,OAAQ5L,EAAYqC,QAE7Cs3C,GAA4B,CACvCjyC,WAAYkyC,EAAKA,MACjBhyC,YAAa,SACbC,WAAY6xC,UCNDG,GAUX77D,YACIolC,EAA8C02B,EAC9CC,GAPJ77D,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,yDACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAKLnB,KAAKoN,YAAc,CAAC83B,EAAW,GAAI02B,EAAWC,EAAU32B,EAAW,IAEnEllC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK6L,UAAY,gBAClB,CAEDjF,cA6CE,MA5CiB,WACbogB,EAAK,kvDA4CV,EC3CI,MAAM80C,GAAqC,CAChDtyC,WAAYuyC,EAAcA,eAC1BryC,YAAa,SACbC,WA3BI,SAAyBV,GAK7B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+yC,OAACA,GAAUhyD,GACXiyD,aAACA,EAAY96D,KAAEA,EAAI+6D,iBAAEA,GAAoB/yC,GAExCyyC,EAAWC,GAAY16D,EAIxBmoB,EAAc,CAClB,CAACpkB,KAAM,UAAWoQ,KAAM,CAJL2mD,GAAgBL,EAAY,EAAI,EAAM,EACvCK,GAAgBJ,EAAW,EAAI,EAAM,IAIvD,CAAC32D,KAAM,UAAWoQ,KAAM,CAHI4mD,EAAmB,GAAM,KAMjD72D,EAAU,IAAIs2D,GAChBK,EAAOv3D,MAA2Cm3D,EAAWC,GAEjE,OAAO3yC,EAAQ1N,iBAAiBnW,EAAS,CAAC22D,GAAS,UAAW1yC,EAChE,SCxBa6yC,GAaXr8D,YACIolC,EAA8C+2B,GATlDj8D,KAAAiH,cAAgB,CAAC,MACjBjH,KAAAyH,SACI,mLAEJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAILnB,KAAKoN,YAAc83B,EAEnBllC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKi8D,aAAeA,EACpBj8D,KAAK6L,UAAY,0BAA0BowD,GAC5C,CAEDr1D,cA4EE,MA3EiB,WACbogB,EAAK,osFA2EV,ECpDI,MAAMo1C,GAAyC,CACpD5yC,WAAY6yC,EAAkBA,mBAC9B3yC,YAAa,SACbC,WAnDI,SAA6BV,GAKjC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+yC,OAACA,EAAM3mB,GAAEA,GAAMrrC,GACfiyD,aAACA,GAAgB9yC,GAEd,CAAAmzC,EAAS9e,GACdwe,EAAOv3D,OACF,CAAA83D,EAASC,GAAUnnB,EAAG5wC,MAEzBg4D,EAAmC,CACtCR,GAAgBM,EAAU,EAAKD,EAAU,EAAIA,EAC7CL,GAAgBO,EAAS,EAAKhf,EAAS,EAAIA,GAGxCkf,EAAmC,CACtCT,GAAgBM,EAAU,EAAKA,EAAU,EAAIA,EAC7CN,GAAgBO,EAAS,EAAKA,EAAS,EAAIA,GAGxCva,EAAcwa,EAAe,GAAKC,EAAe,GACjDta,EAAaqa,EAAe,GAAKC,EAAe,GAEhDC,EAAiB,EAAI1a,EACrB2a,EAAgB,EAAIxa,EAIpBya,EAAyC,EAA5Bv4D,KAAKmJ,KAAKkvD,GAAuB,EAC9CG,EAAuC,EAA3Bx4D,KAAKmJ,KAAKmvD,GAAsB,EAE5Cv3D,EAAU,IAAI82D,GAChBH,EAAOv3D,MAA2Cw3D,GAChD3yC,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAMmnD,GACtB,CAACv3D,KAAM,QAASoQ,KAAMonD,GACtB,CAACx3D,KAAM,UAAWoQ,KAAM,CAAC2sC,IACzB,CAAC/8C,KAAM,UAAWoQ,KAAM,CAAC8sC,IACzB,CAACl9C,KAAM,UAAWoQ,KAAM,CAACqnD,IACzB,CAACz3D,KAAM,UAAWoQ,KAAM,CAACsnD,IACzB,CAAC13D,KAAM,QAASoQ,KAAM,CAACunD,IAAa,CAAC33D,KAAM,QAASoQ,KAAM,CAACwnD,KAE7D,OAAO5zC,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,GAAKA,EAAGhvC,MAAOijB,EAC3D,SChDayzC,GAWXj9D,YACIolC,EAA8C02B,EAC9CC,EAAkBK,GARtBl8D,KAAAiH,cAAgB,CAAC,KACjBjH,KAAQyH,SAAG,kDACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAKLnB,KAAKoN,YAAc,CAAC83B,EAAW,GAAI02B,EAAWC,EAAU32B,EAAW,IAEnEllC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAE9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKk8D,iBAAmBA,EACxBl8D,KAAK6L,UAAY,iBAAiBqwD,GACnC,CAEDt1D,cACE,IAAIo2D,EAEFA,EADEh9D,KAAKk8D,iBAEH,0FAGgB,kDAmCtB,MAhCiB,WACbl1C,EAAK,0uBAmBuBg2C,ybAajC,ECzCI,MAAMC,GAA4C,CACvDzzC,WAAY0zC,EAAqBA,sBACjCxzC,YAAa,SACbC,WA5BI,SAAgCV,GAKpC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+yC,OAACA,GAAUhyD,GACXiyD,aAACA,EAAYC,iBAAEA,EAAgB/6D,KAAEA,GAAQgoB,GAExCyyC,EAAWC,GAAY16D,EAKxBmoB,EAAc,CAClB,CAACpkB,KAAM,UAAWoQ,KAAM,CALL2mD,GAAgBL,EAAY,EAAI,EAAM,EACvCK,GAAgBJ,EAAW,EAAI,EAAM,IAKvD,CAAC32D,KAAM,UAAWoQ,KAAM,CAHR2mD,EAAe,GAAM,KAMjC52D,EAAU,IAAI03D,GAChBf,EAAOv3D,MAA2Cm3D,EAAWC,EAC7DK,GACJ,OAAOhzC,EAAQ1N,iBAAiBnW,EAAS,CAAC22D,GAASA,EAAO31D,MAAOijB,EACnE,SCzBa6zC,GAaXr9D,YACIolC,EAA8C+2B,GATlDj8D,KAAAiH,cAAgB,CAAC,MACjBjH,KAAAyH,SACI,8IAEJzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAILnB,KAAKoN,YAAc83B,EAEnBllC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKi8D,aAAeA,EACpBj8D,KAAK6L,UAAY,gCAAgCowD,GAClD,CAEDr1D,cAiEE,MAhEiB,WACbogB,EAAK,8lDA2CLhnB,KAAKi8D,aAAe,6BACA,kJAKpBj8D,KAAKi8D,aAAe,6BACA,kTAczB,EC5CI,MAAMmB,GAAgD,CAC3D5zC,WAAY6zC,EAAyBA,0BACrC3zC,YAAa,SACbC,WAhDI,SAAoCV,GAKxC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+yC,OAACA,EAAM3mB,GAAEA,GAAMrrC,GACfiyD,aAACA,GAAgB9yC,GAEd,CAAAmzC,EAAS9e,GAAUwe,EAAOv3D,OAC1B,CAAA83D,EAASC,GAAUnnB,EAAG5wC,MAEzBg4D,EAAmC,CACtCR,GAAgBM,EAAU,EAAKD,EAAU,EAAIA,EAC7CL,GAAgBO,EAAS,EAAKhf,EAAS,EAAIA,GAGxCkf,EAAmC,CACtCT,GAAgBM,EAAU,EAAKA,EAAU,EAAIA,EAC7CN,GAAgBO,EAAS,EAAKA,EAAS,EAAIA,GAMxCG,EAAiB,GAHHF,EAAe,GAAKC,EAAe,IAIjDE,EAAgB,GAHHH,EAAe,GAAKC,EAAe,IAOhDG,EAAyC,EAA5Bv4D,KAAKmJ,KAAKkvD,GAAuB,EAC9CG,EAAuC,EAA3Bx4D,KAAKmJ,KAAKmvD,GAAsB,EAE5Cv3D,EAAU,IAAI83D,GAChBnB,EAAOv3D,MAA2Cw3D,GAChD3yC,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAMmnD,GACtB,CAACv3D,KAAM,QAASoQ,KAAMonD,GACtB,CAACx3D,KAAM,UAAWoQ,KAAM,CAACqnD,IACzB,CAACz3D,KAAM,UAAWoQ,KAAM,CAACsnD,IACzB,CAAC13D,KAAM,QAASoQ,KAAM,CAACunD,IAAa,CAAC33D,KAAM,QAASoQ,KAAM,CAACwnD,KAE7D,OAAO5zC,EAAQ1N,iBAAiBnW,EAAS,CAACgwC,GAAKA,EAAGhvC,MAAOijB,EAC3D,SC7Cag0C,GAUXx9D,YAAYsgC,GALZpgC,KAAAiH,cAAgB,CAAC,KAEjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAcgzB,EACnBpgC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKyH,SAAW,qBAChBzH,KAAK6L,UAAY,SAClB,CAEDjF,cAiCE,MAXiB,gvBAEbogB,EAAK,yTAUV,ECPI,MAAMu2C,GAA8B,CACzC/zC,WAAYg0C,EAAOA,QACnB9zC,YAAa,SACbC,WA5CI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNpB,KAACA,GAAQugB,EAETuf,EAAQxhC,EAAEzC,MAAM5C,OACtB,GAAc,IAAV6mC,EACF,OAAO3b,GAAS,CAAC/iB,OAAQ,CAAC9C,KAAIgiB,YAGhC,MAAMkX,EAASl5B,EAAEzC,MACXg5D,EAA6C,CAAC,EAAG,EAAG,EAAG,GAC7Dr9B,EAAO19B,SAAQ,CAACiC,EAAGG,KAEjB24D,EADc34D,EAAI,EAAI4jC,GACJ/jC,CAAC,IAGrB,MAAM6qC,EAAOllC,EAAAA,KAAKw+B,eAAelgC,EAAM1B,EAAEzC,OACnCi5D,EAA2C,CAAC,EAAG,EAAG,EAAG,GAC3DluB,EAAK9sC,SAAQi7D,IAEXD,EADcC,EAAK,EAAIj1B,GACP,CAAC,IAEnB,MAAMpf,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAMooD,IAErChf,EAAY90B,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAOg5D,KAE1Dp4D,EAAU,IAAIi4D,GAAeG,GAC7BpqD,EAAS6V,EAAQ1N,iBACnBnW,EAAS,CAACq5C,GAAYA,EAAUr4C,MAAOijB,GAC3CJ,EAAQlX,YAAY0sC,EAAUzsC,QAE9B,MAAMsd,EACF3F,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGmM,GAAS6V,UAASC,MAAO,CAAC1kB,MAAO27B,KAG1D,OAFAlX,EAAQlX,YAAYqB,EAAOpB,QAEpBsd,CACT,SC5CaquC,GAWX99D,YACI0rD,EACAqS,GAZJ79D,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,KAEjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAElD9F,KAAImB,MAAG,EAKLnB,KAAKoN,YAAco+C,EACnBxrD,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKyH,SAAW,+EAEhBzH,KAAK6L,UAAY,SACjB7L,KAAKoN,YAAco+C,EAEM,iBAAdqS,GACT79D,KAAKyH,UAAY,oBACjBzH,KAAK89D,YAAc,wCACnB99D,KAAK6L,WAAa,WAElB7L,KAAKyH,UAAY,0BACjBzH,KAAK89D,YAAc,mDACnB99D,KAAK6L,WAAa,QAErB,CAEDjF,cAsBE,MArBiB,aACXogB,EAAK,onBAWDhnB,KAAK89D,qTAUhB,ECtDI,MAAMC,GAAuC,CAChDv0C,WAAYw0C,EAAgBA,iBAC5Bt0C,YAAa,SACbC,WAAY,EAAE3f,SAAQmf,QAAOD,cAC3B,MAAMs5B,MAACA,GAASx4C,GACVi0D,QAACA,EAAOJ,UAAEA,EAASK,OAAEA,GACvB/0C,EACEyE,EAAgB1E,EAEhB7jB,EAAU,IAAIu4D,GAAepb,EAAmB/9C,MAAOo5D,IACtDM,EAASC,GACZ3zD,EAAYA,aAAC4zD,eAAeH,EAAQ1b,EAAM/9C,MAAM,GAAI+9C,EAAM/9C,MAAM,IAC9D6kB,EAAc,CACd,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC6oD,IACzB,CAACj5D,KAAM,UAAWoQ,KAAM,CAAC8oD,IACzB,CAACl5D,KAAM,UAAWoQ,KAAM,CAAChR,KAAKg6D,IAAIL,KAClC,CAAC/4D,KAAM,UAAWoQ,KAAM,CAAChR,KAAKy8C,IAAIkd,MAGf,iBAAdJ,EACTv0C,EAAYtnB,KACR,CAACkD,KAAM,UAAWoQ,KAAM,CAAC/U,OAAOg+D,WAAWV,EAAUW,QAAQ,OAEjEl1C,EAAYtnB,KAAK,CAACkD,KAAM,UAAWoQ,KAAMuoD,IAK3C,OAFejwC,EAAcpS,iBACzBnW,EAAS,CAACm9C,GAAQA,EAAMn8C,MAAOijB,EACtB,GC5BNm1C,GAAQhxC,GAAgB,CAACC,OAAQ5L,EAAYsC,QAE7Cs6C,GAA4B,CACvCl1C,WAAYm1C,EAAKA,MACjBj1C,YAAa,SACbC,WAAY80C,ICNDG,GACTnxC,GAAgB,CAACC,OAAQ5L,EAAYuC,MAAOsJ,cAAege,KAElDkzB,GAA4B,CACvCr1C,WAAYs1C,EAAKA,MACjBp1C,YAAa,SACbC,WAAYi1C,UCLDG,GAeXj/D,YACIk/D,EAAyBpQ,EAAkBqQ,EAC3CC,EAAqBt6D,EAAmBH,EACxCgX,EAAuBinB,GAAiB,GAjB5C1iC,KAAAiH,cAAgB,CAAC,UAAW,WAO5BjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAIlD9F,KAAMkI,QAAG,EAOPlI,KAAKoN,YAAc3I,EACnBzE,KAAKkF,KAAOuW,EACZzb,KAAK0iC,eAAiBA,EACtB1iC,KAAKsI,eAAiB8F,EAAmB4wD,GAEzCh/D,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgB02D,EAAeh/D,KAAK8F,eAC7D9F,KAAKm/D,uBAAyBvQ,EAAW,EACzC5uD,KAAK6L,UAAY,WAAWozD,KAAeC,KACvCl/D,KAAKm/D,0BAA0B1jD,KAAeinB,IAClD,MAAM08B,EAAch4D,EAAkBxC,EAAQ/C,QAC9C7B,KAAKyH,SACD,4BAA4B23D,uBAChCp/D,KAAKk/D,YAAcA,EACnBl/D,KAAKi/D,YAAcA,CACpB,CAEDr4D,cACE,IAAIy4D,EAAgB,GACK,IAArBr/D,KAAKi/D,YACPI,EAAgB,YACc,IAArBr/D,KAAKi/D,cACdI,EAAgB,gBAElB,MAAMC,EAAiB,cAAcD,KAE/BxQ,EAAe7uD,KAAKm/D,uBAAyB,sBACA,mBAEnD,IAAII,EAAkB,GAClBC,EAAgC,GACC,IAAjCx/D,KAAKsI,eAAepB,EAAErF,QACxB09D,EAAkB,iBAClBC,EAAgC,0GAKU,IAAjCx/D,KAAKsI,eAAepB,EAAErF,SAC/B09D,EAAkB,uCAClBC,EAAgC,ugBAalC,MAEMC,EAAiB,cADnB56D,MAAMw5B,KAAK,CAACx8B,OAAQ7B,KAAKk/D,cAAc,CAACp3D,EAAG27B,IAAQ,UAAUA,OACd/8B,KAAK,SAwBxD,MAtBiB,SACf84D,YACEx4C,EAAK,oQAK6Bs4C,qEACoBzQ,+DAG9CzoD,EAAkBpG,KAAKkF,SAASu6D,2DACKF,oBAG7Cv/D,KAAK0iC,eACD39B,EACI,qBAAsB,cACtB/E,KAAKkF,MACT,mFAIT,ECnDI,MAAMw6D,GAAgC,CAC3Cl2C,WAAYm2C,EAASA,UACrBj2C,YAAa,SACbC,WAjDI,SAAoBV,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B6I,QAACA,EAAO0Q,QAAEA,GAAWx4B,GACrBvF,MAACA,GAAS0kB,GAEViW,UAACA,EAASqD,WAAEA,EAAUpD,UAAEA,EAASz6B,QAAEA,EAAOuyB,WAAEA,GAC9C1sB,EAAAA,aAAam1D,gBAAgBp9B,EAAS1Q,EAASrtB,GAE7Ck+B,EAAe,CAACxL,EAAakI,EAAWA,GAE9C,GAAmB,IAAflI,EACF,OAAOjO,EAAQrQ,eAAepU,EAAOqtB,EAAQzrB,OAG/C,MAAM4oD,EAAiBrlC,GACnB,CAAC5f,OAAQ,CAAC9C,EAAG4qB,GAAU5I,UAASC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYrD,MAC1D8vB,EAAWtlC,GACb,CAAC5f,OAAQ,CAAC9C,EAAGs7B,GAAUtZ,UAASC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYpD,MAE1Dn6B,EAAOgqD,EAAS7oD,MAChBd,EACFyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAOk+B,EAAcprB,MAAO,EAAGlR,MAAOnB,KAE3DokB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC8pB,IAAa,CAACl6B,KAAM,QAASoQ,KAAM1Q,GAC1D,CAACM,KAAM,QAASoQ,KAAM,CAHXhL,EAAIA,KAACgO,cAAc42C,EAASzqD,UAKnCY,EAAU,IAAI05D,GAChB7P,EAASzqD,MAAO26B,EAAW6vB,EAAexqD,MAAM5C,OAChDqtD,EAASzqD,MAAM5C,OAAQ+C,EAAS+9B,EAAcz9B,GAC5CyE,EAAMuf,EAAQ1N,iBAChBnW,EAAS,CAAC6pD,EAAUD,GAAiB/pD,EAAMokB,EAAa/jB,GAEtDyxC,EAAWptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,WAM7D,OAJAykB,EAAQlX,YAAYi9C,EAAeh9C,QACnCiX,EAAQlX,YAAYk9C,EAASj9C,QAC7BiX,EAAQlX,YAAYrI,EAAIsI,QAEjB+kC,CACT,SCjDa6oB,GAWX//D,YAAYsN,EAA+B0yD,GAV3C9/D,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,iBAAkB,UACnCjH,KAAQyH,SAAG,mBACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAILnB,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAK8/D,KAAOA,EACZ9/D,KAAK6L,UAAY,iBAAiBi0D,GACnC,CAEDl5D,cA0BE,MAxBiB,oPADqB,SAAd5G,KAAK8/D,KAAkB,IAAM,6JAgBjD94C,EAAK,yPAUV,EC9BI,MAAM+4C,GAAmC,CAC9Cv2C,WAAYw2C,EAAYA,aACxBt2C,YAAa,SACbC,WAnBI,SAAuBV,GAK3B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bg3C,eAACA,EAAc5sD,OAAEA,GAAUrJ,GAC3B81D,KAACA,GAAQ32C,EAET9jB,EACF,IAAIw6D,GAAoB,CAACxsD,EAAO5O,MAAM,GAAI4O,EAAO5O,MAAM,IAAKq7D,GAC1Dx2C,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAAC2qD,EAAex7D,MAAM,MACjE,OAAOykB,EAAQ1N,iBACXnW,EAAS,CAAC46D,EAAgB5sD,GAAS,QAASiW,EAClD,SChBa42C,GAWXpgE,YAAYqgE,EAAe17D,EAAiBiE,GAV5C1I,KAAaiH,cAAG,CAAC,IAAK,IAAK,KAK3BjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAGlD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAEhD9F,KAAKmgE,MAAQA,EACbngE,KAAK0I,KAAOA,EACZ1I,KAAK6L,UAAY,QAClB,CAEDjF,cAEE,IAAIw5D,EACAC,EACJ,GAAIrgE,KAAK0I,KAAO,EACd,MAAMrG,MAAM,kBAAkBrC,KAAK0I,6BAGrC,GAAkB,IAAd1I,KAAK0I,KACP23D,EAAW,QACXD,EAAU,YACL,CACL,MAAM/Q,EAAgB,CAAC,UAAW,UAAW,UAAW,WAClDiR,EAAa,GACbC,EAAc,GACpB,IAAK,IAAIz7D,EAAI,EAAGA,EAAI9E,KAAKoN,YAAYvL,OAAQiD,IAC3Cy7D,EAAYv+D,KAAK,GAAGqtD,EAAcvqD,MAC9BA,EAAI9E,KAAKmgE,OACXG,EAAWt+D,KAAK,GAAGqtD,EAAcvqD,MAGrCs7D,EAAUE,EAAW55D,OACrB25D,EAAWE,EAAY75D,MACxB,CAeD,MAbiB,WACbsgB,EAAK,iIAGeo5C,+EAEeC,sEAEAA,6CAMxC,EChDI,MAAMG,GAA6B,CACxCh3C,WAAYi3C,EAAMA,OAClB/2C,YAAa,SACbC,WAdI,SAAiBV,GAErB,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpBk6B,UAACA,EAASp0C,EAAEA,EAACsF,EAAEA,GAAKrK,EAEpB3E,EACF,IAAI66D,GAAc/c,EAAU1+C,MAAM5C,OAAQkN,EAAEtK,MAAOsK,EAAEtK,MAAM5C,QAC/D,OAAOqnB,EAAQ1N,iBACXnW,EAAS,CAAC89C,EAAWp0C,EAAGsF,GAAIoa,EAAAA,WAAW1f,EAAE1I,MAAOgO,EAAEhO,OACxD,GCRaq6D,GAAOjzC,GAAgB,CAACC,OAAQ5L,EAAYQ,OAE5Cq+C,GAA2B,CACtCn3C,WAAYo3C,EAAIA,KAChBl3C,YAAa,SACbC,WAAY+2C,ICPDG,GAAUpzC,GAAgB,CAACC,OAAQ5L,EAAYwC,UAE/Cw8C,GAA8B,CACzCt3C,WAAYu3C,EAAOA,QACnBr3C,YAAa,SACbC,WAAYk3C,ICHDxjC,GAAO5P,GAAgB,CAACC,OAAQ5L,EAAYyC,OAE5Cy8C,GAA2B,CACtCx3C,WAAYy3C,EAAIA,KAChBv3C,YAAa,SACbC,WAAY0T,ICLDihC,GAAM7wC,GAAgB,CAACC,OAAQ5L,EAAY0C,MAE3C08C,GAA0B,CACrC13C,WAAY23C,EAAGA,IACfz3C,YAAa,SACbC,WAAY20C,ICLD8C,GAAO3zC,GAAgB,CAACC,OAAQ5L,EAAY2C,OAE5C48C,GAA2B,CACtC73C,WAAY83C,EAAIA,KAChB53C,YAAa,SACbC,WAAYy3C,ICLDG,GAAW9zC,GAAgB,CAACC,OAAQ5L,EAAY4C,WAEhD88C,GAA+B,CAC1Ch4C,WAAYi4C,EAAQA,SACpB/3C,YAAa,SACbC,WAAY43C,UCNDG,GAaX5hE,YACIsgC,EAAkBuhC,EAClB3L,EAAmC4L,EACnCtzB,EAAkBuzB,GAftB7hE,KAAAiH,cAAgB,CAAC,KACjBjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,GACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAIlD9F,KAAImB,MAAG,EAML,MAAMiM,EAAwB,IAAIvI,MAAM+8D,EAAqB//D,QAC7D,IAAK,IAAIiD,EAAI,EAAGA,EAAIsI,EAAYvL,OAAQiD,IACtCsI,EAAYtI,GAAK88D,EAAqBtzB,EAAOxpC,IAE/C9E,KAAKoN,YAAcA,EACnBpN,KAAKsuC,OAASA,EACdtuC,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKogC,OAASA,EACdpgC,KAAK2hE,aAAeA,EACpB3hE,KAAKyH,UAAY,0BACbL,EACIw6D,EAAqB//D,kCACzBuF,EAAkBy6D,OACtB7L,EAAStxD,KAAI,CAACoD,EAAGhD,KACf9E,KAAKyH,UAAY,OAAO3C,gBAAgB,IAE1C9E,KAAK6L,UAAY,kBAAkByiC,GACpC,CAED1nC,cACE,MAAMP,EAAQe,EAAkBpH,KAAKoN,YAAYvL,QAC3C2sC,EAAWC,GAAkBzuC,KAAKsuC,QAcxC,MAZiB,WACb3nC,EAA0B3G,KAAK2hE,aAAc,qBAC7C36C,EAAK,uJAGqChnB,KAAKoN,YAAYvL,WAC3DwE,KAASmoC,0HAELyrB,GAAUj6D,KAAKogC,QAAQ,8BAKhC,ECrDI,MAkDM0hC,GAAqC,CAChDt4C,WAAYu4C,EAAcA,eAC1Br4C,YAAa,SACbC,WArD6BV,IAK7B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN8sC,WAACA,EAAUkf,SAAEA,GAAY7sC,EAE/B7e,EAAIA,KAACwC,OACD5F,EAAEzC,MAAM5C,QAAU,GAClB,IAAM,0EAGV,MAAM++B,EAAOkW,EAAWnQ,QAAO,CAACvc,EAAGzW,IAAMyW,EAAIzW,IAEvCquD,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBhgE,QAAQg0D,GACzB,IAAK,IAAIlxD,EAAI,EAAIgyC,EAAWj1C,OAAQiD,EAAIoC,EAAEzC,MAAM5C,SAAUiD,EACxDk9D,EAAiBhgE,KAAK,CAAC,EAAG,IAG5B,MAAM2/D,EAAeK,EAAiBt9D,KAClC,CAACwxD,EAAGpxD,IAAMoxD,EAAE,GAAqBhvD,EAAEzC,MAAMK,GAAKoxD,EAAE,KAC9C+L,EACFx3D,EAAAA,aAAawsC,YAAY0qB,EAAc7qB,EAAYlW,GAAM,GAEvDshC,EAAoCz3D,EAAYA,aAAC0sC,YACnD8qB,EAAoBpgE,OAAQi1C,EAAWj1C,QAAQ,GAE7C8gC,EACFl4B,EAAAA,aAAa4sC,oBAAoBsqB,EAAc7qB,EAAYlW,GAAM,GAE/DuhC,EAAsB73D,EAAAA,KAAKsC,eAAe+0D,GAC1Ct8D,EAAU,IAAIq8D,GAChBx6D,EAAEzC,MAAOk9D,EAAcK,EAAkBC,EACzCC,EAAmCC,EAAoBtgE,QACrDynB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM2sD,GACtB,CAAC/8D,KAAM,QAASoQ,KAAM6sD,IAExBH,EAAiBt9D,KACbwxD,GAAK5sC,EAAYtnB,KAAK,CAACkD,KAAM,QAASoQ,KAAM,CAAC4gD,EAAE,GAAIA,EAAE,QACzD,MAAMkM,EAAWl5C,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,GAC3DiG,EACF3F,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGk7D,GAAWl5C,UAASC,MAAO,CAAC1kB,MAAOk+B,KAE5D,OADAzZ,EAAQlX,YAAYowD,EAASnwD,QACtBsd,CAAM,SChDF8yC,GAWXviE,YAAYuI,EAAoBi6D,EAAoB7mD,GAVpDzb,KAAaiH,cAAG,CAAC,QAAS,UAAW,cACrCjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,uCACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EAIPlI,KAAKoN,YAAc/E,EACnBrI,KAAKkF,KAAOuW,EACZzb,KAAKsI,eAAiB8F,EAAmB,CAACk0D,IAC1CtiE,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgB,CAACg6D,GAAatiE,KAAK8F,eAE5D9F,KAAK6L,UAAY,kBAClB,CAEDjF,cAiBE,MAhBiB,SACfogB,EAAK,2cAUHjiB,EACI,oBAAqB,QAAS/E,KAAKkF,2BAK5C,QAGUq9D,GASXziE,YAAYuI,EAAkBm6D,GAR9BxiE,KAAAiH,cAAgB,CAAC,cACjBjH,KAAWoN,YAAa,GAIxBpN,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EAGPlI,KAAKoN,YAAc,CAAC/E,GACpBrI,KAAKsI,eAAiB8F,EAAmBo0D,GACzCxiE,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBk6D,EAAiBxiE,KAAK8F,eAE/C9F,KAAK6L,UAAY,6BAClB,CAEDjF,cASE,MARiB,SACfogB,EAAK,kHAGDjiB,EAAiB,qBAAsB,IAAK,8BAKnD,QAGU09D,GAWX3iE,YAAYuI,EAAoBoT,GAVhCzb,KAAAiH,cAAgB,CAAC,aAAc,sBAC/BjH,KAAWoN,YAAa,GAIxBpN,KAAQyH,SAAG,oBACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAILnB,KAAKoN,YAAc/E,EACnBrI,KAAKkF,KAAOuW,EACZzb,KAAKsI,eAAiB8F,EAAmB/F,GACzCrI,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgBD,EAAUrI,KAAK8F,eAExD9F,KAAK6L,UAAY,mBAClB,CAEDjF,cAeE,MAdiB,SACfogB,EAAK,mMAMW,YAAdhnB,KAAKkF,KACD,2DACA,yFAMT,EC7Ga,SAAAw9D,GACZvmD,EAAmB2V,EAAqBqU,EACxCw8B,GAAQ,EAAOz5C,GACjB,MACM05C,EADYt4D,EAAIA,KAACgO,cAAc6D,EAAM1X,OACX0X,EAAM1X,MAAM,GACtC4B,EAAQ8V,EAAM9V,MAIdggC,EAAa/7B,EAAIA,KAACgO,cAAcwZ,EAAQrtB,OACxCo+D,EAAc35C,EAAQ3T,SAAS4wB,EAAWl0B,QAG1Cu0B,EADFH,EAAa,EAAIw8B,EAAYx8B,EAAa,GAAK,EAAI,EAGvD,IAAIhhC,EACJ,MAAM+H,EAAc+O,EAAM1X,MAAM8C,QAChC6F,EAAY,GAAKo5B,EAEjB,MAAM87B,EAAaj8B,EAAau8B,EAC1BE,EACF95C,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAO2I,EAAamK,MAAO,EAAGlR,WACzDhB,EAAU,IAAIg9D,GAAwBj1D,EAAak1D,EAAYj8D,GAC/D,IAAIijB,EAAc,CAChB,CAACpkB,KAAM,QAASoQ,KAAM,CAACstD,IAAe,CAAC19D,KAAM,QAASoQ,KAAM,CAACgtD,KAE/D,MAAMS,EAAoB75C,EAAQ1N,iBAC9BnW,EAAS,CAAC8W,EAAO2V,EAASqU,GAAa9/B,EAAOijB,EAC9Cw5C,GAEJ,GAAIH,EACF,OAAOI,EAGT,MAAMC,EACFh6C,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAO,CAAC+hC,GAAajvB,MAAO,EAAGlR,MAAO,WACjEhB,EAAU,IAAIk9D,GAA4B/7B,EAAYL,EAAW1hC,OACjE,MAAMw+D,EAAwB/5C,EAAQ1N,iBAClCnW,EAAS,CAAC8gC,GAAa,QAAS,KAAM68B,GAEpCE,EACFl6C,GAAK,CAACE,UAASC,MAAO,CAAC1kB,MAAO2I,EAAamK,MAAO,EAAGlR,WACzDhB,EAAU,IAAIo9D,GAAyBr1D,EAAa/G,GACpDijB,EAAc,CAAC,CAACpkB,KAAM,QAASoQ,KAAM,CAACstD,KACtC,MAAMO,EAAqBj6C,EAAQ1N,iBAC/BnW,EAAS,CAAC09D,EAAmBE,GAAwB58D,EAAOijB,EAC5D45C,GAIJ,OAFAh6C,EAAQlX,YAAY+wD,EAAkB9wD,QACtCiX,EAAQlX,YAAYixD,EAAsBhxD,QACnCkxD,CACT,CC5CO,MAAMC,GAAwC,CACnD55C,WAAY65C,EAAiBA,kBAC7B35C,YAAa,SACbC,WAZI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB3T,KAACA,EAAIwc,QAAEA,EAAOqU,WAAEA,GAAcn8B,EAEpC,OAAO04D,GAAoBptD,EAAMwc,EAASqU,GAAY,EAAOjd,EAC/D,GCEO,MAAMo6C,GAAuC,CAClD95C,WAAY+5C,EAAgBA,iBAC5B75C,YAAa,SACbC,WAZI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,GAAWD,GACpB3T,KAACA,EAAIwc,QAAEA,EAAOqU,WAAEA,GAAcn8B,EAEpC,OAAO04D,GAAoBptD,EAAMwc,EAASqU,GAAY,EAAMjd,EAC9D,SCTas6C,GAUX1jE,YAAYgoB,EAAkBggB,GAT9B9nC,KAAAiH,cAAgB,CAAC,KAKjBjH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAIL,MAAMiM,EAAwB,IAAIvI,MAAMijB,EAAOjmB,QAC/C,IAAK,IAAIiD,EAAI,EAAGA,EAAIsI,EAAYvL,OAAQiD,IACtCsI,EAAYtI,GAAKgjB,EAAOhjB,GAAKgjC,EAAKhjC,GAEpC9E,KAAKoN,YAAcA,EACnBpN,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK0I,KAAO1I,KAAKoN,YAAYvL,OAC7B7B,KAAK6L,UAAY,MAClB,CAEDjF,cACE,MAAMqvC,EAcV,SAAyBvtC,EAAc+6D,EAAgB,IACrD,GAAI/6D,GAAQ,EACV,MAAMrG,MAAM,iBAAiBqG,0BAE/B,GAAa,IAATA,EACF,MAAO,YAAY+6D,WAGrB,MAAMpU,EAAgB,CAAC,UAAW,UAAW,UAAW,WAClDpZ,EAAe,GACrB,IAAK,IAAInxC,EAAI,EAAGA,EAAI4D,EAAM5D,IACxBmxC,EAAaj0C,KAAK,IAAIqtD,EAAcvqD,QAAQ2+D,WAAuB3+D,OAErE,OAAOmxC,EAAavvC,MACtB,CA5ByB4oD,CAAgBtvD,KAAK0I,KAAM,aAUhD,MARiB,WACbse,EAAK,8IAG4BivB,gCAKtC,EChCG,SAAUytB,GACZj3D,GAEF,MAAMzC,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAAS1c,GAC3BvF,EAACA,GAAK8C,GACN89B,KAACA,GAAQ3e,EAGf,GAAID,EAAQrK,mBAAmB,CAAC3X,KAAmB,WAAZA,EAAEb,OACrCa,EAAEzC,MAAM5C,QAAU,EAAG,CAGvB,MAAMyT,EAAO4T,EAAQ3T,SAASrO,EAAE+K,QAC1BsF,EAAoB,WAAZrQ,EAAEb,MACXiP,EAAsB5Q,KAAIC,GAAK2F,EAAIA,KAAC4O,aAAavU,KAClD2Q,EACEquD,EAAMpiE,EAAAA,OAAO2F,EAAEzC,MAAOyC,EAAEb,MAAOkR,GAC/B4mB,EAASqO,GAAYm3B,EAAK77B,GAChC,OAAO5e,EAAQrQ,eAAeslB,EAAO15B,MAAO05B,EAAO93B,MAAO83B,EAAO9qB,OAClE,CAED,MAAMhO,EAAU,IAAIm+D,GAAYt8D,EAAEzC,MAAOqjC,GAGzC,OAFe5e,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAG1D,CAEO,MAAMu9D,GAA2B,CACtCp6C,WAAYq6C,EAAIA,KAChBn6C,YAAa,SACbC,WAAY+5C,IC8EP,MAAMI,GAAoC,CAC/Ct6C,WAAYu6C,EAAaA,cACzBr6C,YAAa,SACbC,WA3GI,SAAwBV,GAK5B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B+6C,cAACA,EAAaC,aAAEA,EAAY3vC,aAAEA,GAAgBtqB,GAC9CoD,YAACA,GAAe+b,GAEhBiW,UAACA,EAASqD,WAAEA,EAAUpD,UAAEA,EAASz6B,QAAEA,EAAOuyB,WAAEA,GAC9C1sB,EAAAA,aAAam1D,gBAAgBqE,EAAcD,EAAe52D,GAExDs1B,GAAiB,EACvB,GAA2B,WAAvBuhC,EAAa59D,MAAoB,CACnC,MAAMo5B,EAAavW,EAAQlQ,WAA0BgrD,GAC/CE,EAAah7C,EAAQlQ,WAA2BirD,GAChDE,EAAgB75D,OAAK4O,aACvBgQ,EAAQ3T,SAAS+e,EAAariB,QAAQ,IACpCksB,EAAS0N,GACXpM,EAAYykC,EAAY92D,EAAa+pB,EAAYkI,EAAWoD,EAC5DrD,EAAWx6B,EAASu/D,EAAezhC,GACvC,OAAOxZ,EAAQrQ,eAAezL,EAAa+wB,EAAO93B,MAAO83B,EAAO9qB,OACjE,CAED,MAAMsvB,EAAe,CAACxL,EAAakI,EAAWA,GAExC+kC,EAAiBx6C,GAAQ,CAC7B5f,OAAQ,CAAC9C,EAAG88D,GACZ96C,UACAC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYrD,MAExBilC,EAAgBJ,EAAax/D,MAAM5C,OACrC+nB,GAAQ,CACN5f,OAAQ,CAAC9C,EAAG+8D,GACZ/6C,UACAC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYpD,MAE9BtS,GAAS,CAAC/iB,OAAQ,CAAC9C,EAAG+8D,GAAe/6C,YAEnChkB,EAAOm/D,EAAch+D,MACrBi4B,EACFpV,EAAQrQ,eAAe,GAAI3T,EAAMoF,EAAIA,KAACuzB,oBAAoB,EAAG34B,IAG3Di/D,EAAgBv6C,GAAQ,CAC5B5f,OAAQ,CAAC9C,EAAGotB,GACZpL,UACAC,MAAO,CAAC1kB,MAAOI,MAAM89B,EAAa9gC,QAAQmnB,KAAK,MAE3Cs7C,EACFZ,GAAK,CAAC15D,OAAQ,CAAC9C,EAAGi9D,GAAgBj7C,UAASC,MAAO,CAAC2e,KAAMnF,KAGvDrZ,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC8pB,IACvB,CAACl6B,KAAM,QAASoQ,KAAM1Q,GACtB,CAACM,KAAM,QAASoQ,KAAM,CAJXhL,EAAAA,KAAKgO,cAAc,CAACmqB,EAAYpD,OAO7C,OAAQoD,GACN,KAAK,EACH,MACF,KAAK,EACO,CACR,MAAMp9B,EAAU,IAAI05D,GAChB,CAACt8B,EAAYpD,GAAYD,EAAWglC,EAAe3/D,MAAM5C,OACzDwiE,EAAc5/D,MAAM5C,OAAQ+C,EAAS+9B,EAAcz9B,EACnDw9B,GACJxZ,EAAQ1N,iBACJnW,EAAS,CAACg/D,EAAeD,GAAiBl/D,EAAMokB,EAChDg7C,EACL,CACD,MACF,QACY,CAER,MAAMj/D,EAAU,IAAI05D,GAChB,CAACt8B,EAAYpD,GAAYD,EAAWglC,EAAe3/D,MAAM5C,OACzDy8B,EAAK75B,MAAM5C,OAAQ+C,EAAS+9B,EAAcz9B,EAAMw9B,GACpDxZ,EAAQ1N,iBACJnW,EAAS,CAACi5B,EAAM8lC,GAAiBl/D,EAAMokB,EAAag7C,EACzD,CACD,CAEE,MAAMj/D,EAAU,IAAI05D,GAChB,CAACt8B,EAAYpD,GAAYD,EAAWglC,EAAe3/D,MAAM5C,OACzDwiE,EAAc5/D,MAAM5C,OAAQ+C,EAAS+9B,EAAcz9B,GACvDgkB,EAAQ1N,iBACJnW,EAAS,CAACg/D,EAAeD,GAAiBl/D,EAAMokB,EAChDg7C,EACL,EAGL,MAAMC,EAAc36C,GAChB,CAAC5f,OAAQ,CAAC9C,EAAGo9D,GAAep7C,UAASC,MAAO,CAAC1kB,MAAO2I,KAOxD,OALA8b,EAAQlX,YAAYoyD,EAAenyD,QACnCiX,EAAQlX,YAAYqyD,EAAcpyD,QAClCiX,EAAQlX,YAAYmyD,EAAclyD,QAClCiX,EAAQlX,YAAYssB,EAAKrsB,QACzBiX,EAAQlX,YAAYsyD,EAAaryD,QAC1BsyD,CACT,GCnFO,MAAMC,GAA6B,CACxCh7C,WAAYi7C,EAAMA,OAClB/6C,YAAa,SACbC,WA3BI,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN06D,gBAACA,EAAe97B,KAAEA,GAAQzf,EAE1B0f,EAAQv+B,EAAIA,KAACw+B,eAAeF,EAAM1hC,EAAEzC,OAAO,GAC3CkgE,EAAal6D,EAAAA,aAAam6D,iBAAiB19D,EAAGw9D,EAAiB77B,GAE/DH,EAAQxhC,EAAEzC,MAAM5C,OAChBkhC,EAAQ,IAAIl+B,MAAM6jC,GAAO1f,KAAK,GAC9B7nB,EAAO+F,EAAEzC,MAAM8C,QAErB,OAAOo9D,EAAWjgE,KAAIsG,IACpB,MAAMq0B,EAAY,IAAIl+B,GACtBk+B,EAAUwJ,GAAS79B,EACnB,MAAM65D,EACFt9D,GAAM,CAACyC,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC4Z,QAAO5hC,KAAMk+B,KAEtD,OADA0D,EAAM8F,IAAU79B,EACT65D,CAAM,GAEjB,GCvBa7oD,GAAOyR,GAAgB,CAACC,OAAQ5L,EAAY6C,OAE5CmgD,GAA2B,CACtCt7C,WAAYu7C,EAAIA,KAChBr7C,YAAa,SACbC,WAAY3N,ICJDgpD,GAA6B,CACxCx7C,WAAYy7C,EAAMA,OAClBv7C,YAAa,SACbC,WAAY,EAAE3f,SAAQkf,cACpB,MAAMhiB,EAACA,GAAK8C,EACNokD,EAAgBllC,EAChB7jB,EAAU,IAAImoB,GAAetmB,EAAEzC,MAAOqd,EAAY8C,QACxD,OAAOwpC,EAAc5yC,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAM,GCPnD6+D,GAAoBl3C,GAAiB,CAChDN,OAAQ1O,EAAa4C,qBAGVujD,GAAwC,CACnD37C,WAAY47C,EAAiBA,kBAC7B17C,YAAa,SACbC,WAAYu7C,ICKP,MAAMG,GAA2B,CACtC77C,WAAY87C,EAAIA,KAChB57C,YAAa,SACbC,WAdI,UACF3f,OAACA,EAAMmf,MAAEA,EAAKD,QAAEA,IAGlB,MAAMhiB,EAACA,GAAK8C,EACN3E,EACF,IAAImoB,GAAetmB,EAAEzC,MAAOqd,EAAY+C,KAAM,oBAC5CyE,EAAc,CAAC,CAACpkB,KAAM,UAAWoQ,KAAM,CAAC6T,EAAMs+B,SACpD,OAAOv+B,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,EACzD,SCZai8C,GAYXzlE,YAAYk2C,GAXZh2C,KAAAiH,cAAgB,CAAC,KAOjBjH,KAAammB,cAAG,EAChBnmB,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc4oC,EACnBh2C,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,cAC5C,CAAC9F,KAAKmmB,cAAe,EAAG,IAE5B,MAAM9f,EAAQe,EAAkBpH,KAAKoN,YAAYvL,QACjD7B,KAAKyH,SAAW,WAAWpB,iBAAqBA,MAChDrG,KAAK6L,UAAY,cAClB,CAEDjF,cAEE,IAAI4+D,EAAY,GAChB,GAAa,IAFAxlE,KAAKoN,YAAYvL,OAG5B2jE,EAAY,iDACP,CACL,IAAIC,EAAa,EACjBD,EACIxlE,KAAKoN,YACA1I,KAAI,CAACoD,EAAGhD,KACP2gE,IACmC,IAA5BzlE,KAAKoN,YAAYvL,OACpB,6BAA6BiD,uBAAuBA,KACpD,UAAU2gE,EAAa,yBACnB3gE,uBAAuBA,QAEhC4B,KAAK,IACf,CAUD,MARiB,YACZsgB,EAAK,kJAG4Bw+C,mCAKvC,EC0BI,MAAME,GAAmC,CAC9Cl8C,WAAYm8C,EAAYA,aACxBj8C,YAAa,SACbC,WA3EI,SAAuBV,GAK3B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACN+4B,MACJA,EAAKhvB,IACLA,EAAGnP,QACHA,EAAOghE,UACPA,EAASC,QACTA,EAAOC,aACPA,EAAYC,YACZA,EAAWC,eACXA,GACE78C,GAEE88C,iBACJA,EAAgBC,WAChBA,EAAUC,WACVA,EAAUC,UACVA,EAASC,cACTA,EACAtjC,MAAOsT,EACPtiC,IAAKuyD,EACL1hE,QAAS2hE,GAEPtjC,EAAUA,WAACujC,UACPt/D,EAAEzC,MAAOs+B,EAAOhvB,EAAKnP,EAASghE,EAAWC,EAASC,EAClDC,EAAaC,GAErB,IAAIz2C,EAEJ,GAAI42C,EAEF52C,EAAS3F,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC1kB,MAAOyhE,UAClD,GAAIE,GAAaC,EAAe,CAErC/7D,EAAAA,KAAKwC,OACD5F,EAAEzC,MAAM5C,QAAU,GAClB,IAAM,yCAAyCqF,EAAEzC,MAAM5C,WAE3D,MAAMV,EAAO8hC,EAAAA,WAAWiY,gBAAgB7E,EAAQiwB,EAAMC,GAEhD3uB,EAASrwC,GAAM,CAACyC,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC4Z,MAAOsT,EAAQl1C,UACnEouB,EACI3F,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG0wC,GAAS1uB,UAASC,MAAO,CAAC1kB,MAAOyhE,KAC1Dh9C,EAAQlX,YAAY4lC,EAAO3lC,OAC5B,KAAM,CAEL,GAD2BiX,EAAQrK,mBAAmB,CAAC3X,IAC/B,CACtB,MAAMmM,EAAS6V,EAAQ3T,SAASrO,EAAE+K,QAC5B6rB,EAAOv8B,EAAAA,OAAO2F,EAAEzC,MAAOyC,EAAEb,MAAOgN,GAChCyvB,EACFqJ,GAAoB85B,EAAkBnoC,EAAMyoC,EAAUlwB,GAC1D9mB,EAASrG,EAAQrQ,eAAeqtD,EAAYh/D,EAAEb,MAAOy8B,EAAazvB,OACnE,KAAM,CACL,MAAMhO,EAAU,IAAIkgE,GAAoBU,GAClC38C,EACF,CAAC,CAACpkB,KAAM,QAASoQ,KAAM+gC,GAAS,CAACnxC,KAAM,QAASoQ,KAAMixD,IACpDzjC,EACF5Z,EAAQ1N,iBAAiBnW,EAAS,CAAC6B,GAAIA,EAAEb,MAAOijB,GACpDiG,EAAS3F,GACL,CAAC5f,OAAQ,CAAC9C,EAAG47B,GAAe5Z,UAASC,MAAO,CAAC1kB,MAAOyhE,KACxDh9C,EAAQlX,YAAY8wB,EAAa7wB,OAClC,CACF,CAED,OAAOsd,CACT,GC/CO,MAAMk3C,GAAmC,CAC9Cj9C,WAAYk9C,EAAYA,aACxBh9C,YAAa,SACbC,WA9BI,SAAuBV,GAK3B,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3BmR,UACJA,EAASC,YACTA,EAAWC,QACXA,EAAOC,SACPA,EAAQC,SACRA,EAAQC,uBACRA,GACEtR,GACE7T,KAACA,EAAI6xB,WAAEA,GAAcn9B,EACrB28D,EAAQz9C,EAAQ3T,SAASD,EAAKrD,QAC9B20D,EAAc19C,EAAQ3T,SAAS4xB,EAAWl1B,SAEzCoqB,EAAQF,GAAgBkQ,GAC3Bs6B,EAAOC,EAAaxsC,EAAWC,EAAaC,EAASC,EAAUC,EAC/DC,GACJ,MAAO,CACLvR,EAAQrQ,eAAe,CAACwjB,EAAOx6B,QAAS,SAAUw6B,GAClDnT,EAAQrQ,eAAesuB,EAAW1iC,MAAO,QAAS03B,GAEtD,GCxBa0qC,GAAM74C,GACf,CAACN,OAAQ1O,EAAa6C,IAAK8L,cAAem5C,GAAQ74C,iBAAiB,IAE1D84C,GAA0B,CACrCv9C,WAAYw9C,EAAGA,IACft9C,YAAa,SACbC,WAAYk9C,ICPDI,GAAMx5C,GAAgB,CAACC,OAAQ5L,EAAYgD,MAE3CoiD,GAA0B,CACrC19C,WAAY29C,EAAGA,IACfz9C,YAAa,SACbC,WAAYs9C,ICNDG,GAAO35C,GAAgB,CAACC,OAAQ5L,EAAYiD,OAE5CsiD,GAA2B,CACtC79C,WAAY89C,EAAIA,KAChB59C,YAAa,SACbC,WAAYy9C,ICuDP,MAAMG,GAA0C,CACrD/9C,WAAYg+C,EAAmBA,oBAC/B99C,YAAa,SACbC,WA3DI,SAA8BV,GAKlC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bra,OAACA,EAAMkjB,QAAEA,EAAO0Q,QAAEA,GAAWx4B,GAG7Bo1B,UAACA,EAASqD,WAAEA,EAAUpD,UAAEA,EAASz6B,QAAEA,EAAOuyB,WAAEA,GAC9C1sB,EAAYA,aAACm1D,gBAAgBp9B,EAAS1Q,EAASljB,EAAOnK,OAEpDk+B,EAAe,CAACxL,EAAakI,EAAWA,GAE9C,GAAmB,IAAflI,EACF,OAAOjO,EAAQrQ,eAAejK,EAAOnK,MAAOqtB,EAAQzrB,OAGtD,MAAMipC,EAAY,GAEZ2f,EAAiBrlC,GACnB,CAAC5f,OAAQ,CAAC9C,EAAG4qB,GAAU5I,UAASC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYrD,MAChEkQ,EAAUttC,KAAKitD,GACf,MAAMC,EAAWtlC,GACb,CAAC5f,OAAQ,CAAC9C,EAAGs7B,GAAUtZ,UAASC,MAAO,CAAC1kB,MAAO,CAACg+B,EAAYpD,MAChEiQ,EAAUttC,KAAKktD,GACf,MAAMuY,EACF79C,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG0H,GAASsa,UAASC,MAAO,CAAC1kB,MAAOk+B,KAC1D2M,EAAUttC,KAAKylE,GACf,MAAMliE,EAASm+D,GAAK,CAClB15D,OAAQ,CAAC9C,EAAGugE,GACZv+C,UACAC,MAAO,CAAC2e,KAAMjjC,MAAM89B,EAAa9gC,QAAQmnB,KAAK,MAE1C3jB,EAAU,IAAI05D,GAChB,CAACt8B,EAAYpD,GAAYD,EAAW6vB,EAAexqD,MAAM5C,OACzDqtD,EAASzqD,MAAM5C,OAAQ+C,EAAS+9B,EAAc/zB,EAAOvI,OAAO,GAE1DijB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAAC8pB,IACvB,CAACl6B,KAAM,QAASoQ,KAAM1Q,GACtB,CAACM,KAAM,QAASoQ,KAAM,CAJXhL,EAAAA,KAAKgO,cAAc,CAACmqB,EAAYpD,OAMvC11B,EAAMuf,EAAQ1N,iBAChBnW,EAAS,CAAC6pD,EAAUD,GAAiBwY,EAAcphE,MAAOijB,EAC1D/jB,GACJ+pC,EAAUttC,KAAK2H,GAEf,MAAMqtC,EACFptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGyC,GAAMuf,UAASC,MAAO,CAAC1kB,MAAOmK,EAAOnK,SAI9D,OAFA6qC,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UAEtC+kC,CACT,SCjDa0wB,GAUX5nE,YAAY2E,GALZzE,KAAAiH,cAAgB,CAAC,IAAK,WAEtBjH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GACnD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAKyH,SAAW,sFAEhBzH,KAAK6L,UAAY,MAClB,CAEDjF,cAqEE,MApEiB,aACXogB,EAAK,g+EAoEZ,QAGU2gD,GAUX7nE,YAAY2E,GALZzE,KAAAiH,cAAgB,CAAC,IAAK,WAEtBjH,KAAa8F,cAA6B,CAAC,IAAK,EAAG,GACnD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc3I,EACnBzE,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAKhD9F,KAAKyH,SAAW,6CAChBzH,KAAK6L,UAAY,OAClB,CAEDjF,cA6DE,MA5DiB,aACXogB,EAAK,63EA4DZ,ECrLH,SAAS4gD,GACL1+C,EAAwBtQ,GACP,OAAfA,GACFsQ,EAAQlX,YAAY4G,EAAW3G,OAEnC,CAEA,SAAS41D,GAAc5nC,GACrB,IAAI6nC,EAAO,EACX,KAAOA,EAAO7nC,GACZ6nC,GAAQ,EAEV,OAAOA,CACT,CAuIO,MAAMC,GAA2B,CACtCv+C,WAAYw+C,EAAIA,KAChBt+C,YAAa,SACbC,WAtII,SACFV,GAEF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,GAAK8C,GACNsN,EAACA,EAACywB,OAAEA,GAAS5e,EAEbiX,EAASl5B,EAAEzC,MACXujC,EAAU5H,EAAOA,EAAOv+B,OAAS,GAEvC,GAAIqnB,EAAQrK,mBAAmB,CAAC3X,IAAK,CACnC,MAAMq2B,EAAQrU,EAAQ3T,SAASrO,EAAE+K,SAC1Bi2B,EAAaC,GAChBuE,GAAYnP,EAAO6C,EAAQl5B,EAAEb,MAA0BiR,EAAGywB,GAE9D,MAAO,CACL7e,EAAQrQ,eACJqvB,EAAYzjC,MAAOyjC,EAAY7hC,MAAO6hC,EAAY70B,QACtD6V,EAAQrQ,eACJsvB,EAAe1jC,MAAO0jC,EAAe9hC,MAAO8hC,EAAe90B,QAElE,CAED,GAAU,IAANiE,EAEF,OADA8oB,EAAOA,EAAOv+B,OAAS,GAAK,EACrB,CACLqnB,EAAQrQ,eAAeunB,EAAQl5B,EAAEb,MAAO,IACxC6iB,EAAQrQ,eAAeunB,EAAQ,QAAS,KAI5C,GAAgB,IAAZ4H,EACF,MAAO,CACL9gC,EAAG8hB,GAAK,CAACG,MAAO,CAAC1kB,MAAO27B,EAAQ/5B,MAAO,QAASkR,MAAO,GAAI2R,aAK/D,MACM+e,EADQ39B,EAAAA,KAAKgO,cAAc8nB,GACX4H,EAChBigC,EAAMr+C,GAAQ,CAAC5f,OAAQ,CAAC9C,KAAIiiB,MAAO,CAAC1kB,MAAO,CAACwjC,EAAOD,IAAW9e,YAE9Dg/C,EAAQL,GAAcvwD,GACtB6wD,EAAcN,GAAc7/B,GAMlC,IAAIlW,EAAsB,KAK1B,MAAMs2C,EAAY,IAAkB,OAAZt2C,EAAmB,CAACm2C,EAAKA,GAAO,CAACA,EAAKn2C,GAExDu2C,EAAU,CAACC,EAAaC,EAAa9jE,KACzC,MAAMuF,EAASo+D,IACT/iE,EAAU,IAAIqiE,GAAYjjE,GAE1B+jE,EAAkB,CACpB,CAACtjE,KAAM,QAASoQ,KAAM,CAAC0yB,IACvB,CAAC9iC,KAAM,QAASoQ,KAAM,CAHI,OAAZwc,EAAmB,EAAI,IAIrC,CAAC5sB,KAAM,UAAWoQ,KAAM,CAAC/U,OAAOwwC,oBAChC,CAAC7rC,KAAM,QAASoQ,KAAM,CAACgzD,IACvB,CAACpjE,KAAM,QAASoQ,KAAM,CAACizD,KAErBE,EAAc32C,EACpBA,EAAU5I,EAAQ1N,iBACdnW,EAAS2E,EAAQ,QAASw+D,GAC9BZ,GAAoC1+C,EAASu/C,EAAY,EAI3D,IAAK,IAAIC,EAAM,EAAGA,EAAMR,EAAOQ,GAAO,EAAG,CACvC,MAAMJ,EAAY,EAANI,EACZ,IAAK,IAAIH,EAAMG,EAAKH,GAAO,EAAGA,GAAO,EACnCF,EAAQC,EAAKC,EAAK,CAACtgC,EAAOkgC,GAE7B,CAGD,IAAK,IAAItY,EAAcsY,EAAatY,EAAcqY,EAAOrY,GAAe,EAAG,CACzE,MAAM7lD,EAASo+D,IACTO,EAAe,IAAIhB,GAAa,CAAC1/B,EAAO4nB,EAAc,IAEtD+Y,EAAmB,CACrB,CAAC1jE,KAAM,QAASoQ,KAAM,CAAC0yB,IACvB,CAAC9iC,KAAM,QAASoQ,KAAM,CAHI,OAAZwc,EAAmB,EAAI,IAIrC,CAAC5sB,KAAM,QAASoQ,KAAM,CAAC4yD,KAErBO,EAAc32C,EACpBA,EAAU5I,EAAQ1N,iBACdmtD,EAAc3+D,EAAQ,QAAS4+D,GACnChB,GAAoC1+C,EAASu/C,GAG7C,MAAMC,EAAMR,EAAQ,EACdI,EAAY,EAANI,EACZ,IAAK,IAAIH,EAAMG,EAAKH,GAAO,EAAGA,GAAO,EACnCF,EAAQC,EAAKC,EAAKz2C,EAAQrtB,MAE7B,CAGD,IAAIgkE,EAAc32C,EAClBA,EAAUvqB,GACN,CAACyC,OAAQ,CAAC9C,EAAG4qB,GAAU5I,UAASC,MAAO,CAAC4Z,MAAO,EAAG5hC,KAAM,CAAC8mC,EAAO3wB,MACpEswD,GAAoC1+C,EAASu/C,GAG7C,IAAIp1D,EAASk8C,GACT,CAACvlD,OAAQ,CAAC9C,EAAG+gE,EAAKn2C,WAAU5I,UAASC,MAAO,CAACyf,KAAM,EAAG4mB,UAAW,KACrEoY,GAAoC1+C,EAAS++C,GAI7C,MAAM94C,EAAWiR,EAAO74B,MAAM,GAAI,GAClC4nB,EAASntB,KAAKsV,GAEdmxD,EAAc32C,EACdA,EAAUlI,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG4qB,GAAU3I,MAAO,CAAC1kB,MAAO0qB,GAAWjG,YACnE0+C,GAAoC1+C,EAASu/C,GAE7C,MAAMI,EAAax1D,EAInB,OAHAA,EAASuW,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGmM,GAAS8V,MAAO,CAAC1kB,MAAO0qB,GAAWjG,YACjE0+C,GAAoC1+C,EAAS2/C,GAEtC,CAACx1D,EAAQye,EAClB,SCzJag3C,GAUXhpE,YAAYuI,GATZrI,KAAAiH,cAAgB,CAAC,QAAS,cAE1BjH,KAAQyH,SAAG,gEAIXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAImB,MAAG,EAGLnB,KAAKoN,YAAc/E,EACnBrI,KAAKsI,eAAiB8F,EAAmBpO,KAAKoN,aAC9CpN,KAAK+M,SAAWI,EACZnN,KAAKsI,eAAgBtI,KAAKoN,YAAapN,KAAK8F,eAChD9F,KAAK6L,UAAY,WAClB,CAEDjF,cAsHE,MArHiB,w5EAgETogB,EAAK,u2EAsDd,EC3FI,MAAM+hD,GAAgC,CAC3Cv/C,WAAYw/C,EAASA,UACrBt/C,YAAa,SACbC,WA/CI,SAAoBV,GAKxB,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3Bu5B,MAACA,EAAKymB,WAAEA,GAAcj/D,GACtBk/D,cAACA,EAAaC,SAAEA,EAAQtL,UAAEA,EAASzwD,YAAEA,GAAe+b,GAEnD8e,EAAOmhC,EAAaC,EAAYzhB,GAAepF,EAAM/9C,OACrDgxC,EAAWC,GACC,MAAftoC,EAAsBA,EAAc,CAACg8D,EAAaC,GAKhDhkE,EAAU,IAAIyjE,GAHhB,CAAC7gC,EAAOwN,EAAWC,EAClBkS,IAGC0hB,EAAwC,YAAlBJ,EAA8B,EAAI,EAC9D,IAAIK,EACJ,OAAQJ,GACN,IAAK,WAYL,QACEI,EAAa,EACb,MAXF,IAAK,UACHA,EAAa,EACb,MACF,IAAK,OACHA,EAAa,EACb,MACF,IAAK,UACHA,EAAa,EAMjB,MAAMjgD,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAACg0D,IACvB,CAACpkE,KAAM,QAASoQ,KAAM,CAACi0D,IAAc,CAACrkE,KAAM,UAAWoQ,KAAM,CAACuoD,KAEhE,OAAO30C,EAAQ1N,iBACXnW,EAAS,CAACm9C,EAAOymB,GAAa,UAAW3/C,EAC/C,GCIO,MAAMkgD,GAA6B,CACxChgD,WAAYigD,EAAMA,OAClB//C,YAAa,SACbC,WA/CI,SACFV,GAGF,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B1R,MAACA,GAASvN,EAChB,IAAI4+B,KAACA,GAAQzf,EAETyf,EAAO,IACTA,GAAQrxB,EAAM9S,MAAM5C,QAGtB,MAAMqF,EAAIqQ,EACJmxB,EAAQxhC,EAAEzC,MAAM5C,OAEhBo+B,EAAM1oB,EAAM9S,MAAMmkC,GAClBvgC,EAAqB,IAAIxD,MAAM6jC,EAAQ,GAC7C,IAAI7B,EAAW,EACf,IAAK,IAAI/hC,EAAI,EAAGA,EAAI4jC,EAAO5jC,IACrBA,IAAM8jC,IACRvgC,EAASw+B,KAAc3/B,EAAEzC,MAAMK,IAInC,MAAMwqC,EAAY,GAEZvM,EAAQ,IAAIl+B,MAAM6jC,GAAO1f,KAAK,GAC9B7nB,EAAO+F,EAAEzC,MAAM8C,QACrBpG,EAAKynC,GAAQ,EACb,MAAMj/B,EAAoB,IAAI9E,MAAMo7B,GACpC,IAAK,IAAIn7B,EAAI,EAAGA,EAAI6E,EAAI9H,OAAQiD,IAAK,CACnCi+B,EAAM6F,GAAQ9jC,EACd,MAAM8yC,EAASrwC,GAAM,CAACyC,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAAC4Z,QAAO5hC,UACrD61C,EACFptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG0wC,GAAS1uB,UAASC,MAAO,CAAC1kB,MAAO4D,KAC1DsB,EAAI7E,GAAKkyC,EAET1H,EAAUttC,KAAK41C,EAChB,CAGD,OADAtI,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UACtCtI,CACT,SC3Ca+/D,GAWX5pE,YAAYuzC,EAAmBhrC,EAAoBoT,GAKjD,GAfFzb,KAAWoN,YAAa,GAIxBpN,KAAAiH,cAAgB,CAAC,IAAK,cACtBjH,KAAQyH,SAAG,iCACXzH,KAAa8F,cAA6B,CAAC,GAAI,EAAG,GAClD9F,KAAMkI,QAAG,EAIPlI,KAAKoN,YAAc/E,EACnBrI,KAAKsI,eAAiB8F,EAAmBilC,GACzCrzC,KAAK+M,SACDI,EAAgBnN,KAAKsI,eAAgB+qC,EAASrzC,KAAK8F,eACnC,YAAhB2V,GAA6C,UAAhBA,EAC/B,MAAM,IAAIpZ,MAAM,6FACkBoZ,WAEpCzb,KAAKkF,KAAOuW,EACZzb,KAAK6L,UAAY,oBAClB,CAEDjF,cAoBE,MAnBiB,SACfogB,EAAK,kYAYHjiB,EACI,qBAAsB,QAAS/E,KAAKkF,sCAM7C,ECYI,MCsGDykE,GAAgC,CACpC39C,GACAghB,GACAG,GACAG,GACAI,GACAM,GACAoC,GACAE,GACAK,GACAK,GACAI,GACAG,GACAG,GACAG,GACAG,GACAkC,GACAM,GACAW,GACAQ,GACAE,GACAe,GACAoB,GACAK,GACAiB,GACAY,GACAI,GACAhtB,GACAwtB,GACA6B,GACAwC,GACAa,GACAI,GACAG,GACAI,GACAE,GACAG,GACAG,GACAmB,GACAwB,GACAE,GACAG,GACAS,GACAmB,GACAE,GACAP,GACAU,GACAI,GACAK,GACAE,GACAK,GACAiB,GACAqB,GACAE,GACAI,GACAG,GACAE,GACAG,GACAE,GACAW,GACA9hC,GACAkiC,GACAU,GACAR,GACAG,GACAiC,GACAO,GACAE,GACAM,GACAsB,GACAI,GACAI,GACA5jC,GACA8jC,GACAxV,GACA2V,GACAG,GACAE,GACAE,GACAI,GACAI,GACAG,GACAK,GACAH,GACAM,GACAG,GACAG,GACAQ,GACAK,GACAjhB,GACAqhB,GACAE,GACAY,GACAV,GACAK,GACAU,GACAriB,GACAyiB,GACAI,GACAU,GACAG,GACAW,GACAnP,GACAyP,GACAE,GACAW,GACAtf,GACAigB,GACAO,GACAG,GACAO,GACAI,GACAE,GACAE,GACAC,GACAzhB,GACA4hB,GACAG,GACAG,GACAG,GACAxxC,GACA6xC,GACAM,GACAa,GACAG,GACAG,GACAQ,GACAW,GACAG,GACAa,GACAK,GACAS,GACAG,GACAG,GACAE,GACAE,GACAG,GACA3qB,GACA2uB,GACAK,GACAe,GACAtP,GACAqK,GACAM,GACAsB,GACAE,GACAQ,GACAU,GACAM,GACAE,GACAG,GACA4B,GACA3e,GACA8e,GACAG,GACAE,GACA3D,GACAmE,GACAgB,GACAn6B,GACA46B,GDtQoD,CACpDhgD,WAAYogD,EAAkBA,mBAC9BlgD,YAAa,SACbC,WAzDI,SAA6BV,GAKjC,MAAMjf,OAACA,EAAMkf,QAAEA,EAAOC,MAAEA,GAASF,GAC3B/hB,EAACA,EAACi/B,WAAEA,GAAcn8B,GAClB6/D,YAACA,GAAe1gD,EAEhBuf,EAAQxhC,EAAEzC,MAAM5C,OAEhBytC,EAAY,GAElB,IAAI1G,EAAO,EACX,MAAM2a,EAAc94C,EAAAA,aAAailC,mBAAmB,CAAC9G,GAAOF,GAC5D,IAAI8a,EAAYt8C,EACG,MAAfq8C,IACFC,EAAYv8B,GAAU,CAACjd,OAAQ,CAAC9C,KAAIgiB,UAASC,MAAO,CAACsf,KAAM8a,KAC3DjU,EAAUttC,KAAKwhD,GACf5a,EAAOn+B,EAAYA,aAACklC,iBAAiB,EAAGjH,GAAO,IAGjD,MAAMrgC,EAAWoC,EAAYA,aAACklD,aAAazU,gBACvCsI,EAAU/+C,MAAOmkC,EAAMihC,GACrB56B,EAAS3kC,EAAIA,KAACgO,cAAc,CAACkrC,EAAU/+C,MAAMmkC,KAC7CkhC,EACFlgD,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAGs8C,GAAYt6B,UAASC,MAAO,CAAC1kB,MAAO,EAAE,EAAGwqC,MAClEK,EAAUttC,KAAK8nE,GAEf,MAAMzjE,EAAQa,EAAEb,MACV5B,EAAQ,CAACqlE,EAAIrlE,MAAM,GAAIolE,GACvBtkE,EAASyjB,GAAK,CAACE,UAASC,MAAO,CAAC1kB,QAAO8S,MAAO,EAAGlR,WACjDhB,EAAU,IAAIqkE,GAA0BI,EAAIrlE,MAAOA,EAAO4B,GAC1DijB,EAAc,CAClB,CAACpkB,KAAM,QAASoQ,KAAM,CAACu0D,IACvB,CAAC3kE,KAAM,QAASoQ,KAAM,CAAChL,EAAIA,KAACgO,cAAcwxD,EAAIrlE,UAE1CslE,EAAY7gD,EAAQ1N,iBACtBnW,EAAS,CAACykE,EAAK3jC,GAAa9/B,EAAOijB,EAAa/jB,GAE9CyxC,EACFptB,GAAQ,CAAC5f,OAAQ,CAAC9C,EAAG6iE,GAAY7gD,UAASC,MAAO,CAAC1kB,MAAO4D,KAC7DinC,EAAUttC,KAAK+nE,GACf,IAAIx6C,EAASynB,EACb,GAAmB,MAAfuM,EAAqB,CACvBjU,EAAUttC,KAAKg1C,GACf,MAAMvO,EAAOh+B,EAAAA,aAAao5C,uBAAuBN,GACjDh0B,EAAStI,GAAU,CAACjd,OAAQ,CAAC9C,EAAGqoB,GAASrG,UAASC,MAAO,CAACsf,SAC3D,CAGD,OADA6G,EAAU5sC,SAAQqM,GAAKma,EAAQlX,YAAYjD,EAAEkD,UACtCsd,CACT,GC0QEiqC,IAGF,IAAK,MAAMwQ,KAAgBL,GACzBM,EAAcA,eAACD"}